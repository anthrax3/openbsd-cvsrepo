head	1.73;
access;
symbols
	OPENBSD_6_1:1.72.0.4
	OPENBSD_6_1_BASE:1.72
	OPENBSD_6_0:1.66.0.6
	OPENBSD_6_0_BASE:1.66
	OPENBSD_5_9:1.66.0.2
	OPENBSD_5_9_BASE:1.66
	OPENBSD_5_8:1.63.0.4
	OPENBSD_5_8_BASE:1.63
	OPENBSD_5_7:1.58.0.2
	OPENBSD_5_7_BASE:1.58
	OPENBSD_5_6:1.16.0.4
	OPENBSD_5_6_BASE:1.16;
locks; strict;
comment	@ * @;


1.73
date	2017.06.22.02.44.37;	author deraadt;	state Exp;
branches;
next	1.72;
commitid	RXe1tjJgGpqrlfaQ;

1.72
date	2017.03.10.11.18.48;	author mpi;	state Exp;
branches;
next	1.71;
commitid	KVR8Na3SYXI1y1RS;

1.71
date	2017.03.10.09.14.06;	author mpi;	state Exp;
branches;
next	1.70;
commitid	3KSzSoIpPvZCUNqm;

1.70
date	2016.11.08.10.31.30;	author mpi;	state Exp;
branches;
next	1.69;
commitid	O7aOV0gp3jDbAW9d;

1.69
date	2016.10.03.14.05.21;	author mpi;	state Exp;
branches;
next	1.68;
commitid	DHyJp6z7eE7WSXfK;

1.68
date	2016.09.21.07.56.22;	author mpi;	state Exp;
branches;
next	1.67;
commitid	RsQESY2RUyY9Zerc;

1.67
date	2016.09.15.02.00.17;	author dlg;	state Exp;
branches;
next	1.66;
commitid	RlO92XR575sygHqm;

1.66
date	2015.12.02.09.23.23;	author mpi;	state Exp;
branches;
next	1.65;
commitid	LYVY8mtQ7Pu08FCI;

1.65
date	2015.11.29.16.30.48;	author kettenis;	state Exp;
branches;
next	1.64;
commitid	glp86s0S4SjqIRKu;

1.64
date	2015.11.02.14.53.10;	author mpi;	state Exp;
branches;
next	1.63;
commitid	y9v7kujtiGDwaQG2;

1.63
date	2015.07.12.12.54.31;	author mpi;	state Exp;
branches;
next	1.62;
commitid	ud5PSreWa5E9hgAo;

1.62
date	2015.06.29.18.33.23;	author mpi;	state Exp;
branches;
next	1.61;
commitid	rZBtJsDrgRV6uKS2;

1.61
date	2015.06.22.10.29.18;	author mpi;	state Exp;
branches;
next	1.60;
commitid	rkuRtn1rvEZDAwYu;

1.60
date	2015.05.27.11.13.34;	author mikeb;	state Exp;
branches;
next	1.59;
commitid	cExdKRzP3JSYj10M;

1.59
date	2015.04.19.11.12.58;	author mpi;	state Exp;
branches;
next	1.58;
commitid	bOxFZfTbOqtbtnl1;

1.58
date	2015.01.21.14.02.33;	author mpi;	state Exp;
branches;
next	1.57;
commitid	55XuT9r6qfoFmjn5;

1.57
date	2015.01.18.20.35.11;	author mpi;	state Exp;
branches;
next	1.56;
commitid	ov3LUoHeJLH18IpP;

1.56
date	2015.01.18.14.49.04;	author mpi;	state Exp;
branches;
next	1.55;
commitid	OXjGuLHACVXicVJA;

1.55
date	2015.01.18.11.54.02;	author mpi;	state Exp;
branches;
next	1.54;
commitid	imkPnwYlZMsIkL0E;

1.54
date	2015.01.17.18.37.12;	author mpi;	state Exp;
branches;
next	1.53;
commitid	at0bSRcpIQg0chBc;

1.53
date	2015.01.09.20.17.05;	author kettenis;	state Exp;
branches;
next	1.52;
commitid	D8Gn2WebStvUb2ES;

1.52
date	2015.01.05.12.38.16;	author mpi;	state Exp;
branches;
next	1.51;
commitid	G1ag9HUzDkn2qlSO;

1.51
date	2015.01.04.20.10.08;	author mpi;	state Exp;
branches;
next	1.50;
commitid	CYW9a2ehGGhpnm8S;

1.50
date	2015.01.02.18.06.25;	author mpi;	state Exp;
branches;
next	1.49;
commitid	BZFmR5DveboP8x7D;

1.49
date	2014.12.21.11.46.53;	author mpi;	state Exp;
branches;
next	1.48;
commitid	vBzHOg4AhSn2PfNi;

1.48
date	2014.12.21.11.20.24;	author mpi;	state Exp;
branches;
next	1.47;
commitid	r6k2auWp5OeByV6w;

1.47
date	2014.12.19.22.44.59;	author guenther;	state Exp;
branches;
next	1.46;
commitid	LS2TNeCue5R9L67C;

1.46
date	2014.12.15.17.10.44;	author mpi;	state Exp;
branches;
next	1.45;
commitid	HisRLxB0I1PGsCpI;

1.45
date	2014.12.08.13.32.34;	author mpi;	state Exp;
branches;
next	1.44;
commitid	rrWK3WQjBbK7mVwI;

1.44
date	2014.11.24.13.02.15;	author mpi;	state Exp;
branches;
next	1.43;
commitid	dzBJ5EWCmvKkfOnI;

1.43
date	2014.11.24.12.55.16;	author mpi;	state Exp;
branches;
next	1.42;
commitid	hwP2DYfV9JqhKA5v;

1.42
date	2014.11.23.10.46.46;	author mpi;	state Exp;
branches;
next	1.41;
commitid	ugddsit23X6cDlNM;

1.41
date	2014.11.16.18.31.07;	author mpi;	state Exp;
branches;
next	1.40;
commitid	81vrSMwmRt4rwATs;

1.40
date	2014.11.11.12.10.44;	author mpi;	state Exp;
branches;
next	1.39;
commitid	Q6RCdD3YraQKbDVp;

1.39
date	2014.11.10.14.29.49;	author mpi;	state Exp;
branches;
next	1.38;
commitid	WaEG8bRHL2I31cIU;

1.38
date	2014.11.10.14.16.13;	author mpi;	state Exp;
branches;
next	1.37;
commitid	xxRIsGrX40leoAgv;

1.37
date	2014.11.09.14.03.04;	author mpi;	state Exp;
branches;
next	1.36;
commitid	TZSDWnxT9xelT4Wb;

1.36
date	2014.11.07.16.33.02;	author mpi;	state Exp;
branches;
next	1.35;
commitid	gFej2GiGRstIVFLr;

1.35
date	2014.11.07.14.06.43;	author mpi;	state Exp;
branches;
next	1.34;
commitid	YPq2TTGj1rS4RAj1;

1.34
date	2014.11.01.18.21.07;	author mpi;	state Exp;
branches;
next	1.33;
commitid	kINPP9qCtTd5VjqO;

1.33
date	2014.10.31.23.11.48;	author mpi;	state Exp;
branches;
next	1.32;
commitid	GQq4vQIovS6ARSw8;

1.32
date	2014.10.31.16.39.34;	author mpi;	state Exp;
branches;
next	1.31;
commitid	DGM1XT03OC39Nv8P;

1.31
date	2014.10.30.18.29.59;	author mpi;	state Exp;
branches;
next	1.30;
commitid	V7ie8mWCSuvMR5O5;

1.30
date	2014.10.30.18.25.08;	author mpi;	state Exp;
branches;
next	1.29;
commitid	YqEjpcfinbNspaim;

1.29
date	2014.10.30.18.08.24;	author mpi;	state Exp;
branches;
next	1.28;
commitid	8hesrfMCDyPQaKfX;

1.28
date	2014.10.05.13.32.14;	author mpi;	state Exp;
branches;
next	1.27;
commitid	gjlAIRq5IwPdCePN;

1.27
date	2014.10.05.12.46.58;	author mpi;	state Exp;
branches;
next	1.26;
commitid	tiGcpXrj0wYdqFfM;

1.26
date	2014.10.04.13.07.22;	author mpi;	state Exp;
branches;
next	1.25;
commitid	EmNkpTd0yCJsdQYH;

1.25
date	2014.08.30.09.32.19;	author mpi;	state Exp;
branches;
next	1.24;
commitid	qNWvh6PgBiq7X4Wg;

1.24
date	2014.08.10.11.21.49;	author mpi;	state Exp;
branches;
next	1.23;
commitid	BvOEdxFK4O9MRPkL;

1.23
date	2014.08.10.11.18.57;	author mpi;	state Exp;
branches;
next	1.22;
commitid	soKLg6qedOsGZg3L;

1.22
date	2014.08.10.11.00.36;	author mpi;	state Exp;
branches;
next	1.21;
commitid	EhRr39ksGEEyKpMd;

1.21
date	2014.08.09.10.32.36;	author mpi;	state Exp;
branches;
next	1.20;
commitid	o6Nz7xRcILzVRm71;

1.20
date	2014.08.08.14.34.11;	author mpi;	state Exp;
branches;
next	1.19;
commitid	UhPCPSu2OnFfwvxf;

1.19
date	2014.08.08.14.28.02;	author mpi;	state Exp;
branches;
next	1.18;
commitid	YIulA8W9slwhmWsf;

1.18
date	2014.08.08.14.22.45;	author mpi;	state Exp;
branches;
next	1.17;
commitid	VkQKlEPJyYImrklX;

1.17
date	2014.08.08.14.17.52;	author mpi;	state Exp;
branches;
next	1.16;
commitid	1mScZBN7mqHh8HnC;

1.16
date	2014.07.11.16.38.58;	author pirofti;	state Exp;
branches;
next	1.15;
commitid	c2lt0lrdrQwPcCI6;

1.15
date	2014.07.10.11.47.14;	author mpi;	state Exp;
branches;
next	1.14;
commitid	zDevcULA8IE8Qbas;

1.14
date	2014.07.09.15.54.39;	author mpi;	state Exp;
branches;
next	1.13;
commitid	KsiSRFYFrZoJPKYn;

1.13
date	2014.05.21.12.31.53;	author mpi;	state Exp;
branches;
next	1.12;

1.12
date	2014.05.20.14.46.19;	author mpi;	state Exp;
branches;
next	1.11;

1.11
date	2014.05.09.11.01.06;	author mpi;	state Exp;
branches;
next	1.10;

1.10
date	2014.04.29.12.45.29;	author mpi;	state Exp;
branches;
next	1.9;

1.9
date	2014.04.07.15.34.27;	author mpi;	state Exp;
branches;
next	1.8;

1.8
date	2014.04.03.14.42.15;	author mpi;	state Exp;
branches;
next	1.7;

1.7
date	2014.03.28.16.19.26;	author mpi;	state Exp;
branches;
next	1.6;

1.6
date	2014.03.28.14.14.11;	author mpi;	state Exp;
branches;
next	1.5;

1.5
date	2014.03.25.20.27.37;	author mpi;	state Exp;
branches;
next	1.4;

1.4
date	2014.03.25.17.23.40;	author mpi;	state Exp;
branches;
next	1.3;

1.3
date	2014.03.18.15.47.23;	author mpi;	state Exp;
branches;
next	1.2;

1.2
date	2014.03.12.13.05.02;	author mpi;	state Exp;
branches;
next	1.1;

1.1
date	2014.03.08.14.34.11;	author mpi;	state Exp;
branches;
next	;


desc
@@


1.73
log
@double ;;.  xhci one found by geoffhill
@
text
@/* $OpenBSD: xhci.c,v 1.72 2017/03/10 11:18:48 mpi Exp $ */

/*
 * Copyright (c) 2014-2015 Martin Pieuchot
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/kernel.h>
#include <sys/malloc.h>
#include <sys/device.h>
#include <sys/queue.h>
#include <sys/timeout.h>
#include <sys/pool.h>
#include <sys/endian.h>

#include <machine/bus.h>

#include <dev/usb/usb.h>
#include <dev/usb/usbdi.h>
#include <dev/usb/usbdivar.h>
#include <dev/usb/usb_mem.h>

#include <dev/usb/xhcireg.h>
#include <dev/usb/xhcivar.h>

struct cfdriver xhci_cd = {
	NULL, "xhci", DV_DULL
};

#ifdef XHCI_DEBUG
#define DPRINTF(x)	do { if (xhcidebug) printf x; } while(0)
#define DPRINTFN(n,x)	do { if (xhcidebug>(n)) printf x; } while (0)
int xhcidebug = 3;
#else
#define DPRINTF(x)
#define DPRINTFN(n,x)
#endif

#define DEVNAME(sc)	((sc)->sc_bus.bdev.dv_xname)

#define TRBOFF(r, trb)	((char *)(trb) - (char *)((r)->trbs))
#define DEQPTR(r)	((r).dma.paddr + (sizeof(struct xhci_trb) * (r).index))

struct pool *xhcixfer;

struct xhci_pipe {
	struct usbd_pipe	pipe;

	uint8_t			dci;
	uint8_t			slot;	/* Device slot ID */
	struct xhci_ring	ring;

	/*
	 * XXX used to pass the xfer pointer back to the
	 * interrupt routine, better way?
	 */
	struct usbd_xfer	*pending_xfers[XHCI_MAX_XFER];
	struct usbd_xfer	*aborted_xfer;
	int			 halted;
	size_t			 free_trbs;
};

int	xhci_reset(struct xhci_softc *);
int	xhci_intr1(struct xhci_softc *);
void	xhci_event_dequeue(struct xhci_softc *);
void	xhci_event_xfer(struct xhci_softc *, uint64_t, uint32_t, uint32_t);
void	xhci_event_command(struct xhci_softc *, uint64_t);
void	xhci_event_port_change(struct xhci_softc *, uint64_t, uint32_t);
int	xhci_pipe_init(struct xhci_softc *, struct usbd_pipe *);
void	xhci_context_setup(struct xhci_softc *, struct usbd_pipe *);
int	xhci_scratchpad_alloc(struct xhci_softc *, int);
void	xhci_scratchpad_free(struct xhci_softc *);
int	xhci_softdev_alloc(struct xhci_softc *, uint8_t);
void	xhci_softdev_free(struct xhci_softc *, uint8_t);
int	xhci_ring_alloc(struct xhci_softc *, struct xhci_ring *, size_t,
	    size_t);
void	xhci_ring_free(struct xhci_softc *, struct xhci_ring *);
void	xhci_ring_reset(struct xhci_softc *, struct xhci_ring *);
struct	xhci_trb *xhci_ring_consume(struct xhci_softc *, struct xhci_ring *);
struct	xhci_trb *xhci_ring_produce(struct xhci_softc *, struct xhci_ring *);

struct	xhci_trb *xhci_xfer_get_trb(struct xhci_softc *, struct usbd_xfer*,
	    uint8_t *, int);
void	xhci_xfer_done(struct usbd_xfer *xfer);
/* xHCI command helpers. */
int	xhci_command_submit(struct xhci_softc *, struct xhci_trb *, int);
int	xhci_command_abort(struct xhci_softc *);

void	xhci_cmd_reset_ep_async(struct xhci_softc *, uint8_t, uint8_t);
void	xhci_cmd_set_tr_deq_async(struct xhci_softc *, uint8_t, uint8_t, uint64_t);
int	xhci_cmd_configure_ep(struct xhci_softc *, uint8_t, uint64_t);
int	xhci_cmd_stop_ep(struct xhci_softc *, uint8_t, uint8_t);
int	xhci_cmd_slot_control(struct xhci_softc *, uint8_t *, int);
int	xhci_cmd_set_address(struct xhci_softc *, uint8_t,  uint64_t, uint32_t);
int	xhci_cmd_evaluate_ctx(struct xhci_softc *, uint8_t, uint64_t);
#ifdef XHCI_DEBUG
int	xhci_cmd_noop(struct xhci_softc *);
#endif

/* XXX should be part of the Bus interface. */
void	xhci_abort_xfer(struct usbd_xfer *, usbd_status);
void	xhci_pipe_close(struct usbd_pipe *);
void	xhci_noop(struct usbd_xfer *);

void 	xhci_timeout(void *);
void	xhci_timeout_task(void *);

/* USBD Bus Interface. */
usbd_status	  xhci_pipe_open(struct usbd_pipe *);
int		  xhci_setaddr(struct usbd_device *, int);
void		  xhci_softintr(void *);
void		  xhci_poll(struct usbd_bus *);
struct usbd_xfer *xhci_allocx(struct usbd_bus *);
void		  xhci_freex(struct usbd_bus *, struct usbd_xfer *);

usbd_status	  xhci_root_ctrl_transfer(struct usbd_xfer *);
usbd_status	  xhci_root_ctrl_start(struct usbd_xfer *);

usbd_status	  xhci_root_intr_transfer(struct usbd_xfer *);
usbd_status	  xhci_root_intr_start(struct usbd_xfer *);
void		  xhci_root_intr_abort(struct usbd_xfer *);
void		  xhci_root_intr_done(struct usbd_xfer *);

usbd_status	  xhci_device_ctrl_transfer(struct usbd_xfer *);
usbd_status	  xhci_device_ctrl_start(struct usbd_xfer *);
void		  xhci_device_ctrl_abort(struct usbd_xfer *);

usbd_status	  xhci_device_generic_transfer(struct usbd_xfer *);
usbd_status	  xhci_device_generic_start(struct usbd_xfer *);
void		  xhci_device_generic_abort(struct usbd_xfer *);
void		  xhci_device_generic_done(struct usbd_xfer *);

#define XHCI_INTR_ENDPT 1

struct usbd_bus_methods xhci_bus_methods = {
	.open_pipe = xhci_pipe_open,
	.dev_setaddr = xhci_setaddr,
	.soft_intr = xhci_softintr,
	.do_poll = xhci_poll,
	.allocx = xhci_allocx,
	.freex = xhci_freex,
};

struct usbd_pipe_methods xhci_root_ctrl_methods = {
	.transfer = xhci_root_ctrl_transfer,
	.start = xhci_root_ctrl_start,
	.abort = xhci_noop,
	.close = xhci_pipe_close,
	.done = xhci_noop,
};

struct usbd_pipe_methods xhci_root_intr_methods = {
	.transfer = xhci_root_intr_transfer,
	.start = xhci_root_intr_start,
	.abort = xhci_root_intr_abort,
	.close = xhci_pipe_close,
	.done = xhci_root_intr_done,
};

struct usbd_pipe_methods xhci_device_ctrl_methods = {
	.transfer = xhci_device_ctrl_transfer,
	.start = xhci_device_ctrl_start,
	.abort = xhci_device_ctrl_abort,
	.close = xhci_pipe_close,
	.done = xhci_noop,
};

#if notyet
struct usbd_pipe_methods xhci_device_isoc_methods = {
};
#endif

struct usbd_pipe_methods xhci_device_bulk_methods = {
	.transfer = xhci_device_generic_transfer,
	.start = xhci_device_generic_start,
	.abort = xhci_device_generic_abort,
	.close = xhci_pipe_close,
	.done = xhci_device_generic_done,
};

struct usbd_pipe_methods xhci_device_generic_methods = {
	.transfer = xhci_device_generic_transfer,
	.start = xhci_device_generic_start,
	.abort = xhci_device_generic_abort,
	.close = xhci_pipe_close,
	.done = xhci_device_generic_done,
};

#ifdef XHCI_DEBUG
static void
xhci_dump_trb(struct xhci_trb *trb)
{
	printf("trb=%p (0x%016llx 0x%08x 0x%b)\n", trb,
	    (long long)letoh64(trb->trb_paddr), letoh32(trb->trb_status),
	    (int)letoh32(trb->trb_flags), XHCI_TRB_FLAGS_BITMASK);
}
#endif

int	usbd_dma_contig_alloc(struct usbd_bus *, struct usbd_dma_info *,
	    void **, bus_size_t, bus_size_t, bus_size_t);
void	usbd_dma_contig_free(struct usbd_bus *, struct usbd_dma_info *);

int
usbd_dma_contig_alloc(struct usbd_bus *bus, struct usbd_dma_info *dma,
    void **kvap, bus_size_t size, bus_size_t alignment, bus_size_t boundary)
{
	int error;

	dma->tag = bus->dmatag;
	dma->size = size;

	error = bus_dmamap_create(dma->tag, size, 1, size, boundary,
	    BUS_DMA_NOWAIT, &dma->map);
	if (error != 0)
		return (error);

	error = bus_dmamem_alloc(dma->tag, size, alignment, boundary, &dma->seg,
	    1, &dma->nsegs, BUS_DMA_NOWAIT | BUS_DMA_ZERO);
	if (error != 0)
		goto destroy;

	error = bus_dmamem_map(dma->tag, &dma->seg, 1, size, &dma->vaddr,
	    BUS_DMA_NOWAIT | BUS_DMA_COHERENT);
	if (error != 0)
		goto free;

	error = bus_dmamap_load_raw(dma->tag, dma->map, &dma->seg, 1, size,
	    BUS_DMA_NOWAIT);
	if (error != 0)
		goto unmap;

	bus_dmamap_sync(dma->tag, dma->map, 0, size, BUS_DMASYNC_PREREAD |
	    BUS_DMASYNC_PREWRITE);

	dma->paddr = dma->map->dm_segs[0].ds_addr;
	if (kvap != NULL)
		*kvap = dma->vaddr;

	return (0);

unmap:
	bus_dmamem_unmap(dma->tag, dma->vaddr, size);
free:
	bus_dmamem_free(dma->tag, &dma->seg, 1);
destroy:
	bus_dmamap_destroy(dma->tag, dma->map);
	return (error);
}

void
usbd_dma_contig_free(struct usbd_bus *bus, struct usbd_dma_info *dma)
{
	if (dma->map != NULL) {
		bus_dmamap_sync(bus->dmatag, dma->map, 0, dma->size,
		    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);
		bus_dmamap_unload(bus->dmatag, dma->map);
		bus_dmamem_unmap(bus->dmatag, dma->vaddr, dma->size);
		bus_dmamem_free(bus->dmatag, &dma->seg, 1);
		bus_dmamap_destroy(bus->dmatag, dma->map);
		dma->map = NULL;
	}
}

int
xhci_init(struct xhci_softc *sc)
{
	uint32_t hcr;
	int npage, error;

#ifdef XHCI_DEBUG
	uint16_t vers;

	vers = XREAD2(sc, XHCI_HCIVERSION);
	printf("%s: xHCI version %x.%x\n", DEVNAME(sc), vers >> 8, vers & 0xff);
#endif
	sc->sc_bus.usbrev = USBREV_3_0;
	sc->sc_bus.methods = &xhci_bus_methods;
	sc->sc_bus.pipe_size = sizeof(struct xhci_pipe);

	sc->sc_oper_off = XREAD1(sc, XHCI_CAPLENGTH);
	sc->sc_door_off = XREAD4(sc, XHCI_DBOFF);
	sc->sc_runt_off = XREAD4(sc, XHCI_RTSOFF);

#ifdef XHCI_DEBUG
	printf("%s: CAPLENGTH=%#lx\n", DEVNAME(sc), sc->sc_oper_off);
	printf("%s: DOORBELL=%#lx\n", DEVNAME(sc), sc->sc_door_off);
	printf("%s: RUNTIME=%#lx\n", DEVNAME(sc), sc->sc_runt_off);
#endif

	error = xhci_reset(sc);
	if (error)
		return (error);

	if (xhcixfer == NULL) {
		xhcixfer = malloc(sizeof(struct pool), M_DEVBUF, M_NOWAIT);
		if (xhcixfer == NULL) {
			printf("%s: unable to allocate pool descriptor\n",
			    DEVNAME(sc));
			return (ENOMEM);
		}
		pool_init(xhcixfer, sizeof(struct xhci_xfer), 0, IPL_SOFTUSB,
		    0, "xhcixfer", NULL);
	}

	hcr = XREAD4(sc, XHCI_HCCPARAMS);
	sc->sc_ctxsize = XHCI_HCC_CSZ(hcr) ? 64 : 32;
	DPRINTF(("%s: %d bytes context\n", DEVNAME(sc), sc->sc_ctxsize));

#ifdef XHCI_DEBUG
	hcr = XOREAD4(sc, XHCI_PAGESIZE);
	printf("%s: supported page size 0x%08x\n", DEVNAME(sc), hcr);
#endif
	/* Use 4K for the moment since it's easier. */
	sc->sc_pagesize = 4096;

	/* Get port and device slot numbers. */
	hcr = XREAD4(sc, XHCI_HCSPARAMS1);
	sc->sc_noport = XHCI_HCS1_N_PORTS(hcr);
	sc->sc_noslot = XHCI_HCS1_DEVSLOT_MAX(hcr);
	DPRINTF(("%s: %d ports and %d slots\n", DEVNAME(sc), sc->sc_noport,
	    sc->sc_noslot));

	/* Setup Device Context Base Address Array. */
	error = usbd_dma_contig_alloc(&sc->sc_bus, &sc->sc_dcbaa.dma,
	    (void **)&sc->sc_dcbaa.segs, (sc->sc_noslot + 1) * sizeof(uint64_t),
	    XHCI_DCBAA_ALIGN, sc->sc_pagesize);
	if (error)
		return (ENOMEM);

	/* Setup command ring. */
	error = xhci_ring_alloc(sc, &sc->sc_cmd_ring, XHCI_MAX_CMDS,
	    XHCI_CMDS_RING_ALIGN);
	if (error) {
		printf("%s: could not allocate command ring.\n", DEVNAME(sc));
		usbd_dma_contig_free(&sc->sc_bus, &sc->sc_dcbaa.dma);
		return (error);
	}

	/* Setup one event ring and its segment table (ERST). */
	error = xhci_ring_alloc(sc, &sc->sc_evt_ring, XHCI_MAX_EVTS,
	    XHCI_EVTS_RING_ALIGN);
	if (error) {
		printf("%s: could not allocate event ring.\n", DEVNAME(sc));
		xhci_ring_free(sc, &sc->sc_cmd_ring);
		usbd_dma_contig_free(&sc->sc_bus, &sc->sc_dcbaa.dma);
		return (error);
	}

	/* Allocate the required entry for the segment table. */
	error = usbd_dma_contig_alloc(&sc->sc_bus, &sc->sc_erst.dma,
	    (void **)&sc->sc_erst.segs, sizeof(struct xhci_erseg),
	    XHCI_ERST_ALIGN, XHCI_ERST_BOUNDARY);
	if (error) {
		printf("%s: could not allocate segment table.\n", DEVNAME(sc));
		xhci_ring_free(sc, &sc->sc_evt_ring);
		xhci_ring_free(sc, &sc->sc_cmd_ring);
		usbd_dma_contig_free(&sc->sc_bus, &sc->sc_dcbaa.dma);
		return (ENOMEM);
	}

	/* Set our ring address and size in its corresponding segment. */
	sc->sc_erst.segs[0].er_addr = htole64(sc->sc_evt_ring.dma.paddr);
	sc->sc_erst.segs[0].er_size = htole32(XHCI_MAX_EVTS);
	sc->sc_erst.segs[0].er_rsvd = 0;
	bus_dmamap_sync(sc->sc_erst.dma.tag, sc->sc_erst.dma.map, 0,
	    sc->sc_erst.dma.size, BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);

	/* Get the number of scratch pages and configure them if necessary. */
	hcr = XREAD4(sc, XHCI_HCSPARAMS2);
	npage = XHCI_HCS2_SPB_MAX(hcr);
	DPRINTF(("%s: %d scratch pages\n", DEVNAME(sc), npage));

	if (npage > 0 && xhci_scratchpad_alloc(sc, npage)) {
		printf("%s: could not allocate scratchpad.\n", DEVNAME(sc));
		usbd_dma_contig_free(&sc->sc_bus, &sc->sc_erst.dma);
		xhci_ring_free(sc, &sc->sc_evt_ring);
		xhci_ring_free(sc, &sc->sc_cmd_ring);
		usbd_dma_contig_free(&sc->sc_bus, &sc->sc_dcbaa.dma);
		return (ENOMEM);
	}


	return (0);
}

void
xhci_config(struct xhci_softc *sc)
{
	uint64_t paddr;
	uint32_t hcr;

	/* Make sure to program a number of device slots we can handle. */
	if (sc->sc_noslot > USB_MAX_DEVICES)
		sc->sc_noslot = USB_MAX_DEVICES;
	hcr = XOREAD4(sc, XHCI_CONFIG) & ~XHCI_CONFIG_SLOTS_MASK;
	XOWRITE4(sc, XHCI_CONFIG, hcr | sc->sc_noslot);

	/* Set the device context base array address. */
	paddr = (uint64_t)sc->sc_dcbaa.dma.paddr;
	XOWRITE4(sc, XHCI_DCBAAP_LO, (uint32_t)paddr);
	XOWRITE4(sc, XHCI_DCBAAP_HI, (uint32_t)(paddr >> 32));

	DPRINTF(("%s: DCBAAP=%#x%#x\n", DEVNAME(sc),
	    XOREAD4(sc, XHCI_DCBAAP_HI), XOREAD4(sc, XHCI_DCBAAP_LO)));

	/* Set the command ring address. */
	paddr = (uint64_t)sc->sc_cmd_ring.dma.paddr;
	XOWRITE4(sc, XHCI_CRCR_LO, ((uint32_t)paddr) | XHCI_CRCR_LO_RCS);
	XOWRITE4(sc, XHCI_CRCR_HI, (uint32_t)(paddr >> 32));

	DPRINTF(("%s: CRCR=%#x%#x (%016llx)\n", DEVNAME(sc),
	    XOREAD4(sc, XHCI_CRCR_HI), XOREAD4(sc, XHCI_CRCR_LO), paddr));

	/* Set the ERST count number to 1, since we use only one event ring. */
	XRWRITE4(sc, XHCI_ERSTSZ(0), XHCI_ERSTS_SET(1));

	/* Set the segment table address. */
	paddr = (uint64_t)sc->sc_erst.dma.paddr;
	XRWRITE4(sc, XHCI_ERSTBA_LO(0), (uint32_t)paddr);
	XRWRITE4(sc, XHCI_ERSTBA_HI(0), (uint32_t)(paddr >> 32));

	DPRINTF(("%s: ERSTBA=%#x%#x\n", DEVNAME(sc),
	    XRREAD4(sc, XHCI_ERSTBA_HI(0)), XRREAD4(sc, XHCI_ERSTBA_LO(0))));

	/* Set the ring dequeue address. */
	paddr = (uint64_t)sc->sc_evt_ring.dma.paddr;
	XRWRITE4(sc, XHCI_ERDP_LO(0), (uint32_t)paddr);
	XRWRITE4(sc, XHCI_ERDP_HI(0), (uint32_t)(paddr >> 32));

	DPRINTF(("%s: ERDP=%#x%#x\n", DEVNAME(sc),
	    XRREAD4(sc, XHCI_ERDP_HI(0)), XRREAD4(sc, XHCI_ERDP_LO(0))));

	/* Enable interrupts. */
	hcr = XRREAD4(sc, XHCI_IMAN(0));
	XRWRITE4(sc, XHCI_IMAN(0), hcr | XHCI_IMAN_INTR_ENA);

	/* Set default interrupt moderation. */
	XRWRITE4(sc, XHCI_IMOD(0), XHCI_IMOD_DEFAULT);

	/* Allow event interrupt and start the controller. */
	XOWRITE4(sc, XHCI_USBCMD, XHCI_CMD_INTE|XHCI_CMD_RS);

	DPRINTF(("%s: USBCMD=%#x\n", DEVNAME(sc), XOREAD4(sc, XHCI_USBCMD)));
	DPRINTF(("%s: IMAN=%#x\n", DEVNAME(sc), XRREAD4(sc, XHCI_IMAN(0))));
}

int
xhci_detach(struct device *self, int flags)
{
	struct xhci_softc *sc = (struct xhci_softc *)self;
	int rv;

	rv = config_detach_children(self, flags);
	if (rv != 0) {
		printf("%s: error while detaching %d\n", DEVNAME(sc), rv);
		return (rv);
	}

	/* Since the hardware might already be gone, ignore the errors. */
	xhci_command_abort(sc);

	xhci_reset(sc);

	/* Disable interrupts. */
	XRWRITE4(sc, XHCI_IMOD(0), 0);
	XRWRITE4(sc, XHCI_IMAN(0), 0);

	/* Clear the event ring address. */
	XRWRITE4(sc, XHCI_ERDP_LO(0), 0);
	XRWRITE4(sc, XHCI_ERDP_HI(0), 0);

	XRWRITE4(sc, XHCI_ERSTBA_LO(0), 0);
	XRWRITE4(sc, XHCI_ERSTBA_HI(0), 0);

	XRWRITE4(sc, XHCI_ERSTSZ(0), 0);

	/* Clear the command ring address. */
	XOWRITE4(sc, XHCI_CRCR_LO, 0);
	XOWRITE4(sc, XHCI_CRCR_HI, 0);

	XOWRITE4(sc, XHCI_DCBAAP_LO, 0);
	XOWRITE4(sc, XHCI_DCBAAP_HI, 0);

	if (sc->sc_spad.npage > 0)
		xhci_scratchpad_free(sc);

	usbd_dma_contig_free(&sc->sc_bus, &sc->sc_erst.dma);
	xhci_ring_free(sc, &sc->sc_evt_ring);
	xhci_ring_free(sc, &sc->sc_cmd_ring);
	usbd_dma_contig_free(&sc->sc_bus, &sc->sc_dcbaa.dma);

	return (0);
}

int
xhci_activate(struct device *self, int act)
{
	struct xhci_softc *sc = (struct xhci_softc *)self;
	int rv = 0;

	switch (act) {
	case DVACT_RESUME:
		sc->sc_bus.use_polling++;

		xhci_reset(sc);
		xhci_ring_reset(sc, &sc->sc_cmd_ring);
		xhci_ring_reset(sc, &sc->sc_evt_ring);

		/* Renesas controllers, at least, need more time to resume. */
		usb_delay_ms(&sc->sc_bus, USB_RESUME_WAIT);

		xhci_config(sc);

		sc->sc_bus.use_polling--;
		rv = config_activate_children(self, act);
		break;
	case DVACT_POWERDOWN:
		rv = config_activate_children(self, act);
		xhci_reset(sc);
		break;
	default:
		rv = config_activate_children(self, act);
		break;
	}

	return (rv);
}

int
xhci_reset(struct xhci_softc *sc)
{
	uint32_t hcr;
	int i;

	XOWRITE4(sc, XHCI_USBCMD, 0);	/* Halt controller */
	for (i = 0; i < 100; i++) {
		usb_delay_ms(&sc->sc_bus, 1);
		hcr = XOREAD4(sc, XHCI_USBSTS) & XHCI_STS_HCH;
		if (hcr)
			break;
	}

	if (!hcr)
		printf("%s: halt timeout\n", DEVNAME(sc));

	XOWRITE4(sc, XHCI_USBCMD, XHCI_CMD_HCRST);
	for (i = 0; i < 100; i++) {
		usb_delay_ms(&sc->sc_bus, 1);
		hcr = (XOREAD4(sc, XHCI_USBCMD) & XHCI_CMD_HCRST) |
		    (XOREAD4(sc, XHCI_USBSTS) & XHCI_STS_CNR);
		if (!hcr)
			break;
	}

	if (hcr) {
		printf("%s: reset timeout\n", DEVNAME(sc));
		return (EIO);
	}

	return (0);
}


int
xhci_intr(void *v)
{
	struct xhci_softc *sc = v;

	if (sc == NULL || sc->sc_bus.dying)
		return (0);

	/* If we get an interrupt while polling, then just ignore it. */
	if (sc->sc_bus.use_polling) {
		DPRINTFN(16, ("xhci_intr: ignored interrupt while polling\n"));
		return (0);
	}

	return (xhci_intr1(sc));
}

int
xhci_intr1(struct xhci_softc *sc)
{
	uint32_t intrs;

	intrs = XOREAD4(sc, XHCI_USBSTS);
	if (intrs == 0xffffffff) {
		sc->sc_bus.dying = 1;
		return (0);
	}

	if ((intrs & XHCI_STS_EINT) == 0)
		return (0);

	sc->sc_bus.no_intrs++;

	if (intrs & XHCI_STS_HSE) {
		printf("%s: host system error\n", DEVNAME(sc));
		sc->sc_bus.dying = 1;
		return (1);
	}

	XOWRITE4(sc, XHCI_USBSTS, intrs); /* Acknowledge */
	usb_schedsoftintr(&sc->sc_bus);

	/* Acknowledge PCI interrupt */
	intrs = XRREAD4(sc, XHCI_IMAN(0));
	XRWRITE4(sc, XHCI_IMAN(0), intrs | XHCI_IMAN_INTR_PEND);

	return (1);
}

void
xhci_poll(struct usbd_bus *bus)
{
	struct xhci_softc *sc = (struct xhci_softc *)bus;

	if (XOREAD4(sc, XHCI_USBSTS))
		xhci_intr1(sc);
}

void
xhci_softintr(void *v)
{
	struct xhci_softc *sc = v;

	if (sc->sc_bus.dying)
		return;

	sc->sc_bus.intr_context++;
	xhci_event_dequeue(sc);
	sc->sc_bus.intr_context--;
}

void
xhci_event_dequeue(struct xhci_softc *sc)
{
	struct xhci_trb *trb;
	uint64_t paddr;
	uint32_t status, flags;

	while ((trb = xhci_ring_consume(sc, &sc->sc_evt_ring)) != NULL) {
		paddr = letoh64(trb->trb_paddr);
		status = letoh32(trb->trb_status);
		flags = letoh32(trb->trb_flags);

		switch (flags & XHCI_TRB_TYPE_MASK) {
		case XHCI_EVT_XFER:
			xhci_event_xfer(sc, paddr, status, flags);
			break;
		case XHCI_EVT_CMD_COMPLETE:
			memcpy(&sc->sc_result_trb, trb, sizeof(*trb));
			xhci_event_command(sc, paddr);
			break;
		case XHCI_EVT_PORT_CHANGE:
			xhci_event_port_change(sc, paddr, status);
			break;
		default:
#ifdef XHCI_DEBUG
			printf("event (%d): ", XHCI_TRB_TYPE(flags));
			xhci_dump_trb(trb);
#endif
			break;
		}

	}

	paddr = (uint64_t)DEQPTR(sc->sc_evt_ring);
	XRWRITE4(sc, XHCI_ERDP_LO(0), ((uint32_t)paddr) | XHCI_ERDP_LO_BUSY);
	XRWRITE4(sc, XHCI_ERDP_HI(0), (uint32_t)(paddr >> 32));
}

void
xhci_event_xfer(struct xhci_softc *sc, uint64_t paddr, uint32_t status,
    uint32_t flags)
{
	struct xhci_pipe *xp;
	struct usbd_xfer *xfer;
	struct xhci_xfer *xx;
	uint8_t dci, slot, code;
	uint32_t remain;
	int trb_idx;

	slot = XHCI_TRB_GET_SLOT(flags);
	dci = XHCI_TRB_GET_EP(flags);
	if (slot > sc->sc_noslot) {
		DPRINTF(("%s: incorrect slot (%u)\n", DEVNAME(sc), slot));
		return;
	}

	xp = sc->sc_sdevs[slot].pipes[dci - 1];
	if (xp == NULL)
		return;

	code = XHCI_TRB_GET_CODE(status);
	remain = XHCI_TRB_REMAIN(status);

	trb_idx = (paddr - xp->ring.dma.paddr) / sizeof(struct xhci_trb);
	if (trb_idx < 0 || trb_idx >= xp->ring.ntrb) {
		printf("%s: wrong trb index (%d) max is %zu\n", DEVNAME(sc),
		    trb_idx, xp->ring.ntrb - 1);
		return;
	}

	xfer = xp->pending_xfers[trb_idx];
	if (xfer == NULL) {
		printf("%s: NULL xfer pointer\n", DEVNAME(sc));
		return;
	}

	if (remain > xfer->length)
		remain = xfer->length;

	switch (code) {
	case XHCI_CODE_SUCCESS:
		/*
		 * This might be the last TRB of a TD that ended up
		 * with a Short Transfer condition, see below.
		 */
		if (xfer->actlen == 0)
			xfer->actlen = xfer->length - remain;

		xfer->status = USBD_NORMAL_COMPLETION;
		break;
	case XHCI_CODE_SHORT_XFER:
		xfer->actlen = xfer->length - remain;

		/*
		 * If this is not the last TRB of a transfer, we should
		 * theoretically clear the IOC at the end of the chain
		 * but the HC might have already processed it before we
		 * had a change to schedule the softinterrupt.
		 */
		xx = (struct xhci_xfer *)xfer;
		if (xx->index != trb_idx)
			return;

		xfer->status = USBD_NORMAL_COMPLETION;
		break;
	case XHCI_CODE_TXERR:
	case XHCI_CODE_SPLITERR:
		xfer->status = USBD_IOERROR;
		break;
	case XHCI_CODE_STALL:
	case XHCI_CODE_BABBLE:
		/* Prevent any timeout to kick in. */
		timeout_del(&xfer->timeout_handle);
		usb_rem_task(xfer->device, &xfer->abort_task);

		/* We need to report this condition for umass(4). */
		if (code == XHCI_CODE_STALL)
			xp->halted = USBD_STALLED;
		else
			xp->halted = USBD_IOERROR;
		/*
		 * Since the stack might try to start a new transfer as
		 * soon as a pending one finishes, make sure the endpoint
		 * is fully reset before calling usb_transfer_complete().
		 */
		xp->aborted_xfer = xfer;
		xhci_cmd_reset_ep_async(sc, slot, dci);
		return;
	case XHCI_CODE_XFER_STOPPED:
	case XHCI_CODE_XFER_STOPINV:
		/* Endpoint stopped while processing a TD. */
		if (xfer == xp->aborted_xfer) {
			DPRINTF(("%s: stopped xfer=%p\n", __func__, xfer));
		    	return;
		}

		/* FALLTHROUGH */
	default:
		DPRINTF(("%s: unhandled code %d\n", DEVNAME(sc), code));
		xfer->status = USBD_IOERROR;
		xp->halted = 1;
		break;
	}

	xhci_xfer_done(xfer);
}

void
xhci_event_command(struct xhci_softc *sc, uint64_t paddr)
{
	struct xhci_trb *trb;
	struct xhci_pipe *xp;
	uint32_t flags;
	uint8_t dci, slot;
	int trb_idx, status;

	trb_idx = (paddr - sc->sc_cmd_ring.dma.paddr) / sizeof(*trb);
	if (trb_idx < 0 || trb_idx >= sc->sc_cmd_ring.ntrb) {
		printf("%s: wrong trb index (%d) max is %zu\n", DEVNAME(sc),
		    trb_idx, sc->sc_cmd_ring.ntrb - 1);
		return;
	}

	trb = &sc->sc_cmd_ring.trbs[trb_idx];

	bus_dmamap_sync(sc->sc_cmd_ring.dma.tag, sc->sc_cmd_ring.dma.map,
	    TRBOFF(&sc->sc_cmd_ring, trb), sizeof(struct xhci_trb),
	    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);

	flags = letoh32(trb->trb_flags);

	slot = XHCI_TRB_GET_SLOT(flags);
	dci = XHCI_TRB_GET_EP(flags);

	switch (flags & XHCI_TRB_TYPE_MASK) {
	case XHCI_CMD_RESET_EP:
		xp = sc->sc_sdevs[slot].pipes[dci - 1];
		if (xp == NULL)
			break;

		/* Update the dequeue pointer past the last TRB. */
		xhci_cmd_set_tr_deq_async(sc, xp->slot, xp->dci,
		    DEQPTR(xp->ring) | xp->ring.toggle);
		break;
	case XHCI_CMD_SET_TR_DEQ:
		xp = sc->sc_sdevs[slot].pipes[dci - 1];
		if (xp == NULL)
			break;

		status = xp->halted;
		xp->halted = 0;
		if (xp->aborted_xfer != NULL) {
			xp->aborted_xfer->status = status;
			xhci_xfer_done(xp->aborted_xfer);
			wakeup(xp);
		}
		break;
	case XHCI_CMD_CONFIG_EP:
	case XHCI_CMD_STOP_EP:
	case XHCI_CMD_DISABLE_SLOT:
	case XHCI_CMD_ENABLE_SLOT:
	case XHCI_CMD_ADDRESS_DEVICE:
	case XHCI_CMD_EVAL_CTX:
	case XHCI_CMD_NOOP:
		/* All these commands are synchronous. */
		KASSERT(sc->sc_cmd_trb == trb);
		sc->sc_cmd_trb = NULL;
		wakeup(&sc->sc_cmd_trb);
		break;
	default:
		DPRINTF(("%s: unexpected command %x\n", DEVNAME(sc), flags));
	}
}

void
xhci_event_port_change(struct xhci_softc *sc, uint64_t paddr, uint32_t status)
{
	struct usbd_xfer *xfer = sc->sc_intrxfer;
	uint32_t port = XHCI_TRB_PORTID(paddr);
	uint8_t *p;

	if (XHCI_TRB_GET_CODE(status) != XHCI_CODE_SUCCESS) {
		DPRINTF(("%s: failed port status event\n", DEVNAME(sc)));
		return;
	}

	if (xfer == NULL)
		return;

	p = KERNADDR(&xfer->dmabuf, 0);
	memset(p, 0, xfer->length);

	p[port/8] |= 1 << (port%8);
	DPRINTF(("%s: port=%d change=0x%02x\n", DEVNAME(sc), port, *p));

	xfer->actlen = xfer->length;
	xfer->status = USBD_NORMAL_COMPLETION;

	usb_transfer_complete(xfer);
}

void
xhci_xfer_done(struct usbd_xfer *xfer)
{
	struct xhci_pipe *xp = (struct xhci_pipe *)xfer->pipe;
	struct xhci_xfer *xx = (struct xhci_xfer *)xfer;
	int ntrb, i;

	splsoftassert(IPL_SOFTUSB);

#ifdef XHCI_DEBUG
	if (xx->index < 0 || xp->pending_xfers[xx->index] == NULL) {
		printf("%s: xfer=%p done (idx=%d, ntrb=%zd)\n", __func__,
		    xfer, xx->index, xx->ntrb);
	}
#endif

	if (xp->aborted_xfer == xfer)
		xp->aborted_xfer = NULL;

	for (ntrb = 0, i = xx->index; ntrb < xx->ntrb; ntrb++, i--) {
		xp->pending_xfers[i] = NULL;
		if (i == 0)
			i = (xp->ring.ntrb - 1);
	}
	xp->free_trbs += xx->ntrb;
	xx->index = -1;
	xx->ntrb = 0;

	timeout_del(&xfer->timeout_handle);
	usb_rem_task(xfer->device, &xfer->abort_task);
	usb_transfer_complete(xfer);
}

/*
 * Calculate the Device Context Index (DCI) for endpoints as stated
 * in section 4.5.1 of xHCI specification r1.1.
 */
static inline uint8_t
xhci_ed2dci(usb_endpoint_descriptor_t *ed)
{
	uint8_t dir;

	if (UE_GET_XFERTYPE(ed->bmAttributes) == UE_CONTROL)
		return (UE_GET_ADDR(ed->bEndpointAddress) * 2 + 1);

	if (UE_GET_DIR(ed->bEndpointAddress) == UE_DIR_IN)
		dir = 1;
	else
		dir = 0;

	return (UE_GET_ADDR(ed->bEndpointAddress) * 2 + dir);
}

usbd_status
xhci_pipe_open(struct usbd_pipe *pipe)
{
	struct xhci_softc *sc = (struct xhci_softc *)pipe->device->bus;
	struct xhci_pipe *xp = (struct xhci_pipe *)pipe;
	usb_endpoint_descriptor_t *ed = pipe->endpoint->edesc;
	uint8_t slot = 0, xfertype = UE_GET_XFERTYPE(ed->bmAttributes);
	int error;

	KASSERT(xp->slot == 0);

	if (sc->sc_bus.dying)
		return (USBD_IOERROR);

	/* Root Hub */
	if (pipe->device->depth == 0) {
		switch (ed->bEndpointAddress) {
		case USB_CONTROL_ENDPOINT:
			pipe->methods = &xhci_root_ctrl_methods;
			break;
		case UE_DIR_IN | XHCI_INTR_ENDPT:
			pipe->methods = &xhci_root_intr_methods;
			break;
		default:
			pipe->methods = NULL;
			return (USBD_INVAL);
		}
		return (USBD_NORMAL_COMPLETION);
	}

#if 0
	/* Issue a noop to check if the command ring is correctly configured. */
	xhci_cmd_noop(sc);
#endif

	switch (xfertype) {
	case UE_CONTROL:
		pipe->methods = &xhci_device_ctrl_methods;

		/*
		 * Get a slot and init the device's contexts.
		 *
		 * Since the control enpoint, represented as the default
		 * pipe, is always opened first we are dealing with a
		 * new device.  Put a new slot in the ENABLED state.
		 *
		 */
		error = xhci_cmd_slot_control(sc, &slot, 1);
		if (error || slot == 0 || slot > sc->sc_noslot)
			return (USBD_INVAL);

		if (xhci_softdev_alloc(sc, slot)) {
			xhci_cmd_slot_control(sc, &slot, 0);
			return (USBD_NOMEM);
		}

		break;
	case UE_ISOCHRONOUS:
#if notyet
		pipe->methods = &xhci_device_isoc_methods;
		break;
#else
		DPRINTF(("%s: isochronous xfer not supported \n", __func__));
		return (USBD_INVAL);
#endif
	case UE_BULK:
		pipe->methods = &xhci_device_bulk_methods;
		break;
	case UE_INTERRUPT:
		pipe->methods = &xhci_device_generic_methods;
		break;
	default:
		return (USBD_INVAL);
	}

	/*
	 * Our USBD Bus Interface is pipe-oriented but for most of the
	 * operations we need to access a device context, so keep trace
	 * of the slot ID in every pipe.
	 */
	if (slot == 0)
		slot = ((struct xhci_pipe *)pipe->device->default_pipe)->slot;

	xp->slot = slot;
	xp->dci = xhci_ed2dci(ed);

	if (xhci_pipe_init(sc, pipe)) {
		xhci_cmd_slot_control(sc, &slot, 0);
		return (USBD_IOERROR);
	}

	return (USBD_NORMAL_COMPLETION);
}

/*
 * Set the maximum Endpoint Service Interface Time (ESIT) payload and
 * the average TRB buffer length for an endpoint.
 */
static inline uint32_t
xhci_get_txinfo(struct xhci_softc *sc, struct usbd_pipe *pipe)
{
	usb_endpoint_descriptor_t *ed = pipe->endpoint->edesc;
	uint32_t mep, atl, mps = UGETW(ed->wMaxPacketSize);

	switch (ed->bmAttributes & UE_XFERTYPE) {
	case UE_CONTROL:
		mep = 0;
		atl = 8;
		break;
	case UE_INTERRUPT:
	case UE_ISOCHRONOUS:
		if (pipe->device->speed == USB_SPEED_SUPER) {
			/*  XXX Read the companion descriptor */
		}

		mep = (UE_GET_TRANS(mps) | 0x1) * UE_GET_SIZE(mps);
		atl = min(sc->sc_pagesize, mep);
		break;
	case UE_BULK:
	default:
		mep = 0;
		atl = 0;
	}

	return (XHCI_EPCTX_MAX_ESIT_PAYLOAD(mep) | XHCI_EPCTX_AVG_TRB_LEN(atl));
}

void
xhci_context_setup(struct xhci_softc *sc, struct usbd_pipe *pipe)
{
	struct xhci_pipe *xp = (struct xhci_pipe *)pipe;
	struct xhci_soft_dev *sdev = &sc->sc_sdevs[xp->slot];
	usb_endpoint_descriptor_t *ed = pipe->endpoint->edesc;
	uint32_t mps = UE_GET_SIZE(UGETW(ed->wMaxPacketSize));
	uint8_t xfertype = UE_GET_XFERTYPE(ed->bmAttributes);
	uint8_t ival, speed, cerr = 0;
	uint32_t route = 0, rhport = 0;
	struct usbd_device *hub;

	/*
	 * Calculate the Route String.  Assume that there is no hub with
	 * more than 15 ports and that they all have a detph < 6.  See
	 * section 8.9 of USB 3.1 Specification for more details.
	 */
	for (hub = pipe->device; hub->myhub->depth; hub = hub->myhub) {
		uint32_t port = hub->powersrc->portno;
		uint32_t depth = hub->myhub->depth;

		route |= port << (4 * (depth - 1));
	}

	/* Get Root Hub port */
	rhport = hub->powersrc->portno;

	switch (pipe->device->speed) {
	case USB_SPEED_LOW:
		ival= 3;
		speed = XHCI_SPEED_LOW;
		break;
	case USB_SPEED_FULL:
		ival = 3;
		speed = XHCI_SPEED_FULL;
		break;
	case USB_SPEED_HIGH:
		ival = min(3, ed->bInterval);
		speed = XHCI_SPEED_HIGH;
		break;
	case USB_SPEED_SUPER:
		ival = min(3, ed->bInterval);
		speed = XHCI_SPEED_SUPER;
		break;
	default:
		return;
	}

	if (pipe->interval != USBD_DEFAULT_INTERVAL)
		ival = min(ival, pipe->interval);

	/* Setup the endpoint context */
	if (xfertype != UE_ISOCHRONOUS)
		cerr = 3;

	if (xfertype == UE_CONTROL || xfertype == UE_BULK)
		ival = 0;

	if ((ed->bEndpointAddress & UE_DIR_IN) || (xfertype == UE_CONTROL))
		xfertype |= 0x4;

	sdev->ep_ctx[xp->dci-1]->info_lo = htole32(XHCI_EPCTX_SET_IVAL(ival));
	sdev->ep_ctx[xp->dci-1]->info_hi = htole32(
	    XHCI_EPCTX_SET_MPS(mps) | XHCI_EPCTX_SET_EPTYPE(xfertype) |
	    XHCI_EPCTX_SET_CERR(cerr) | XHCI_EPCTX_SET_MAXB(0)
	);
	sdev->ep_ctx[xp->dci-1]->txinfo = htole32(xhci_get_txinfo(sc, pipe));
	sdev->ep_ctx[xp->dci-1]->deqp = htole64(
	    DEQPTR(xp->ring) | xp->ring.toggle
	);

	/* Unmask the new endoint */
	sdev->input_ctx->drop_flags = 0;
	sdev->input_ctx->add_flags = htole32(XHCI_INCTX_MASK_DCI(xp->dci));

	/* Setup the slot context */
	sdev->slot_ctx->info_lo = htole32(
	    XHCI_SCTX_DCI(xp->dci) | XHCI_SCTX_SPEED(speed) |
	    XHCI_SCTX_ROUTE(route)
	);
	sdev->slot_ctx->info_hi = htole32(XHCI_SCTX_RHPORT(rhport));
	sdev->slot_ctx->tt = 0;
	sdev->slot_ctx->state = 0;

/* XXX */
#define UHUB_IS_MTT(dev) (dev->ddesc.bDeviceProtocol == UDPROTO_HSHUBMTT)
	/*
	 * If we are opening the interrupt pipe of a hub, update its
	 * context before putting it in the CONFIGURED state.
	 */
	if (pipe->device->hub != NULL) {
		int nports = pipe->device->hub->nports;

		sdev->slot_ctx->info_lo |= htole32(XHCI_SCTX_HUB(1));
		sdev->slot_ctx->info_hi |= htole32(XHCI_SCTX_NPORTS(nports));

		if (UHUB_IS_MTT(pipe->device))
			sdev->slot_ctx->info_lo |= htole32(XHCI_SCTX_MTT(1));

		sdev->slot_ctx->tt |= htole32(
		    XHCI_SCTX_TT_THINK_TIME(pipe->device->hub->ttthink)
		);
	}

	/*
	 * If this is a Low or Full Speed device below an external High
	 * Speed hub, it needs some TT love.
	 */
	if (speed < XHCI_SPEED_HIGH && pipe->device->myhsport != NULL) {
		struct usbd_device *hshub = pipe->device->myhsport->parent;
		uint8_t slot = ((struct xhci_pipe *)hshub->default_pipe)->slot;

		if (UHUB_IS_MTT(hshub))
			sdev->slot_ctx->info_lo |= htole32(XHCI_SCTX_MTT(1));

		sdev->slot_ctx->tt |= htole32(
		    XHCI_SCTX_TT_HUB_SID(slot) |
		    XHCI_SCTX_TT_PORT_NUM(pipe->device->myhsport->portno)
		);
	}
#undef UHUB_IS_MTT

	/* Unmask the slot context */
	sdev->input_ctx->add_flags |= htole32(XHCI_INCTX_MASK_DCI(0));

	bus_dmamap_sync(sdev->ictx_dma.tag, sdev->ictx_dma.map, 0,
	    sc->sc_pagesize, BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);
}

int
xhci_pipe_init(struct xhci_softc *sc, struct usbd_pipe *pipe)
{
	struct xhci_pipe *xp = (struct xhci_pipe *)pipe;
	struct xhci_soft_dev *sdev = &sc->sc_sdevs[xp->slot];
	int error;

#ifdef XHCI_DEBUG
	struct usbd_device *dev = pipe->device;
	printf("%s: pipe=%p addr=%d depth=%d port=%d speed=%d dev %d dci %u"
	    " (epAddr=0x%x)\n", __func__, pipe, dev->address, dev->depth,
	    dev->powersrc->portno, dev->speed, xp->slot, xp->dci,
	    pipe->endpoint->edesc->bEndpointAddress);
#endif

	if (xhci_ring_alloc(sc, &xp->ring, XHCI_MAX_XFER, XHCI_XFER_RING_ALIGN))
		return (ENOMEM);

	xp->free_trbs = xp->ring.ntrb;
	xp->halted = 0;

	sdev->pipes[xp->dci - 1] = xp;

	xhci_context_setup(sc, pipe);

	if (xp->dci == 1) {
		/*
		 * If we are opening the default pipe, the Slot should
		 * be in the ENABLED state.  Issue an "Address Device"
		 * with BSR=1 to put the device in the DEFAULT state.
		 * We cannot jump directly to the ADDRESSED state with
		 * BSR=0 because some Low/Full speed devices wont accept
		 * a SET_ADDRESS command before we've read their device
		 * descriptor.
		 */
		error = xhci_cmd_set_address(sc, xp->slot,
		    sdev->ictx_dma.paddr, XHCI_TRB_BSR);
	} else {
		error = xhci_cmd_configure_ep(sc, xp->slot,
		    sdev->ictx_dma.paddr);
	}

	if (error) {
		xhci_ring_free(sc, &xp->ring);
		return (EIO);
	}

	return (0);
}

void
xhci_pipe_close(struct usbd_pipe *pipe)
{
	struct xhci_softc *sc = (struct xhci_softc *)pipe->device->bus;
	struct xhci_pipe *lxp, *xp = (struct xhci_pipe *)pipe;
	struct xhci_soft_dev *sdev = &sc->sc_sdevs[xp->slot];
	int i;

	/* Root Hub */
	if (pipe->device->depth == 0)
		return;

	/* Mask the endpoint */
	sdev->input_ctx->drop_flags = htole32(XHCI_INCTX_MASK_DCI(xp->dci));
	sdev->input_ctx->add_flags = 0;

	/* Update last valid Endpoint Context */
	for (i = 30; i >= 0; i--) {
		lxp = sdev->pipes[i];
		if (lxp != NULL && lxp != xp)
			break;
	}
	sdev->slot_ctx->info_lo = htole32(XHCI_SCTX_DCI(lxp->dci));

	/* Clear the Endpoint Context */
	memset(sdev->ep_ctx[xp->dci - 1], 0, sizeof(struct xhci_epctx));

	bus_dmamap_sync(sdev->ictx_dma.tag, sdev->ictx_dma.map, 0,
	    sc->sc_pagesize, BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);

	if (xhci_cmd_configure_ep(sc, xp->slot, sdev->ictx_dma.paddr))
		DPRINTF(("%s: error clearing ep (%d)\n", DEVNAME(sc), xp->dci));

	xhci_ring_free(sc, &xp->ring);
	sdev->pipes[xp->dci - 1] = NULL;

	/*
	 * If we are closing the default pipe, the device is probably
	 * gone, so put its slot in the DISABLED state.
	 */
	if (xp->dci == 1) {
		xhci_cmd_slot_control(sc, &xp->slot, 0);
		xhci_softdev_free(sc, xp->slot);
	}
}

/*
 * Transition a device from DEFAULT to ADDRESSED Slot state, this hook
 * is needed for Low/Full speed devices.
 *
 * See section 4.5.3 of USB 3.1 Specification for more details.
 */
int
xhci_setaddr(struct usbd_device *dev, int addr)
{
	struct xhci_softc *sc = (struct xhci_softc *)dev->bus;
	struct xhci_pipe *xp = (struct xhci_pipe *)dev->default_pipe;
	struct xhci_soft_dev *sdev = &sc->sc_sdevs[xp->slot];
	int error;

	/* Root Hub */
	if (dev->depth == 0)
		return (0);

	KASSERT(xp->dci == 1);

	xhci_context_setup(sc, dev->default_pipe);

	error = xhci_cmd_set_address(sc, xp->slot, sdev->ictx_dma.paddr, 0);

#ifdef XHCI_DEBUG
	if (error == 0) {
		struct xhci_sctx *sctx;
		uint8_t addr;

		bus_dmamap_sync(sdev->octx_dma.tag, sdev->octx_dma.map, 0,
		    sc->sc_pagesize, BUS_DMASYNC_POSTREAD);

		/* Get output slot context. */
		sctx = (struct xhci_sctx *)sdev->octx_dma.vaddr;
		addr = XHCI_SCTX_DEV_ADDR(letoh32(sctx->state));
		error = (addr == 0);

		printf("%s: dev %d addr %d\n", DEVNAME(sc), xp->slot, addr);
	}
#endif

	return (error);
}

struct usbd_xfer *
xhci_allocx(struct usbd_bus *bus)
{
	return (pool_get(xhcixfer, PR_NOWAIT | PR_ZERO));
}

void
xhci_freex(struct usbd_bus *bus, struct usbd_xfer *xfer)
{
	pool_put(xhcixfer, xfer);
}

int
xhci_scratchpad_alloc(struct xhci_softc *sc, int npage)
{
	uint64_t *pte;
	int error, i;

	/* Allocate the required entry for the table. */
	error = usbd_dma_contig_alloc(&sc->sc_bus, &sc->sc_spad.table_dma,
	    (void **)&pte, npage * sizeof(uint64_t), XHCI_SPAD_TABLE_ALIGN,
	    sc->sc_pagesize);
	if (error)
		return (ENOMEM);

	/* Allocate pages. XXX does not need to be contiguous. */
	error = usbd_dma_contig_alloc(&sc->sc_bus, &sc->sc_spad.pages_dma,
	    NULL, npage * sc->sc_pagesize, sc->sc_pagesize, 0);
	if (error) {
		usbd_dma_contig_free(&sc->sc_bus, &sc->sc_spad.table_dma);
		return (ENOMEM);
	}

	for (i = 0; i < npage; i++) {
		pte[i] = htole64(
		    sc->sc_spad.pages_dma.paddr + (i * sc->sc_pagesize)
		);
	}

	bus_dmamap_sync(sc->sc_spad.table_dma.tag, sc->sc_spad.table_dma.map, 0,
	    npage * sizeof(uint64_t), BUS_DMASYNC_PREREAD |
	    BUS_DMASYNC_PREWRITE);

	/*  Entry 0 points to the table of scratchpad pointers. */
	sc->sc_dcbaa.segs[0] = htole64(sc->sc_spad.table_dma.paddr);
	bus_dmamap_sync(sc->sc_dcbaa.dma.tag, sc->sc_dcbaa.dma.map, 0,
	    sizeof(uint64_t), BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);

	sc->sc_spad.npage = npage;

	return (0);
}

void
xhci_scratchpad_free(struct xhci_softc *sc)
{
	sc->sc_dcbaa.segs[0] = 0;
	bus_dmamap_sync(sc->sc_dcbaa.dma.tag, sc->sc_dcbaa.dma.map, 0,
	    sizeof(uint64_t), BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);

	usbd_dma_contig_free(&sc->sc_bus, &sc->sc_spad.pages_dma);
	usbd_dma_contig_free(&sc->sc_bus, &sc->sc_spad.table_dma);
}

int
xhci_ring_alloc(struct xhci_softc *sc, struct xhci_ring *ring, size_t ntrb,
    size_t alignment)
{
	size_t size;
	int error;

	size = ntrb * sizeof(struct xhci_trb);

	error = usbd_dma_contig_alloc(&sc->sc_bus, &ring->dma,
	    (void **)&ring->trbs, size, alignment, XHCI_RING_BOUNDARY);
	if (error)
		return (error);

	ring->ntrb = ntrb;

	xhci_ring_reset(sc, ring);

	return (0);
}

void
xhci_ring_free(struct xhci_softc *sc, struct xhci_ring *ring)
{
	usbd_dma_contig_free(&sc->sc_bus, &ring->dma);
}

void
xhci_ring_reset(struct xhci_softc *sc, struct xhci_ring *ring)
{
	size_t size;

	size = ring->ntrb * sizeof(struct xhci_trb);

	memset(ring->trbs, 0, size);

	ring->index = 0;
	ring->toggle = XHCI_TRB_CYCLE;

	/*
	 * Since all our rings use only one segment, at least for
	 * the moment, link their tail to their head.
	 */
	if (ring != &sc->sc_evt_ring) {
		struct xhci_trb *trb = &ring->trbs[ring->ntrb - 1];

		trb->trb_paddr = htole64(ring->dma.paddr);
		trb->trb_flags = htole32(XHCI_TRB_TYPE_LINK | XHCI_TRB_LINKSEG);
		bus_dmamap_sync(ring->dma.tag, ring->dma.map, 0, size,
		    BUS_DMASYNC_PREWRITE);
	} else
		bus_dmamap_sync(ring->dma.tag, ring->dma.map, 0, size,
		    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);
}

struct xhci_trb*
xhci_ring_consume(struct xhci_softc *sc, struct xhci_ring *ring)
{
	struct xhci_trb *trb = &ring->trbs[ring->index];

	KASSERT(ring->index < ring->ntrb);

	bus_dmamap_sync(ring->dma.tag, ring->dma.map, TRBOFF(ring, trb),
	    sizeof(struct xhci_trb), BUS_DMASYNC_POSTREAD);

	/* Make sure this TRB can be consumed. */
	if (ring->toggle != (letoh32(trb->trb_flags) & XHCI_TRB_CYCLE))
		return (NULL);

	ring->index++;

	if (ring->index == ring->ntrb) {
		ring->index = 0;
		ring->toggle ^= 1;
	}

	return (trb);
}

struct xhci_trb*
xhci_ring_produce(struct xhci_softc *sc, struct xhci_ring *ring)
{
	struct xhci_trb *trb = &ring->trbs[ring->index];

	KASSERT(ring->index < ring->ntrb);

	bus_dmamap_sync(ring->dma.tag, ring->dma.map, TRBOFF(ring, trb),
	    sizeof(struct xhci_trb), BUS_DMASYNC_POSTREAD |
	    BUS_DMASYNC_POSTWRITE);

	ring->index++;

	/* Toggle cycle state of the link TRB and skip it. */
	if (ring->index == (ring->ntrb - 1)) {
		struct xhci_trb *lnk = &ring->trbs[ring->index];

		bus_dmamap_sync(ring->dma.tag, ring->dma.map, TRBOFF(ring, lnk),
		    sizeof(struct xhci_trb), BUS_DMASYNC_POSTREAD |
		    BUS_DMASYNC_POSTWRITE);

		lnk->trb_flags ^= htole32(XHCI_TRB_CYCLE);

		bus_dmamap_sync(ring->dma.tag, ring->dma.map, TRBOFF(ring, lnk),
		    sizeof(struct xhci_trb), BUS_DMASYNC_PREWRITE);

		ring->index = 0;
		ring->toggle ^= 1;
	}

	return (trb);
}

struct xhci_trb *
xhci_xfer_get_trb(struct xhci_softc *sc, struct usbd_xfer *xfer,
    uint8_t *togglep, int last)
{
	struct xhci_pipe *xp = (struct xhci_pipe *)xfer->pipe;
	struct xhci_xfer *xx = (struct xhci_xfer *)xfer;

	KASSERT(xp->free_trbs >= 1);

	/* Associate this TRB to our xfer. */
	xp->pending_xfers[xp->ring.index] = xfer;
	xp->free_trbs--;

	xx->index = (last) ? xp->ring.index : -2;
	xx->ntrb += 1;

	*togglep = xp->ring.toggle;
	return (xhci_ring_produce(sc, &xp->ring));
}

int
xhci_command_submit(struct xhci_softc *sc, struct xhci_trb *trb0, int timeout)
{
	struct xhci_trb *trb;
	int s, error = 0;

	KASSERT(timeout == 0 || sc->sc_cmd_trb == NULL);

	trb0->trb_flags |= htole32(sc->sc_cmd_ring.toggle);

	trb = xhci_ring_produce(sc, &sc->sc_cmd_ring);
	if (trb == NULL)
		return (EAGAIN);
	memcpy(trb, trb0, sizeof(struct xhci_trb));
	bus_dmamap_sync(sc->sc_cmd_ring.dma.tag, sc->sc_cmd_ring.dma.map,
	    TRBOFF(&sc->sc_cmd_ring, trb), sizeof(struct xhci_trb),
	    BUS_DMASYNC_PREWRITE);


	if (timeout == 0) {
		XDWRITE4(sc, XHCI_DOORBELL(0), 0);
		return (0);
	}

	assertwaitok();

	s = splusb();
	sc->sc_cmd_trb = trb;
	XDWRITE4(sc, XHCI_DOORBELL(0), 0);
	error = tsleep(&sc->sc_cmd_trb, PZERO, "xhcicmd",
	    (timeout*hz+999)/ 1000 + 1);
	if (error) {
#ifdef XHCI_DEBUG
		printf("%s: tsleep() = %d\n", __func__, error);
		printf("cmd = %d ", XHCI_TRB_TYPE(letoh32(trb->trb_flags)));
		xhci_dump_trb(trb);
#endif
		KASSERT(sc->sc_cmd_trb == trb);
		sc->sc_cmd_trb = NULL;
		splx(s);
		return (error);
	}
	splx(s);

	memcpy(trb0, &sc->sc_result_trb, sizeof(struct xhci_trb));

	if (XHCI_TRB_GET_CODE(letoh32(trb0->trb_status)) == XHCI_CODE_SUCCESS)
		return (0);

#ifdef XHCI_DEBUG
	printf("%s: event error code=%d, result=%d  \n", DEVNAME(sc),
	    XHCI_TRB_GET_CODE(letoh32(trb0->trb_status)),
	    XHCI_TRB_TYPE(letoh32(trb0->trb_flags)));
	xhci_dump_trb(trb0);
#endif
	return (EIO);
}

int
xhci_command_abort(struct xhci_softc *sc)
{
	uint32_t reg;
	int i;

	reg = XOREAD4(sc, XHCI_CRCR_LO);
	if ((reg & XHCI_CRCR_LO_CRR) == 0)
		return (0);

	XOWRITE4(sc, XHCI_CRCR_LO, reg | XHCI_CRCR_LO_CA);
	XOWRITE4(sc, XHCI_CRCR_HI, 0);

	for (i = 0; i < 250; i++) {
		usb_delay_ms(&sc->sc_bus, 1);
		reg = XOREAD4(sc, XHCI_CRCR_LO) & XHCI_CRCR_LO_CRR;
		if (!reg)
			break;
	}

	if (reg) {
		printf("%s: command ring abort timeout\n", DEVNAME(sc));
		return (1);
	}

	return (0);
}

int
xhci_cmd_configure_ep(struct xhci_softc *sc, uint8_t slot, uint64_t addr)
{
	struct xhci_trb trb;

	DPRINTF(("%s: %s dev %u\n", DEVNAME(sc), __func__, slot));

	trb.trb_paddr = htole64(addr);
	trb.trb_status = 0;
	trb.trb_flags = htole32(
	    XHCI_TRB_SET_SLOT(slot) | XHCI_CMD_CONFIG_EP
	);

	return (xhci_command_submit(sc, &trb, XHCI_CMD_TIMEOUT));
}

int
xhci_cmd_stop_ep(struct xhci_softc *sc, uint8_t slot, uint8_t dci)
{
	struct xhci_trb trb;

	DPRINTF(("%s: %s dev %u dci %u\n", DEVNAME(sc), __func__, slot, dci));

	trb.trb_paddr = 0;
	trb.trb_status = 0;
	trb.trb_flags = htole32(
	    XHCI_TRB_SET_SLOT(slot) | XHCI_TRB_SET_EP(dci) | XHCI_CMD_STOP_EP
	);

	return (xhci_command_submit(sc, &trb, XHCI_CMD_TIMEOUT));
}

void
xhci_cmd_reset_ep_async(struct xhci_softc *sc, uint8_t slot, uint8_t dci)
{
	struct xhci_trb trb;

	DPRINTF(("%s: %s dev %u dci %u\n", DEVNAME(sc), __func__, slot, dci));

	trb.trb_paddr = 0;
	trb.trb_status = 0;
	trb.trb_flags = htole32(
	    XHCI_TRB_SET_SLOT(slot) | XHCI_TRB_SET_EP(dci) | XHCI_CMD_RESET_EP
	);

	xhci_command_submit(sc, &trb, 0);
}

void
xhci_cmd_set_tr_deq_async(struct xhci_softc *sc, uint8_t slot, uint8_t dci,
   uint64_t addr)
{
	struct xhci_trb trb;

	DPRINTF(("%s: %s dev %u dci %u\n", DEVNAME(sc), __func__, slot, dci));

	trb.trb_paddr = htole64(addr);
	trb.trb_status = 0;
	trb.trb_flags = htole32(
	    XHCI_TRB_SET_SLOT(slot) | XHCI_TRB_SET_EP(dci) | XHCI_CMD_SET_TR_DEQ
	);

	xhci_command_submit(sc, &trb, 0);
}

int
xhci_cmd_slot_control(struct xhci_softc *sc, uint8_t *slotp, int enable)
{
	struct xhci_trb trb;

	DPRINTF(("%s: %s\n", DEVNAME(sc), __func__));

	trb.trb_paddr = 0;
	trb.trb_status = 0;
	if (enable)
		trb.trb_flags = htole32(XHCI_CMD_ENABLE_SLOT);
	else
		trb.trb_flags = htole32(
			XHCI_TRB_SET_SLOT(*slotp) | XHCI_CMD_DISABLE_SLOT
		);

	if (xhci_command_submit(sc, &trb, XHCI_CMD_TIMEOUT))
		return (EIO);

	if (enable)
		*slotp = XHCI_TRB_GET_SLOT(letoh32(trb.trb_flags));

	return (0);
}

int
xhci_cmd_set_address(struct xhci_softc *sc, uint8_t slot, uint64_t addr,
    uint32_t bsr)
{
	struct xhci_trb trb;

	DPRINTF(("%s: %s BSR=%u\n", DEVNAME(sc), __func__, bsr ? 1 : 0));

	trb.trb_paddr = htole64(addr);
	trb.trb_status = 0;
	trb.trb_flags = htole32(
	    XHCI_TRB_SET_SLOT(slot) | XHCI_CMD_ADDRESS_DEVICE | bsr
	);

	return (xhci_command_submit(sc, &trb, XHCI_CMD_TIMEOUT));
}

int
xhci_cmd_evaluate_ctx(struct xhci_softc *sc, uint8_t slot, uint64_t addr)
{
	struct xhci_trb trb;

	DPRINTF(("%s: %s dev %u\n", DEVNAME(sc), __func__, slot));

	trb.trb_paddr = htole64(addr);
	trb.trb_status = 0;
	trb.trb_flags = htole32(
	    XHCI_TRB_SET_SLOT(slot) | XHCI_CMD_EVAL_CTX
	);

	return (xhci_command_submit(sc, &trb, XHCI_CMD_TIMEOUT));
}

#ifdef XHCI_DEBUG
int
xhci_cmd_noop(struct xhci_softc *sc)
{
	struct xhci_trb trb;

	DPRINTF(("%s: %s\n", DEVNAME(sc), __func__));

	trb.trb_paddr = 0;
	trb.trb_status = 0;
	trb.trb_flags = htole32(XHCI_CMD_NOOP);

	return (xhci_command_submit(sc, &trb, XHCI_CMD_TIMEOUT));
}
#endif

int
xhci_softdev_alloc(struct xhci_softc *sc, uint8_t slot)
{
	struct xhci_soft_dev *sdev = &sc->sc_sdevs[slot];
	int i, error;
	uint8_t *kva;

	/*
	 * Setup input context.  Even with 64 byte context size, it
	 * fits into the smallest supported page size, so use that.
	 */
	error = usbd_dma_contig_alloc(&sc->sc_bus, &sdev->ictx_dma,
	    (void **)&kva, sc->sc_pagesize, XHCI_ICTX_ALIGN, sc->sc_pagesize);
	if (error)
		return (ENOMEM);

	sdev->input_ctx = (struct xhci_inctx *)kva;
	sdev->slot_ctx = (struct xhci_sctx *)(kva + sc->sc_ctxsize);
	for (i = 0; i < 31; i++)
		sdev->ep_ctx[i] =
		    (struct xhci_epctx *)(kva + (i + 2) * sc->sc_ctxsize);

	DPRINTF(("%s: dev %d, input=%p slot=%p ep0=%p\n", DEVNAME(sc),
	 slot, sdev->input_ctx, sdev->slot_ctx, sdev->ep_ctx[0]));

	/* Setup output context */
	error = usbd_dma_contig_alloc(&sc->sc_bus, &sdev->octx_dma, NULL,
	    sc->sc_pagesize, XHCI_OCTX_ALIGN, sc->sc_pagesize);
	if (error) {
		usbd_dma_contig_free(&sc->sc_bus, &sdev->ictx_dma);
		return (ENOMEM);
	}

	memset(&sdev->pipes, 0, sizeof(sdev->pipes));

	DPRINTF(("%s: dev %d, setting DCBAA to 0x%016llx\n", DEVNAME(sc),
	    slot, (long long)sdev->octx_dma.paddr));

	sc->sc_dcbaa.segs[slot] = htole64(sdev->octx_dma.paddr);
	bus_dmamap_sync(sc->sc_dcbaa.dma.tag, sc->sc_dcbaa.dma.map,
	    slot * sizeof(uint64_t), sizeof(uint64_t), BUS_DMASYNC_PREREAD |
	    BUS_DMASYNC_PREWRITE);

	return (0);
}

void
xhci_softdev_free(struct xhci_softc *sc, uint8_t slot)
{
	struct xhci_soft_dev *sdev = &sc->sc_sdevs[slot];

	sc->sc_dcbaa.segs[slot] = 0;
	bus_dmamap_sync(sc->sc_dcbaa.dma.tag, sc->sc_dcbaa.dma.map,
	    slot * sizeof(uint64_t), sizeof(uint64_t), BUS_DMASYNC_PREREAD |
	    BUS_DMASYNC_PREWRITE);

	usbd_dma_contig_free(&sc->sc_bus, &sdev->octx_dma);
	usbd_dma_contig_free(&sc->sc_bus, &sdev->ictx_dma);

	memset(sdev, 0, sizeof(struct xhci_soft_dev));
}

/* Root hub descriptors. */
usb_device_descriptor_t xhci_devd = {
	USB_DEVICE_DESCRIPTOR_SIZE,
	UDESC_DEVICE,		/* type */
	{0x00, 0x03},		/* USB version */
	UDCLASS_HUB,		/* class */
	UDSUBCLASS_HUB,		/* subclass */
	UDPROTO_HSHUBSTT,	/* protocol */
	9,			/* max packet */
	{0},{0},{0x00,0x01},	/* device id */
	1,2,0,			/* string indexes */
	1			/* # of configurations */
};

const usb_config_descriptor_t xhci_confd = {
	USB_CONFIG_DESCRIPTOR_SIZE,
	UDESC_CONFIG,
	{USB_CONFIG_DESCRIPTOR_SIZE +
	 USB_INTERFACE_DESCRIPTOR_SIZE +
	 USB_ENDPOINT_DESCRIPTOR_SIZE},
	1,
	1,
	0,
	UC_SELF_POWERED,
	0                      /* max power */
};

const usb_interface_descriptor_t xhci_ifcd = {
	USB_INTERFACE_DESCRIPTOR_SIZE,
	UDESC_INTERFACE,
	0,
	0,
	1,
	UICLASS_HUB,
	UISUBCLASS_HUB,
	UIPROTO_HSHUBSTT,
	0
};

const usb_endpoint_descriptor_t xhci_endpd = {
	USB_ENDPOINT_DESCRIPTOR_SIZE,
	UDESC_ENDPOINT,
	UE_DIR_IN | XHCI_INTR_ENDPT,
	UE_INTERRUPT,
	{2, 0},                 /* max 15 ports */
	255
};

const usb_endpoint_ss_comp_descriptor_t xhci_endpcd = {
	USB_ENDPOINT_SS_COMP_DESCRIPTOR_SIZE,
	UDESC_ENDPOINT_SS_COMP,
	0,
	0,
	{0, 0}
};

const usb_hub_descriptor_t xhci_hubd = {
	USB_HUB_DESCRIPTOR_SIZE,
	UDESC_SS_HUB,
	0,
	{0,0},
	0,
	0,
	{0},
};

void
xhci_abort_xfer(struct usbd_xfer *xfer, usbd_status status)
{
	struct xhci_softc *sc = (struct xhci_softc *)xfer->device->bus;
	struct xhci_pipe *xp = (struct xhci_pipe *)xfer->pipe;
	int error;

	splsoftassert(IPL_SOFTUSB);

	DPRINTF(("%s: xfer=%p status=%s err=%s actlen=%d len=%d idx=%d\n",
	    __func__, xfer, usbd_errstr(xfer->status), usbd_errstr(status),
	    xfer->actlen, xfer->length, ((struct xhci_xfer *)xfer)->index));

	/* XXX The stack should not call abort() in this case. */
	if (sc->sc_bus.dying || xfer->status == USBD_NOT_STARTED) {
		xfer->status = status;
		timeout_del(&xfer->timeout_handle);
		usb_rem_task(xfer->device, &xfer->abort_task);
		usb_transfer_complete(xfer);
		return;
	}

	/* Transfer is already done. */
	if (xfer->status != USBD_IN_PROGRESS) {
		DPRINTF(("%s: already done \n", __func__));
		return;
	}

	/* Prevent any timeout to kick in. */
	timeout_del(&xfer->timeout_handle);
	usb_rem_task(xfer->device, &xfer->abort_task);

	/* Indicate that we are aborting this transfer. */
	xp->halted = status;
	xp->aborted_xfer = xfer;

	/* Stop the endpoint and wait until the hardware says so. */
	if (xhci_cmd_stop_ep(sc, xp->slot, xp->dci))
		DPRINTF(("%s: error stopping endpoint\n", DEVNAME(sc)));

	/*
	 * The transfer was already completed when we stopped the
	 * endpoint, no need to move the dequeue pointer past its
	 * TRBs.
	 */
	if (xp->aborted_xfer == NULL) {
		DPRINTF(("%s: done before stopping the endpoint\n", __func__));
		xp->halted = 0;
		return;
	}

	/*
	 * At this stage the endpoint has been stopped, so update its
	 * dequeue pointer past the last TRB of the transfer.
	 *
	 * Note: This assume that only one transfer per endpoint has
	 *	 pending TRBs on the ring.
	 */
	xhci_cmd_set_tr_deq_async(sc, xp->slot, xp->dci,
	    DEQPTR(xp->ring) | xp->ring.toggle);
	error = tsleep(xp, PZERO, "xhciab", (XHCI_CMD_TIMEOUT*hz+999)/1000 + 1);
	if (error)
		printf("%s: timeout aborting transfer\n", DEVNAME(sc));
}

void
xhci_timeout(void *addr)
{
	struct usbd_xfer *xfer = addr;
	struct xhci_softc *sc = (struct xhci_softc *)xfer->device->bus;

	if (sc->sc_bus.dying) {
		xhci_timeout_task(addr);
		return;
	}

	usb_init_task(&xfer->abort_task, xhci_timeout_task, addr,
	    USB_TASK_TYPE_ABORT);
	usb_add_task(xfer->device, &xfer->abort_task);
}

void
xhci_timeout_task(void *addr)
{
	struct usbd_xfer *xfer = addr;
	int s;

	s = splusb();
	xhci_abort_xfer(xfer, USBD_TIMEOUT);
	splx(s);
}

usbd_status
xhci_root_ctrl_transfer(struct usbd_xfer *xfer)
{
	usbd_status err;

	err = usb_insert_transfer(xfer);
	if (err)
		return (err);

	return (xhci_root_ctrl_start(SIMPLEQ_FIRST(&xfer->pipe->queue)));
}

usbd_status
xhci_root_ctrl_start(struct usbd_xfer *xfer)
{
	struct xhci_softc *sc = (struct xhci_softc *)xfer->device->bus;
	usb_port_status_t ps;
	usb_device_request_t *req;
	void *buf = NULL;
	usb_hub_descriptor_t hubd;
	usbd_status err;
	int s, len, value, index;
	int l, totlen = 0;
	int port, i;
	uint32_t v;

	KASSERT(xfer->rqflags & URQ_REQUEST);

	if (sc->sc_bus.dying)
		return (USBD_IOERROR);

	req = &xfer->request;

	DPRINTFN(4,("%s: type=0x%02x request=%02x\n", __func__,
	    req->bmRequestType, req->bRequest));

	len = UGETW(req->wLength);
	value = UGETW(req->wValue);
	index = UGETW(req->wIndex);

	if (len != 0)
		buf = KERNADDR(&xfer->dmabuf, 0);

#define C(x,y) ((x) | ((y) << 8))
	switch(C(req->bRequest, req->bmRequestType)) {
	case C(UR_CLEAR_FEATURE, UT_WRITE_DEVICE):
	case C(UR_CLEAR_FEATURE, UT_WRITE_INTERFACE):
	case C(UR_CLEAR_FEATURE, UT_WRITE_ENDPOINT):
		/*
		 * DEVICE_REMOTE_WAKEUP and ENDPOINT_HALT are no-ops
		 * for the integrated root hub.
		 */
		break;
	case C(UR_GET_CONFIG, UT_READ_DEVICE):
		if (len > 0) {
			*(uint8_t *)buf = sc->sc_conf;
			totlen = 1;
		}
		break;
	case C(UR_GET_DESCRIPTOR, UT_READ_DEVICE):
		DPRINTFN(8,("xhci_root_ctrl_start: wValue=0x%04x\n", value));
		switch(value >> 8) {
		case UDESC_DEVICE:
			if ((value & 0xff) != 0) {
				err = USBD_IOERROR;
				goto ret;
			}
			totlen = l = min(len, USB_DEVICE_DESCRIPTOR_SIZE);
			USETW(xhci_devd.idVendor, sc->sc_id_vendor);
			memcpy(buf, &xhci_devd, l);
			break;
		/*
		 * We can't really operate at another speed, but the spec says
		 * we need this descriptor.
		 */
		case UDESC_OTHER_SPEED_CONFIGURATION:
		case UDESC_CONFIG:
			if ((value & 0xff) != 0) {
				err = USBD_IOERROR;
				goto ret;
			}
			totlen = l = min(len, USB_CONFIG_DESCRIPTOR_SIZE);
			memcpy(buf, &xhci_confd, l);
			((usb_config_descriptor_t *)buf)->bDescriptorType =
			    value >> 8;
			buf = (char *)buf + l;
			len -= l;
			l = min(len, USB_INTERFACE_DESCRIPTOR_SIZE);
			totlen += l;
			memcpy(buf, &xhci_ifcd, l);
			buf = (char *)buf + l;
			len -= l;
			l = min(len, USB_ENDPOINT_DESCRIPTOR_SIZE);
			totlen += l;
			memcpy(buf, &xhci_endpd, l);
			break;
		case UDESC_STRING:
			if (len == 0)
				break;
			*(u_int8_t *)buf = 0;
			totlen = 1;
			switch (value & 0xff) {
			case 0: /* Language table */
				totlen = usbd_str(buf, len, "\001");
				break;
			case 1: /* Vendor */
				totlen = usbd_str(buf, len, sc->sc_vendor);
				break;
			case 2: /* Product */
				totlen = usbd_str(buf, len, "xHCI root hub");
				break;
			}
			break;
		default:
			err = USBD_IOERROR;
			goto ret;
		}
		break;
	case C(UR_GET_INTERFACE, UT_READ_INTERFACE):
		if (len > 0) {
			*(uint8_t *)buf = 0;
			totlen = 1;
		}
		break;
	case C(UR_GET_STATUS, UT_READ_DEVICE):
		if (len > 1) {
			USETW(((usb_status_t *)buf)->wStatus,UDS_SELF_POWERED);
			totlen = 2;
		}
		break;
	case C(UR_GET_STATUS, UT_READ_INTERFACE):
	case C(UR_GET_STATUS, UT_READ_ENDPOINT):
		if (len > 1) {
			USETW(((usb_status_t *)buf)->wStatus, 0);
			totlen = 2;
		}
		break;
	case C(UR_SET_ADDRESS, UT_WRITE_DEVICE):
		if (value >= USB_MAX_DEVICES) {
			err = USBD_IOERROR;
			goto ret;
		}
		break;
	case C(UR_SET_CONFIG, UT_WRITE_DEVICE):
		if (value != 0 && value != 1) {
			err = USBD_IOERROR;
			goto ret;
		}
		sc->sc_conf = value;
		break;
	case C(UR_SET_DESCRIPTOR, UT_WRITE_DEVICE):
		break;
	case C(UR_SET_FEATURE, UT_WRITE_DEVICE):
	case C(UR_SET_FEATURE, UT_WRITE_INTERFACE):
	case C(UR_SET_FEATURE, UT_WRITE_ENDPOINT):
		err = USBD_IOERROR;
		goto ret;
	case C(UR_SET_INTERFACE, UT_WRITE_INTERFACE):
		break;
	case C(UR_SYNCH_FRAME, UT_WRITE_ENDPOINT):
		break;
	/* Hub requests */
	case C(UR_CLEAR_FEATURE, UT_WRITE_CLASS_DEVICE):
		break;
	case C(UR_CLEAR_FEATURE, UT_WRITE_CLASS_OTHER):
		DPRINTFN(8, ("xhci_root_ctrl_start: UR_CLEAR_PORT_FEATURE "
		    "port=%d feature=%d\n", index, value));
		if (index < 1 || index > sc->sc_noport) {
			err = USBD_IOERROR;
			goto ret;
		}
		port = XHCI_PORTSC(index);
		v = XOREAD4(sc, port) & ~XHCI_PS_CLEAR;
		switch (value) {
		case UHF_PORT_ENABLE:
			XOWRITE4(sc, port, v | XHCI_PS_PED);
			break;
		case UHF_PORT_SUSPEND:
			/* TODO */
			break;
		case UHF_PORT_POWER:
			XOWRITE4(sc, port, v & ~XHCI_PS_PP);
			break;
		case UHF_PORT_INDICATOR:
			XOWRITE4(sc, port, v & ~XHCI_PS_SET_PIC(3));
			break;
		case UHF_C_PORT_CONNECTION:
			XOWRITE4(sc, port, v | XHCI_PS_CSC);
			break;
		case UHF_C_PORT_ENABLE:
			XOWRITE4(sc, port, v | XHCI_PS_PEC);
			break;
		case UHF_C_PORT_SUSPEND:
		case UHF_C_PORT_LINK_STATE:
			XOWRITE4(sc, port, v | XHCI_PS_PLC);
			break;
		case UHF_C_PORT_OVER_CURRENT:
			XOWRITE4(sc, port, v | XHCI_PS_OCC);
			break;
		case UHF_C_PORT_RESET:
			XOWRITE4(sc, port, v | XHCI_PS_PRC);
			break;
		case UHF_C_BH_PORT_RESET:
			XOWRITE4(sc, port, v | XHCI_PS_WRC);
			break;
		default:
			err = USBD_IOERROR;
			goto ret;
		}
		break;

	case C(UR_GET_DESCRIPTOR, UT_READ_CLASS_DEVICE):
		if (len == 0)
			break;
		if ((value & 0xff) != 0) {
			err = USBD_IOERROR;
			goto ret;
		}
		v = XREAD4(sc, XHCI_HCCPARAMS);
		hubd = xhci_hubd;
		hubd.bNbrPorts = sc->sc_noport;
		USETW(hubd.wHubCharacteristics,
		    (XHCI_HCC_PPC(v) ? UHD_PWR_INDIVIDUAL : UHD_PWR_GANGED) |
		    (XHCI_HCC_PIND(v) ? UHD_PORT_IND : 0));
		hubd.bPwrOn2PwrGood = 10; /* xHCI section 5.4.9 */
		for (i = 1; i <= sc->sc_noport; i++) {
			v = XOREAD4(sc, XHCI_PORTSC(i));
			if (v & XHCI_PS_DR)
				hubd.DeviceRemovable[i / 8] |= 1U << (i % 8);
		}
		hubd.bDescLength = USB_HUB_DESCRIPTOR_SIZE + i;
		l = min(len, hubd.bDescLength);
		totlen = l;
		memcpy(buf, &hubd, l);
		break;
	case C(UR_GET_STATUS, UT_READ_CLASS_DEVICE):
		if (len != 16) {
			err = USBD_IOERROR;
			goto ret;
		}
		memset(buf, 0, len);
		totlen = len;
		break;
	case C(UR_GET_STATUS, UT_READ_CLASS_OTHER):
		DPRINTFN(8,("xhci_root_ctrl_start: get port status i=%d\n",
		    index));
		if (index < 1 || index > sc->sc_noport) {
			err = USBD_IOERROR;
			goto ret;
		}
		if (len != 4) {
			err = USBD_IOERROR;
			goto ret;
		}
		v = XOREAD4(sc, XHCI_PORTSC(index));
		DPRINTFN(8,("xhci_root_ctrl_start: port status=0x%04x\n", v));
		i = UPS_PORT_LS_SET(XHCI_PS_GET_PLS(v));
		switch (XHCI_PS_SPEED(v)) {
		case XHCI_SPEED_FULL:
			i |= UPS_FULL_SPEED;
			break;
		case XHCI_SPEED_LOW:
			i |= UPS_LOW_SPEED;
			break;
		case XHCI_SPEED_HIGH:
			i |= UPS_HIGH_SPEED;
			break;
		case XHCI_SPEED_SUPER:
		default:
			break;
		}
		if (v & XHCI_PS_CCS)	i |= UPS_CURRENT_CONNECT_STATUS;
		if (v & XHCI_PS_PED)	i |= UPS_PORT_ENABLED;
		if (v & XHCI_PS_OCA)	i |= UPS_OVERCURRENT_INDICATOR;
		if (v & XHCI_PS_PR)	i |= UPS_RESET;
		if (v & XHCI_PS_PP)	{
			if (XHCI_PS_SPEED(v) >= XHCI_SPEED_FULL &&
			    XHCI_PS_SPEED(v) <= XHCI_SPEED_HIGH)
				i |= UPS_PORT_POWER;
			else
				i |= UPS_PORT_POWER_SS;
		}
		USETW(ps.wPortStatus, i);
		i = 0;
		if (v & XHCI_PS_CSC)    i |= UPS_C_CONNECT_STATUS;
		if (v & XHCI_PS_PEC)    i |= UPS_C_PORT_ENABLED;
		if (v & XHCI_PS_OCC)    i |= UPS_C_OVERCURRENT_INDICATOR;
		if (v & XHCI_PS_PRC)	i |= UPS_C_PORT_RESET;
		if (v & XHCI_PS_WRC)	i |= UPS_C_BH_PORT_RESET;
		if (v & XHCI_PS_PLC)	i |= UPS_C_PORT_LINK_STATE;
		if (v & XHCI_PS_CEC)	i |= UPS_C_PORT_CONFIG_ERROR;
		USETW(ps.wPortChange, i);
		l = min(len, sizeof ps);
		memcpy(buf, &ps, l);
		totlen = l;
		break;
	case C(UR_SET_DESCRIPTOR, UT_WRITE_CLASS_DEVICE):
		err = USBD_IOERROR;
		goto ret;
	case C(UR_SET_FEATURE, UT_WRITE_CLASS_DEVICE):
		break;
	case C(UR_SET_FEATURE, UT_WRITE_CLASS_OTHER):

		i = index >> 8;
		index &= 0x00ff;

		if (index < 1 || index > sc->sc_noport) {
			err = USBD_IOERROR;
			goto ret;
		}
		port = XHCI_PORTSC(index);
		v = XOREAD4(sc, port) & ~XHCI_PS_CLEAR;

		switch (value) {
		case UHF_PORT_ENABLE:
			XOWRITE4(sc, port, v | XHCI_PS_PED);
			break;
		case UHF_PORT_SUSPEND:
			DPRINTFN(6, ("suspend port %u (LPM=%u)\n", index, i));
			if (XHCI_PS_SPEED(v) == XHCI_SPEED_SUPER) {
				err = USBD_IOERROR;
				goto ret;
			}
			XOWRITE4(sc, port, v |
			    XHCI_PS_SET_PLS(i ? 2 /* LPM */ : 3) | XHCI_PS_LWS);
			break;
		case UHF_PORT_RESET:
			DPRINTFN(6, ("reset port %d\n", index));
			XOWRITE4(sc, port, v | XHCI_PS_PR);
			break;
		case UHF_PORT_POWER:
			DPRINTFN(3, ("set port power %d\n", index));
			XOWRITE4(sc, port, v | XHCI_PS_PP);
			break;
		case UHF_PORT_INDICATOR:
			DPRINTFN(3, ("set port indicator %d\n", index));

			v &= ~XHCI_PS_SET_PIC(3);
			v |= XHCI_PS_SET_PIC(1);

			XOWRITE4(sc, port, v);
			break;
		case UHF_C_PORT_RESET:
			XOWRITE4(sc, port, v | XHCI_PS_PRC);
			break;
		case UHF_C_BH_PORT_RESET:
			XOWRITE4(sc, port, v | XHCI_PS_WRC);
			break;
		default:
			err = USBD_IOERROR;
			goto ret;
		}
		break;
	case C(UR_CLEAR_TT_BUFFER, UT_WRITE_CLASS_OTHER):
	case C(UR_RESET_TT, UT_WRITE_CLASS_OTHER):
	case C(UR_GET_TT_STATE, UT_READ_CLASS_OTHER):
	case C(UR_STOP_TT, UT_WRITE_CLASS_OTHER):
		break;
	default:
		err = USBD_IOERROR;
		goto ret;
	}
	xfer->actlen = totlen;
	err = USBD_NORMAL_COMPLETION;
ret:
	xfer->status = err;
	s = splusb();
	usb_transfer_complete(xfer);
	splx(s);
	return (err);
}


void
xhci_noop(struct usbd_xfer *xfer)
{
}


usbd_status
xhci_root_intr_transfer(struct usbd_xfer *xfer)
{
	usbd_status err;

	err = usb_insert_transfer(xfer);
	if (err)
		return (err);

	return (xhci_root_intr_start(SIMPLEQ_FIRST(&xfer->pipe->queue)));
}

usbd_status
xhci_root_intr_start(struct usbd_xfer *xfer)
{
	struct xhci_softc *sc = (struct xhci_softc *)xfer->device->bus;

	if (sc->sc_bus.dying)
		return (USBD_IOERROR);

	sc->sc_intrxfer = xfer;

	return (USBD_IN_PROGRESS);
}

void
xhci_root_intr_abort(struct usbd_xfer *xfer)
{
	struct xhci_softc *sc = (struct xhci_softc *)xfer->device->bus;
	int s;

	sc->sc_intrxfer = NULL;

	xfer->status = USBD_CANCELLED;
	s = splusb();
	usb_transfer_complete(xfer);
	splx(s);
}

void
xhci_root_intr_done(struct usbd_xfer *xfer)
{
}

/* Number of packets remaining in the TD after the corresponding TRB. */
static inline uint32_t
xhci_xfer_tdsize(struct usbd_xfer *xfer, uint32_t remain, uint32_t len)
{
	uint32_t npkt, mps = UGETW(xfer->pipe->endpoint->edesc->wMaxPacketSize);

	if (len == 0)
		return XHCI_TRB_TDREM(0);

	npkt = (remain - len) / mps;
	if (npkt > 31)
		npkt = 31;

	return XHCI_TRB_TDREM(npkt);
}

usbd_status
xhci_device_ctrl_transfer(struct usbd_xfer *xfer)
{
	usbd_status err;

	err = usb_insert_transfer(xfer);
	if (err)
		return (err);

	return (xhci_device_ctrl_start(SIMPLEQ_FIRST(&xfer->pipe->queue)));
}

usbd_status
xhci_device_ctrl_start(struct usbd_xfer *xfer)
{
	struct xhci_softc *sc = (struct xhci_softc *)xfer->device->bus;
	struct xhci_pipe *xp = (struct xhci_pipe *)xfer->pipe;
	struct xhci_trb *trb0, *trb;
	uint32_t flags, len = UGETW(xfer->request.wLength);
	uint8_t toggle0, toggle;
	int s;

	KASSERT(xfer->rqflags & URQ_REQUEST);

	if (sc->sc_bus.dying || xp->halted)
		return (USBD_IOERROR);

	if (xp->free_trbs < 3)
		return (USBD_NOMEM);

	/* We'll do the setup TRB once we're finished with the other stages. */
	trb0 = xhci_xfer_get_trb(sc, xfer, &toggle0, 0);

	/* Data TRB */
	if (len != 0) {
		trb = xhci_xfer_get_trb(sc, xfer, &toggle, 0);

		flags = XHCI_TRB_TYPE_DATA | toggle;
		if (usbd_xfer_isread(xfer))
			flags |= XHCI_TRB_DIR_IN | XHCI_TRB_ISP;

		trb->trb_paddr = htole64(DMAADDR(&xfer->dmabuf, 0));
		trb->trb_status = htole32(
		    XHCI_TRB_INTR(0) | XHCI_TRB_LEN(len) |
		    xhci_xfer_tdsize(xfer, len, len)
		);
		trb->trb_flags = htole32(flags);

		bus_dmamap_sync(xp->ring.dma.tag, xp->ring.dma.map,
		    TRBOFF(&xp->ring, trb), sizeof(struct xhci_trb),
		    BUS_DMASYNC_PREWRITE);
	}

	/* Status TRB */
	trb = xhci_xfer_get_trb(sc, xfer, &toggle, 1);

	flags = XHCI_TRB_TYPE_STATUS | XHCI_TRB_IOC | toggle;
	if (len == 0 || !usbd_xfer_isread(xfer))
		flags |= XHCI_TRB_DIR_IN;

	trb->trb_paddr = 0;
	trb->trb_status = htole32(XHCI_TRB_INTR(0));
	trb->trb_flags = htole32(flags);

	bus_dmamap_sync(xp->ring.dma.tag, xp->ring.dma.map,
	    TRBOFF(&xp->ring, trb), sizeof(struct xhci_trb),
	    BUS_DMASYNC_PREWRITE);

	/* Setup TRB */
	flags = XHCI_TRB_TYPE_SETUP | XHCI_TRB_IDT | toggle0;
	if (len != 0) {
		if (usbd_xfer_isread(xfer))
			flags |= XHCI_TRB_TRT_IN;
		else
			flags |= XHCI_TRB_TRT_OUT;
	}

	trb0->trb_paddr = (uint64_t)*((uint64_t *)&xfer->request);
	trb0->trb_status = htole32(XHCI_TRB_INTR(0) | XHCI_TRB_LEN(8));
	trb0->trb_flags = htole32(flags);

	bus_dmamap_sync(xp->ring.dma.tag, xp->ring.dma.map,
	    TRBOFF(&xp->ring, trb0), sizeof(struct xhci_trb),
	    BUS_DMASYNC_PREWRITE);

	s = splusb();
	XDWRITE4(sc, XHCI_DOORBELL(xp->slot), xp->dci);

	xfer->status = USBD_IN_PROGRESS;
	if (xfer->timeout && !sc->sc_bus.use_polling) {
		timeout_del(&xfer->timeout_handle);
		timeout_set(&xfer->timeout_handle, xhci_timeout, xfer);
		timeout_add_msec(&xfer->timeout_handle, xfer->timeout);
	}
	splx(s);

	return (USBD_IN_PROGRESS);
}

void
xhci_device_ctrl_abort(struct usbd_xfer *xfer)
{
	xhci_abort_xfer(xfer, USBD_CANCELLED);
}

usbd_status
xhci_device_generic_transfer(struct usbd_xfer *xfer)
{
	usbd_status err;

	err = usb_insert_transfer(xfer);
	if (err)
		return (err);

	return (xhci_device_generic_start(SIMPLEQ_FIRST(&xfer->pipe->queue)));
}

usbd_status
xhci_device_generic_start(struct usbd_xfer *xfer)
{
	struct xhci_softc *sc = (struct xhci_softc *)xfer->device->bus;
	struct xhci_pipe *xp = (struct xhci_pipe *)xfer->pipe;
	struct xhci_trb *trb0, *trb;
	uint32_t len, remain, flags;
	uint32_t len0, mps;
	uint64_t paddr = DMAADDR(&xfer->dmabuf, 0);
	uint8_t toggle0, toggle;
	int s, i, ntrb;

	KASSERT(!(xfer->rqflags & URQ_REQUEST));

	if (sc->sc_bus.dying || xp->halted)
		return (USBD_IOERROR);

	/* How many TRBs do we need for this transfer? */
	ntrb = (xfer->length + XHCI_TRB_MAXSIZE - 1) / XHCI_TRB_MAXSIZE;

	/* If the buffer crosses a 64k boundary, we need one more. */
	len0 = XHCI_TRB_MAXSIZE - (paddr & (XHCI_TRB_MAXSIZE - 1));
	if (len0 < xfer->length)
		ntrb++;
	else
		len0 = xfer->length;

	/* If we need to append a zero length packet, we need one more. */
	mps = UGETW(xfer->pipe->endpoint->edesc->wMaxPacketSize);
	if ((xfer->flags & USBD_FORCE_SHORT_XFER || xfer->length == 0) &&
	    (xfer->length % mps == 0))
		ntrb++;

	if (xp->free_trbs < ntrb)
		return (USBD_NOMEM);

	/* We'll do the first TRB once we're finished with the chain. */
	trb0 = xhci_xfer_get_trb(sc, xfer, &toggle0, (ntrb == 1));

	remain = xfer->length - len0;
	paddr += len0;
	len = min(remain, XHCI_TRB_MAXSIZE);

	/* Chain more TRBs if needed. */
	for (i = ntrb - 1; i > 0; i--) {
		/* Next (or Last) TRB. */
		trb = xhci_xfer_get_trb(sc, xfer, &toggle, (i == 1));
		flags = XHCI_TRB_TYPE_NORMAL | toggle;
		if (usbd_xfer_isread(xfer))
			flags |= XHCI_TRB_ISP;
		flags |= (i == 1) ? XHCI_TRB_IOC : XHCI_TRB_CHAIN;

		trb->trb_paddr = htole64(paddr);
		trb->trb_status = htole32(
		    XHCI_TRB_INTR(0) | XHCI_TRB_LEN(len) |
		    xhci_xfer_tdsize(xfer, remain, len)
		);
		trb->trb_flags = htole32(flags);

		bus_dmamap_sync(xp->ring.dma.tag, xp->ring.dma.map,
		    TRBOFF(&xp->ring, trb), sizeof(struct xhci_trb),
		    BUS_DMASYNC_PREWRITE);

		remain -= len;
		paddr += len;
		len = min(remain, XHCI_TRB_MAXSIZE);
	}

	/* First TRB. */
	flags = XHCI_TRB_TYPE_NORMAL | toggle0;
	if (usbd_xfer_isread(xfer))
		flags |= XHCI_TRB_ISP;
	flags |= (ntrb == 1) ? XHCI_TRB_IOC : XHCI_TRB_CHAIN;

	trb0->trb_paddr = htole64(DMAADDR(&xfer->dmabuf, 0));
	trb0->trb_status = htole32(
	    XHCI_TRB_INTR(0) | XHCI_TRB_LEN(len0) |
	    xhci_xfer_tdsize(xfer, xfer->length, len0)
 	);
	trb0->trb_flags = htole32(flags);

	bus_dmamap_sync(xp->ring.dma.tag, xp->ring.dma.map,
	    TRBOFF(&xp->ring, trb0), sizeof(struct xhci_trb),
	    BUS_DMASYNC_PREWRITE);

	s = splusb();
	XDWRITE4(sc, XHCI_DOORBELL(xp->slot), xp->dci);

	xfer->status = USBD_IN_PROGRESS;
	if (xfer->timeout && !sc->sc_bus.use_polling) {
		timeout_del(&xfer->timeout_handle);
		timeout_set(&xfer->timeout_handle, xhci_timeout, xfer);
		timeout_add_msec(&xfer->timeout_handle, xfer->timeout);
	}
	splx(s);

	return (USBD_IN_PROGRESS);
}

void
xhci_device_generic_done(struct usbd_xfer *xfer)
{
	/* Only happens with interrupt transfers. */
	if (xfer->pipe->repeat) {
		xfer->actlen = 0;
		xhci_device_generic_start(xfer);
	}
}

void
xhci_device_generic_abort(struct usbd_xfer *xfer)
{
	KASSERT(!xfer->pipe->repeat || xfer->pipe->intrxfer == xfer);

	xhci_abort_xfer(xfer, USBD_CANCELLED);
}
@


1.72
log
@Fix a use-after-free when sending root hub control transfers.

*_root_ctrl_start() routines are synchronous and all end up calling
usb_transfer_complete() in the non-error case.  After calling this
function it is unsafe to dereference ``xfer'' since the transfer
callback has been called.  So returning USBD_IN_PROGRESS is wrong in
this case since transfers are always completed at this point.

So return USBD_NORMAL_COMPLETION or the corresponding error code if
something wrong happen.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.71 2017/03/10 09:14:06 mpi Exp $ */
d228 1
a228 1
		return (error);;
@


1.71
log
@Move per HC polling code to the stack.

This code contains a use-after-free which be addressed in an upcoming
diff.

This fix xhci(4) polling mode.

ok kettenis@@
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.70 2016/11/08 10:31:30 mpi Exp $ */
d2348 1
a2348 1
	return (USBD_IN_PROGRESS);
@


1.70
log
@Remove superfluous DMA synchronization now that the stack is doing it for
all HCs.

ok patrick@@
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.69 2016/10/03 14:05:21 mpi Exp $ */
a77 1
void	xhci_waitintr(struct xhci_softc *, struct usbd_xfer *);
a635 20
xhci_waitintr(struct xhci_softc *sc, struct usbd_xfer *xfer)
{
	int timo;

	for (timo = xfer->timeout; timo >= 0; timo--) {
		usb_delay_ms(&sc->sc_bus, 1);
		if (sc->sc_bus.dying)
			break;

		if (xfer->status != USBD_IN_PROGRESS)
			return;

		xhci_intr1(sc);
	}

	xfer->status = USBD_TIMEOUT;
	usb_transfer_complete(xfer);
}

void
d2507 1
a2507 4

	if (sc->sc_bus.use_polling)
		xhci_waitintr(sc, xfer);
	else if (xfer->timeout) {
d2624 1
a2624 4

	if (sc->sc_bus.use_polling)
		xhci_waitintr(sc, xfer);
	else if (xfer->timeout) {
@


1.69
log
@Fix some bus_dmamap_sync(9) calls.

Do not fold multiple DMA synchronizations into one when chaining TRBs
as the ring might wrap.

Add missing "READ" transfer direction from the HC to host when applicable.

From Marius Strobl.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.68 2016/09/21 07:56:22 mpi Exp $ */
a2663 3
	usb_syncmem(&xfer->dmabuf, 0, xfer->length, usbd_xfer_isread(xfer) ?
	    BUS_DMASYNC_POSTREAD : BUS_DMASYNC_POSTWRITE);

@


1.68
log
@Remove a hack now that the USB stack correctly set the maximum packet
size based on the device speed.

Tested by and ok jsg@@, mlarkin@@
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.67 2016/09/15 02:00:17 dlg Exp $ */
d246 2
a247 1
	bus_dmamap_sync(dma->tag, dma->map, 0, size, BUS_DMASYNC_PREWRITE);
d380 1
a380 1
	    sc->sc_erst.dma.size, BUS_DMASYNC_PREWRITE);
d834 4
d1216 1
a1216 1
	    sc->sc_pagesize, BUS_DMASYNC_PREWRITE);
d1297 1
a1297 1
	    sc->sc_pagesize, BUS_DMASYNC_PREWRITE);
d1399 2
a1400 1
	    npage * sizeof(uint64_t), BUS_DMASYNC_PREWRITE);
d1405 1
a1405 1
	    sizeof(uint64_t), BUS_DMASYNC_PREWRITE);
d1417 1
a1417 1
	    sizeof(uint64_t), BUS_DMASYNC_PREWRITE);
d1471 5
a1475 3
	}
	bus_dmamap_sync(ring->dma.tag, ring->dma.map, 0, size,
	    BUS_DMASYNC_PREWRITE);
d1510 2
a1511 1
	    sizeof(struct xhci_trb), BUS_DMASYNC_POSTREAD);
d1520 2
a1521 1
		    sizeof(struct xhci_trb), BUS_DMASYNC_POSTREAD);
d1820 2
a1821 1
	    slot * sizeof(uint64_t), sizeof(uint64_t), BUS_DMASYNC_PREWRITE);
d1833 2
a1834 1
	    slot * sizeof(uint64_t), sizeof(uint64_t), BUS_DMASYNC_PREWRITE);
d2487 3
d2503 4
d2521 1
a2521 1
	    TRBOFF(&xp->ring, trb0), 3 * sizeof(struct xhci_trb),
d2618 4
d2641 1
a2641 1
	    TRBOFF(&xp->ring, trb0), sizeof(struct xhci_trb) * ntrb,
@


1.67
log
@all pools have their ipl set via pool_setipl, so fold it into pool_init.

the ioff argument to pool_init() is unused and has been for many
years, so this replaces it with an ipl argument. because the ipl
will be set on init we no longer need pool_setipl.

most of these changes have been done with coccinelle using the spatch
below. cocci sucks at formatting code though, so i fixed that by hand.

the manpage and subr_pool.c bits i did myself.

ok tedu@@ jmatthew@@

@@ipl@@
expression pp;
expression ipl;
expression s, a, o, f, m, p;
@@@@
-pool_init(pp, s, a, o, f, m, p);
-pool_setipl(pp, ipl);
+pool_init(pp, s, a, ipl, f, m, p);
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.66 2015/12/02 09:23:23 mpi Exp $ */
d1091 1
d1094 1
a1094 1
	uint32_t mps, route = 0, rhport = 0;
a1115 1
		mps = 8;
a1119 1
		mps = 8;
a1123 1
		mps = 64;
a1127 1
		mps = 512;
a1131 3

	/* XXX Until we fix wMaxPacketSize for ctrl ep depending on the speed */
	mps = max(mps, UE_GET_SIZE(UGETW(ed->wMaxPacketSize)));
@


1.66
log
@Do not change the status of a transfer before giving it back to the
stack.

Unbreak polling mode when the host Babbles because a reset of the ring
is necessary and xhci_waitintr() stops polling as soon as the xfer
status changed.

Problem reported by and ok krw@@
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.65 2015/11/29 16:30:48 kettenis Exp $ */
d314 2
a315 3
		pool_init(xhcixfer, sizeof(struct xhci_xfer), 0, 0, 0,
		    "xhcixfer", NULL);
		pool_setipl(xhcixfer, IPL_SOFTUSB);
@


1.65
log
@Unconnected xhci(4) super speed ports may come up with the XHCI_PS_WRC,
indicating a warm reset has happened.  Communicate this as UPS_C_BH_PORT_RESET
to the upper layers and make uhub(4) clear this bit such that we receive
further connection status change notifications.  Make sure we only do this
for super speed (USB 3.0) hubs as high speed (USB 2.0) hubs use the same bit
for UPS_C_PORT_L1.

Make hotplugging USB 3.0 devices work on my MacBookPro12,1.

ok mpi@@
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.64 2015/11/02 14:53:10 mpi Exp $ */
d786 1
a786 1
			xfer->status = USBD_STALLED;
d788 1
a788 1
			xfer->status = USBD_IOERROR;
a793 1
		xp->halted = 1;
d823 1
a823 1
	int trb_idx;
d854 1
d857 1
d1936 1
a1936 2
	xfer->status = status;
	xp->halted = 1;
@


1.64
log
@Mark xhci_intr() as IPL_MPSAFE since it only schedules a soft-interrupt.

ok visa@@
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.63 2015/07/12 12:54:31 mpi Exp $ */
d2197 3
d2283 1
d2339 3
@


1.63
log
@Do not trust the hardware when it says that the number of remaining
bytes to transfer is superior to the length of the transfer.

Found by krw@@ with an ETRON controller.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.62 2015/06/29 18:33:23 mpi Exp $ */
a608 1
	sc->sc_bus.intr_context++;
a613 1
		sc->sc_bus.intr_context--;
a622 2

	sc->sc_bus.intr_context--;
@


1.62
log
@Clear root hub's "port link state".

Allow to re-plug USB3 devices on the root hub withtout going through a
suspend/resume cycle (or rebooting) with Intel ICH7 xHCI as found the
hardway by sobrado@@.

Debugging help from M.A.R. Osorio, tested by sobrado@@
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.61 2015/06/22 10:29:18 mpi Exp $ */
d748 3
@


1.61
log
@Make xhci(4)'s root hub report the same status bits as physical USB3 hubs.

There's not bit to indicate the speed of a USB3.0 device attached to a hub
port so do not abuse the PORT_TEST bit.  Instead make the xhci(4) root hub
report the PORT_POWER_SS bit when appropriate and use it to determin the
speed of a new device.

While here make the root hub report the link state and config error, from
FreeBSD.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.60 2015/05/27 11:13:34 mikeb Exp $ */
d2189 1
@


1.60
log
@Improve the controller state check in xhci_reset

From FreeBSD, OK mpi
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.59 2015/04/19 11:12:58 mpi Exp $ */
d2248 1
d2251 1
a2251 1
			i = UPS_FULL_SPEED;
d2254 1
a2254 1
			i = UPS_LOW_SPEED;
d2257 1
a2257 1
			i = UPS_HIGH_SPEED;
a2260 1
			i = UPS_SUPER_SPEED;
d2267 7
a2273 1
		if (v & XHCI_PS_PP)	i |= UPS_PORT_POWER;
d2280 2
@


1.59
log
@Do not truncate possible remaining transfer length.

Reported by Takahiro HAYASHI on bugs@@, thanks!
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.58 2015/01/21 14:02:33 mpi Exp $ */
d563 2
a564 1
		hcr = XOREAD4(sc, XHCI_USBCMD) & XHCI_STS_CNR;
@


1.58
log
@Do not try to stop and reset endpoints if USB transfers are aborted
because the HC has been shut down (during suspend/hibernate) or
removed (PCIe card).

In both cases the hardware wont complete the commands, resulting in
timeouts.  Instead just do the software part of the abort process.

Unbreak suspend/resume with USB a device connected to xhci(4) as
reported by Fabian Raetz on bugs@@.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.57 2015/01/18 20:35:11 mpi Exp $ */
d717 2
a718 1
	uint8_t dci, slot, code, remain;
@


1.57
log
@Do not trust the content of event TRBs coming from the hardware and
maintain a list of possibly submitted commands.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.56 2015/01/18 14:49:04 mpi Exp $ */
d1915 1
a1915 1
	if (xfer->status == USBD_NOT_STARTED) {
d1917 2
@


1.56
log
@Complete synchronous abort method modeled after the existing ones.

Because our USB stack wants the aborted xfer to be removed from the
pipe during abort(), we have to sleep in the abort function.

Regarding the xHCI process, when a TD is being aborted, we simply stop
the endpoint and then move the dequeue pointer past its last TRB.  This
is fairly simple for the moment since only one xfer can be pending on a
given pipe.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.55 2015/01/18 11:54:02 mpi Exp $ */
d860 8
a867 2
	default:
		/* All other commands are synchronous. */
d872 2
d1649 1
a1649 1
	return (xhci_command_submit(sc, &trb, XHCI_COMMAND_TIMEOUT));
d1665 1
a1665 1
	return (xhci_command_submit(sc, &trb, XHCI_COMMAND_TIMEOUT));
d1717 1
a1717 1
	if (xhci_command_submit(sc, &trb, XHCI_COMMAND_TIMEOUT))
d1740 1
a1740 1
	return (xhci_command_submit(sc, &trb, XHCI_COMMAND_TIMEOUT));
d1756 1
a1756 1
	return (xhci_command_submit(sc, &trb, XHCI_COMMAND_TIMEOUT));
d1771 1
a1771 1
	return (xhci_command_submit(sc, &trb, XHCI_COMMAND_TIMEOUT));
d1960 1
a1960 1
	error = tsleep(xp, PZERO, "xhciab", (XHCI_COMMAND_TIMEOUT*hz+999)/1000 + 1);
@


1.55
log
@Since we are no longer resetting rings when a Babble or Stall condition
is detected, simply keep track of the faulty xfer instead of completing
all the pending ones.

Fix a race condition where we could end up aborting a freshly enqueued
xfer when two different threads are submitting control transfers (i.e.
usbdevs(8) and a kernel driver).
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.54 2015/01/17 18:37:12 mpi Exp $ */
d52 1
a52 1
#define DEVNAME(sc)		((sc)->sc_bus.bdev.dv_xname)
d120 1
d781 1
d797 9
a854 1

d857 1
d925 1
a1271 2
	if (!xp->halted || xhci_cmd_stop_ep(sc, xp->slot, xp->dci))
		DPRINTF(("%s: error stopping ep (%d)\n", DEVNAME(sc), xp->dci));
d1896 4
d1906 18
d1925 30
a1954 1
	xhci_xfer_done(xfer);
d1959 16
@


1.54
log
@Split the consumer & producer logic into two different functions in
order to read last TRB of the event ring.

Fix a bug introduced in r1.1.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.53 2015/01/09 20:17:05 kettenis Exp $ */
d4 1
a4 1
 * Copyright (c) 2014 Martin Pieuchot
d71 1
a741 5
#if 1
		DPRINTF(("%s: dev %d dci=%d paddr=0x%016llx idx=%d remain=%u"
		    " code=%u\n", DEVNAME(sc), slot, dci, (long long)paddr,
		    trb_idx, remain, code));
#endif
d777 4
d782 4
a785 4
		xfer->status = USBD_STALLED;

		/* FALLTHROUGH */
	case XHCI_CODE_BABBLE:
d792 1
a795 5
#if 1
		DPRINTF(("%s: dev %d dci=%d paddr=0x%016llx idx=%d remain=%u"
		    " code=%u\n", DEVNAME(sc), slot, dci, (long long)paddr,
		    trb_idx, remain, code));
#endif
a808 1
	struct usbd_xfer *xfer;
d812 1
a812 1
	int i, trb_idx;
d845 2
a846 8
		/* Complete all pending transfers. */
		for (i = 0; i < XHCI_MAX_XFER; i++) {
			xfer = xp->pending_xfers[i];
			if (xfer != NULL && xfer->done == 0) {
				if (xfer->status != USBD_STALLED)
					xfer->status = USBD_IOERROR;
				xhci_xfer_done(xfer);
			}
d892 2
d896 1
a896 1
		printf("%s: xfer=%p done (index=%d, ntrb=%zd)\n", __func__,
d901 3
a1259 1

d1513 1
a1513 1
xhci_xfer_get_trb(struct xhci_softc *sc, struct usbd_xfer* xfer,
d1578 2
a1579 5
	if (XHCI_TRB_GET_CODE(letoh32(trb0->trb_status)) != XHCI_CODE_SUCCESS) {
		printf("%s: event error code=%d\n", DEVNAME(sc),
		    XHCI_TRB_GET_CODE(letoh32(trb0->trb_status)));
		error = EIO;
	}
d1582 4
a1585 4
	if (error) {
		printf("result = %d ", XHCI_TRB_TYPE(letoh32(trb0->trb_flags)));
		xhci_dump_trb(trb0);
	}
d1587 1
a1587 1
	return (error);
d1888 1
a1888 1
	DPRINTF(("%s: xfer=%p status=%s err=%s actlen=%d len=%d index=%d\n",
@


1.53
log
@Properly unwind from a failure in usbd_dma_contig_alloc().  Calling
bus_dmamap_unload(9) on a map that failed to load is a bad idea and causes
panics on some architectures (such as sparc64).

ok mpi@@
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.52 2015/01/05 12:38:16 mpi Exp $ */
d54 1
a54 1
#define TRBOFF(r, trb)	((char *)(trb) - (char *)((r).trbs))
d92 2
a93 2
struct	xhci_trb *xhci_ring_dequeue(struct xhci_softc *, struct xhci_ring *,
	    int);
d677 1
a677 1
	while ((trb = xhci_ring_dequeue(sc, &sc->sc_evt_ring, 1)) != NULL) {
d1465 1
a1465 1
xhci_ring_dequeue(struct xhci_softc *sc, struct xhci_ring *ring, int cons)
d1467 1
a1467 4
	struct xhci_trb *trb;
	uint32_t idx = ring->index;

	KASSERT(idx < ring->ntrb);
d1469 1
a1469 2
	bus_dmamap_sync(ring->dma.tag, ring->dma.map, idx * sizeof(*trb),
	    sizeof(*trb), BUS_DMASYNC_POSTREAD);
d1471 2
a1472 1
	trb = &ring->trbs[idx];
d1475 1
a1475 1
	if (cons && ring->toggle != (letoh32(trb->trb_flags) & XHCI_TRB_CYCLE))
a1476 1
	idx++;
d1478 30
a1507 7
	if (idx < (ring->ntrb - 1)) {
		ring->index = idx;
	} else {
		if (ring->toggle)
			ring->trbs[idx].trb_flags |= htole32(XHCI_TRB_CYCLE);
		else
			ring->trbs[idx].trb_flags &= ~htole32(XHCI_TRB_CYCLE);
d1509 2
a1510 3
		bus_dmamap_sync(ring->dma.tag, ring->dma.map,
		    sizeof(struct xhci_trb) * idx, sizeof(struct xhci_trb),
		    BUS_DMASYNC_PREWRITE);
d1536 1
a1536 1
	return (xhci_ring_dequeue(sc, &xp->ring, 0));
d1549 1
a1549 1
	trb = xhci_ring_dequeue(sc, &sc->sc_cmd_ring, 0);
d1554 1
a1554 1
	    TRBOFF(sc->sc_cmd_ring, trb), sizeof(struct xhci_trb),
d2415 1
a2415 1
	    TRBOFF(xp->ring, trb0), 3 * sizeof(struct xhci_trb),
d2531 1
a2531 1
	    TRBOFF(xp->ring, trb0), sizeof(struct xhci_trb) * ntrb,
@


1.52
log
@Prevent a race condition upon resume by adding a supplementary delay.

This is a workaround needed at least by Renesas controllers.  I didn't
find any documentation about this issue and I guess other open source
xHCI implementations do not see this race because they do much more work
upon resume.

Thanks to Remi Locherer for reporting this issue on bugs@@.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.51 2015/01/04 20:10:08 mpi Exp $ */
d227 1
a227 1
		goto fail;
d232 1
a232 1
		goto fail;
d237 1
a237 1
		goto fail;
d242 1
a242 1
		goto fail;
d252 6
a257 1
fail:	usbd_dma_contig_free(bus, dma);
d265 5
a269 8
		if (dma->vaddr != NULL) {
			bus_dmamap_sync(bus->dmatag, dma->map, 0, dma->size,
			    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);
			bus_dmamap_unload(bus->dmatag, dma->map);
			bus_dmamem_unmap(bus->dmatag, dma->vaddr, dma->size);
			bus_dmamem_free(bus->dmatag, &dma->seg, 1);
			dma->vaddr = NULL;
		}
@


1.51
log
@Only set the status of a completed xfer just before giving it back to
the stack.  This will allow stricter checks when aborting transfers.

While here update a comment about short transfer and multi-TRB TD since
bulk transfers can also use a chain now.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.50 2015/01/02 18:06:25 mpi Exp $ */
d518 4
@


1.50
log
@When chaining TRBs, calculate the TD Size as described in section
4.11.2.4 instead of using one TRB per packet.  Also make sure that
it is not greater than 31.

While here be paranoid about xfer buffer crossing a 64k boundary
and use a supplementary TRB in such case.

Fix a problem with uplcom(4) on Intel xHCI reported by jasper@@.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.49 2014/12/21 11:46:53 mpi Exp $ */
d747 2
a748 3
		 * This might be the ``Event Status TRB'' of a control
		 * request for which the ``Event Data TRB'' triggered
		 * a Short Transfer condition, see below.
d750 2
a751 2
		if (xfer->actlen)
			break;
d753 2
a754 1
		/* FALLTHROUGH */
a756 1
		xfer->status = USBD_NORMAL_COMPLETION;
d760 3
a762 5
		 * not assume the USB packet is finished.  In the case
		 * of a Sort Transfer condition we should theoretically
		 * clear the IOC flags on the ``Event Status TRB'' but
		 * the HC might have already processed it since before
		 * we start processing the softinterrupt.
d767 2
@


1.49
log
@Various transfer improvements/fixes.

Chain TRBs when submitting bulk or interrupt transfers with a length
bigger than the Maxium Packet Size of the endpoint.

Append a supplementary TRB if a zero length packet is required.

While here, set the flags of each TRB at once.  Even if this driver
implementation fills the first TRB of a chain last, be safe and make
sure the hardware wont miss any flag.

Note that with this change, DMA sync operations might not cover the
whole chain, just like for control transfers, if the ring is starting
over.

Previous version of this diff tested by Peter N. M. Hansteen, thanks!
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.48 2014/12/21 11:20:24 mpi Exp $ */
d2301 16
d2360 2
a2361 1
		    XHCI_TRB_INTR(0) | XHCI_TRB_TDREM(1) | XHCI_TRB_LEN(len)
d2438 1
a2438 1
	uint64_t paddr;
d2448 8
a2455 2
	mps = UGETW(xfer->pipe->endpoint->edesc->wMaxPacketSize);
	ntrb = (xfer->length + mps - 1) / mps;
d2458 1
a2467 1
	len0 = min(xfer->length, mps);
d2470 2
a2471 2
	paddr = DMAADDR(&xfer->dmabuf, 0) + len0;
	len = min(remain, mps);
d2484 2
a2485 2
		    XHCI_TRB_INTR(0) | XHCI_TRB_TDREM(i) |
		    XHCI_TRB_LEN(len)
d2491 1
a2491 1
		len = min(remain, mps);
d2502 2
a2503 1
	    XHCI_TRB_INTR(0) | XHCI_TRB_TDREM(ntrb) | XHCI_TRB_LEN(len0)
@


1.48
log
@Use a bitmask when dumping TRB flags.  No change in !XHCI_DEBUG.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.47 2014/12/19 22:44:59 guenther Exp $ */
d2319 1
a2319 1
	uint32_t len = UGETW(xfer->request.wLength);
d2337 5
d2346 1
a2346 4
		trb->trb_flags = htole32(XHCI_TRB_TYPE_DATA | toggle);

		if (usbd_xfer_isread(xfer))
			trb->trb_flags |= htole32(XHCI_TRB_DIR_IN|XHCI_TRB_ISP);
d2352 5
d2359 1
a2359 4
	trb->trb_flags = htole32(XHCI_TRB_TYPE_STATUS | XHCI_TRB_IOC | toggle);

	if (len == 0 || !usbd_xfer_isread(xfer))
		trb->trb_flags |= htole32(XHCI_TRB_DIR_IN);
d2362 1
a2362 4
	trb0->trb_paddr = (uint64_t)*((uint64_t *)&xfer->request);
	trb0->trb_status = htole32(XHCI_TRB_INTR(0) | XHCI_TRB_LEN(8));
	trb0->trb_flags = htole32(XHCI_TRB_TYPE_SETUP | XHCI_TRB_IDT);

d2365 1
a2365 1
			trb0->trb_flags |= htole32(XHCI_TRB_TRT_IN);
d2367 1
a2367 1
			trb0->trb_flags |= htole32(XHCI_TRB_TRT_OUT);
d2370 3
a2372 1
	trb0->trb_flags |= htole32(toggle0);
d2418 6
a2423 3
	struct xhci_trb *trb;
	uint8_t toggle;
	int s;
d2430 10
a2439 1
	if (xp->free_trbs < 1)
d2442 28
a2469 6
	trb = xhci_xfer_get_trb(sc, xfer, &toggle, 1);
	trb->trb_paddr = htole64(DMAADDR(&xfer->dmabuf, 0));
	trb->trb_status = htole32(
	    XHCI_TRB_INTR(0) | XHCI_TRB_TDREM(1) | XHCI_TRB_LEN(xfer->length)
	);
	trb->trb_flags = htole32(XHCI_TRB_TYPE_NORMAL | XHCI_TRB_IOC | toggle);
d2471 2
d2474 8
a2481 1
		trb->trb_flags |= htole32(XHCI_TRB_ISP);
d2484 1
a2484 1
	    TRBOFF(xp->ring, trb), sizeof(struct xhci_trb),
@


1.47
log
@Use <sys/endian.h> instead of <machine/endian.h>

ok dlg@@ mpi@@ bcook@@ millert@@ miod@@
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.46 2014/12/15 17:10:44 mpi Exp $ */
d205 3
a207 2
	printf("trb=%p (0x%016llx 0x%08x 0x%08x)\n", trb,
	   (long long)trb->trb_paddr, trb->trb_status, trb->trb_flags);
@


1.46
log
@Stop using usb_{alloc,free}mem() for the rings and internal structures.

Since xhci(4) does not allocate memory for its rings in interrupt
context, it has no use for the free lists offered by the USB memory
allocator.

Using bus_dmamem_alloc(9) and friends also allows us to respect the
boundary requirement for the various structures specified in Table 54.

While here make use of defines for every alignment and boundary
requirements which are different than a page size.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.45 2014/12/08 13:32:34 mpi Exp $ */
d27 1
a29 1
#include <machine/endian.h>
@


1.45
log
@When resetting an endpoint do not purge the ring.  Instead set the
dequeue pointer past the last enqueued TRB and let xhci_xfer_done()
properly accounts free TRBs.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.44 2014/11/24 13:02:15 mpi Exp $ */
d55 1
a55 1
#define DEQPTR(r)	(DMAADDR(&(r).dma, sizeof(struct xhci_trb) * (r).index))
d70 1
a70 1
	struct usbd_xfer	*pending_xfers[XHCI_MAX_TRANSFERS];
d88 2
a89 1
int	xhci_ring_alloc(struct xhci_softc *, struct xhci_ring *, size_t);
d210 62
d332 4
a335 7
	/*
	 * Section 6.1 - Device Context Base Address Array
	 * shall be aligned to a 64 byte boundary.
	 */
	sc->sc_dcbaa.size = (sc->sc_noslot + 1) * sizeof(uint64_t);
	error = usb_allocmem(&sc->sc_bus, sc->sc_dcbaa.size, 64,
	    &sc->sc_dcbaa.dma);
a337 4
	sc->sc_dcbaa.segs = KERNADDR(&sc->sc_dcbaa.dma, 0);
	memset(sc->sc_dcbaa.segs, 0, sc->sc_dcbaa.size);
	usb_syncmem(&sc->sc_dcbaa.dma, 0, sc->sc_dcbaa.size,
	    BUS_DMASYNC_PREWRITE);
d340 2
a341 1
	error = xhci_ring_alloc(sc, &sc->sc_cmd_ring, XHCI_MAX_COMMANDS);
d344 1
a344 1
		usb_freemem(&sc->sc_bus, &sc->sc_dcbaa.dma);
d349 2
a350 1
	error = xhci_ring_alloc(sc, &sc->sc_evt_ring, XHCI_MAX_EVENTS);
d354 1
a354 1
		usb_freemem(&sc->sc_bus, &sc->sc_dcbaa.dma);
d359 3
a361 3
	sc->sc_erst.size = 1 * sizeof(struct xhci_erseg);
	error = usb_allocmem(&sc->sc_bus, sc->sc_erst.size, 64,
	    &sc->sc_erst.dma);
d366 1
a366 1
		usb_freemem(&sc->sc_bus, &sc->sc_dcbaa.dma);
a368 1
	sc->sc_erst.segs = KERNADDR(&sc->sc_erst.dma, 0);
d371 2
a372 2
	sc->sc_erst.segs[0].er_addr = htole64(DMAADDR(&sc->sc_evt_ring.dma, 0));
	sc->sc_erst.segs[0].er_size = htole32(XHCI_MAX_EVENTS);
d374 2
a375 2
	usb_syncmem(&sc->sc_erst.dma, 0, sc->sc_erst.size,
	   BUS_DMASYNC_PREWRITE);
d384 1
a384 1
		usb_freemem(&sc->sc_bus, &sc->sc_erst.dma);
d387 1
a387 1
		usb_freemem(&sc->sc_bus, &sc->sc_dcbaa.dma);
d408 1
a408 1
	paddr = (uint64_t)DMAADDR(&sc->sc_dcbaa.dma, 0);
d416 1
a416 1
	paddr = (uint64_t)DMAADDR(&sc->sc_cmd_ring.dma, 0);
d427 1
a427 1
	paddr = (uint64_t)DMAADDR(&sc->sc_erst.dma, 0);
d435 1
a435 1
	paddr = (uint64_t)DMAADDR(&sc->sc_evt_ring.dma, 0);
d496 1
a496 1
	usb_freemem(&sc->sc_bus, &sc->sc_erst.dma);
d499 1
a499 1
	usb_freemem(&sc->sc_bus, &sc->sc_dcbaa.dma);
d725 1
a725 1
	trb_idx = (paddr - DMAADDR(&xp->ring.dma, 0)) / sizeof(struct xhci_trb);
d813 1
a813 1
	trb_idx = (paddr - DMAADDR(&sc->sc_cmd_ring.dma, 0)) / sizeof(*trb);
d845 1
a845 1
		for (i = 0; i < XHCI_MAX_TRANSFERS; i++) {
d1195 2
a1196 1
	usb_syncmem(&sdev->ictx_dma, 0, sc->sc_pagesize, BUS_DMASYNC_PREWRITE);
d1214 1
a1214 1
	if (xhci_ring_alloc(sc, &xp->ring, XHCI_MAX_TRANSFERS))
d1235 1
a1235 1
		    DMAADDR(&sdev->ictx_dma, 0), XHCI_TRB_BSR);
d1238 1
a1238 1
		    DMAADDR(&sdev->ictx_dma, 0));
d1279 2
a1280 1
	usb_syncmem(&sdev->ictx_dma, 0, sc->sc_pagesize, BUS_DMASYNC_PREWRITE);
d1282 1
a1282 1
	if (xhci_cmd_configure_ep(sc, xp->slot, DMAADDR(&sdev->ictx_dma, 0)))
d1320 1
a1320 2
	error = xhci_cmd_set_address(sc, xp->slot,
	    DMAADDR(&sdev->ictx_dma, 0), 0);
d1327 2
a1328 2
		usb_syncmem(&sdev->octx_dma, 0, sc->sc_pagesize,
		    BUS_DMASYNC_POSTREAD);
d1331 1
a1331 1
		sctx = KERNADDR(&sdev->octx_dma, 0);
d1361 3
a1363 2
	error = usb_allocmem(&sc->sc_bus, npage * sizeof(uint64_t), 64,
	    &sc->sc_spad.table_dma);
a1365 1
	pte = KERNADDR(&sc->sc_spad.table_dma, 0);
d1367 3
a1369 3
	/* Alloccate space for the pages. */
	error = usb_allocmem(&sc->sc_bus, npage * sc->sc_pagesize,
	    sc->sc_pagesize, &sc->sc_spad.pages_dma);
d1371 1
a1371 1
		usb_freemem(&sc->sc_bus, &sc->sc_spad.table_dma);
a1373 3
	memset(KERNADDR(&sc->sc_spad.pages_dma, 0), 0, npage * sc->sc_pagesize);
	usb_syncmem(&sc->sc_spad.pages_dma, 0, npage * sc->sc_pagesize,
	    BUS_DMASYNC_PREREAD|BUS_DMASYNC_PREWRITE);
d1377 1
a1377 1
		    DMAADDR(&sc->sc_spad.pages_dma, i * sc->sc_pagesize)
d1380 3
a1382 2
	usb_syncmem(&sc->sc_spad.table_dma, 0, npage * sizeof(uint64_t),
	    BUS_DMASYNC_PREWRITE);
d1385 3
a1387 3
	sc->sc_dcbaa.segs[0] = htole64(DMAADDR(&sc->sc_spad.table_dma, 0));
	usb_syncmem(&sc->sc_dcbaa.dma, 0, sizeof(uint64_t),
	    BUS_DMASYNC_PREWRITE);
d1398 2
a1399 2
	usb_syncmem(&sc->sc_dcbaa.dma, 0, sizeof(uint64_t),
	    BUS_DMASYNC_PREWRITE);
d1401 2
a1402 2
	usb_freemem(&sc->sc_bus, &sc->sc_spad.pages_dma);
	usb_freemem(&sc->sc_bus, &sc->sc_spad.table_dma);
a1404 1

d1406 2
a1407 1
xhci_ring_alloc(struct xhci_softc *sc, struct xhci_ring *ring, size_t ntrb)
d1410 1
d1414 4
a1417 2
	if (usb_allocmem(&sc->sc_bus, size, 16, &ring->dma) != 0)
		return (ENOMEM);
a1418 1
	ring->trbs = KERNADDR(&ring->dma, 0);
d1429 1
a1429 1
	usb_freemem(&sc->sc_bus, &ring->dma);
d1451 1
a1451 1
		trb->trb_paddr = htole64(DMAADDR(&ring->dma, 0));
d1454 2
a1455 1
	usb_syncmem(&ring->dma, 0, size, BUS_DMASYNC_PREWRITE);
d1466 2
a1467 2
	usb_syncmem(&ring->dma, idx * sizeof(struct xhci_trb),
	    sizeof(struct xhci_trb), BUS_DMASYNC_POSTREAD);
d1484 3
a1486 2
		usb_syncmem(&ring->dma, sizeof(struct xhci_trb) * idx,
		    sizeof(struct xhci_trb), BUS_DMASYNC_PREWRITE);
d1529 4
a1532 2
	usb_syncmem(&sc->sc_cmd_ring.dma, TRBOFF(sc->sc_cmd_ring, trb),
	    sizeof(struct xhci_trb), BUS_DMASYNC_PREWRITE);
d1748 1
d1754 2
a1755 2
	error = usb_allocmem(&sc->sc_bus, sc->sc_pagesize, sc->sc_pagesize,
	    &sdev->ictx_dma);
a1757 1
	memset(KERNADDR(&sdev->ictx_dma, 0), 0, sc->sc_pagesize);
d1759 2
a1760 2
	sdev->input_ctx = KERNADDR(&sdev->ictx_dma, 0);
	sdev->slot_ctx = KERNADDR(&sdev->ictx_dma, sc->sc_ctxsize);
d1763 1
a1763 1
		   KERNADDR(&sdev->ictx_dma, (i + 2) * sc->sc_ctxsize);
d1769 2
a1770 2
	error = usb_allocmem(&sc->sc_bus, sc->sc_pagesize, sc->sc_pagesize,
	    &sdev->octx_dma);
d1772 1
a1772 1
		usb_freemem(&sc->sc_bus, &sdev->ictx_dma);
a1774 1
	memset(KERNADDR(&sdev->octx_dma, 0), 0, sc->sc_pagesize);
d1779 1
a1779 1
	    slot, (long long)DMAADDR(&sdev->octx_dma, 0)));
d1781 3
a1783 3
	sc->sc_dcbaa.segs[slot] = htole64(DMAADDR(&sdev->octx_dma, 0));
	usb_syncmem(&sc->sc_dcbaa.dma, slot * sizeof(uint64_t),
	    sizeof(uint64_t), BUS_DMASYNC_PREWRITE);
d1794 2
a1795 2
	usb_syncmem(&sc->sc_dcbaa.dma, slot * sizeof(uint64_t),
	    sizeof(uint64_t), BUS_DMASYNC_PREWRITE);
d1797 2
a1798 2
	usb_freemem(&sc->sc_bus, &sdev->octx_dma);
	usb_freemem(&sc->sc_bus, &sdev->ictx_dma);
d2370 3
a2372 2
	usb_syncmem(&xp->ring.dma, TRBOFF(xp->ring, trb0),
	    3 * sizeof(struct xhci_trb), BUS_DMASYNC_PREWRITE);
d2436 3
a2438 2
	usb_syncmem(&xp->ring.dma, TRBOFF(xp->ring, trb),
	    sizeof(struct xhci_trb), BUS_DMASYNC_PREWRITE);
@


1.44
log
@No point in setting the Interrupt-on Short Packet bit on OUT endpoint.
As explained in section 4.11.7 it should be used when a device is
allowed to supply less data than the provided buffer space.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.43 2014/11/24 12:55:16 mpi Exp $ */
d54 2
a55 1
#define TRBOFF(ring, trb)	((char *)(trb) - (char *)((ring).trbs))
d101 1
a101 1
void	xhci_cmd_reset_endpoint_async(struct xhci_softc *, uint8_t, uint8_t);
d639 1
a639 2
	paddr = (uint64_t)DMAADDR(&sc->sc_evt_ring.dma,
	    sizeof(struct xhci_trb) * sc->sc_evt_ring.index);
d729 1
a729 1
		xhci_cmd_reset_endpoint_async(sc, slot, dci);
a771 4
		/*
		 * Clear the TRBs and reconfigure the dequeue pointer
		 * before declaring the endpoint ready.
		 */
d776 1
a776 2
		xhci_ring_reset(sc, &xp->ring);
		xp->free_trbs = xp->ring.ntrb;
d778 1
a778 1
		    DMAADDR(&xp->ring.dma, 0) | XHCI_EPCTX_DCS);
a780 5
		/*
		 * Now that the endpoint is in its initial state, we
		 * can finish all its pending transfers and let the
		 * stack play with it again.
		 */
d786 2
a794 1
			xp->pending_xfers[i] = NULL;
d1081 1
a1081 2
	    DMAADDR(&xp->ring.dma, sizeof(struct xhci_trb) * xp->ring.index) |
	    XHCI_EPCTX_DCS
d1575 1
a1575 1
xhci_cmd_reset_endpoint_async(struct xhci_softc *sc, uint8_t slot, uint8_t dci)
@


1.43
log
@In debug mode, print more information when a transfer is aborted and use
a different index value for a chained TRB and a freed one.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.42 2014/11/23 10:46:46 mpi Exp $ */
d2379 4
a2382 3
	trb->trb_flags = htole32(
	    XHCI_TRB_TYPE_NORMAL | XHCI_TRB_ISP | XHCI_TRB_IOC | toggle
	);
@


1.42
log
@Be less verbose when opening a pipe and print the endpoint & slot
when submitting a command.  No change for non-XHCI_DEBUG kernel.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.41 2014/11/16 18:31:07 mpi Exp $ */
d850 3
a852 3
	if (xx->index == -1 || xp->pending_xfers[xx->index] == NULL) {
		printf("%s: xfer=%p already done (index=%d)\n", __func__,
		    xfer, xx->index);
d1458 1
a1458 1
	xx->index = (last) ? xp->ring.index : -1;
d1821 1
a1821 1
	int s;
d1823 3
a1825 1
	DPRINTF(("%s: xfer=%p err=%s\n", __func__, xfer, usbd_errstr(status)));
a1827 2

	s = splusb();
a1828 1
	splx(s);
d1835 1
d1837 1
d1839 1
@


1.41
log
@Two fixes to make Qemu and VMware xHCI implementations work:

1. Always unmask the slot context for the "Set Address" command.

2. Use the right spl when submitting a transfer to prevent from
   setting up a timer on an already completed xfer.

Analyzed with and ok jsg@@
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.40 2014/11/11 12:10:44 mpi Exp $ */
d850 1
a850 1
	if (xp->pending_xfers[xx->index] == NULL) {
a852 1
		return;
a899 6
#ifdef XHCI_DEBUG
	struct usbd_device *dev = pipe->device;
	printf("%s: pipe=%p addr=%d depth=%d port=%d speed=%d\n", __func__,
	    pipe, dev->address, dev->depth, dev->powersrc->portno, dev->speed);
#endif

a913 2
			DPRINTF(("%s: bad bEndpointAddress 0x%02x\n", __func__,
			    ed->bEndpointAddress));
a960 1
		DPRINTF(("%s: bad xfer type %d\n", __func__, xfertype));
a1012 3
	DPRINTF(("%s: max ESIT payload = %u, average TRB length = %u\n",
	    DEVNAME(sc), mep, atl));

a1072 3
	DPRINTF(("%s: speed %d mps %d rhport %d route 0x%x\n", DEVNAME(sc),
	    speed, mps, rhport, route));

d1158 7
a1164 2
	DPRINTF(("%s: dev %d dci %u (epAddr=0x%x)\n", DEVNAME(sc), xp->slot,
	    xp->dci, pipe->endpoint->edesc->bEndpointAddress));
d1557 1
a1557 1
	DPRINTF(("%s: %s\n", DEVNAME(sc), __func__));
d1573 1
a1573 1
	DPRINTF(("%s: %s\n", DEVNAME(sc), __func__));
d1589 1
a1589 1
	DPRINTF(("%s: %s\n", DEVNAME(sc), __func__));
d1606 1
a1606 1
	DPRINTF(("%s: %s\n", DEVNAME(sc), __func__));
d1664 1
a1664 1
	DPRINTF(("%s: %s\n", DEVNAME(sc), __func__));
@


1.40
log
@Do not reset the base address of the control endpoint's ring when
the second "Set Address" command is issued.  This would lead the
HC to reprocess TRBs corresponding to completed transfers.

This was the cause of the "xhci0: NULL xfer pointer" message that
could be seen after attaching a device and reported by naddy@@.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.39 2014/11/10 14:29:49 mpi Exp $ */
a1124 1

a1131 3
		/* Unmask the slot context */
		sdev->input_ctx->add_flags |= htole32(XHCI_INCTX_MASK_DCI(0));

d1161 3
d2278 1
d2330 2
d2343 1
d2373 1
d2394 2
d2407 1
@


1.39
log
@Support USB 1.x devices below external hubs.

This code is violating various layers of abstraction, just like ehci(4)
does.  Transaction translators need a bit more love.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.38 2014/11/10 14:16:13 mpi Exp $ */
d1106 2
a1107 1
	    DMAADDR(&xp->ring.dma, 0) | XHCI_EPCTX_DCS
@


1.38
log
@Apparently xhci(4) also needs a hook to set the address of a device.

Some Low/Full speed devices do not like to get a SET_ADDRESS command
before we have read (some bits of) their device descriptor.  So change
the attach logic to issue two "Device Address" command with a BSR dance.

This should fix the "device problem, disabling port" error seen on root
hubs with some Low/Full speed devices, reported by miod@@.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.37 2014/11/09 14:03:04 mpi Exp $ */
d1122 3
d1137 24
d1162 1
@


1.37
log
@When a pipe is closed, clear the memory of the corresponding enpoint
context, not the whole array of endpoints.  Yeah, pointers are hard.

Fix a panic reported by Dimitris Papastamos on tech@@
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.36 2014/11/07 16:33:02 mpi Exp $ */
d82 1
d105 1
a105 1
int	xhci_cmd_address_device(struct xhci_softc *,uint8_t,  uint64_t);
d120 1
d147 1
d1029 2
a1030 2
int
xhci_pipe_init(struct xhci_softc *sc, struct usbd_pipe *pipe)
a1038 12
	int error;

	DPRINTF(("%s: dev %d dci %u (epAddr=0x%x)\n", DEVNAME(sc), xp->slot,
	    xp->dci, pipe->endpoint->edesc->bEndpointAddress));

	if (xhci_ring_alloc(sc, &xp->ring, XHCI_MAX_TRANSFERS))
		return (ENOMEM);

	xp->free_trbs = xp->ring.ntrb;
	xp->halted = 0;

	sdev->pipes[xp->dci - 1] = xp;
d1077 1
a1077 2
		xhci_ring_free(sc, &xp->ring);
		return (EINVAL);
d1137 21
d1163 5
a1167 2
		 * with BSR=0 and jump directly to the ADDRESSED state.
		 * This way we don't need a callback to assign an addr.
d1169 2
a1170 2
		error = xhci_cmd_address_device(sc, xp->slot,
		    DMAADDR(&sdev->ictx_dma, 0));
a1175 16
	usb_syncmem(&sdev->octx_dma, 0, sc->sc_pagesize, BUS_DMASYNC_POSTREAD);

#ifdef XHCI_DEBUG
	if (xp->dci == 1 && !error) {
		struct xhci_sctx *sctx;
		uint8_t addr;

		/* Get output slot context. */
		sctx = KERNADDR(&sdev->octx_dma, 0);
		addr = XHCI_SCTX_DEV_ADDR(letoh32(sctx->state));
		error = (addr == 0);

		printf("%s: dev %d addr %d\n", DEVNAME(sc), xp->slot, addr);
	}
#endif

d1232 45
d1626 2
a1627 1
xhci_cmd_address_device(struct xhci_softc *sc, uint8_t slot, uint64_t addr)
d1631 1
a1631 1
	DPRINTF(("%s: %s\n", DEVNAME(sc), __func__));
d1636 1
a1636 1
	    XHCI_TRB_SET_SLOT(slot) | XHCI_CMD_ADDRESS_DEVICE
@


1.36
log
@Document how the Slot States transitions described in section 4.5.3 of
xHCI specification r1.1 are handled in this implementation.  This is a
bit tricky because our bus interface is pipe-oriented.  Hopefully this
will help other people squash the remaining bugs in this area.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.34 2014/11/01 18:21:07 mpi Exp $ */
d1214 1
a1214 1
	memset(&sdev->ep_ctx[xp->dci - 1], 0, sizeof(struct xhci_epctx));
@


1.35
log
@Prevent a race when submitting a command by using the appropriate spl
protection.

Fix a panic reported by Patrick Wildt.
@
text
@d81 1
a81 2
int	xhci_pipe_init(struct xhci_softc *, struct usbd_pipe *, uint32_t,
	    uint32_t);
d867 4
a893 2
	struct usbd_device *hub;
	uint32_t route = 0, rhport = 0;
d934 8
a941 1
		/* Get a slot and init the device's contexts. */
d946 2
a947 1
		if (xhci_softdev_alloc(sc, slot))
a948 11

		/*
		 * Calculate the Route String.  Note that this code assume
		 * that there is no hub with more than 16 ports and that
		 * they all are at a detph < USB_HUB_MAX_DEPTH.
		 */
		for (hub = pipe->device; hub->myhub->depth; hub = hub->myhub) {
			uint32_t port = hub->powersrc->portno;
			uint32_t depth = hub->myhub->depth;

			route |= port << (4 * (depth - 1));
a950 2
		/* Get Root Hub port */
		rhport = hub->powersrc->portno;
d971 9
a979 1
	/* XXX Section nb? */
d982 2
a983 6
	if (slot != 0)
		xp->slot = slot;
	else
		xp->slot = ((struct xhci_pipe *)pipe->device->default_pipe)->slot;

	if (xhci_pipe_init(sc, pipe, rhport, route))
d985 1
d1027 1
a1027 2
xhci_pipe_init(struct xhci_softc *sc, struct usbd_pipe *pipe, uint32_t port,
    uint32_t route)
d1034 2
a1035 1
	uint32_t mps;
d1049 15
d1086 1
d1097 1
a1097 1
	    speed, mps, port, route));
d1128 1
a1128 1
	sdev->slot_ctx->info_hi = htole32(XHCI_SCTX_RHPORT(port));
d1132 4
a1135 1
	/* If we are opening the interrupt pipe of a hub, update its context. */
a1147 4
	/*
	 * Issue only one Set address to set up the slot context and
	 * assign an address.
	 */
d1149 6
a1190 1
	usb_endpoint_descriptor_t *ed = pipe->endpoint->edesc;
d1224 5
a1228 1
	if (UE_GET_XFERTYPE(ed->bmAttributes) == UE_CONTROL) {
@


1.34
log
@Use the correct default MaxPacketSize for Full Speed devices and make them
work with xhci(4).
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.33 2014/10/31 23:11:48 mpi Exp $ */
d1384 1
a1384 1
	int error = 0;
d1391 2
d1397 2
a1398 6
	if (timeout)
		sc->sc_cmd_trb = trb;

	XDWRITE4(sc, XHCI_DOORBELL(0), 0);

	if (timeout == 0)
d1400 1
d1404 3
d1412 1
a1412 1
		printf("cmd = %d " ,XHCI_TRB_TYPE(letoh32(trb->trb_flags)));
d1417 1
d1420 1
@


1.33
log
@If an event is dequeued just/right after a device is detached, its pipes
might be NULL.  Prevent from crashing in this case 8)
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.32 2014/10/31 16:39:34 mpi Exp $ */
d1052 1
a1052 1
		mps = USB_MAX_IPACKET;
d1057 1
a1057 1
		mps = 64;
@


1.32
log
@Enable timeouts, just in case(tm).

Even if it's very handy to know where a thread is sleeping in order to
debug HC drivers, users might not like to have to restart their machine
if a transfer timed and nothing will wakeup the discovery thread.

Note that I still haven't seen any hardware timeout in all my tests.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.31 2014/10/30 18:29:59 mpi Exp $ */
d660 2
a766 1
	xp = sc->sc_sdevs[slot].pipes[dci - 1];
d774 4
d789 4
@


1.31
log
@Do not use void * for pointer artithmetics, it's a GNU extension, from
Patrick Wildt.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.30 2014/10/30 18:25:08 mpi Exp $ */
a115 1
/* XXX these are common to all HC drivers and should be merged. */
a116 1
void 	xhci_timeout_task(void *);
a739 1
	usb_transfer_complete(xfer);
d790 1
a790 1
				usb_transfer_complete(xfer);
d854 3
d1724 2
a1726 2
	timeout_del(&xfer->timeout_handle);
	usb_rem_task(xfer->device, &xfer->abort_task);
a1729 1
	usb_transfer_complete(xfer);
a1736 18
	struct xhci_softc *sc = (struct xhci_softc *)xfer->device->bus;

	if (sc->sc_bus.dying) {
		xhci_timeout_task(addr);
		return;
	}

	usb_init_task(&xfer->abort_task, xhci_timeout_task, addr,
	    USB_TASK_TYPE_ABORT);
	usb_add_task(xfer->device, &xfer->abort_task);
}

void
xhci_timeout_task(void *addr)
{
	struct usbd_xfer *xfer = addr;

	DPRINTF(("%s: xfer=%p\n", __func__, xfer));
a2224 1
#if notyet
a2229 1
#endif
a2284 1
#if notyet
a2289 1
#endif
@


1.30
log
@Do not enable interrupts before attaching usb(4), fix a panic when an
Express Card is plugged with USB devices on it.

While here do not print an unitialized error value if xhci_init() fails,
from Patrick Wildt.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.29 2014/10/30 18:08:24 mpi Exp $ */
d54 1
a54 1
#define TRBOFF(ring, trb)	((void *)(trb) - (void *)((ring).trbs))
d2298 1
a2298 1
	usb_syncmem(&xp->ring.dma, ((void *)trb - (void *)xp->ring.trbs),
@


1.29
log
@Calculate the Route String when attaching a new device.  This is still
not enough to attach Super Speed devices below USB 3 hubs, but we're
getting there.

While here reset `acten` when re-enqueuing an interrupt transfers.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.28 2014/10/05 13:32:14 mpi Exp $ */
a74 1
void	xhci_config(struct xhci_softc *);
a332 2

	xhci_config(sc);
@


1.28
log
@Only synchronize used TRBs and not the full ring when sending a control
transfer.  While here remove/fix other XXXs.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.26 2014/10/04 13:07:22 mpi Exp $ */
d82 2
a83 1
int	xhci_pipe_init(struct xhci_softc *, struct usbd_pipe *, uint32_t);
d886 1
a886 1
	uint32_t rhport = 0;
d935 13
a947 3
		/* Get root hub port */
		for (hub = pipe->device; hub->myhub->depth; hub = hub->myhub)
			;
d977 1
a977 1
	if (xhci_pipe_init(sc, pipe, rhport))
d1020 2
a1021 1
xhci_pipe_init(struct xhci_softc *sc, struct usbd_pipe *pipe, uint32_t port)
d1073 2
a1074 2
	DPRINTF(("%s: speed %d mps %d rhport %d\n", DEVNAME(sc), speed, mps,
	    port));
d1102 2
a1103 1
	    XHCI_SCTX_DCI(xp->dci) | XHCI_SCTX_SPEED(speed)
d1109 1
d2327 4
a2330 2
	if (xfer->pipe->repeat)
		xfer->status = xhci_device_generic_start(xfer);
@


1.27
log
@Do not mark the pipe as halted when the HC reports a (split) transaction
error.  Makes Intel Series 7 controllers happy and no longer report an
illegal context state transition when detaching devices.
@
text
@d658 4
a661 2
	if (slot > sc->sc_noslot)
		return; /* XXX */
d718 1
a718 1
		/* XXX We need to report this condition for umass(4). */
d720 2
d817 1
a817 1
		DPRINTF(("failed port status event\n"));/* XXX can it happen? */
d1677 1
a1677 1
	UIPROTO_HSHUBSTT,	/* XXX */
d1695 1
a1695 1
	{0, 0}			/* XXX */
d2225 2
a2226 2
	usb_syncmem(&xp->ring.dma, 0, xp->ring.ntrb * sizeof(struct xhci_trb),
	    BUS_DMASYNC_PREWRITE); /* XXX too big hammer? */
@


1.26
log
@Wait until a read control transfer is really completed before passing
it to the stack when a Short Transfer condition is reported.

In this dummy implementation the ``Event Data TRB'' of a read control
transfer is the only TRB that can trigger an interrupt without being
the last TRB of a transfer.  This is done in order to report the
remaining length of a short transfer.  But when that happens, we want
to wait until all Transfer TRBs are completed before passing the xfer
to the stack.

Note that clearing the ISP and IOC flags in all Transfer TRBs like it
is specified in 4.10.1.1.1 might not work in our cases because the HC
has most of the time already processed all Transfer TRBs when the driver
dequeues the events in the softinterrupt path.

While here, use the right spl protection when aborting a xfer.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.25 2014/08/30 09:32:19 mpi Exp $ */
d710 4
@


1.25
log
@Allow new devices to get an address when XHCI_DEBUG is defined.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.24 2014/08/10 11:21:49 mpi Exp $ */
d652 1
d686 9
d698 12
a1704 4
	DPRINTF(("%s: partial stub\n", __func__));

	xhci_xfer_done(xfer);

d1710 1
@


1.24
log
@Merge xhci_device_setup() into xhci_pipe_init() there's no reason to
have a separate function anymore, it is just a wrapper around the "set
address" command.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.23 2014/08/10 11:18:57 mpi Exp $ */
d1100 1
a1100 1
		error = (addr != 0);
@


1.23
log
@Since USB xfer pools are accessed in interrupt context, initialize them
with the correct ipl to prevent your CPU from locking against itself.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.22 2014/08/10 11:00:36 mpi Exp $ */
a82 1
int	xhci_device_setup(struct xhci_softc *, struct usbd_device *, uint8_t);
a978 29
xhci_device_setup(struct xhci_softc *sc, struct usbd_device *dev, uint8_t slot)
{
	struct xhci_soft_dev *sdev = &sc->sc_sdevs[slot];
	struct xhci_sctx *sctx;
	uint8_t addr;
	int error;

	/*
	 * Issue only one Set address to set up the slot context and
	 * assign an address.
	 */
	error = xhci_cmd_address_device(sc, slot, DMAADDR(&sdev->ictx_dma, 0));
	if (error)
		return (error);

	usb_syncmem(&sdev->octx_dma, 0, sc->sc_pagesize, BUS_DMASYNC_POSTREAD);

	/* Get output slot context. */
	sctx = KERNADDR(&sdev->octx_dma, 0);
	addr = XHCI_SCTX_DEV_ADDR(letoh32(sctx->state));
	if (addr == 0)
		return (EINVAL);

	DPRINTF(("%s: dev %d internal addr %d\n", DEVNAME(sc), slot, addr));

	return (0);
}

int
d1078 8
a1085 3
	if (xp->dci == 1)
		error = xhci_device_setup(sc, pipe->device, xp->slot);
	else
d1088 1
d1091 14
@


1.22
log
@Set and check for XFER_BUSY in the common methods instead of doing it
in every HC driver.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.21 2014/08/09 10:32:36 mpi Exp $ */
d248 1
@


1.21
log
@Add support for non-root hubs now that uhub(4) can deal with them.  For
the moment only Super and High Speed devices are properly recognized.

Some TT love is required for Full and Low speed devices.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.20 2014/08/08 14:34:11 mpi Exp $ */
d1171 1
a1171 8
	struct xhci_xfer *xx;

	xx = pool_get(xhcixfer, PR_NOWAIT | PR_ZERO);
#ifdef DIAGNOSTIC
	if (xx != NULL)
		xx->xfer.busy_free = XFER_BUSY;
#endif
	return ((struct usbd_xfer *)xx);
d1177 1
a1177 10
	struct xhci_xfer *xx = (struct xhci_xfer*)xfer;

#ifdef DIAGNOSTIC
	if (xfer->busy_free != XFER_BUSY) {
		printf("%s: xfer=%p not busy, 0x%08x\n", __func__, xfer,
		    xfer->busy_free);
		return;
	}
#endif
	pool_put(xhcixfer, xx);
@


1.20
log
@Make sure asynchronous commands do not race with synchronous ones.

Since asynchronous commands can be submitted from interrupt context
it was possible to race with a process waiting for the completion of
a previously submitted command.  So stop relying on the per-softc
TRB pointer for asynchronous commands and simply get the address of
the command TRB from the event TRB.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.19 2014/08/08 14:28:02 mpi Exp $ */
d994 1
a994 2
	usb_syncmem(&sdev->octx_dma, 0, sc->sc_pagesize,
	    BUS_DMASYNC_POSTREAD);
a1006 2


d1088 4
a1091 2
	sdev->slot_ctx->info_lo = htole32(XHCI_SCTX_DCI(xp->dci));
	sdev->slot_ctx->info_hi = 0;
d1095 8
a1102 3
	if (UE_GET_XFERTYPE(ed->bmAttributes) == UE_CONTROL) {
		sdev->slot_ctx->info_lo |= htole32(XHCI_SCTX_SPEED(speed));
		sdev->slot_ctx->info_hi |= htole32(XHCI_SCTX_RHPORT(port));
d1113 2
a1118 2

	usb_syncmem(&sdev->octx_dma, 0, sc->sc_pagesize, BUS_DMASYNC_POSTREAD);
@


1.19
log
@Improve the logic to determine the maximum endpoint service interface
time payload.  Super speed companion descriptor are still not used but
at least we can properly initialize super speed interrupt pipes.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.18 2014/08/08 14:22:45 mpi Exp $ */
a54 1
#define TRBADDR(ring, trb)	DMAADDR(&(ring).dma, TRBOFF(ring, trb))
d720 1
d725 8
a732 1
	int i;
d734 1
a734 1
	KASSERT(paddr == TRBADDR(sc->sc_cmd_ring, sc->sc_cmd_trb));
d736 1
a736 1
	flags = letoh32(sc->sc_cmd_trb->trb_flags);
a741 2
	sc->sc_cmd_trb = NULL;

d772 2
d1357 1
a1357 1
	KASSERT(sc->sc_cmd_trb == NULL);
d1366 3
a1368 1
	sc->sc_cmd_trb = trb;
d1384 1
@


1.18
log
@Implement polling.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.17 2014/08/08 14:17:52 mpi Exp $ */
d935 4
d940 1
a940 1
xhci_endpoint_txinfo(struct xhci_softc *sc, usb_endpoint_descriptor_t *ed)
d942 3
d947 3
a949 3
		return (XHCI_EPCTX_AVG_TRB_LEN(8));
	case UE_BULK:
		return (0);
d952 8
d961 2
a962 1
		break;
d965 2
a966 1
	DPRINTF(("%s: partial stub\n", __func__));
d968 1
a968 1
	return (XHCI_EPCTX_MAX_ESIT_PAYLOAD(0) | XHCI_EPCTX_AVG_TRB_LEN(0));
d1051 1
a1051 1
	mps = max(mps, UGETW(ed->wMaxPacketSize));
d1074 1
a1074 1
	sdev->ep_ctx[xp->dci-1]->txinfo = htole32(xhci_endpoint_txinfo(sc, ed));
d1084 1
a1084 1
	sdev->slot_ctx->info_lo = htole32(XHCI_SCTX_SET_DCI(xp->dci));
d1090 2
a1091 2
		sdev->slot_ctx->info_lo |= htole32(XHCI_SCTX_SET_SPEED(speed));
		sdev->slot_ctx->info_hi |= htole32(XHCI_SCTX_SET_RHPORT(port));
d1138 1
a1138 1
	sdev->slot_ctx->info_lo = htole32(XHCI_SCTX_SET_DCI(lxp->dci));
@


1.17
log
@Even if the endpoint it reseted before the stack gets informed that a
transfer stalled, report that a stall happen because umass(4) relies
on this behavior...
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.16 2014/07/11 16:38:58 pirofti Exp $ */
d578 15
a592 1
	DPRINTF(("%s: stub\n", __func__));
@


1.16
log
@Remove redundant mask check in the interrupt routine.

We return earlier if the interrupt is masked.

Discussed with and okay mpi@@
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.15 2014/07/10 11:47:14 mpi Exp $ */
d677 2
d744 2
a745 1
				xfer->status = USBD_IOERROR;
@


1.15
log
@Always assign the device address found by the USB stack even if it
does not match the hardware address.

This change only matters for xHCI buses where the controller assigns
device addresses.  But it is the simplest way to comply with the stack
requirement of assigning the first `logical' address to the root hub
device.

Device addresses are not much used anyway and a cleanup will follow to
avoid possible confusions.

This makes usbdevs(8) correctly report devices connected to xhci(4).
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.14 2014/07/09 15:54:39 mpi Exp $ */
d555 1
a555 2
	if (intrs & XHCI_STS_EINT)
		usb_schedsoftintr(&sc->sc_bus);
@


1.14
log
@Now that the stack handles properly the xhci(4) way of setting an
address, kill some no longer true comments and create a proper
function to assign an address.

For the moment, an address is assigned when setting up a slot for a
new device.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.13 2014/05/21 12:31:53 mpi Exp $ */
d963 1
a963 4
	DPRINTF(("%s: dev %d new addr %d\n", DEVNAME(sc), slot, addr));

	dev->address = addr;
	dev->bus->devices[addr] = dev;
@


1.13
log
@Handle the stall condition just like the bable one since in both cases
the ring is halted.

Do not bother reporting USBD_STALLED to the stack like other HC drivers
do since the endpoint is automatically reseted.  What is the point of
this error apart from making sure driver authors will forget to call
usbd_clear_endpoint_stall_async() correctly?

The Renesas uPD720202 xHCI, provided by Stefan Wollny, now works as
expected.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.12 2014/05/20 14:46:19 mpi Exp $ */
d84 1
d107 1
a107 1
int	xhci_cmd_address_device(struct xhci_softc *,uint8_t,  uint64_t, int);
d939 35
d1066 3
a1068 33
	if (xp->dci == 1) {
		error = xhci_cmd_address_device(sc, xp->slot,
		    DMAADDR(&sdev->ictx_dma, 0), 1 /* XXX see below */);
		if (error)
			return (error);
		/*
		 * XXX Set the address.  This is ugly and is not
		 * adapted to our stack.  But the whole idea of
		 * reopening the default pipes should be revisited
		 * anyway...
		 */
#if 1
		struct usbd_device *dev = pipe->device;
		struct xhci_sctx *slot;
		uint8_t addr;

		usb_syncmem(&sdev->octx_dma, 0, sc->sc_pagesize,
		    BUS_DMASYNC_POSTREAD);

		/* Get output slot context. */
		slot = KERNADDR(&sdev->octx_dma, 0);
		addr = XHCI_SCTX_DEV_ADDR(letoh32(slot->state));
		if (addr == 0)
			return (EINVAL);

		DPRINTF(("%s: dev %d new addr %d (old %d)\n", DEVNAME(sc),
		    xp->slot, addr, dev->address));

		dev->bus->devices[dev->address] = 0;
		dev->bus->devices[addr] = dev;
		dev->address = addr;
#endif
	} else {
d1071 4
a1074 4
		if (error) {
			xhci_ring_free(sc, &xp->ring);
			return (EIO);
		}
d1485 1
a1485 2
xhci_cmd_address_device(struct xhci_softc *sc, uint8_t slot, uint64_t addr,
    int set_address)
d1494 1
a1494 2
	    XHCI_TRB_SET_SLOT(slot) | (set_address ? 0 : XHCI_TRB_BSR) |
	    XHCI_CMD_ADDRESS_DEVICE
@


1.12
log
@Format string fixes for XHCI_DEBUG.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.11 2014/05/09 11:01:06 mpi Exp $ */
a675 1
#if 0
a676 4
		xfer->status = USBD_STALLED;
		xp->halted = 1;
		break;
#endif
@


1.11
log
@Plug an xfer leak when detaching root hubs.

This leak is similar to the public xfer leak #1 that was affecting
device interrupt pipes except that root hubs are rarely detached.

Note that this xfer is never associated to any TD and is just used
to indicate that some of the HC ports has changed status, so there
is no need to flag it as "done" before completing it.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.10 2014/04/29 12:45:29 mpi Exp $ */
d230 3
a232 3
        printf("%s: CAPLENGTH=0x%x\n", DEVNAME(sc), sc->sc_oper_off);
	printf("%s: DOORBELL=0x%x\n", DEVNAME(sc), sc->sc_door_off);
	printf("%s: RUNTIME=0x%x\n", DEVNAME(sc), sc->sc_runt_off);
d356 1
a356 1
	DPRINTF(("%s: DCBAAP=%08lx%08lx\n", DEVNAME(sc),
d364 1
a364 1
	DPRINTF(("%s: CRCR=%08lx%08lx (%016llx)\n", DEVNAME(sc),
d375 1
a375 1
	DPRINTF(("%s: ERSTBA=%08lx%08lx\n", DEVNAME(sc),
d383 1
a383 1
	DPRINTF(("%s: ERDP=%08lx%08lx\n", DEVNAME(sc),
d396 2
a397 2
	DPRINTF(("%s: USBCMD=%08lx\n", DEVNAME(sc), XOREAD4(sc, XHCI_USBCMD)));
	DPRINTF(("%s: IMAN=%08lx\n", DEVNAME(sc), XRREAD4(sc, XHCI_IMAN(0))));
d654 1
a654 1
		printf("%s: wrong trb index (%d) max is %d\n", DEVNAME(sc),
@


1.10
log
@Get rid of the per-softc freelist of transfer descriptors and use a
per-driver pool(9) instead.

With inputs from mikeb@@
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.9 2014/04/07 15:34:27 mpi Exp $ */
d2095 1
d2098 2
a2100 1

a2108 6
	struct xhci_softc *sc = (struct xhci_softc *)xfer->device->bus;

	KASSERT(sc->sc_intrxfer == xfer);

	if (!xfer->pipe->repeat)
		sc->sc_intrxfer = NULL;
@


1.9
log
@Use the `use_polling' hack to make sure usb_delay_ms() will not
call tsleep(9) on resume.  deraadt@@ pointed that this not needed
for powerdown since `cold' is set.

Another approach would be to call delay() directly in the reset
functions, but let stay coherent with the other HC drivers.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.8 2014/04/03 14:42:15 mpi Exp $ */
d24 1
d26 1
d57 2
d239 11
d1129 1
a1129 2
	struct xhci_softc *sc = (struct xhci_softc *)bus;
	struct usbd_xfer *xfer;
d1131 1
a1131 3
	xfer = SIMPLEQ_FIRST(&sc->sc_free_xfers);
	if (xfer != NULL) {
		SIMPLEQ_REMOVE_HEAD(&sc->sc_free_xfers, next);
d1133 2
a1134 3
		if (xfer->busy_free != XFER_FREE)
			printf("%s: xfer=%p not free, 0x%08x\n", __func__,
			    xfer, xfer->busy_free);
d1136 1
a1136 10
	} else
		xfer = malloc(sizeof(struct xhci_xfer), M_USB, M_NOWAIT);

	if (xfer != NULL) {
		memset(xfer, 0, sizeof(struct xhci_xfer));
#ifdef DIAGNOSTIC
		xfer->busy_free = XFER_BUSY;
#endif
	}
	return (xfer);
d1142 1
a1142 1
	struct xhci_softc *sc = (struct xhci_softc *)bus;
d1146 1
a1146 1
		printf("xhci_freex: xfer=%p not busy, 0x%08x\n", xfer,
a1149 1
	xfer->busy_free = XFER_FREE;
d1151 1
a1151 2

	SIMPLEQ_INSERT_HEAD(&sc->sc_free_xfers, xfer, next);
@


1.8
log
@XHCI -> xHCI to be consistent with device names.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.7 2014/03/28 16:19:26 mpi Exp $ */
d441 2
d447 2
@


1.7
log
@Do not declare a struct as const if we write to it, fix build on sparc64
reported by brad@@.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.6 2014/03/28 14:14:11 mpi Exp $ */
d1809 1
a1809 1
				totlen = usbd_str(buf, len, "XHCI root hub");
@


1.6
log
@If a command is submitted when the hardware is already gone, it will
obviously time out.  That is what happen when pipes are closed after
unplugging an xhci(4) express card for example.  In such case, make
sure the command TRB is reset.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.5 2014/03/25 20:27:37 mpi Exp $ */
d1591 1
a1591 1
const usb_device_descriptor_t xhci_devd = {
@


1.5
log
@Instead of matching root hubs with a custom address, that only works
because USB_START_ADDR is defined to 0 and the softc is M_ZERO'd,
assume that root hubs are the only devices with a depth of 0.

Root hubs can now happily be detached and reattached.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.4 2014/03/25 17:23:40 mpi Exp $ */
a690 1
	uint32_t flags = letoh32(sc->sc_cmd_trb->trb_flags);
d693 1
d699 2
d1336 1
d1340 2
a1341 4
#ifdef DIAGNOSTIC
		printf("%s: tsleep() = %d\n", __func__, error);
#endif
		goto timedout;
a1351 1
timedout:
@


1.4
log
@Upon resume do a full reset of the HC, including the command and event
rings, and rewrite all the addresses in the registers.

While here don't keep a copy of our usb(4) child device, autoconf(9)
knows how to reach our children.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.3 2014/03/18 15:47:23 mpi Exp $ */
a1841 1
		sc->sc_addr = value;
@


1.3
log
@Properly clear and free the endpoint associated to a pipe.  Do not
forget to update the Endpoint Context with the last valid endpoint
and free the device resources, including its slot, when the default
pipe is closed.

Device addresses can now be reused and I should be done with
descriptor leaks.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.2 2014/03/12 13:05:02 mpi Exp $ */
d72 1
a207 1
	uint64_t paddr;
a252 6
	/* Make sure to program a number of device slots we can handle. */
	if (sc->sc_noslot > USB_MAX_DEVICES)
		sc->sc_noslot = USB_MAX_DEVICES;
	hcr = XOREAD4(sc, XHCI_CONFIG) & ~XHCI_CONFIG_SLOTS_MASK;
	XOWRITE4(sc, XHCI_CONFIG, hcr | sc->sc_noslot);

d318 18
a382 2

	return (0);
d386 1
a386 1
xhci_detach(struct xhci_softc *sc, int flags)
d388 1
d391 1
a391 3
	if (sc->sc_child != NULL)
		rv = config_detach(sc->sc_child, flags);

d440 6
a445 4
	case DVACT_DEACTIVATE:
		if (sc->sc_child != NULL)
			rv = config_deactivate(sc->sc_child);
		sc->sc_bus.dying = 1;
@


1.2
log
@If a device is babbling do a full reset of the associated endpoint
before telling the stack/driver that the responsible transfer is
done.

Since the request sequence requires, in the present form, to submit
two commands from the interrupt handler, modify the command routine
to be able to submit asynchronous commands.

I can now use my crappy urtwn(4) over xhci(4).

While here convert some #if -> #ifdef, pointed out by brad@@.
@
text
@d1 1
a1 1
/* $OpenBSD: xhci.c,v 1.1 2014/03/08 14:34:11 mpi Exp $ */
d98 2
a99 2
int	xhci_cmd_configure_endpoint(struct xhci_softc *, uint8_t, uint64_t);
int	xhci_cmd_stop_endpoint(struct xhci_softc *, uint8_t, uint8_t);
d1036 1
a1036 1
		error = xhci_cmd_configure_endpoint(sc, xp->slot,
d1053 2
a1054 1
	struct xhci_pipe *xp = (struct xhci_pipe *)pipe;
d1056 1
d1062 2
a1063 6
	/* XXX this is wrong */
	if (!xp->halted || xhci_cmd_stop_endpoint(sc, xp->slot, xp->dci)) {
		DPRINTF(("%s: unable to stop pipe=%p dci=%d\n", DEVNAME(sc),
		    pipe, xp->dci));
		return;
	}
d1066 2
a1067 2
	sdev->input_ctx->drop_flags |= htole32(XHCI_INCTX_MASK_DCI(xp->dci));
	sdev->input_ctx->add_flags &= ~htole32(XHCI_INCTX_MASK_DCI(xp->dci));
d1069 10
a1078 2
	/* Clear the endpoint context */
	memset(&sdev->ep_ctx[xp->dci-1], 0, sizeof(struct xhci_epctx));
d1082 3
d1086 6
d1379 1
a1379 1
xhci_cmd_configure_endpoint(struct xhci_softc *sc, uint8_t slot, uint64_t addr)
d1395 1
a1395 1
xhci_cmd_stop_endpoint(struct xhci_softc *sc, uint8_t slot, uint8_t dci)
d1452 6
a1457 3
	trb.trb_flags = htole32(
	    enable ? XHCI_CMD_ENABLE_SLOT : XHCI_CMD_DISABLE_SLOT
	);
d1462 2
a1463 1
	*slotp = XHCI_TRB_GET_SLOT(letoh32(trb.trb_flags));
a1567 1
	int i;
a1571 5

	for (i = 0; i < 31; i++) {
		if (sdev->pipes[i] != NULL)
			xhci_ring_free(sc, &sdev->pipes[i]->ring);
	}
@


1.1
log
@Dumb xhci(4) implementation.

This driver does not handle isochronous endpoint (yet) and has no logical
TD representation.  Each transfer is linked to the raw TRB of its related
endpoint.

Most of the transfer error completion codes are not handled, even with all
the cheese provided by miod@@ I couldn't find a proper way to reset an
endpoint asynchronously when a device babbles.  Or maybe it was the wine?
Anyway this will come soon.

In general the endpoint configuration and reset code is really crude and
requires some love, but our stack should be fixed to properly open only
once the default pipe of every new USB device first.

This means this driver wont work as it is, our stack needs other changes
first.

Suspend/resume works but ports are not suspended for the moment.

But even with these problems, interrupt devices: ukbd(4), ums(4) and
sensors like ugold(4) work properly and USB 3.0 umass(4) devices give
me a reasonnable read/write speed.

Timeouts to cancel USB transfers are not enabled *on purpose*, to be able
to track down potential timing issues.

I'm committing now so that others can help fixing my bugs (8

All this work has been done on an ExpressCard with a NEC xHCI 0.96, other
implementations/versions might trigger more bugs :)
@
text
@d1 1
a1 1
/* $OpenBSD$ */
d76 1
d96 2
a97 2
int	xhci_cmd_reset_endpoint(struct xhci_softc *, uint8_t, uint8_t);
int	xhci_cmd_set_tr_deq(struct xhci_softc *, uint8_t, uint8_t, uint64_t);
d195 1
a195 1
#if XHCI_DEBUG
d581 2
a582 4
			if (paddr == TRBADDR(sc->sc_cmd_ring, sc->sc_cmd_trb)) {
				memcpy(&sc->sc_result_trb, trb, sizeof(*trb));
				wakeup(&sc->sc_cmd_trb);
			}
d588 1
a588 1
#if XHCI_DEBUG
a639 2
	xhci_xfer_done(xfer);

d651 1
d653 5
a657 1
		xfer->status = USBD_IOERROR;
d659 2
a660 2
		/* FALLTHROUGH */
#endif
d670 1
d673 1
d678 51
d809 1
a809 1
#if XHCI_DEBUG
d928 2
d1189 1
a1189 16
	memset(ring->trbs, 0, size);

	ring->index = 0;
	ring->toggle = XHCI_TRB_CYCLE;

	/*
	 * Since all our rings use only one segment, at least for
	 * the moment, link their tail to their head.
	 */
	if (ring != &sc->sc_evt_ring) {
		ring->trbs[ntrb - 1].trb_paddr = htole64(DMAADDR(&ring->dma, 0));
		ring->trbs[ntrb - 1].trb_flags = htole32(
		    XHCI_TRB_TYPE_LINK | XHCI_TRB_LINKSEG
		);
	}
	usb_syncmem(&ring->dma, 0, size, BUS_DMASYNC_PREWRITE);
d1205 2
a1206 2
	/* Don't touch the link TRB, hence the -1. */
	size = (ring->ntrb - 1) * sizeof(struct xhci_trb);
d1212 10
d1255 1
a1255 1
		ring->toggle ^= XHCI_TRB_CYCLE;
d1297 6
a1303 1
	XDWRITE4(sc, XHCI_DOORBELL(0), 0);
d1307 1
a1307 1
#if XHCI_DEBUG
d1326 1
a1326 1
#if XHCI_DEBUG
a1331 1
	sc->sc_cmd_trb = NULL;
d1395 2
a1396 2
int
xhci_cmd_reset_endpoint(struct xhci_softc *sc, uint8_t slot, uint8_t dci)
d1408 1
a1408 1
	return (xhci_command_submit(sc, &trb, XHCI_COMMAND_TIMEOUT));
d1411 2
a1412 2
int
xhci_cmd_set_tr_deq(struct xhci_softc *sc, uint8_t slot, uint8_t dci,
d1425 1
a1425 1
	return (xhci_command_submit(sc, &trb, XHCI_COMMAND_TIMEOUT));
d2111 1
a2111 1
	if (sc->sc_bus.dying)
d2204 1
a2204 1
	if (sc->sc_bus.dying)
@

