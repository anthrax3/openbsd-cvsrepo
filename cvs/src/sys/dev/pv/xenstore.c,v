head	1.44;
access;
symbols
	OPENBSD_6_2:1.44.0.2
	OPENBSD_6_2_BASE:1.44
	OPENBSD_6_1:1.43.0.4
	OPENBSD_6_1_BASE:1.43
	OPENBSD_6_0:1.28.0.2
	OPENBSD_6_0_BASE:1.28
	OPENBSD_5_9:1.27.0.2
	OPENBSD_5_9_BASE:1.27;
locks; strict;
comment	@ * @;


1.44
date	2017.08.10.18.14.56;	author mikeb;	state Exp;
branches;
next	1.43;
commitid	BA0cDBfiVRx8aD3b;

1.43
date	2017.03.13.01.10.03;	author mikeb;	state Exp;
branches;
next	1.42;
commitid	7qXoPSATw8fQxunw;

1.42
date	2017.03.13.01.00.15;	author mikeb;	state Exp;
branches;
next	1.41;
commitid	knAVpjVB7fgmCUNq;

1.41
date	2017.02.12.11.56.41;	author mikeb;	state Exp;
branches;
next	1.40;
commitid	AUMkst1IHNIcIpQC;

1.40
date	2017.02.07.11.52.07;	author mikeb;	state Exp;
branches;
next	1.39;
commitid	klmY2vjnWfhQeL1t;

1.39
date	2017.02.06.21.52.02;	author mikeb;	state Exp;
branches;
next	1.38;
commitid	uLYJdmDVwCLofDEA;

1.38
date	2017.02.06.21.43.48;	author mikeb;	state Exp;
branches;
next	1.37;
commitid	NscjkKs6gyrHx1os;

1.37
date	2017.01.12.20.29.46;	author mikeb;	state Exp;
branches;
next	1.36;
commitid	77L0PLGRBhAZfhud;

1.36
date	2016.12.09.17.24.55;	author mikeb;	state Exp;
branches;
next	1.35;
commitid	JcAbCgH7EdZVJZid;

1.35
date	2016.12.07.15.21.04;	author mikeb;	state Exp;
branches;
next	1.34;
commitid	AMLEifex6cUtuqNv;

1.34
date	2016.12.07.15.18.02;	author mikeb;	state Exp;
branches;
next	1.33;
commitid	CnOq7BCEdNW5r5Mw;

1.33
date	2016.12.07.15.13.23;	author mikeb;	state Exp;
branches;
next	1.32;
commitid	dibJ3wbP0QtpFG6j;

1.32
date	2016.11.29.14.55.04;	author mikeb;	state Exp;
branches;
next	1.31;
commitid	tsMjTSHgEUUjCy08;

1.31
date	2016.11.29.13.55.33;	author mikeb;	state Exp;
branches;
next	1.30;
commitid	wUluX7TJ50t0yQ2U;

1.30
date	2016.11.29.12.12.29;	author mikeb;	state Exp;
branches;
next	1.29;
commitid	FMTBkEDj66DV0X8y;

1.29
date	2016.07.29.21.05.26;	author mikeb;	state Exp;
branches;
next	1.28;
commitid	kYt9NhxdfNdG3qdT;

1.28
date	2016.04.19.18.15.41;	author mikeb;	state Exp;
branches;
next	1.27;
commitid	3qNUUD4LouZDwEm4;

1.27
date	2016.02.05.10.30.37;	author mikeb;	state Exp;
branches;
next	1.26;
commitid	hC9DmZs6JEBo9krq;

1.26
date	2016.02.04.12.50.56;	author mikeb;	state Exp;
branches;
next	1.25;
commitid	aROW6h33OAiSY6Gd;

1.25
date	2016.02.02.17.52.46;	author mikeb;	state Exp;
branches;
next	1.24;
commitid	9CqV2Pl3GitdAPFk;

1.24
date	2016.01.29.19.04.30;	author mikeb;	state Exp;
branches;
next	1.23;
commitid	JnL9q61QcwW3tbUG;

1.23
date	2016.01.29.18.49.06;	author mikeb;	state Exp;
branches;
next	1.22;
commitid	Pre5L4C8fKqWmy3c;

1.22
date	2016.01.27.09.04.19;	author reyk;	state Exp;
branches;
next	1.21;
commitid	xjeRSSQ0SXSd3nFz;

1.21
date	2016.01.25.15.22.56;	author mikeb;	state Exp;
branches;
next	1.20;
commitid	fNd5qUc1O1ALVnQH;

1.20
date	2016.01.22.19.26.40;	author mikeb;	state Exp;
branches;
next	1.19;
commitid	8WKKDjpXSgA8QRPP;

1.19
date	2016.01.18.18.54.38;	author mikeb;	state Exp;
branches;
next	1.18;
commitid	tkUrhnJaI1rp2d3y;

1.18
date	2016.01.15.18.20.41;	author mikeb;	state Exp;
branches;
next	1.17;
commitid	iowr1UutJmouij7D;

1.17
date	2016.01.12.12.12.05;	author mikeb;	state Exp;
branches;
next	1.16;
commitid	pZIhZIgs6g6DXAyy;

1.16
date	2016.01.12.11.54.05;	author mikeb;	state Exp;
branches;
next	1.15;
commitid	6C25mz5cPfJyNE9D;

1.15
date	2016.01.11.16.54.33;	author mikeb;	state Exp;
branches;
next	1.14;
commitid	HETMZQjA29E7Sd03;

1.14
date	2016.01.11.16.34.49;	author reyk;	state Exp;
branches;
next	1.13;
commitid	2wIU7DgItCNrMdQz;

1.13
date	2016.01.11.16.14.16;	author mikeb;	state Exp;
branches;
next	1.12;
commitid	pAxhf6CpdrR8gyKb;

1.12
date	2016.01.04.16.06.50;	author mikeb;	state Exp;
branches;
next	1.11;
commitid	iktkrWXWyuFiTlJa;

1.11
date	2015.12.22.22.19.46;	author mikeb;	state Exp;
branches;
next	1.10;
commitid	JtwCqhB3iy6hPLQv;

1.10
date	2015.12.22.22.16.53;	author mikeb;	state Exp;
branches;
next	1.9;
commitid	6HhBROM8QMXkOoyd;

1.9
date	2015.12.21.18.17.36;	author mikeb;	state Exp;
branches;
next	1.8;
commitid	iEb7l4w8l1M3rzzp;

1.8
date	2015.12.19.09.12.29;	author mikeb;	state Exp;
branches;
next	1.7;
commitid	eHm03WCGPUA4gBis;

1.7
date	2015.12.12.21.07.45;	author reyk;	state Exp;
branches;
next	1.6;
commitid	h86qK9FFdj1rQhW1;

1.6
date	2015.12.11.12.41.57;	author mikeb;	state Exp;
branches;
next	1.5;
commitid	DDzMgfX7vCBESvV6;

1.5
date	2015.12.11.12.39.46;	author mikeb;	state Exp;
branches;
next	1.4;
commitid	870myquGU7uGt31P;

1.4
date	2015.12.09.17.27.29;	author mikeb;	state Exp;
branches;
next	1.3;
commitid	b1Q0zJcVaeOHJqND;

1.3
date	2015.12.09.14.20.53;	author mikeb;	state Exp;
branches;
next	1.2;
commitid	dvfqxtToBFhclEbT;

1.2
date	2015.12.09.01.23.26;	author mikeb;	state Exp;
branches;
next	1.1;
commitid	uSDUOo3xfdf8LJmy;

1.1
date	2015.12.08.22.14.40;	author mikeb;	state Exp;
branches;
next	;
commitid	TtYskjHMvQp6NRMk;


desc
@@


1.44
log
@Prevent an unlikely resource leak

Coverity CID 1453069; Severity: unlikely, not user-visible.
@
text
@/*	$OpenBSD: xenstore.c,v 1.43 2017/03/13 01:10:03 mikeb Exp $	*/

/*
 * Copyright (c) 2015 Mike Belopuhov
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/atomic.h>
#include <sys/kernel.h>
#include <sys/malloc.h>
#include <sys/device.h>
#include <sys/mutex.h>
#include <sys/rwlock.h>
#include <sys/ioctl.h>
#include <sys/task.h>

#include <machine/bus.h>

#include <uvm/uvm_extern.h>

#include <dev/pv/pvvar.h>
#include <dev/pv/xenreg.h>
#include <dev/pv/xenvar.h>

/* #define XS_DEBUG */

#ifdef XS_DEBUG
#define DPRINTF(x...)		printf(x)
#else
#define DPRINTF(x...)
#endif

/*
 * The XenStore interface is a simple storage system that is a means of
 * communicating state and configuration data between the Xen Domain 0
 * and the various guest domains.  All configuration data other than
 * a small amount of essential information required during the early
 * boot process of launching a Xen aware guest, is managed using the
 * XenStore.
 *
 * The XenStore is ASCII string based, and has a structure and semantics
 * similar to a filesystem.  There are files and directories that are
 * able to contain files or other directories.  The depth of the hierachy
 * is only limited by the XenStore's maximum path length.
 *
 * The communication channel between the XenStore service and other
 * domains is via two, guest specific, ring buffers in a shared memory
 * area.  One ring buffer is used for communicating in each direction.
 * The grant table references for this shared memory are given to the
 * guest via HVM hypercalls.
 *
 * The XenStore communication relies on an event channel and thus
 * interrupts. Several Xen services depend on the XenStore, most
 * notably the XenBus used to discover and manage Xen devices.
 */

const struct {
	const char		*xse_errstr;
	int			 xse_errnum;
} xs_errors[] = {
	{ "EINVAL",	EINVAL },
	{ "EACCES",	EACCES },
	{ "EEXIST",	EEXIST },
	{ "EISDIR",	EISDIR },
	{ "ENOENT",	ENOENT },
	{ "ENOMEM",	ENOMEM },
	{ "ENOSPC",	ENOSPC },
	{ "EIO",	EIO },
	{ "ENOTEMPTY",	ENOTEMPTY },
	{ "ENOSYS",	ENOSYS },
	{ "EROFS",	EROFS },
	{ "EBUSY",	EBUSY },
	{ "EAGAIN",	EAGAIN },
	{ "EISCONN",	EISCONN },
	{ NULL,		-1 },
};

struct xs_msghdr {
	/* Message type */
	uint32_t		 xmh_type;
	/* Request identifier, echoed in daemon's response.  */
	uint32_t		 xmh_rid;
	/* Transaction id (0 if not related to a transaction). */
	uint32_t		 xmh_tid;
	/* Length of data following this. */
	uint32_t		 xmh_len;
	/* Generally followed by nul-terminated string(s). */
} __packed;

/*
 * A minimum output buffer size needed to store an error string.
 */
#define XS_ERR_PAYLOAD		16

/*
 * Although the Xen source code implies that the limit is 4k,
 * in practice it turns out that we can only send 2k bytes of
 * payload before receiving a ENOSPC.  We set it to an even
 * smaller value however, because there's no real need to use
 * large buffers for anything.
 */
#define XS_MAX_PAYLOAD		1024

struct xs_msg {
	struct xs_msghdr	 xsm_hdr;
	uint32_t		 xsm_read;
	uint32_t		 xsm_dlen;
	uint8_t			*xsm_data;
	TAILQ_ENTRY(xs_msg)	 xsm_link;
};
TAILQ_HEAD(xs_msgq, xs_msg);

#define XS_RING_SIZE		1024

struct xs_ring {
	uint8_t			xsr_req[XS_RING_SIZE];
	uint8_t			xsr_rsp[XS_RING_SIZE];
	uint32_t		xsr_req_cons;
	uint32_t		xsr_req_prod;
	uint32_t		xsr_rsp_cons;
	uint32_t		xsr_rsp_prod;
} __packed;

#define XST_DELAY		1	/* in seconds */

#define XSW_TOKLEN		(sizeof(void *) * 2 + 1)

struct xs_watch {
	TAILQ_ENTRY(xs_watch)	 xsw_entry;
	uint8_t			 xsw_token[XSW_TOKLEN];
	struct task		*xsw_task;
};

/*
 * Container for all XenStore related state.
 */
struct xs_softc {
	struct xen_softc	*xs_sc;

	evtchn_port_t		 xs_port;
	xen_intr_handle_t	 xs_ih;

	struct xs_ring		*xs_ring;

	struct xs_msg		 xs_msgs[10];
	struct xs_msg		*xs_rmsg;

	struct xs_msgq		 xs_free;
	struct xs_msgq		 xs_reqs;
	struct xs_msgq		 xs_rsps;

	volatile uint		 xs_rid;

	const char		*xs_wchan;
	const char		*xs_rchan;

	struct mutex		 xs_reqlck;	/* request queue mutex */
	struct mutex		 xs_rsplck;	/* response queue mutex */
	struct mutex		 xs_frqlck;	/* free queue mutex */

	TAILQ_HEAD(, xs_watch)	 xs_watches;
	struct mutex		 xs_watchlck;
	struct xs_msg		 xs_emsg;
	struct taskq		*xs_watchtq;

	struct rwlock		 xs_rnglck;
};

struct xs_msg *
	xs_get_msg(struct xs_softc *, int);
void	xs_put_msg(struct xs_softc *, struct xs_msg *);
int	xs_ring_get(struct xs_softc *, void *, size_t);
int	xs_ring_put(struct xs_softc *, void *, size_t);
void	xs_intr(void *);
void	xs_poll(struct xs_softc *, int);
int	xs_output(struct xs_transaction *, uint8_t *, int);
int	xs_start(struct xs_transaction *, struct xs_msg *, struct iovec *, int);
struct xs_msg *
	xs_reply(struct xs_transaction *, uint);
int	xs_parse(struct xs_transaction *, struct xs_msg *, struct iovec **,
	    int *);
int	xs_event(struct xs_softc *, struct xs_msg *);

int
xs_attach(struct xen_softc *sc)
{
        struct xen_hvm_param xhv;
	struct xs_softc *xs;
	paddr_t pa;
	int i;

	if ((xs = malloc(sizeof(*xs), M_DEVBUF, M_NOWAIT | M_ZERO)) == NULL) {
		printf(": failed to allocate xenstore softc\n");
		return (-1);
	}
	sc->sc_xs = xs;
	xs->xs_sc = sc;

	/* Fetch event channel port */
	memset(&xhv, 0, sizeof(xhv));
	xhv.domid = DOMID_SELF;
	xhv.index = HVM_PARAM_STORE_EVTCHN;
	if (xen_hypercall(sc, XC_HVM, 2, HVMOP_get_param, &xhv)) {
		printf(": failed to obtain a xenstore event channel\n");
		goto fail_1;
	}
	xs->xs_port = xhv.value;

	printf(", event channel %u\n", xs->xs_port);

	/* Fetch a frame number (PA) of a shared xenstore page */
	memset(&xhv, 0, sizeof(xhv));
	xhv.domid = DOMID_SELF;
	xhv.index = HVM_PARAM_STORE_PFN;
	if (xen_hypercall(sc, XC_HVM, 2, HVMOP_get_param, &xhv))
		goto fail_1;
	pa = ptoa(xhv.value);
	/* Allocate a page of virtual memory */
	xs->xs_ring = km_alloc(PAGE_SIZE, &kv_any, &kp_none, &kd_nowait);
	if (xs->xs_ring == NULL)
		goto fail_1;
	/* Map in the xenstore page into our KVA */
	pa |= PMAP_NOCACHE;
	pmap_kenter_pa((vaddr_t)xs->xs_ring, pa, PROT_READ | PROT_WRITE);
	pmap_update(pmap_kernel());

	if (xen_intr_establish(xs->xs_port, &xs->xs_ih, 0, xs_intr, xs,
	    sc->sc_dev.dv_xname))
		goto fail_2;

	xs->xs_wchan = "xswrite";
	xs->xs_rchan = "xsread";

	TAILQ_INIT(&xs->xs_free);
	TAILQ_INIT(&xs->xs_reqs);
	TAILQ_INIT(&xs->xs_rsps);
	for (i = 0; i < nitems(xs->xs_msgs); i++)
		TAILQ_INSERT_TAIL(&xs->xs_free, &xs->xs_msgs[i], xsm_link);

	mtx_init(&xs->xs_reqlck, IPL_NET);
	mtx_init(&xs->xs_rsplck, IPL_NET);
	mtx_init(&xs->xs_frqlck, IPL_NET);

	rw_init(&xs->xs_rnglck, "xsrnglck");

	xs->xs_watchtq = taskq_create("xenwatch", 1, IPL_NET, 0);

	mtx_init(&xs->xs_watchlck, IPL_NET);
	TAILQ_INIT(&xs->xs_watches);

	xs->xs_emsg.xsm_data = malloc(XS_MAX_PAYLOAD, M_DEVBUF,
	    M_ZERO | M_NOWAIT);
	if (xs->xs_emsg.xsm_data == NULL)
		goto fail_2;
	xs->xs_emsg.xsm_dlen = XS_MAX_PAYLOAD;

	return (0);

 fail_2:
	pmap_kremove((vaddr_t)xs->xs_ring, PAGE_SIZE);
	pmap_update(pmap_kernel());
	km_free(xs->xs_ring, PAGE_SIZE, &kv_any, &kp_none);
	xs->xs_ring = NULL;
 fail_1:
	free(xs, sizeof(*xs), M_DEVBUF);
	sc->sc_xs = NULL;
	return (-1);
}

struct xs_msg *
xs_get_msg(struct xs_softc *xs, int waitok)
{
	static const char *chan = "xsalloc";
	struct xs_msg *xsm;

	mtx_enter(&xs->xs_frqlck);
	for (;;) {
		xsm = TAILQ_FIRST(&xs->xs_free);
		if (xsm != NULL) {
			TAILQ_REMOVE(&xs->xs_free, xsm, xsm_link);
			break;
		}
		if (!waitok) {
			mtx_leave(&xs->xs_frqlck);
			delay(XST_DELAY * 1000 >> 2);
			mtx_enter(&xs->xs_frqlck);
		} else
			msleep(chan, &xs->xs_frqlck, PRIBIO, chan,
			    XST_DELAY * hz >> 2);
	}
	mtx_leave(&xs->xs_frqlck);
	return (xsm);
}

void
xs_put_msg(struct xs_softc *xs, struct xs_msg *xsm)
{
	memset(xsm, 0, sizeof(*xsm));
	mtx_enter(&xs->xs_frqlck);
	TAILQ_INSERT_TAIL(&xs->xs_free, xsm, xsm_link);
	mtx_leave(&xs->xs_frqlck);
}

int
xs_geterror(struct xs_msg *xsm)
{
	int i;

	for (i = 0; i < nitems(xs_errors); i++)
		if (strcmp(xs_errors[i].xse_errstr, xsm->xsm_data) == 0)
			return (xs_errors[i].xse_errnum);
	return (EOPNOTSUPP);
}

static inline uint32_t
xs_ring_avail(struct xs_ring *xsr, int req)
{
	uint32_t cons = req ? xsr->xsr_req_cons : xsr->xsr_rsp_cons;
	uint32_t prod = req ? xsr->xsr_req_prod : xsr->xsr_rsp_prod;

	KASSERT(prod - cons <= XS_RING_SIZE);
	return (req ? XS_RING_SIZE - (prod - cons) : prod - cons);
}

void
xs_poll(struct xs_softc *xs, int nosleep)
{
	int s;

	if (nosleep) {
		delay(XST_DELAY * 1000 >> 2);
		s = splnet();
		xs_intr(xs);
		splx(s);
	} else
		tsleep(xs->xs_wchan, PRIBIO, xs->xs_wchan, XST_DELAY * hz >> 2);
}

int
xs_output(struct xs_transaction *xst, uint8_t *bp, int len)
{
	struct xs_softc *xs = xst->xst_cookie;
	int chunk;

	while (len > 0) {
		chunk = xs_ring_put(xs, bp, MIN(len, XS_RING_SIZE));
		if (chunk < 0)
			return (-1);
		if (chunk > 0) {
			len -= chunk;
			bp += chunk;
			if (xs_ring_avail(xs->xs_ring, 1) > 0)
				continue;
		}
		/* Squeaky wheel gets the kick */
		xen_intr_signal(xs->xs_ih);
		/*
		 * chunk == 0: we need to wait for hv to consume
		 * what has already been written;
		 *
		 * Alternatively we have managed to fill the ring
		 * and must wait for HV to collect the data.
		 */
		while (xs->xs_ring->xsr_req_prod != xs->xs_ring->xsr_req_cons)
			xs_poll(xs, 1);
	}
	return (0);
}

int
xs_start(struct xs_transaction *xst, struct xs_msg *xsm, struct iovec *iov,
    int iov_cnt)
{
	struct xs_softc *xs = xst->xst_cookie;
	int i;

	rw_enter_write(&xs->xs_rnglck);

	/* Header */
	if (xs_output(xst, (uint8_t *)&xsm->xsm_hdr,
	    sizeof(xsm->xsm_hdr)) == -1) {
		printf("%s: failed to write the header\n", __func__);
		rw_exit_write(&xs->xs_rnglck);
		return (-1);
	}

	/* Data loop */
	for (i = 0; i < iov_cnt; i++) {
		if (xs_output(xst, iov[i].iov_base, iov[i].iov_len) == -1) {
			printf("%s: failed on iovec #%d len %lu\n", __func__,
			    i, iov[i].iov_len);
			rw_exit_write(&xs->xs_rnglck);
			return (-1);
		}
	}

	mtx_enter(&xs->xs_reqlck);
	TAILQ_INSERT_TAIL(&xs->xs_reqs, xsm, xsm_link);
	mtx_leave(&xs->xs_reqlck);

	xen_intr_signal(xs->xs_ih);

	rw_exit_write(&xs->xs_rnglck);

	return (0);
}

struct xs_msg *
xs_reply(struct xs_transaction *xst, uint rid)
{
	struct xs_softc *xs = xst->xst_cookie;
	struct xs_msg *xsm;
	int s;

	mtx_enter(&xs->xs_rsplck);
	for (;;) {
		TAILQ_FOREACH(xsm, &xs->xs_rsps, xsm_link) {
			if (xsm->xsm_hdr.xmh_tid == xst->xst_id &&
			    xsm->xsm_hdr.xmh_rid == rid)
				break;
		}
		if (xsm != NULL) {
			TAILQ_REMOVE(&xs->xs_rsps, xsm, xsm_link);
			break;
		}
		if (cold) {
			mtx_leave(&xs->xs_rsplck);
			delay(XST_DELAY * 1000 >> 2);
			s = splnet();
			xs_intr(xs);
			splx(s);
			mtx_enter(&xs->xs_rsplck);
		} else
			msleep(xs->xs_rchan, &xs->xs_rsplck, PRIBIO,
			    xs->xs_rchan, XST_DELAY * hz >> 2);
	}
	mtx_leave(&xs->xs_rsplck);
	return (xsm);
}

int
xs_ring_put(struct xs_softc *xs, void *src, size_t size)
{
	struct xs_ring *xsr = xs->xs_ring;
	uint32_t prod = xsr->xsr_req_prod & (XS_RING_SIZE - 1);
	uint32_t avail = xs_ring_avail(xsr, 1);
	size_t left;

	if (size > XS_RING_SIZE)
		return (-1);
	if (avail == 0)
		return (0);

	/* Bound the size by the number of available slots */
	size = MIN(size, avail);
	/* How many contiguous bytes can we memcpy... */
	left = XS_RING_SIZE - prod;
	/* ...bounded by by how much we need to write? */
	left = MIN(left, size);

	memcpy(&xsr->xsr_req[prod], src, left);
	memcpy(&xsr->xsr_req[0], (caddr_t)src + left, size - left);
	virtio_membar_sync();
	xsr->xsr_req_prod += size;
	return (size);
}

int
xs_ring_get(struct xs_softc *xs, void *dst, size_t size)
{
	struct xs_ring *xsr = xs->xs_ring;
	uint32_t cons = xsr->xsr_rsp_cons & (XS_RING_SIZE - 1);
	uint32_t avail = xs_ring_avail(xsr, 0);
	size_t left;

	if (size > XS_RING_SIZE)
		return (-1);
	if (avail == 0)
		return (0);

	/* Bound the size by the number of available slots */
	size = MIN(size, avail);
	/* How many contiguous bytes can we memcpy... */
	left = XS_RING_SIZE - cons;
	/* ...bounded by by how much we need to read? */
	left = MIN(left, size);

	memcpy(dst, &xsr->xsr_rsp[cons], left);
	memcpy((caddr_t)dst + left, &xsr->xsr_rsp[0], size - left);
	virtio_membar_sync();
	xsr->xsr_rsp_cons += size;
	return (size);
}

void
xs_intr(void *arg)
{
	struct xs_softc *xs = arg;
	struct xs_ring *xsr = xs->xs_ring;
	struct xen_softc *sc = xs->xs_sc;
	struct xs_msg *xsm = xs->xs_rmsg;
	struct xs_msghdr xmh;
	uint32_t avail;
	int len;

	virtio_membar_sync();

	if (xsr->xsr_rsp_cons == xsr->xsr_rsp_prod)
		return;

	avail = xs_ring_avail(xsr, 0);

	/* Response processing */

 again:
	if (xs->xs_rmsg == NULL) {
		if (avail < sizeof(xmh)) {
			DPRINTF("%s: incomplete header: %u\n",
			    sc->sc_dev.dv_xname, avail);
			goto out;
		}
		avail -= sizeof(xmh);

		if ((len = xs_ring_get(xs, &xmh, sizeof(xmh))) != sizeof(xmh)) {
			printf("%s: message too short: %d\n",
			    sc->sc_dev.dv_xname, len);
			goto out;
		}

		if (xmh.xmh_type == XS_EVENT) {
			xsm = &xs->xs_emsg;
			xsm->xsm_read = 0;
		} else {
			mtx_enter(&xs->xs_reqlck);
			TAILQ_FOREACH(xsm, &xs->xs_reqs, xsm_link) {
				if (xsm->xsm_hdr.xmh_rid == xmh.xmh_rid) {
					TAILQ_REMOVE(&xs->xs_reqs, xsm,
					    xsm_link);
					break;
				}
			}
			mtx_leave(&xs->xs_reqlck);
			if (xsm == NULL) {
				printf("%s: unexpected message id %u\n",
				    sc->sc_dev.dv_xname, xmh.xmh_rid);
				goto out;
			}
		}
		memcpy(&xsm->xsm_hdr, &xmh, sizeof(xmh));
		xs->xs_rmsg = xsm;
	}

	if (xsm->xsm_hdr.xmh_len > xsm->xsm_dlen)
		panic("message too large: %d vs %d for type %d, rid %u",
		    xsm->xsm_hdr.xmh_len, xsm->xsm_dlen, xsm->xsm_hdr.xmh_type,
		    xsm->xsm_hdr.xmh_rid);

	len = MIN(xsm->xsm_hdr.xmh_len - xsm->xsm_read, avail);
	if (len) {
		/* Get data if reply is not empty */
		if ((len = xs_ring_get(xs,
		    &xsm->xsm_data[xsm->xsm_read], len)) <= 0) {
			printf("%s: read failure %d\n", sc->sc_dev.dv_xname,
			    len);
			goto out;
		}
		xsm->xsm_read += len;
	}

	/* Notify reader that we've managed to read the whole message */
	if (xsm->xsm_read == xsm->xsm_hdr.xmh_len) {
		xs->xs_rmsg = NULL;
		if (xsm->xsm_hdr.xmh_type == XS_EVENT) {
			xs_event(xs, xsm);
		} else {
			mtx_enter(&xs->xs_rsplck);
			TAILQ_INSERT_TAIL(&xs->xs_rsps, xsm, xsm_link);
			mtx_leave(&xs->xs_rsplck);
			wakeup(xs->xs_rchan);
		}
	}

	if ((avail = xs_ring_avail(xsr, 0)) > 0)
		goto again;

 out:
	/* Wakeup sleeping writes (if any) */
	wakeup(xs->xs_wchan);
	xen_intr_signal(xs->xs_ih);
}

static inline int
xs_get_buf(struct xs_transaction *xst, struct xs_msg *xsm, int len)
{
	unsigned char *buf;

	buf = malloc(len, M_DEVBUF, M_ZERO | (cold ? M_NOWAIT : M_WAITOK));
	if (buf == NULL)
		return (-1);
	xsm->xsm_dlen = len;
	xsm->xsm_data = buf;
	return (0);
}

static inline void
xs_put_buf(struct xs_transaction *xst, struct xs_msg *xsm)
{
	free(xsm->xsm_data, M_DEVBUF, xsm->xsm_dlen);
	xsm->xsm_data = NULL;
}

void
xs_resfree(struct xs_transaction *xst, struct iovec *iov, int iov_cnt)
{
	int i;

	for (i = 0; i < iov_cnt; i++)
		free(iov[i].iov_base, M_DEVBUF, iov[i].iov_len);
	free(iov, M_DEVBUF, sizeof(struct iovec) * iov_cnt);
}

int
xs_parse(struct xs_transaction *xst, struct xs_msg *xsm, struct iovec **iov,
    int *iov_cnt)
{
	char *bp, *cp;
	uint32_t dlen;
	int i, flags;

	/* If the response size is zero, we return an empty string */
	dlen = MAX(xsm->xsm_hdr.xmh_len, 1);
	flags = M_ZERO | (cold ? M_NOWAIT : M_WAITOK);

	*iov_cnt = 0;
	/* Make sure that the data is NUL terminated */
	if (xsm->xsm_data[dlen - 1] != '\0') {
		/*
		 * The XS_READ operation always returns length without
		 * the trailing NUL so we have to adjust the length.
		 */
		dlen = MIN(dlen + 1, xsm->xsm_dlen);
		xsm->xsm_data[dlen - 1] = '\0';
	}
	for (i = 0; i < dlen; i++)
		if (xsm->xsm_data[i] == '\0')
			(*iov_cnt)++;
	*iov = mallocarray(*iov_cnt, sizeof(struct iovec), M_DEVBUF, flags);
	if (*iov == NULL)
		goto cleanup;
	bp = xsm->xsm_data;
	for (i = 0; i < *iov_cnt; i++) {
		cp = bp;
		while (cp - (caddr_t)xsm->xsm_data < dlen && *cp != '\0')
			cp++;
		(*iov)[i].iov_len = cp - bp + 1;
		(*iov)[i].iov_base = malloc((*iov)[i].iov_len, M_DEVBUF, flags);
		if (!(*iov)[i].iov_base) {
			xs_resfree(xst, *iov, *iov_cnt);
			goto cleanup;
		}
		memcpy((*iov)[i].iov_base, bp, (*iov)[i].iov_len);
		bp = ++cp;
	}
	return (0);

 cleanup:
	*iov = NULL;
	*iov_cnt = 0;
	return (ENOMEM);
}

int
xs_event(struct xs_softc *xs, struct xs_msg *xsm)
{
	struct xs_watch *xsw;
	char *token = NULL;
	int i;

	for (i = 0; i < xsm->xsm_read; i++) {
		if (xsm->xsm_data[i] == '\0') {
			token = &xsm->xsm_data[i+1];
			break;
		}
	}
	if (token == NULL) {
		printf("%s: event on \"%s\" without token\n",
		    xs->xs_sc->sc_dev.dv_xname, xsm->xsm_data);
		return (-1);
	}

	mtx_enter(&xs->xs_watchlck);
	TAILQ_FOREACH(xsw, &xs->xs_watches, xsw_entry) {
		if (strcmp(xsw->xsw_token, token))
			continue;
		mtx_leave(&xs->xs_watchlck);
		task_add(xs->xs_watchtq, xsw->xsw_task);
		return (0);
	}
	mtx_leave(&xs->xs_watchlck);

	printf("%s: no watchers for node \"%s\"\n",
	    xs->xs_sc->sc_dev.dv_xname, xsm->xsm_data);
	return (-1);
}

int
xs_cmd(struct xs_transaction *xst, int cmd, const char *path,
    struct iovec **iov, int *iov_cnt)
{
	struct xs_softc *xs = xst->xst_cookie;
	struct xs_msg *xsm;
	struct iovec ov[10];	/* output vector */
	int datalen = XS_ERR_PAYLOAD;
	int ov_cnt = 0;
	enum { READ, WRITE } mode = READ;
	int i, error = 0;

	if (cmd >= XS_MAX)
		return (EINVAL);

	switch (cmd) {
	case XS_TOPEN:
		ov[0].iov_base = "";
		ov[0].iov_len = 1;
		ov_cnt++;
		break;
	case XS_TCLOSE:
	case XS_RM:
	case XS_WATCH:
	case XS_WRITE:
		mode = WRITE;
		/* FALLTHROUGH */
	default:
		if (mode == READ)
			datalen = XS_MAX_PAYLOAD;
		break;
	}

	if (path) {
		ov[ov_cnt].iov_base = (void *)path;
		ov[ov_cnt++].iov_len = strlen(path) + 1; /* +NUL */
	}

	if (mode == WRITE && iov && iov_cnt && *iov_cnt > 0) {
		for (i = 0; i < *iov_cnt && ov_cnt < nitems(ov);
		     i++, ov_cnt++) {
			ov[ov_cnt].iov_base = (*iov)[i].iov_base;
			ov[ov_cnt].iov_len = (*iov)[i].iov_len;
		}
	}

	xsm = xs_get_msg(xs, !cold);

	if (xs_get_buf(xst, xsm, datalen)) {
		xs_put_msg(xs, xsm);
		return (ENOMEM);
	}

	xsm->xsm_hdr.xmh_tid = xst->xst_id;
	xsm->xsm_hdr.xmh_type = cmd;
	xsm->xsm_hdr.xmh_rid = atomic_inc_int_nv(&xs->xs_rid);

	for (i = 0; i < ov_cnt; i++)
		xsm->xsm_hdr.xmh_len += ov[i].iov_len;

	if (xsm->xsm_hdr.xmh_len > XS_MAX_PAYLOAD) {
		printf("%s: message type %d with payload above the limit\n",
		    xs->xs_sc->sc_dev.dv_xname, cmd);
		xs_put_buf(xst, xsm);
		xs_put_msg(xs, xsm);
		return (EIO);
	}

	if (xs_start(xst, xsm, ov, ov_cnt)) {
		printf("%s: message type %d transmission failed\n",
		    xs->xs_sc->sc_dev.dv_xname, cmd);
		xs_put_buf(xst, xsm);
		xs_put_msg(xs, xsm);
		return (EIO);
	}

	xsm = xs_reply(xst, xsm->xsm_hdr.xmh_rid);

	if (xsm->xsm_hdr.xmh_type == XS_ERROR) {
		error = xs_geterror(xsm);
		DPRINTF("%s: xenstore request %d \"%s\" error %s\n",
		    xs->xs_sc->sc_dev.dv_xname, cmd, path, xsm->xsm_data);
	} else if (mode == READ) {
		KASSERT(iov && iov_cnt);
		error = xs_parse(xst, xsm, iov, iov_cnt);
	}
#ifdef XS_DEBUG
	else
		if (strcmp(xsm->xsm_data, "OK"))
			printf("%s: xenstore request %d failed: %s\n",
			    xs->xs_sc->sc_dev.dv_xname, cmd, xsm->xsm_data);
#endif

	xs_put_buf(xst, xsm);
	xs_put_msg(xs, xsm);

	return (error);
}

int
xs_watch(void *xsc, const char *path, const char *property, struct task *task,
    void (*cb)(void *), void *arg)
{
	struct xen_softc *sc = xsc;
	struct xs_softc *xs = sc->sc_xs;
	struct xs_transaction xst;
	struct xs_watch *xsw;
	struct iovec iov, *iovp = &iov;
	char key[256];
	int error, iov_cnt, ret;

	memset(&xst, 0, sizeof(xst));
	xst.xst_id = 0;
	xst.xst_cookie = sc->sc_xs;

	xsw = malloc(sizeof(*xsw), M_DEVBUF, M_NOWAIT | M_ZERO);
	if (xsw == NULL)
		return (-1);

	task_set(task, cb, arg);
	xsw->xsw_task = task;

	snprintf(xsw->xsw_token, sizeof(xsw->xsw_token), "%0lx",
	    (unsigned long)xsw);

	if (path)
		ret = snprintf(key, sizeof(key), "%s/%s", path, property);
	else
		ret = snprintf(key, sizeof(key), "%s", property);
	if (ret == -1 || ret >= sizeof(key)) {
		free(xsw, M_DEVBUF, sizeof(*xsw));
		return (EINVAL);
	}

	iov.iov_base = xsw->xsw_token;
	iov.iov_len = sizeof(xsw->xsw_token);
	iov_cnt = 1;

	/*
	 * xs_watches must be prepared pre-emptively because a xenstore
	 * event is raised immediately after a watch is established.
	 */
	mtx_enter(&xs->xs_watchlck);
	TAILQ_INSERT_TAIL(&xs->xs_watches, xsw, xsw_entry);
	mtx_leave(&xs->xs_watchlck);

	if ((error = xs_cmd(&xst, XS_WATCH, key, &iovp, &iov_cnt)) != 0) {
		mtx_enter(&xs->xs_watchlck);
		TAILQ_REMOVE(&xs->xs_watches, xsw, xsw_entry);
		mtx_leave(&xs->xs_watchlck);
		free(xsw, M_DEVBUF, sizeof(*xsw));
		return (error);
	}

	return (0);
}

static unsigned long long
atoull(const char *cp, int *error)
{
	unsigned long long res, cutoff;
	int ch;
	int cutlim;

	res = 0;
	cutoff = ULLONG_MAX / (unsigned long long)10;
	cutlim = ULLONG_MAX % (unsigned long long)10;

	do {
		if (*cp < '0' || *cp > '9') {
			*error = EINVAL;
			return (res);
		}
		ch = *cp - '0';
		if (res > cutoff || (res == cutoff && ch > cutlim)) {
			*error = ERANGE;
			return (res);
		}
		res *= 10;
		res += ch;
	} while (*(++cp) != '\0');

	*error = 0;
	return (res);
}

int
xs_getnum(void *xsc, const char *path, const char *property,
    unsigned long long *val)
{
	char *buf;
	int error = 0;

	buf = malloc(XS_MAX_PAYLOAD, M_DEVBUF, M_ZERO |
	    (cold ? M_NOWAIT : M_WAITOK));
	if (buf == NULL)
		return (ENOMEM);

	error = xs_getprop(xsc, path, property, buf, XS_MAX_PAYLOAD);
	if (error)
		goto out;

	*val = atoull(buf, &error);
	if (error)
		goto out;

 out:
	free(buf, M_DEVBUF, XS_MAX_PAYLOAD);
	return (error);
}

int
xs_setnum(void *xsc, const char *path, const char *property,
    unsigned long long val)
{
	char buf[32];
	int ret;

	ret = snprintf(buf, sizeof(buf), "%llu", val);
	if (ret == -1 || ret >= sizeof(buf))
		return (ERANGE);

	return (xs_setprop(xsc, path, property, buf, strlen(buf)));
}

int
xs_getprop(void *xsc, const char *path, const char *property, char *value,
    int size)
{
	struct xen_softc *sc = xsc;
	struct xs_transaction xst;
	struct iovec *iovp = NULL;
	char key[256];
	int error, ret, iov_cnt = 0;

	if (!property)
		return (EINVAL);

	memset(&xst, 0, sizeof(xst));
	xst.xst_id = 0;
	xst.xst_cookie = sc->sc_xs;

	if (path)
		ret = snprintf(key, sizeof(key), "%s/%s", path, property);
	else
		ret = snprintf(key, sizeof(key), "%s", property);
	if (ret == -1 || ret >= sizeof(key))
		return (EINVAL);

	if ((error = xs_cmd(&xst, XS_READ, key, &iovp, &iov_cnt)) != 0)
		return (error);

	if (iov_cnt > 0)
		strlcpy(value, (char *)iovp->iov_base, size);

	xs_resfree(&xst, iovp, iov_cnt);

	return (0);
}

int
xs_setprop(void *xsc, const char *path, const char *property, char *value,
    int size)
{
	struct xen_softc *sc = xsc;
	struct xs_transaction xst;
	struct iovec iov, *iovp = &iov;
	char key[256];
	int error, ret, iov_cnt = 0;

	if (!property)
		return (EINVAL);

	memset(&xst, 0, sizeof(xst));
	xst.xst_id = 0;
	xst.xst_cookie = sc->sc_xs;

	if (path)
		ret = snprintf(key, sizeof(key), "%s/%s", path, property);
	else
		ret = snprintf(key, sizeof(key), "%s", property);
	if (ret == -1 || ret >= sizeof(key))
		return (EINVAL);

	iov.iov_base = value;
	iov.iov_len = size;
	iov_cnt = 1;

	error = xs_cmd(&xst, XS_WRITE, key, &iovp, &iov_cnt);

	return (error);
}

int
xs_cmpprop(void *xsc, const char *path, const char *property, const char *value,
    int *result)
{
	struct xen_softc *sc = xsc;
	struct xs_transaction xst;
	struct iovec *iovp = NULL;
	char key[256];
	int error, ret, iov_cnt = 0;

	if (!property)
		return (EINVAL);

	memset(&xst, 0, sizeof(xst));
	xst.xst_id = 0;
	xst.xst_cookie = sc->sc_xs;

	if (path)
		ret = snprintf(key, sizeof(key), "%s/%s", path, property);
	else
		ret = snprintf(key, sizeof(key), "%s", property);
	if (ret == -1 || ret >= sizeof(key))
		return (EINVAL);

	if ((error = xs_cmd(&xst, XS_READ, key, &iovp, &iov_cnt)) != 0)
		return (error);

	*result = strcmp(value, (char *)iovp->iov_base);

	xs_resfree(&xst, iovp, iov_cnt);

	return (0);
}

int
xs_await_transition(void *xsc, const char *path, const char *property,
    const char *value, int timo)
{
	struct xen_softc *sc = xsc;
	int error, res;

	do {
		error = xs_cmpprop(xsc, path, property, value, &res);
		if (error)
			return (error);
		if (timo && --timo == 0)
			return (ETIMEDOUT);
		xs_poll(sc->sc_xs, cold);
	} while (res != 0);

	return (0);
}

int
xs_kvop(void *xsc, int op, char *key, char *value, size_t valuelen)
{
	struct xen_softc *sc = xsc;
	struct xs_transaction xst;
	struct iovec iov, *iovp = &iov;
	int error = 0, iov_cnt = 0, cmd, i;

	switch (op) {
	case PVBUS_KVWRITE:
		cmd = XS_WRITE;
		iov.iov_base = value;
		iov.iov_len = strlen(value);
		iov_cnt = 1;
		break;
	case PVBUS_KVREAD:
		cmd = XS_READ;
		break;
	case PVBUS_KVLS:
		cmd = XS_LIST;
		break;
	default:
		return (EOPNOTSUPP);
	}

	memset(&xst, 0, sizeof(xst));
	xst.xst_id = 0;
	xst.xst_cookie = sc->sc_xs;

	if ((error = xs_cmd(&xst, cmd, key, &iovp, &iov_cnt)) != 0)
		return (error);

	memset(value, 0, valuelen);

	switch (cmd) {
	case XS_READ:
		if (iov_cnt == 1 && iovp[0].iov_len == 1) {
			xs_resfree(&xst, iovp, iov_cnt);

			/*
			 * We cannot distinguish if the returned value is
			 * a directory or a file in the xenstore.  The only
			 * indication is that the read value of a directory
			 * returns an empty string (single nul byte),
			 * so try to get the directory list in this case.
			 */
			return (xs_kvop(xsc, PVBUS_KVLS, key, value, valuelen));
		}
		/* FALLTHROUGH */
	case XS_LIST:
		for (i = 0; i < iov_cnt; i++) {
			if (i && strlcat(value, "\n", valuelen) >= valuelen)
				break;
			if (strlcat(value, iovp[i].iov_base,
			    valuelen) >= valuelen)
				break;
		}
		xs_resfree(&xst, iovp, iov_cnt);
		break;
	default:
		break;
	}

	return (0);
}
@


1.43
log
@Fixup format strings in debug messages found by cppcheck
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.42 2017/03/13 01:00:15 mikeb Exp $	*/
d848 2
a849 1
	if (ret == -1 || ret >= sizeof(key))
d851 1
@


1.42
log
@Fixup format string and type issues found by cppcheck
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.41 2017/02/12 11:56:41 mikeb Exp $	*/
d531 1
a531 1
			DPRINTF("%s: incomplete header: %d\n",
@


1.41
log
@Remove incorrect if statement

Pointed out by jsg@@ and Nathanael Rensen, <nathanael at
list ! polymorpheus ! com>, thanks!
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.40 2017/02/07 11:52:07 mikeb Exp $	*/
d119 2
a120 2
	int			 xsm_read;
	int			 xsm_dlen;
d222 1
a222 1
	printf(", event channel %d\n", xs->xs_port);
d324 2
a325 2
			break;
	return (xs_errors[i].xse_errnum);
d403 1
a403 1
			printf("%s: failed on iovec #%d len %ld\n", __func__,
d608 1
a608 1
	unsigned char *buf = NULL;
d640 2
a641 1
	int i, dlen, flags;
@


1.40
log
@Make the 'incomplete header' message debug only
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.39 2017/02/06 21:52:02 mikeb Exp $	*/
d1036 1
a1036 2
	if (*result)
		*result = strcmp(value, (char *)iovp->iov_base);
@


1.39
log
@XST_POLL turned out to be pretty useless since it's only set when cold
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.38 2017/02/06 21:43:48 mikeb Exp $	*/
d531 1
a531 1
			printf("%s: incomplete header: %d\n",
@


1.38
log
@Use separate compile time debug flags for xen, xnf and xbf
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.37 2017/01/12 20:29:46 mikeb Exp $	*/
d339 1
a339 1
xs_poll(struct xs_softc *xs, int nowait)
d343 1
a343 1
	if (nowait) {
a349 1
	virtio_membar_sync();
d378 1
a378 1
			xs_poll(xs, xst->xst_flags & XST_POLL);
d439 1
a439 1
		if (xst->xst_flags & XST_POLL) {
d610 1
a610 2
	buf = malloc(len, M_DEVBUF, M_ZERO | (xst->xst_flags & XST_POLL ?
	    M_NOWAIT : M_WAITOK));
d644 1
a644 1
	flags = M_ZERO | (xst->xst_flags & XST_POLL ? M_NOWAIT : M_WAITOK);
d764 1
a764 1
	xsm = xs_get_msg(xs, !(xst->xst_flags & XST_POLL));
a831 2
	if (cold)
		xst.xst_flags = XST_POLL;
a956 2
	if (cold)
		xst.xst_flags = XST_POLL;
a991 2
	if (cold)
		xst.xst_flags = XST_POLL;
a1024 2
	if (cold)
		xst.xst_flags = XST_POLL;
@


1.37
log
@Execute XenStore watch callbacks on a dedicated task queue

Some watch callbacks like xen_hotplug can hog the task queue for
a considerable amount of time due to XenStore interrupt driven
I/O operations and running them on the system task queue causes
problems with other timed operations for instance during boot.

Bug reported and fix tested by ajacoutot@@, thanks!
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.36 2016/12/09 17:24:55 mikeb Exp $	*/
d38 8
d806 1
a806 1
#ifdef XEN_DEBUG
@


1.36
log
@New XenStore public API function to read numeric values

A need for a function to perform string to number conversion arose
when domain identifier needed to be read and converted to numerical
representation.  With xbf(4) the usage became broader as greater
values (such as the sector count) needed to be converted.  And as a
result another function was implemented to perform string to unsigned
long long conversion but unfortunately multiplication overflows were
not handled correctly.  This new version consolidates the code in
one place and exports a proper XenStore API function to get and set
numeric values.  The new atoull function borrows multiplication
overflow detection logic from the libc.
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.35 2016/12/07 15:21:04 mikeb Exp $	*/
d169 1
d251 2
d702 1
a702 1
		task_add(systq, xsw->xsw_task);
@


1.35
log
@Add a simple mechanism to poll for a change in the property value
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.34 2016/12/07 15:18:02 mikeb Exp $	*/
d864 68
@


1.34
log
@Factor out the polling loop into a separate function
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.33 2016/12/07 15:13:23 mikeb Exp $	*/
d936 56
@


1.33
log
@Return proper error values from xs_{get,set}prop
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.32 2016/11/29 14:55:04 mikeb Exp $	*/
d179 1
d327 15
d346 1
a346 1
	int chunk, s;
d367 2
a368 11
		while (xs->xs_ring->xsr_req_prod != xs->xs_ring->xsr_req_cons) {
			if (xst->xst_flags & XST_POLL) {
				delay(XST_DELAY * 1000 >> 2);
				s = splnet();
				xs_intr(xs);
				splx(s);
			} else
				tsleep(xs->xs_wchan, PRIBIO, xs->xs_wchan,
				    XST_DELAY * hz >> 2);
			virtio_membar_sync();
		}
@


1.32
log
@Stop exposing xen_softc to PV devices directly
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.31 2016/11/29 13:55:33 mikeb Exp $	*/
d870 1
a870 1
		return (-1);
d907 1
a907 1
		return (-1);
@


1.31
log
@Don't expose the xen_softc pointer in the XenStore transaction struct
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.30 2016/11/29 12:12:29 mikeb Exp $	*/
d802 2
a803 2
xs_watch(struct xen_softc *sc, const char *path, const char *property,
    struct task *task, void (*cb)(void *), void *arg)
d805 1
d860 2
a861 2
xs_getprop(struct xen_softc *sc, const char *path, const char *property,
    char *value, int size)
d863 1
d897 2
a898 2
xs_setprop(struct xen_softc *sc, const char *path, const char *property,
    char *value, int size)
d900 1
d932 1
a932 1
xs_kvop(void *arg, int op, char *key, char *value, size_t valuelen)
d934 1
a934 1
	struct xen_softc *sc = arg;
d977 1
a977 1
			return (xs_kvop(arg, PVBUS_KVLS, key, value, valuelen));
@


1.30
log
@Replace the hand-rolled semaphore with a read-write lock

This was sitting in my tree for many a month and since the introduction
of interrupt threads, the interrupt vs. process context interlock became
irrelevant.  Taking uncontended write locks while "cold" doesn't look
like a big deal as well.
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.29 2016/07/29 21:05:26 mikeb Exp $	*/
d329 1
a329 1
	struct xs_softc *xs = xst->xst_sc;
d370 1
a370 1
	struct xs_softc *xs = xst->xst_sc;
d407 1
a407 1
	struct xs_softc *xs = xst->xst_sc;
d706 1
a706 1
	struct xs_softc *xs = xst->xst_sc;
d814 1
a814 1
	xst.xst_sc = sc->sc_xs;
d872 1
a872 1
	xst.xst_sc = sc->sc_xs;
d908 1
a908 1
	xst.xst_sc = sc->sc_xs;
d955 1
a955 1
	xst.xst_sc = sc->sc_xs;
@


1.29
log
@Loop until we've read all available responses
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.28 2016/04/19 18:15:41 mikeb Exp $	*/
d26 1
d170 1
a170 1
	uint			 xs_rngsem;
d247 2
a270 19
static inline int
xs_sem_get(uint *semaphore)
{
	if (atomic_inc_int_nv(semaphore) != 1) {
		/* we're out of luck */
		if (atomic_dec_int_nv(semaphore) == 0)
			wakeup(semaphore);
		return (0);
	}
	return (1);
}

static inline void
xs_sem_put(uint *semaphore)
{
	if (atomic_dec_int_nv(semaphore) == 0)
		wakeup(semaphore);
}

d373 1
a373 7
	while (!xs_sem_get(&xs->xs_rngsem)) {
		if (xst->xst_flags & XST_POLL)
			delay(XST_DELAY * 1000 >> 2);
		else
			tsleep(&xs->xs_rngsem, PRIBIO, "xsaccess",
			    XST_DELAY * hz >> 2);
	}
d379 1
a379 1
		xs_sem_put(&xs->xs_rngsem);
d388 1
a388 1
			xs_sem_put(&xs->xs_rngsem);
d399 1
a399 1
	xs_sem_put(&xs->xs_rngsem);
@


1.28
log
@Bind event channels to backend domains

This is another piece of the QubesOS "chained VM" puzzle reported by
Marco Peereboom.
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.27 2016/02/05 10:30:37 mikeb Exp $	*/
d533 1
d600 3
@


1.27
log
@Silence warnings from static analyzers; found by jsg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.26 2016/02/04 12:50:56 mikeb Exp $	*/
d229 1
a229 1
	if (xen_intr_establish(xs->xs_port, &xs->xs_ih, xs_intr, xs,
@


1.26
log
@Bail early if there's no token; found by jsg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.25 2016/02/02 17:52:46 mikeb Exp $	*/
d881 1
a881 1
	struct iovec *iovp;
d883 1
a883 1
	int error, iov_cnt, ret;
d904 2
a905 1
	strlcpy(value, (char *)iovp->iov_base, size);
d919 1
a919 1
	int error, iov_cnt, ret;
d952 1
a952 1
	int error = 0, iov_cnt, cmd, i;
@


1.25
log
@A few reliability improvements in the power management interface

Nathanael Rensen <nathanael at list ! polymorpheus ! com> came up with
a few improvements to the event watcher and power management interface,
namely:

 o Make sure to put our watcher on a list before issuing an XS_WATCH
   command since Xen will raise the event right after it's been set up.

 o The first time xen_control is called the "control/shutdown" node
   may not exist, so skip printing the error message in this case.

 o Acknowledge requests by writing back an empty string.

 o log(9) reboot and halt requests like vmt(4) does.

Huge thanks!
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.24 2016/01/29 19:04:30 mikeb Exp $	*/
d61 1
a61 2
const struct
{
d82 1
a82 2
struct xs_msghdr
{
d591 1
a591 3
			if (xs_event(xs, xsm))
				printf("%s: no watchers for node \"%s\"\n",
				    sc->sc_dev.dv_xname, xsm->xsm_data);
d690 1
a690 1
	char *token;
d699 5
d714 3
@


1.24
log
@Add support for XS_WATCH: XenStore notification facility

After configuring a watch for the node, XenStore will asynchronously
notify the system when the value of the specified node changes with
an event message.
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.23 2016/01/29 18:49:06 mikeb Exp $	*/
d853 8
d862 3
a867 4

	mtx_enter(&xs->xs_watchlck);
	TAILQ_INSERT_TAIL(&xs->xs_watches, xsw, xsw_entry);
	mtx_leave(&xs->xs_watchlck);
@


1.23
log
@Cleanup XenStore API

Turns out that we want to let devices choose whether they're issuing
XenStore requests to the backend or frontend.  This also unifies the
the API somewhat as providing the xen softcore structure is now
mandatory.
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.22 2016/01/27 09:04:19 reyk Exp $	*/
d27 1
d132 8
d167 4
d174 13
a186 11
struct xs_msg	*xs_get_msg(struct xs_softc *, int);
void		 xs_put_msg(struct xs_softc *, struct xs_msg *);
int		 xs_ring_get(struct xs_softc *, void *, size_t);
int		 xs_ring_put(struct xs_softc *, void *, size_t);
void		 xs_intr(void *);
int		 xs_output(struct xs_transaction *, uint8_t *, int);
int		 xs_start(struct xs_transaction *, struct xs_msg *,
		    struct iovec *, int);
struct xs_msg	*xs_reply(struct xs_transaction *, uint);
int		 xs_parse(struct xs_transaction *, struct xs_msg *,
		     struct iovec **, int *);
d248 9
a542 5
		if (TAILQ_EMPTY(&xs->xs_reqs)) {
			printf("%s: missing requests\n", sc->sc_dev.dv_xname);
			goto out;
		}

d549 18
a566 8
		TAILQ_FOREACH(xsm, &xs->xs_reqs, xsm_link) {
			if (xsm->xsm_hdr.xmh_rid == xmh.xmh_rid)
				break;
		}
		if (xsm == NULL) {
			printf("%s: received unexpected message id %u\n",
			    sc->sc_dev.dv_xname, xmh.xmh_rid);
			goto out;
a567 1

d592 10
a601 5
		mtx_enter(&xs->xs_rsplck);
		TAILQ_REMOVE(&xs->xs_reqs, xsm, xsm_link);
		TAILQ_INSERT_TAIL(&xs->xs_rsps, xsm, xsm_link);
		mtx_leave(&xs->xs_rsplck);
		wakeup(xs->xs_rchan);
d691 26
d739 1
d813 50
@


1.22
log
@Add a key-value interface to pvbus(4) that allows to get or set values
in the underlying information store of the host from the OpenBSD-VM's
userspace.  OpenBSD did not provide access to these stores before,
mostly because we did not want to add a custom tool and interface for
each hypervisor.  The pvbus(4) interface provides backends for
xen(4)'s XenStore and vmt(4)'s VMware Tools "guestinfo".  These
information stores are fairly different, XenStore is a "filesystem"
while vmt is a RPC, and the key-value abstraction limits them a bit
but provides the most wanted functionality.

Discussed with many
OK mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.21 2016/01/25 15:22:56 mikeb Exp $	*/
d756 2
a757 2
xs_getprop(struct xen_attach_args *xa, const char *property, char *value,
    int size)
a758 1
	struct xen_softc *sc = xa->xa_parent;
d761 2
a762 2
	char path[128];
	int error, iov_cnt;
d773 8
a780 3
	snprintf(path, sizeof(path), "%s/%s", xa->xa_node, property);
	if ((error = xs_cmd(&xst, XS_READ, path, &iovp, &iov_cnt)) != 0 &&
	     error != ENOENT)
a782 7
	/* Try backend */
	if (error == ENOENT) {
		snprintf(path, sizeof(path), "%s/%s", xa->xa_backend, property);
		if ((error = xs_cmd(&xst, XS_READ, path, &iovp, &iov_cnt)) != 0)
			return (error);
	}

d791 2
a792 2
xs_setprop(struct xen_attach_args *xa, const char *property, char *value,
    int size)
a793 1
	struct xen_softc *sc = xa->xa_parent;
d796 2
a797 2
	char path[128];
	int error, iov_cnt;
d808 13
a820 11
	if (value && size > 0) {
		iov.iov_base = value;
		iov.iov_len = size;
		iov_cnt = 1;

		snprintf(path, sizeof(path), "%s/%s", xa->xa_node, property);
		error = xs_cmd(&xst, XS_WRITE, path, &iovp, &iov_cnt);
	} else {
		snprintf(path, sizeof(path), "%s/%s", xa->xa_node, property);
		error = xs_cmd(&xst, XS_RM, path, NULL, NULL);
	}
@


1.21
log
@Don't count the total number of Xen upcalls
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.20 2016/01/22 19:26:40 mikeb Exp $	*/
d26 1
d32 1
d824 66
@


1.20
log
@Convert membar_* calls into virtio_membar_sync where it matters

membar_* functions are defined only as compiler barriers on !MP
kernels, while we're trying to be conservative in our use of the
barriers.  Barriers are placed only where loads and stores might
get reordered and it matters at the same time.  Shared info page
operations are using atomic instructions on Linux, so they get
barriers as well.
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.19 2016/01/18 18:54:38 mikeb Exp $	*/
d214 2
a215 1
	if (xen_intr_establish(xs->xs_port, &xs->xs_ih, xs_intr, xs, "xs0"))
@


1.19
log
@Fixup a hang while performing a read operation on XenStore

Reyk has reported an issue that turned out to be an incorrect calculation
of bytes available for reading.  This diff also places missed semaphore
releases in the xs_start and makes 'left' a size_t in xs_ring_{get,put}.
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.18 2016/01/15 18:20:41 mikeb Exp $	*/
a312 1
	membar_consumer();
d351 1
a351 1
			membar_sync();
a441 1
	membar_consumer();
d456 1
a456 1
	membar_producer();
a468 1
	membar_consumer();
d483 1
a483 1
	membar_producer();
d499 1
a499 1
	membar_sync();
@


1.18
log
@Cleanup dmesg output, disable debugging; prodding and suggestions from reyk@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.17 2016/01/12 12:12:05 mikeb Exp $	*/
d314 2
a315 1
	return ((cons - prod - 1) & (XS_RING_SIZE - 1));
d377 1
d386 1
d441 1
a441 1
	int left;
d469 1
a469 1
	int left;
@


1.17
log
@A couple of unused variables have sneaked in from the debug code
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.16 2016/01/12 11:54:05 mikeb Exp $	*/
d180 1
a180 2
		printf("%s: failed to allocate xenstore softc\n",
		    sc->sc_dev.dv_xname);
d190 2
a191 1
	if (xen_hypercall(sc, XC_HVM, 2, HVMOP_get_param, &xhv))
d193 1
d196 1
a196 2
	DPRINTF("%s: xenstore event channel %d\n", sc->sc_dev.dv_xname,
	    xs->xs_port);
a213 3
	DPRINTF("%s: xenstore ring at va %p pa %#lx\n", sc->sc_dev.dv_xname,
	    xs->xs_ring, pa & ~PMAP_NOCACHE);

a215 3

	DPRINTF("%s: xenstore interrupt established for port %d\n",
	    sc->sc_dev.dv_xname, xs->xs_ih);
@


1.16
log
@Convert XenStore code to free running producer/consumer indices

After some hair pulling while implementing xnf(4) I've realised that
Xen uses free running producer/consumer indices wrapping with their
type (unsigned 32 bit integer).  Later I've confirmed it with free
chapters of the "The Definitive Guide to the Xen Hypervisor" by David
Chisnall available online.
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.15 2016/01/11 16:54:33 mikeb Exp $	*/
a442 1
	uint32_t cons = xsr->xsr_req_cons & (XS_RING_SIZE - 1);
a470 1
	uint32_t prod = xsr->xsr_rsp_prod & (XS_RING_SIZE - 1);
@


1.15
log
@xs_cmd should always return errno(2) codes
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.14 2016/01/11 16:34:49 reyk Exp $	*/
d99 5
a103 4
 * Although Xen source code implies that the limit is 4k, in practice
 * Mike has figured out that we can only send 2k bytes of payload w/o
 * receiving a ENOSPC.  We set it to an even smaller value however,
 * because there's no real need to use large buffers for anything.
d313 1
a313 1
static inline int
d316 2
a317 2
	int cons = req ? xsr->xsr_req_cons : xsr->xsr_rsp_cons;
	int prod = req ? xsr->xsr_req_prod : xsr->xsr_rsp_prod;
d320 1
a320 23
#ifdef XEN_DEBUG
	KASSERT(prod <= XS_RING_SIZE && cons < XS_RING_SIZE);
#endif
	if (prod > cons)
		return (prod - cons);
	else
		return (XS_RING_SIZE - cons + prod);
	return (0);
}

static inline void
xs_ring_reset(struct xs_softc *xs, int req)
{
	struct xs_ring *xsr = xs->xs_ring;

	if (req) {
		xsr->xsr_req_cons = 0;
		xsr->xsr_req_prod = 0;
	} else {
		xsr->xsr_rsp_prod = 0;
		xsr->xsr_rsp_cons = 0;
	}
	membar_producer();
d336 1
a336 1
			if (xs->xs_ring->xsr_req_prod < XS_RING_SIZE)
d348 1
a348 1
		while (xs->xs_ring->xsr_req_prod > xs->xs_ring->xsr_req_cons) {
a358 3
		/* It's safe to do a reset here because cons == prod == 1024 */
		if (xs->xs_ring->xsr_req_prod == XS_RING_SIZE)
			xs_ring_reset(xs, 1);
d442 4
a445 3
	int cons = xsr->xsr_req_cons;
	int prod = xsr->xsr_req_prod;
	int left = XS_RING_SIZE - prod;
a447 3
#ifdef XEN_DEBUG
	KASSERT(prod <= XS_RING_SIZE && cons < XS_RING_SIZE);
#endif
d450 12
a461 5
	if (cons > prod)
		size = MIN(size, cons - prod);
	else
		size = MIN(size, left);
	memcpy(&xsr->xsr_req[prod], src, size);
d463 1
a463 1
	xsr->xsr_req_prod += size; /* This never goes above the ring size */
d471 4
a474 3
	int cons = xsr->xsr_rsp_cons;
	int prod = xsr->xsr_rsp_prod;
	int left = XS_RING_SIZE - cons;
a476 3
#ifdef XEN_DEBUG
	KASSERT(prod <= XS_RING_SIZE && cons < XS_RING_SIZE);
#endif
d479 1
a479 1
	if (prod == cons)
d481 10
a490 5
	if (prod > cons)
		size = MIN(size, prod - cons);
	else
		size = MIN(size, left);
	memcpy(dst, &xsr->xsr_rsp[cons], size);
d492 1
a492 1
	xsr->xsr_rsp_cons += size; /* This never goes above the ring size */
d504 2
a505 1
	int avail, len;
a573 2

		xs_ring_reset(xs, 0);
a575 4
	/* It's safe to do a reset here because cons == prod == 1024 */
	if (xs->xs_ring->xsr_rsp_prod == XS_RING_SIZE)
		xs_ring_reset(xs, 0);

d721 1
a721 1
	if (xsm->xsm_hdr.xmh_len >= XS_MAX_PAYLOAD) {
@


1.14
log
@Do not fail when receiving an empty reply (or directory node) in
xs_intr() but put an empty message in the queue.  This prevents
xs_reply() from being stuck in an endless loop because it expectes a
message in the queue to break out of it. Depends on mikeb@@'s previous
commit because it would otherwise panic on trying to cleanup the empty
message.

OK mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.13 2016/01/11 16:14:16 mikeb Exp $	*/
d696 1
a696 1
		return (-1);
d732 1
a732 1
		return (-1);
d747 1
a747 1
		return (-1);
d755 1
a755 1
		return (-1);
@


1.13
log
@Handle zero lenght messages in the xs_parse by returning an empty string

Problem was reported and analyzed by reyk@@
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.12 2016/01/04 16:06:50 mikeb Exp $	*/
a561 3

		if (avail == 0)
			goto out;
d570 9
a578 3
	if ((len = xs_ring_get(xs, &xsm->xsm_data[xsm->xsm_read], len)) <= 0) {
		printf("%s: read failure %d\n", sc->sc_dev.dv_xname, len);
		goto out;
a579 1
	xsm->xsm_read += len;
@


1.12
log
@Include the node name into the error message
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.11 2015/12/22 22:19:46 mikeb Exp $	*/
a635 1
	int dlen = xsm->xsm_hdr.xmh_len;
d637 1
a637 1
	int i, flags;
d639 2
d654 1
a654 1
		if (i > 0 && xsm->xsm_data[i] == '\0')
a655 2
	if (!*iov_cnt)
		return (0);
d658 1
a658 1
		return (-1);
d666 2
a667 1
		if (!(*iov)[i].iov_base)
d669 1
a672 1

d676 2
a677 1
	xs_resfree(xst, *iov, *iov_cnt);
@


1.11
log
@Make xs_setprop a bit more useful by removing property nodes
when NULL or zero length value was specified.
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.10 2015/12/22 22:16:53 mikeb Exp $	*/
d759 2
a760 2
		DPRINTF("%s: xenstore request %d error %s\n",
		    xs->xs_sc->sc_dev.dv_xname, cmd, xsm->xsm_data);
@


1.10
log
@Implement a bus_dma(9) abstraction on top of Grant Table API
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.9 2015/12/21 18:17:36 mikeb Exp $	*/
d702 1
a722 1
		KASSERT(ov_cnt < nitems(ov));
d835 4
a838 3
	iov.iov_base = value;
	iov.iov_len = size;
	iov_cnt = 1;
d840 7
a846 4
	snprintf(path, sizeof(path), "%s/%s", xa->xa_node, property);
	if ((error = xs_cmd(&xst, XS_WRITE, path, &iovp, &iov_cnt)) != 0)
		return (error);
	return (0);
@


1.9
log
@Cleanup hypercall subsystem type defines
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.8 2015/12/19 09:12:29 mikeb Exp $	*/
d26 2
@


1.8
log
@Add xs_setprop to set device properties
@
text
@d1 1
a1 1
/*	$OpenBSD: xenstore.c,v 1.7 2015/12/12 21:07:45 reyk Exp $	*/
d188 1
a188 1
	if (xen_hypercall(sc, hvm_op, 2, HVMOP_get_param, &xhv))
d199 1
a199 1
	if (xen_hypercall(sc, hvm_op, 2, HVMOP_get_param, &xhv))
@


1.7
log
@Add OpenBSD CVS/RCS Ids.

mikeb@@ doesn't like the Ids, "somebody else has to add them".
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d811 29
@


1.6
log
@Remove xs_resume for now; pointed out by mlarkin@@
@
text
@d1 2
@


1.5
log
@Let xs_getprop decide itself whether it's OK to sleep or not
@
text
@a243 19
int
xs_resume(struct xen_softc *sc)
{
	struct xs_softc *xs = sc->sc_xs;

	xs->xs_ring->xsr_rsp_prod = xs->xs_ring->xsr_rsp_cons;

	if (xen_intr_disestablish(xs->xs_ih))
		return (-1);

	if (xen_intr_establish(xs->xs_port, &xs->xs_ih, xs_intr, xs, "xs0"))
		return (-1);

	DPRINTF("%s: xenstore interrupt established for port %d\n",
	    sc->sc_dev.dv_xname, xs->xs_ih);

	return (0);
}

@


1.4
log
@Correct the response string length

Apparently length values returned by XenStore depend on which
operation has been requested: for instance XS_READ will always
return an strlen() result without accounting for the trailing
NUL character, however XS_LIST will return length that includes
it.  While staying within our data buffer limit (xsm_dlen) we
can readjust the length of the resulting string accordingly.
@
text
@d795 1
a795 1
    int size, int waitok)
d809 1
a809 1
	if (!waitok)
@


1.3
log
@Implement a function to fetch device properties
@
text
@d651 1
d659 9
a667 2
	xsm->xsm_data[xsm->xsm_hdr.xmh_len - 1] = '\0';
	for (i = 0; i < xsm->xsm_hdr.xmh_len; i++)
d677 3
a679 4
		for (cp = bp;
		     cp - (caddr_t)xsm->xsm_data < xsm->xsm_hdr.xmh_len; cp++)
			if (*cp == '\0')
				break;
@


1.2
log
@Don't expose XenStore ops we don't know how to deal with
@
text
@d785 38
@


1.1
log
@Driver for XenStore, the configuration storage

XenStore provides a hierarchical storage for Xen configuration
in a style of an OpenFirmware.  Itself it's an interrupt driven
producer/consumer interface with two 1kb rings for input and
output.

It's required in order to do virtual device discovery and device
configuration (fetch MAC address, various parameters).

With input from and OK mlarkin, reyk
@
text
@d704 1
a704 1
	case XS_TRANSACTION_START:
d709 1
a709 5
	case XS_TRANSACTION_END:
		mode = WRITE;
		break;
	case XS_MKDIR:
	case XS_RM:
@

