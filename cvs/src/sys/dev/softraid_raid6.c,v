head	1.71;
access;
symbols
	OPENBSD_6_2:1.71.0.8
	OPENBSD_6_2_BASE:1.71
	OPENBSD_6_1:1.71.0.6
	OPENBSD_6_1_BASE:1.71
	OPENBSD_6_0:1.71.0.2
	OPENBSD_6_0_BASE:1.71
	OPENBSD_5_9:1.69.0.2
	OPENBSD_5_9_BASE:1.69
	OPENBSD_5_8:1.69.0.4
	OPENBSD_5_8_BASE:1.69
	OPENBSD_5_7:1.63.0.4
	OPENBSD_5_7_BASE:1.63
	OPENBSD_5_6:1.62.0.4
	OPENBSD_5_6_BASE:1.62
	OPENBSD_5_5:1.61.0.4
	OPENBSD_5_5_BASE:1.61
	OPENBSD_5_4:1.53.0.2
	OPENBSD_5_4_BASE:1.53
	OPENBSD_5_3:1.33.0.2
	OPENBSD_5_3_BASE:1.33
	OPENBSD_5_2:1.25.0.4
	OPENBSD_5_2_BASE:1.25
	OPENBSD_5_1_BASE:1.25
	OPENBSD_5_1:1.25.0.2
	OPENBSD_5_0:1.24.0.2
	OPENBSD_5_0_BASE:1.24
	OPENBSD_4_9:1.19.0.4
	OPENBSD_4_9_BASE:1.19
	OPENBSD_4_8:1.19.0.2
	OPENBSD_4_8_BASE:1.19
	OPENBSD_4_7:1.15.0.2
	OPENBSD_4_7_BASE:1.15;
locks; strict;
comment	@ * @;


1.71
date	2016.04.12.16.26.54;	author krw;	state Exp;
branches;
next	1.70;
commitid	ATfj2h1H9b585gss;

1.70
date	2016.04.04.18.48.39;	author krw;	state Exp;
branches;
next	1.69;
commitid	1ISokwrtQ24zRrhW;

1.69
date	2015.07.21.03.30.51;	author krw;	state Exp;
branches;
next	1.68;
commitid	TJiPw62Nfq0KhqBx;

1.68
date	2015.07.19.21.06.04;	author krw;	state Exp;
branches;
next	1.67;
commitid	DQBduvhX3UJc1lbB;

1.67
date	2015.07.19.18.24.16;	author krw;	state Exp;
branches;
next	1.66;
commitid	soWovNPxU9gU33mQ;

1.66
date	2015.07.19.17.04.31;	author krw;	state Exp;
branches;
next	1.65;
commitid	WthDQr0yYlXab4V8;

1.65
date	2015.05.29.13.48.45;	author krw;	state Exp;
branches;
next	1.64;
commitid	4T685JZ45NUupSv2;

1.64
date	2015.03.14.03.38.46;	author jsg;	state Exp;
branches;
next	1.63;
commitid	p4LJxGKbi0BU2cG6;

1.63
date	2014.09.14.14.17.24;	author jsg;	state Exp;
branches;
next	1.62;
commitid	uzzBR7hz9ncd4O6G;

1.62
date	2014.07.12.18.48.51;	author tedu;	state Exp;
branches;
next	1.61;
commitid	OBNa5kfxQ2UXoiIw;

1.61
date	2014.01.22.05.11.36;	author jsing;	state Exp;
branches;
next	1.60;

1.60
date	2014.01.22.04.24.29;	author jsing;	state Exp;
branches;
next	1.59;

1.59
date	2014.01.21.10.25.25;	author jsing;	state Exp;
branches;
next	1.58;

1.58
date	2014.01.18.09.33.53;	author jsing;	state Exp;
branches;
next	1.57;

1.57
date	2013.11.21.17.06.45;	author krw;	state Exp;
branches;
next	1.56;

1.56
date	2013.11.21.16.34.50;	author krw;	state Exp;
branches;
next	1.55;

1.55
date	2013.11.05.08.55.58;	author reyk;	state Exp;
branches;
next	1.54;

1.54
date	2013.11.01.17.36.19;	author krw;	state Exp;
branches;
next	1.53;

1.53
date	2013.06.11.16.42.13;	author deraadt;	state Exp;
branches;
next	1.52;

1.52
date	2013.05.21.15.01.53;	author jsing;	state Exp;
branches;
next	1.51;

1.51
date	2013.05.21.14.30.01;	author jsing;	state Exp;
branches;
next	1.50;

1.50
date	2013.05.21.14.25.23;	author jsing;	state Exp;
branches;
next	1.49;

1.49
date	2013.04.27.14.06.09;	author jsing;	state Exp;
branches;
next	1.48;

1.48
date	2013.04.26.15.45.35;	author jsing;	state Exp;
branches;
next	1.47;

1.47
date	2013.04.23.13.36.19;	author jsing;	state Exp;
branches;
next	1.46;

1.46
date	2013.04.23.13.13.11;	author jsing;	state Exp;
branches;
next	1.45;

1.45
date	2013.04.23.12.49.52;	author jsing;	state Exp;
branches;
next	1.44;

1.44
date	2013.03.31.15.44.52;	author jsing;	state Exp;
branches;
next	1.43;

1.43
date	2013.03.31.11.12.06;	author jsing;	state Exp;
branches;
next	1.42;

1.42
date	2013.03.31.10.41.16;	author jsing;	state Exp;
branches;
next	1.41;

1.41
date	2013.03.30.14.41.37;	author jsing;	state Exp;
branches;
next	1.40;

1.40
date	2013.03.29.15.26.45;	author jsing;	state Exp;
branches;
next	1.39;

1.39
date	2013.03.29.13.05.47;	author jsing;	state Exp;
branches;
next	1.38;

1.38
date	2013.03.29.12.00.59;	author jsing;	state Exp;
branches;
next	1.37;

1.37
date	2013.03.29.11.46.45;	author jsing;	state Exp;
branches;
next	1.36;

1.36
date	2013.03.27.14.30.11;	author jsing;	state Exp;
branches;
next	1.35;

1.35
date	2013.03.25.16.01.49;	author jsing;	state Exp;
branches;
next	1.34;

1.34
date	2013.03.02.12.50.01;	author jsing;	state Exp;
branches;
next	1.33;

1.33
date	2013.01.16.09.21.50;	author jsing;	state Exp;
branches;
next	1.32;

1.32
date	2013.01.16.07.06.29;	author jsing;	state Exp;
branches;
next	1.31;

1.31
date	2013.01.16.06.42.22;	author jsing;	state Exp;
branches;
next	1.30;

1.30
date	2013.01.16.06.29.14;	author jsing;	state Exp;
branches;
next	1.29;

1.29
date	2013.01.15.09.28.29;	author jsing;	state Exp;
branches;
next	1.28;

1.28
date	2013.01.15.04.03.01;	author jsing;	state Exp;
branches;
next	1.27;

1.27
date	2012.12.31.10.07.51;	author miod;	state Exp;
branches;
next	1.26;

1.26
date	2012.10.08.14.22.41;	author jsing;	state Exp;
branches;
next	1.25;

1.25
date	2011.12.25.15.28.17;	author jsing;	state Exp;
branches;
next	1.24;

1.24
date	2011.04.21.20.28.16;	author jordan;	state Exp;
branches;
next	1.23;

1.23
date	2011.04.08.04.30.11;	author jordan;	state Exp;
branches;
next	1.22;

1.22
date	2011.04.08.00.12.54;	author jordan;	state Exp;
branches;
next	1.21;

1.21
date	2011.04.06.02.45.55;	author marco;	state Exp;
branches;
next	1.20;

1.20
date	2011.04.05.19.52.02;	author krw;	state Exp;
branches;
next	1.19;

1.19
date	2010.08.07.03.50.01;	author krw;	state Exp;
branches;
next	1.18;

1.18
date	2010.07.02.09.20.26;	author jsing;	state Exp;
branches;
next	1.17;

1.17
date	2010.07.01.19.31.04;	author thib;	state Exp;
branches;
next	1.16;

1.16
date	2010.03.26.11.20.34;	author jsing;	state Exp;
branches;
next	1.15;

1.15
date	2010.02.09.01.18.05;	author jordan;	state Exp;
branches;
next	1.14;

1.14
date	2010.02.04.07.30.27;	author jordan;	state Exp;
branches;
next	1.13;

1.13
date	2010.02.04.03.34.05;	author jordan;	state Exp;
branches;
next	1.12;

1.12
date	2010.01.20.19.55.15;	author jordan;	state Exp;
branches;
next	1.11;

1.11
date	2010.01.09.23.15.06;	author krw;	state Exp;
branches;
next	1.10;

1.10
date	2009.12.15.13.19.37;	author jsing;	state Exp;
branches;
next	1.9;

1.9
date	2009.12.07.14.33.38;	author jsing;	state Exp;
branches;
next	1.8;

1.8
date	2009.12.07.14.27.12;	author jsing;	state Exp;
branches;
next	1.7;

1.7
date	2009.11.13.23.34.24;	author jordan;	state Exp;
branches;
next	1.6;

1.6
date	2009.08.26.20.14.44;	author jordan;	state Exp;
branches;
next	1.5;

1.5
date	2009.08.12.22.01.15;	author jordan;	state Exp;
branches;
next	1.4;

1.4
date	2009.08.09.14.12.25;	author marco;	state Exp;
branches;
next	1.3;

1.3
date	2009.08.06.22.39.40;	author jordan;	state Exp;
branches;
next	1.2;

1.2
date	2009.08.04.20.17.14;	author jordan;	state Exp;
branches;
next	1.1;

1.1
date	2009.07.23.15.15.26;	author jordan;	state Exp;
branches;
next	;


desc
@@


1.71
log
@No need to rescan chunks in each discipline to find appropriate
volume sector size.  Determine volume sector size in sr_meta_init().

Pointed out, tweaked and ok jsing@@
@
text
@/* $OpenBSD: softraid_raid6.c,v 1.70 2016/04/04 18:48:39 krw Exp $ */
/*
 * Copyright (c) 2009 Marco Peereboom <marco@@peereboom.us>
 * Copyright (c) 2009 Jordan Hargrave <jordan@@openbsd.org>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

#include "bio.h"

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/buf.h>
#include <sys/device.h>
#include <sys/ioctl.h>
#include <sys/malloc.h>
#include <sys/kernel.h>
#include <sys/disk.h>
#include <sys/rwlock.h>
#include <sys/queue.h>
#include <sys/fcntl.h>
#include <sys/mount.h>
#include <sys/sensors.h>
#include <sys/stat.h>
#include <sys/task.h>
#include <sys/conf.h>
#include <sys/uio.h>

#include <scsi/scsi_all.h>
#include <scsi/scsiconf.h>
#include <scsi/scsi_disk.h>

#include <dev/softraidvar.h>

uint8_t *gf_map[256];
uint8_t	gf_pow[768];
int	gf_log[256];

/* RAID 6 functions. */
int	sr_raid6_create(struct sr_discipline *, struct bioc_createraid *,
	    int, int64_t);
int	sr_raid6_assemble(struct sr_discipline *, struct bioc_createraid *,
	    int, void *);
int	sr_raid6_init(struct sr_discipline *);
int	sr_raid6_rw(struct sr_workunit *);
int	sr_raid6_openings(struct sr_discipline *);
void	sr_raid6_intr(struct buf *);
int	sr_raid6_wu_done(struct sr_workunit *);
void	sr_raid6_set_chunk_state(struct sr_discipline *, int, int);
void	sr_raid6_set_vol_state(struct sr_discipline *);

void	sr_raid6_xorp(void *, void *, int);
void	sr_raid6_xorq(void *, void *, int, int);
int	sr_raid6_addio(struct sr_workunit *wu, int, daddr_t, long,
	    void *, int, int, void *, void *, int);
void	sr_raid6_scrub(struct sr_discipline *);
int	sr_failio(struct sr_workunit *);

void	gf_init(void);
uint8_t gf_inv(uint8_t);
int	gf_premul(uint8_t);
uint8_t gf_mul(uint8_t, uint8_t);

#define SR_NOFAIL		0x00
#define SR_FAILX		(1L << 0)
#define SR_FAILY		(1L << 1)
#define SR_FAILP		(1L << 2)
#define SR_FAILQ		(1L << 3)

struct sr_raid6_opaque {
	int	gn;
	void	*pbuf;
	void	*qbuf;
};

/* discipline initialisation. */
void
sr_raid6_discipline_init(struct sr_discipline *sd)
{
	/* Initialize GF256 tables. */
	gf_init();

	/* Fill out discipline members. */
	sd->sd_type = SR_MD_RAID6;
	strlcpy(sd->sd_name, "RAID 6", sizeof(sd->sd_name));
	sd->sd_capabilities = SR_CAP_SYSTEM_DISK | SR_CAP_AUTO_ASSEMBLE |
	    SR_CAP_REDUNDANT;
	sd->sd_max_wu = SR_RAID6_NOWU;

	/* Setup discipline specific function pointers. */
	sd->sd_assemble = sr_raid6_assemble;
	sd->sd_create = sr_raid6_create;
	sd->sd_openings = sr_raid6_openings;
	sd->sd_scsi_rw = sr_raid6_rw;
	sd->sd_scsi_intr = sr_raid6_intr;
	sd->sd_scsi_wu_done = sr_raid6_wu_done;
	sd->sd_set_chunk_state = sr_raid6_set_chunk_state;
	sd->sd_set_vol_state = sr_raid6_set_vol_state;
}

int
sr_raid6_create(struct sr_discipline *sd, struct bioc_createraid *bc,
    int no_chunk, int64_t coerced_size)
{
	if (no_chunk < 4) {
		sr_error(sd->sd_sc, "%s requires four or more chunks",
		    sd->sd_name);
		return EINVAL;
	}

	/*
	 * XXX add variable strip size later even though MAXPHYS is really
	 * the clever value, users like * to tinker with that type of stuff.
	 */
	sd->sd_meta->ssdi.ssd_strip_size = MAXPHYS;
	sd->sd_meta->ssdi.ssd_size = (coerced_size &
	    ~(((u_int64_t)sd->sd_meta->ssdi.ssd_strip_size >>
	    DEV_BSHIFT) - 1)) * (no_chunk - 2);

	return sr_raid6_init(sd);
}

int
sr_raid6_assemble(struct sr_discipline *sd, struct bioc_createraid *bc,
    int no_chunk, void *data)
{
	return sr_raid6_init(sd);
}

int
sr_raid6_init(struct sr_discipline *sd)
{
	/* Initialise runtime values. */
	sd->mds.mdd_raid6.sr6_strip_bits =
	    sr_validate_stripsize(sd->sd_meta->ssdi.ssd_strip_size);
	if (sd->mds.mdd_raid6.sr6_strip_bits == -1) {
		sr_error(sd->sd_sc, "invalid strip size");
		return EINVAL;
	}

	/* only if stripsize <= MAXPHYS */
	sd->sd_max_ccb_per_wu = max(6, 2 * sd->sd_meta->ssdi.ssd_chunk_no);

	return 0;
}

int
sr_raid6_openings(struct sr_discipline *sd)
{
	return (sd->sd_max_wu >> 1); /* 2 wu's per IO */
}

void
sr_raid6_set_chunk_state(struct sr_discipline *sd, int c, int new_state)
{
	int			old_state, s;

	/* XXX this is for RAID 0 */
	DNPRINTF(SR_D_STATE, "%s: %s: %s: sr_raid_set_chunk_state %d -> %d\n",
	    DEVNAME(sd->sd_sc), sd->sd_meta->ssd_devname,
	    sd->sd_vol.sv_chunks[c]->src_meta.scmi.scm_devname, c, new_state);

	/* ok to go to splbio since this only happens in error path */
	s = splbio();
	old_state = sd->sd_vol.sv_chunks[c]->src_meta.scm_status;

	/* multiple IOs to the same chunk that fail will come through here */
	if (old_state == new_state)
		goto done;

	switch (old_state) {
	case BIOC_SDONLINE:
		switch (new_state) {
		case BIOC_SDOFFLINE:
		case BIOC_SDSCRUB:
			break;
		default:
			goto die;
		}
		break;

	case BIOC_SDOFFLINE:
		if (new_state == BIOC_SDREBUILD) {
			;
		} else
			goto die;
		break;

	case BIOC_SDSCRUB:
		switch (new_state) {
		case BIOC_SDONLINE:
		case BIOC_SDOFFLINE:
			break;
		default:
			goto die;
		}
		break;

	case BIOC_SDREBUILD:
		switch (new_state) {
		case BIOC_SDONLINE:
		case BIOC_SDOFFLINE:
			break;
		default:
			goto die;
		}
		break;

	default:
die:
		splx(s); /* XXX */
		panic("%s: %s: %s: invalid chunk state transition "
		    "%d -> %d", DEVNAME(sd->sd_sc),
		    sd->sd_meta->ssd_devname,
		    sd->sd_vol.sv_chunks[c]->src_meta.scmi.scm_devname,
		    old_state, new_state);
		/* NOTREACHED */
	}

	sd->sd_vol.sv_chunks[c]->src_meta.scm_status = new_state;
	sd->sd_set_vol_state(sd);

	sd->sd_must_flush = 1;
	task_add(systq, &sd->sd_meta_save_task);
done:
	splx(s);
}

void
sr_raid6_set_vol_state(struct sr_discipline *sd)
{
	int			states[SR_MAX_STATES];
	int			new_state, i, s, nd;
	int			old_state = sd->sd_vol_status;

	/* XXX this is for RAID 0 */

	DNPRINTF(SR_D_STATE, "%s: %s: sr_raid_set_vol_state\n",
	    DEVNAME(sd->sd_sc), sd->sd_meta->ssd_devname);

	nd = sd->sd_meta->ssdi.ssd_chunk_no;

	for (i = 0; i < SR_MAX_STATES; i++)
		states[i] = 0;

	for (i = 0; i < nd; i++) {
		s = sd->sd_vol.sv_chunks[i]->src_meta.scm_status;
		if (s >= SR_MAX_STATES)
			panic("%s: %s: %s: invalid chunk state",
			    DEVNAME(sd->sd_sc),
			    sd->sd_meta->ssd_devname,
			    sd->sd_vol.sv_chunks[i]->src_meta.scmi.scm_devname);
		states[s]++;
	}

	if (states[BIOC_SDONLINE] == nd)
		new_state = BIOC_SVONLINE;
	else if (states[BIOC_SDONLINE] < nd - 2)
		new_state = BIOC_SVOFFLINE;
	else if (states[BIOC_SDSCRUB] != 0)
		new_state = BIOC_SVSCRUB;
	else if (states[BIOC_SDREBUILD] != 0)
		new_state = BIOC_SVREBUILD;
	else if (states[BIOC_SDONLINE] < nd)
		new_state = BIOC_SVDEGRADED;
	else {
		printf("old_state = %d, ", old_state);
		for (i = 0; i < nd; i++)
			printf("%d = %d, ", i,
			    sd->sd_vol.sv_chunks[i]->src_meta.scm_status);
		panic("invalid new_state");
	}

	DNPRINTF(SR_D_STATE, "%s: %s: sr_raid_set_vol_state %d -> %d\n",
	    DEVNAME(sd->sd_sc), sd->sd_meta->ssd_devname,
	    old_state, new_state);

	switch (old_state) {
	case BIOC_SVONLINE:
		switch (new_state) {
		case BIOC_SVONLINE: /* can go to same state */
		case BIOC_SVOFFLINE:
		case BIOC_SVDEGRADED:
		case BIOC_SVREBUILD: /* happens on boot */
			break;
		default:
			goto die;
		}
		break;

	case BIOC_SVOFFLINE:
		/* XXX this might be a little too much */
		goto die;

	case BIOC_SVDEGRADED:
		switch (new_state) {
		case BIOC_SVOFFLINE:
		case BIOC_SVREBUILD:
		case BIOC_SVDEGRADED: /* can go to the same state */
			break;
		default:
			goto die;
		}
		break;

	case BIOC_SVBUILDING:
		switch (new_state) {
		case BIOC_SVONLINE:
		case BIOC_SVOFFLINE:
		case BIOC_SVBUILDING: /* can go to the same state */
			break;
		default:
			goto die;
		}
		break;

	case BIOC_SVSCRUB:
		switch (new_state) {
		case BIOC_SVONLINE:
		case BIOC_SVOFFLINE:
		case BIOC_SVDEGRADED:
		case BIOC_SVSCRUB: /* can go to same state */
			break;
		default:
			goto die;
		}
		break;

	case BIOC_SVREBUILD:
		switch (new_state) {
		case BIOC_SVONLINE:
		case BIOC_SVOFFLINE:
		case BIOC_SVDEGRADED:
		case BIOC_SVREBUILD: /* can go to the same state */
			break;
		default:
			goto die;
		}
		break;

	default:
die:
		panic("%s: %s: invalid volume state transition %d -> %d",
		    DEVNAME(sd->sd_sc), sd->sd_meta->ssd_devname,
		    old_state, new_state);
		/* NOTREACHED */
	}

	sd->sd_vol_status = new_state;
}

/*  modes:
 *   readq: sr_raid6_addio(i, lba, length, NULL, SCSI_DATA_IN,
 *		0, qbuf, NULL, 0);
 *   readp: sr_raid6_addio(i, lba, length, NULL, SCSI_DATA_IN,
 *		0, pbuf, NULL, 0);
 *   readx: sr_raid6_addio(i, lba, length, NULL, SCSI_DATA_IN,
 *		0, pbuf, qbuf, gf_pow[i]);
 */

int
sr_raid6_rw(struct sr_workunit *wu)
{
	struct sr_workunit	*wu_r = NULL;
	struct sr_discipline	*sd = wu->swu_dis;
	struct scsi_xfer	*xs = wu->swu_xs;
	struct sr_chunk		*scp;
	int			s, fail, i, gxinv, pxinv;
	daddr_t			blkno, lba;
	int64_t			chunk_offs, lbaoffs, offset, strip_offs;
	int64_t			strip_no, strip_size, strip_bits, row_size;
	int64_t			fchunk, no_chunk, chunk, qchunk, pchunk;
	long			length, datalen;
	void			*pbuf, *data, *qbuf;

	/* blkno and scsi error will be handled by sr_validate_io */
	if (sr_validate_io(wu, &blkno, "sr_raid6_rw"))
		goto bad;

	strip_size = sd->sd_meta->ssdi.ssd_strip_size;
	strip_bits = sd->mds.mdd_raid6.sr6_strip_bits;
	no_chunk = sd->sd_meta->ssdi.ssd_chunk_no - 2;
	row_size = (no_chunk << strip_bits) >> DEV_BSHIFT;

	data = xs->data;
	datalen = xs->datalen;
	lbaoffs	= blkno << DEV_BSHIFT;

	if (xs->flags & SCSI_DATA_OUT) {
		if ((wu_r = sr_scsi_wu_get(sd, SCSI_NOSLEEP)) == NULL){
			printf("%s: can't get wu_r", DEVNAME(sd->sd_sc));
			goto bad;
		}
		wu_r->swu_state = SR_WU_INPROGRESS;
		wu_r->swu_flags |= SR_WUF_DISCIPLINE;
	}

	wu->swu_blk_start = 0;
	while (datalen != 0) {
		strip_no = lbaoffs >> strip_bits;
		strip_offs = lbaoffs & (strip_size - 1);
		chunk_offs = (strip_no / no_chunk) << strip_bits;
		offset = chunk_offs + strip_offs;

		/* get size remaining in this stripe */
		length = MIN(strip_size - strip_offs, datalen);

		/* map disk offset to parity/data drive */
		chunk = strip_no % no_chunk;

		qchunk = (no_chunk + 1) - ((strip_no / no_chunk) % (no_chunk+2));
		if (qchunk == 0)
			pchunk = no_chunk + 1;
		else
			pchunk = qchunk - 1;
		if (chunk >= pchunk)
			chunk++;
		if (chunk >= qchunk)
			chunk++;

		lba = offset >> DEV_BSHIFT;

		/* XXX big hammer.. exclude I/O from entire stripe */
		if (wu->swu_blk_start == 0)
			wu->swu_blk_start = (strip_no / no_chunk) * row_size;
		wu->swu_blk_end = (strip_no / no_chunk) * row_size + (row_size - 1);

		fail = 0;
		fchunk = -1;

		/* Get disk-fail flags */
		for (i=0; i< no_chunk+2; i++) {
			scp = sd->sd_vol.sv_chunks[i];
			switch (scp->src_meta.scm_status) {
			case BIOC_SDOFFLINE:
			case BIOC_SDREBUILD:
			case BIOC_SDHOTSPARE:
				if (i == qchunk)
					fail |= SR_FAILQ;
				else if (i == pchunk)
					fail |= SR_FAILP;
				else if (i == chunk)
					fail |= SR_FAILX;
				else {
					/* dual data-disk failure */
					fail |= SR_FAILY;
					fchunk = i;
				}
				break;
			}
		}
		if (xs->flags & SCSI_DATA_IN) {
			if (!(fail & SR_FAILX)) {
				/* drive is good. issue single read request */
				if (sr_raid6_addio(wu, chunk, lba, length,
				    data, xs->flags, 0, NULL, NULL, 0))
					goto bad;
			} else if (fail & SR_FAILP) {
				/* Dx, P failed */
				printf("Disk %llx offline, "
				    "regenerating Dx+P\n", chunk);

				gxinv = gf_inv(gf_pow[chunk]);

				/* Calculate: Dx = (Q^Dz*gz)*inv(gx) */
				memset(data, 0, length);
				if (sr_raid6_addio(wu, qchunk, lba, length,
				    NULL, SCSI_DATA_IN, 0, NULL, data, gxinv))
					goto bad;

				/* Read Dz * gz * inv(gx) */
				for (i = 0; i < no_chunk+2; i++) {
					if  (i == qchunk || i == pchunk || i == chunk)
						continue;

					if (sr_raid6_addio(wu, i, lba, length,
					    NULL, SCSI_DATA_IN, 0, NULL, data,
					    gf_mul(gf_pow[i], gxinv)))
						goto bad;
				}

				/* data will contain correct value on completion */
			} else if (fail & SR_FAILY) {
				/* Dx, Dy failed */
				printf("Disk %llx & %llx offline, "
				    "regenerating Dx+Dy\n", chunk, fchunk);

				gxinv = gf_inv(gf_pow[chunk] ^ gf_pow[fchunk]);
				pxinv = gf_mul(gf_pow[fchunk], gxinv);

				/* read Q * inv(gx + gy) */
				memset(data, 0, length);
				if (sr_raid6_addio(wu, qchunk, lba, length,
				    NULL, SCSI_DATA_IN, 0, NULL, data, gxinv))
					goto bad;

				/* read P * gy * inv(gx + gy) */
				if (sr_raid6_addio(wu, pchunk, lba, length,
				    NULL, SCSI_DATA_IN, 0, NULL, data, pxinv))
					goto bad;

				/* Calculate: Dx*gx^Dy*gy = Q^(Dz*gz) ; Dx^Dy = P^Dz
				 *   Q:  sr_raid6_xorp(qbuf, --, length);
				 *   P:  sr_raid6_xorp(pbuf, --, length);
				 *   Dz: sr_raid6_xorp(pbuf, --, length);
				 *	 sr_raid6_xorq(qbuf, --, length, gf_pow[i]);
				 */
				for (i = 0; i < no_chunk+2; i++) {
					if (i == qchunk || i == pchunk ||
					    i == chunk || i == fchunk)
						continue;

					/* read Dz * (gz + gy) * inv(gx + gy) */
					if (sr_raid6_addio(wu, i, lba, length,
					    NULL, SCSI_DATA_IN, 0, NULL, data,
					    pxinv ^ gf_mul(gf_pow[i], gxinv)))
						goto bad;
				}
			} else {
				/* Two cases: single disk (Dx) or (Dx+Q)
				 *   Dx = Dz ^ P (same as RAID5)
				 */
				printf("Disk %llx offline, "
				    "regenerating Dx%s\n", chunk,
				    fail & SR_FAILQ ? "+Q" : " single");

				/* Calculate: Dx = P^Dz
				 *   P:  sr_raid6_xorp(data, ---, length);
				 *   Dz: sr_raid6_xorp(data, ---, length);
				 */
				memset(data, 0, length);
				for (i = 0; i < no_chunk+2; i++) {
					if (i != chunk && i != qchunk) {
						/* Read Dz */
						if (sr_raid6_addio(wu, i, lba,
						    length, NULL, SCSI_DATA_IN,
						    0, data, NULL, 0))
							goto bad;
					}
				}

				/* data will contain correct value on completion */
			}
		} else {
			/* XXX handle writes to failed/offline disk? */
			if (fail & (SR_FAILX|SR_FAILQ|SR_FAILP))
				goto bad;

			/*
			 * initialize pbuf with contents of new data to be
			 * written. This will be XORed with old data and old
			 * parity in the intr routine. The result in pbuf
			 * is the new parity data.
			 */
			qbuf = sr_block_get(sd, length);
			if (qbuf == NULL)
				goto bad;

			pbuf = sr_block_get(sd, length);
			if (pbuf == NULL)
				goto bad;

			/* Calculate P = Dn; Q = gn * Dn */
			if (gf_premul(gf_pow[chunk]))
				goto bad;
			sr_raid6_xorp(pbuf, data, length);
			sr_raid6_xorq(qbuf, data, length, gf_pow[chunk]);

			/* Read old data: P ^= Dn' ; Q ^= (gn * Dn') */
			if (sr_raid6_addio(wu_r, chunk, lba, length, NULL,
				SCSI_DATA_IN, 0, pbuf, qbuf, gf_pow[chunk]))
				goto bad;

			/* Read old xor-parity: P ^= P' */
			if (sr_raid6_addio(wu_r, pchunk, lba, length, NULL,
				SCSI_DATA_IN, 0, pbuf, NULL, 0))
				goto bad;

			/* Read old q-parity: Q ^= Q' */
			if (sr_raid6_addio(wu_r, qchunk, lba, length, NULL,
				SCSI_DATA_IN, 0, qbuf, NULL, 0))
				goto bad;

			/* write new data */
			if (sr_raid6_addio(wu, chunk, lba, length, data,
			    xs->flags, 0, NULL, NULL, 0))
				goto bad;

			/* write new xor-parity */
			if (sr_raid6_addio(wu, pchunk, lba, length, pbuf,
			    xs->flags, SR_CCBF_FREEBUF, NULL, NULL, 0))
				goto bad;

			/* write new q-parity */
			if (sr_raid6_addio(wu, qchunk, lba, length, qbuf,
			    xs->flags, SR_CCBF_FREEBUF, NULL, NULL, 0))
				goto bad;
		}

		/* advance to next block */
		lbaoffs += length;
		datalen -= length;
		data += length;
	}

	s = splbio();
	if (wu_r) {
		/* collide write request with reads */
		wu_r->swu_blk_start = wu->swu_blk_start;
		wu_r->swu_blk_end = wu->swu_blk_end;

		wu->swu_state = SR_WU_DEFERRED;
		wu_r->swu_collider = wu;
		TAILQ_INSERT_TAIL(&sd->sd_wu_defq, wu, swu_link);

		wu = wu_r;
	}
	splx(s);

	sr_schedule_wu(wu);

	return (0);
bad:
	/* XXX - can leak pbuf/qbuf on error. */
	/* wu is unwound by sr_wu_put */
	if (wu_r)
		sr_scsi_wu_put(sd, wu_r);
	return (1);
}

/* Handle failure I/O completion */
int
sr_failio(struct sr_workunit *wu)
{
	struct sr_discipline	*sd = wu->swu_dis;
	struct sr_ccb		*ccb;

	if (!(wu->swu_flags & SR_WUF_FAIL))
		return (0);

	/* Wu is a 'fake'.. don't do real I/O just intr */
	TAILQ_INSERT_TAIL(&sd->sd_wu_pendq, wu, swu_link);
	TAILQ_FOREACH(ccb, &wu->swu_ccb, ccb_link)
		sr_raid6_intr(&ccb->ccb_buf);
	return (1);
}

void
sr_raid6_intr(struct buf *bp)
{
	struct sr_ccb		*ccb = (struct sr_ccb *)bp;
	struct sr_workunit	*wu = ccb->ccb_wu;
	struct sr_discipline	*sd = wu->swu_dis;
	struct sr_raid6_opaque  *pq = ccb->ccb_opaque;
	int			s;

	DNPRINTF(SR_D_INTR, "%s: sr_raid6_intr bp %p xs %p\n",
	    DEVNAME(sd->sd_sc), bp, wu->swu_xs);

	s = splbio();
	sr_ccb_done(ccb);

	/* XOR data to result. */
	if (ccb->ccb_state == SR_CCB_OK && pq) {
		if (pq->pbuf)
			/* Calculate xor-parity */
			sr_raid6_xorp(pq->pbuf, ccb->ccb_buf.b_data,
			    ccb->ccb_buf.b_bcount);
		if (pq->qbuf)
			/* Calculate q-parity */
			sr_raid6_xorq(pq->qbuf, ccb->ccb_buf.b_data,
			    ccb->ccb_buf.b_bcount, pq->gn);
		free(pq, M_DEVBUF, 0);
		ccb->ccb_opaque = NULL;
	}

	/* Free allocated data buffer. */
	if (ccb->ccb_flags & SR_CCBF_FREEBUF) {
		sr_block_put(sd, ccb->ccb_buf.b_data, ccb->ccb_buf.b_bcount);
		ccb->ccb_buf.b_data = NULL;
	}

	sr_wu_done(wu);
	splx(s);
}

int
sr_raid6_wu_done(struct sr_workunit *wu)
{
	struct sr_discipline	*sd = wu->swu_dis;
	struct scsi_xfer	*xs = wu->swu_xs;

	/* XXX - we have no way of propagating errors... */
	if (wu->swu_flags & SR_WUF_DISCIPLINE)
		return SR_WU_OK;

	/* XXX - This is insufficient for RAID 6. */
	if (wu->swu_ios_succeeded > 0) {
		xs->error = XS_NOERROR;
		return SR_WU_OK;
	}

	if (xs->flags & SCSI_DATA_IN) {
		printf("%s: retrying read on block %lld\n",
		    sd->sd_meta->ssd_devname, (long long)wu->swu_blk_start);
		sr_wu_release_ccbs(wu);
		wu->swu_state = SR_WU_RESTART;
		if (sd->sd_scsi_rw(wu) == 0)
			return SR_WU_RESTART;
	} else {
		printf("%s: permanently fail write on block %lld\n",
		    sd->sd_meta->ssd_devname, (long long)wu->swu_blk_start);
	}

	wu->swu_state = SR_WU_FAILED;
	xs->error = XS_DRIVER_STUFFUP;

	return SR_WU_FAILED;
}

int
sr_raid6_addio(struct sr_workunit *wu, int chunk, daddr_t blkno,
    long len, void *data, int xsflags, int ccbflags, void *pbuf,
    void *qbuf, int gn)
{
	struct sr_discipline	*sd = wu->swu_dis;
	struct sr_ccb		*ccb;
	struct sr_raid6_opaque  *pqbuf;

	DNPRINTF(SR_D_DIS, "sr_raid6_addio: %s %d.%lld %ld %p:%p\n",
	    (xsflags & SCSI_DATA_IN) ? "read" : "write", chunk,
	    (long long)blkno, len, pbuf, qbuf);

	/* Allocate temporary buffer. */
	if (data == NULL) {
		data = sr_block_get(sd, len);
		if (data == NULL)
			return (-1);
		ccbflags |= SR_CCBF_FREEBUF;
	}

	ccb = sr_ccb_rw(sd, chunk, blkno, len, data, xsflags, ccbflags);
	if (ccb == NULL) {
		if (ccbflags & SR_CCBF_FREEBUF)
			sr_block_put(sd, data, len);
		return (-1);
	}
	if (pbuf || qbuf) {
		/* XXX - can leak data and ccb on failure. */
		if (qbuf && gf_premul(gn))
			return (-1);

		/* XXX - should be preallocated? */
		pqbuf = malloc(sizeof(struct sr_raid6_opaque),
		    M_DEVBUF, M_ZERO | M_NOWAIT);
		if (pqbuf == NULL) {
			sr_ccb_put(ccb);
			return (-1);
		}
		pqbuf->pbuf = pbuf;
		pqbuf->qbuf = qbuf;
		pqbuf->gn = gn;
		ccb->ccb_opaque = pqbuf;
	}
	sr_wu_enqueue_ccb(wu, ccb);

	return (0);
}

/* Perform RAID6 parity calculation.
 *   P=xor parity, Q=GF256 parity, D=data, gn=disk# */
void
sr_raid6_xorp(void *p, void *d, int len)
{
	uint32_t *pbuf = p, *data = d;

	len >>= 2;
	while (len--)
		*pbuf++ ^= *data++;
}

void
sr_raid6_xorq(void *q, void *d, int len, int gn)
{
	uint32_t	*qbuf = q, *data = d, x;
	uint8_t		*gn_map = gf_map[gn];

	len >>= 2;
	while (len--) {
		x = *data++;
		*qbuf++ ^= (((uint32_t)gn_map[x & 0xff]) |
			    ((uint32_t)gn_map[(x >> 8) & 0xff] << 8) |
			    ((uint32_t)gn_map[(x >> 16) & 0xff] << 16) |
			    ((uint32_t)gn_map[(x >> 24) & 0xff] << 24));
	}
}

/* Create GF256 log/pow tables: polynomial = 0x11D */
void
gf_init(void)
{
	int i;
	uint8_t p = 1;

	/* use 2N pow table to avoid using % in multiply */
	for (i=0; i<256; i++) {
		gf_log[p] = i;
		gf_pow[i] = gf_pow[i+255] = p;
		p = ((p << 1) ^ ((p & 0x80) ? 0x1D : 0x00));
	}
	gf_log[0] = 512;
}

uint8_t
gf_inv(uint8_t a)
{
	return gf_pow[255 - gf_log[a]];
}

uint8_t
gf_mul(uint8_t a, uint8_t b)
{
	return gf_pow[gf_log[a] + gf_log[b]];
}

/* Precalculate multiplication tables for drive gn */
int
gf_premul(uint8_t gn)
{
	int i;

	if (gf_map[gn] != NULL)
		return (0);

	if ((gf_map[gn] = malloc(256, M_DEVBUF, M_ZERO | M_NOWAIT)) == NULL)
		return (-1);

	for (i=0; i<256; i++)
		gf_map[gn][i] = gf_pow[gf_log[i] + gf_log[gn]];
	return (0);
}
@


1.70
log
@Enable creation of softraid volumes using disks with non-512 byte
sectors. Volumes created will present a sector size equal to the
largest sector size of the constituent disks.

Softraid Metadata version cranks to 6 due to new field.

ok jsing@@ with tweaks that will follow soon.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.69 2015/07/21 03:30:51 krw Exp $ */
a114 3
	int i;
	u_int32_t secsize;

a119 7

	secsize = 0;
	for (i = 0; i < no_chunk; i++) {
		if (sd->sd_vol.sv_chunks[i]->src_secsize > secsize)
			secsize = sd->sd_vol.sv_chunks[i]->src_secsize;
	}
	sd->sd_meta->ssdi.ssd_secsize = secsize;
@


1.69
log
@A few more daddr_t fixes. Rename 'phys_off' variables to 'offset'
since they are now relative to chunks. Use 'blkno' as normal variable
name for daddr_t items rather than mix of 'blkno, blk, offset.
Change field name ssd_data_offset to ssd_data_blkno since it is a
block and not byte quantity.

No intentional functional change.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.68 2015/07/19 21:06:04 krw Exp $ */
d115 3
d123 7
@


1.68
log
@Remove unneeded #include <disklabel.h>.

ok jsing@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.67 2015/07/19 18:24:16 krw Exp $ */
d379 2
a380 2
	daddr_t			blk, lba;
	int64_t			chunk_offs, lbaoffs, phys_offs, strip_offs;
d386 2
a387 2
	/* blk and scsi error will be handled by sr_validate_io */
	if (sr_validate_io(wu, &blk, "sr_raid6_rw"))
d397 1
a397 1
	lbaoffs	= blk << DEV_BSHIFT;
d413 1
a413 1
		phys_offs = chunk_offs + strip_offs;
d431 1
a431 1
		lba = phys_offs >> DEV_BSHIFT;
d740 1
a740 1
	DNPRINTF(SR_D_DIS, "sr_raid6_addio: %s %d.%llx %llx %p:%p\n",
d742 1
a742 2
	    (long long)blkno, (long long)len,
	    pbuf, qbuf);
@


1.67
log
@Stop passing daddr_t parameters for lengths. Use long since that's the type
of the destination fields.

ok jsing@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.66 2015/07/19 17:04:31 krw Exp $ */
a31 1
#include <sys/disklabel.h>
@


1.66
log
@Stop adding and subtracting data offset. Just keep to chunk relative
block offsets until actual i/o is constructed and needs the physical
offset. Eliminate a number of <<DEV_BSIZE shifts as a bonus.

No intentional functional change.

Fixed and ok jsing@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.65 2015/05/29 13:48:45 krw Exp $ */
d65 1
a65 1
int	sr_raid6_addio(struct sr_workunit *wu, int, daddr_t, daddr_t,
d382 1
a382 1
	int64_t			strip_no, strip_size, strip_bits;
d384 1
a384 1
	int64_t			length, datalen, row_size;
d734 1
a734 1
    daddr_t len, void *data, int xsflags, int ccbflags, void *pbuf,
@


1.65
log
@Nuke annoying whitespace nits to shrink some future diffs.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.64 2015/03/14 03:38:46 jsg Exp $ */
d414 1
a414 2
		phys_offs = chunk_offs + strip_offs +
		    (sd->sd_meta->ssd_data_offset << DEV_BSHIFT);
@


1.64
log
@Remove some includes include-what-you-use claims don't
have any direct symbols used.  Tested for indirect use by compiling
amd64/i386/sparc64 kernels.

ok tedu@@ deraadt@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.63 2014/09/14 14:17:24 jsg Exp $ */
d798 2
a799 2
	uint32_t 	*qbuf = q, *data = d, x;
	uint8_t	 	*gn_map = gf_map[gn];
d805 1
a805 1
		  	    ((uint32_t)gn_map[(x >> 8) & 0xff] << 8) |
@


1.63
log
@remove uneeded proc.h includes
ok mpi@@ kspillner@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.62 2014/07/12 18:48:51 tedu Exp $ */
a44 1
#include <dev/rndvar.h>
@


1.62
log
@add a size argument to free. will be used soon, but for now default to 0.
after discussions with beck deraadt kettenis.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.61 2014/01/22 05:11:36 jsing Exp $ */
a25 1
#include <sys/proc.h>
@


1.61
log
@Move sr_dump from the RAID5 code into shared code. Rename it to
sr_dump_block and place it under the debug define in the process.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.60 2014/01/22 04:24:29 jsing Exp $ */
d687 1
a687 1
		free(pq, M_DEVBUF);
@


1.60
log
@Switch metadata saves from the system workq to the system taskq.

ok dlg@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.59 2014/01/21 10:25:25 jsing Exp $ */
a68 1
void	sr_dump(void *, int);
@


1.59
log
@Order the volume state transitions by state value.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.58 2014/01/18 09:33:53 jsing Exp $ */
d37 1
d238 1
a238 1
	workq_add_task(NULL, 0, sr_meta_save_callback, sd, NULL);
@


1.58
log
@Move the block get/put routines into the common code, instead of having
RAID 6 borrow them from RAID 5.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.57 2013/11/21 17:06:45 krw Exp $ */
d308 1
a308 1
	case BIOC_SVSCRUB:
a309 1
		case BIOC_SVONLINE:
d311 2
a312 2
		case BIOC_SVDEGRADED:
		case BIOC_SVSCRUB: /* can go to same state */
d330 1
a330 1
	case BIOC_SVREBUILD:
d335 1
a335 1
		case BIOC_SVREBUILD: /* can go to the same state */
d342 1
a342 1
	case BIOC_SVDEGRADED:
d344 1
d346 2
a347 2
		case BIOC_SVREBUILD:
		case BIOC_SVDEGRADED: /* can go to the same state */
@


1.57
log
@Cast daddr_t variable to (long long) even for %llx!
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.56 2013/11/21 16:34:50 krw Exp $ */
a71 3
void	*sr_get_block(struct sr_discipline *, int);
void	sr_put_block(struct sr_discipline *, void *, int);

d569 1
a569 1
			qbuf = sr_get_block(sd, length);
d573 1
a573 1
			pbuf = sr_get_block(sd, length);
d693 1
a693 1
		sr_put_block(sd, ccb->ccb_buf.b_data, ccb->ccb_buf.b_bcount);
d751 1
a751 1
		data = sr_get_block(sd, len);
d760 1
a760 1
			sr_put_block(sd, data, len);
@


1.56
log
@Change a bunch of daddr_t variables that don't (obviously) contain
512-byte-block information to int64_t, the underlying type of
daddr_t at the moment. No change to .o files. Removal of now
unneeded (long long) casts is next.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.55 2013/11/05 08:55:58 reyk Exp $ */
d748 2
a749 1
	    (xsflags & SCSI_DATA_IN) ? "read" : "write", chunk, blkno, len,
@


1.55
log
@Fix RAID levels 0, 4, 5, and 6 with partitions larger than 2TB.

A 64bit bit operation with the 32bit strip size could overflow and
result in ridiculously small volumes when using large partitions (eg.
4x 3TB in RAID 5 resulted in a ~2TB volume).  It is fixed by casting
the strip size to an unsigned 64bit value.

ok tedu@@ millert@@ deraadt@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.54 2013/11/01 17:36:19 krw Exp $ */
d385 5
a389 3
	daddr_t			blk, lbaoffs, strip_no, chunk, qchunk, pchunk, fchunk;
	daddr_t			strip_size, no_chunk, lba, chunk_offs, phys_offs;
	daddr_t			strip_bits, length, strip_offs, datalen, row_size;
@


1.54
log
@Sprinkle (long long) casts where %lld is being used to print daddr_t
variables. Some random whitespace/knf repairs encountered on the way.

ok miod@@ on inspection, feedback & more suggestions from millert@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.53 2013/06/11 16:42:13 deraadt Exp $ */
d133 2
a134 2
	    ~((sd->sd_meta->ssdi.ssd_strip_size >> DEV_BSHIFT) - 1)) *
	    (no_chunk - 2);
@


1.53
log
@final removal of daddr64_t.  daddr_t has been 64 bit for a long enough
test period; i think 3 years ago the last bugs fell out.
ok otto beck others
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.52 2013/05/21 15:01:53 jsing Exp $ */
d720 1
a720 1
		    sd->sd_meta->ssd_devname, wu->swu_blk_start);
d727 1
a727 1
		    sd->sd_meta->ssd_devname, wu->swu_blk_start);
@


1.52
log
@Provide a function that handles the scheduling of work units. This
simplifies the discipline code, avoids code duplication and moves the
scheduling logic into a single location.

ok krw@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.49 2013/04/27 14:06:09 jsing Exp $ */
d66 1
a66 1
int	sr_raid6_addio(struct sr_workunit *wu, int, daddr64_t, daddr64_t,
d385 3
a387 3
	daddr64_t		blk, lbaoffs, strip_no, chunk, qchunk, pchunk, fchunk;
	daddr64_t		strip_size, no_chunk, lba, chunk_offs, phys_offs;
	daddr64_t		strip_bits, length, strip_offs, datalen, row_size;
d737 2
a738 2
sr_raid6_addio(struct sr_workunit *wu, int chunk, daddr64_t blkno,
    daddr64_t len, void *data, int xsflags, int ccbflags, void *pbuf,
@


1.51
log
@Fix missing work unit state initialisations.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.50 2013/05/21 14:25:23 jsing Exp $ */
d633 3
a636 19
	/* Construct the work unit, do not schedule it. */
	if (wu->swu_state == SR_WU_CONSTRUCT)
		goto queued;

	/* current io failed, restart */
	if (wu->swu_state == SR_WU_RESTART)
		goto start;

	/* deferred io failed, don't restart */
	if (wu->swu_state == SR_WU_REQUEUE)
		goto queued;

	if (sr_check_io_collision(wu))
		goto queued;

start:
	sr_raid_startwu(wu);
queued:
	splx(s);
@


1.50
log
@Use a state to indicate that a work unit should only be constructed and not
scheduled, rather than trying to imply this from the rebuild flag.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.49 2013/04/27 14:06:09 jsing Exp $ */
d408 1
@


1.49
log
@Convert RAID 6 to new work unit completion routines.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.48 2013/04/26 15:45:35 jsing Exp $ */
d633 2
a634 2
	/* rebuild io, let rebuild routine deal with it */
	if (wu->swu_flags & SR_WUF_REBUILD)
@


1.48
log
@Add a SR_WUF_DISCIPLINE flag that identifies work units that have resulted
from discipline specific I/O. Such work units are not associated with a
SCSI xfer and are returned via sr_wu_put() on completion.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.47 2013/04/23 13:36:19 jsing Exp $ */
d60 1
d112 1
d682 1
a682 1
	struct sr_workunit	*wu = ccb->ccb_wu, *wup;
a683 2
	struct scsi_xfer	*xs = wu->swu_xs;
	struct sr_softc		*sc = sd->sd_sc;
d688 1
a688 1
	    DEVNAME(sc), bp, xs);
a690 1

d713 3
a715 3
	DNPRINTF(SR_D_INTR, "%s: sr_intr: comp: %d count: %d failed: %d\n",
	    DEVNAME(sc), wu->swu_ios_complete, wu->swu_io_count,
	    wu->swu_ios_failed);
d717 9
a725 2
	if (wu->swu_ios_complete < wu->swu_io_count)
		goto done;
d727 2
a728 1
	if (xs != NULL)
d730 1
a730 17

	/* if all ios failed, retry reads and give up on writes */
	if (wu->swu_ios_failed == wu->swu_ios_complete) {
		/* XXX xs could be NULL. */
		if (xs->flags & SCSI_DATA_IN) {
			printf("%s: retrying read on block %lld\n",
			    DEVNAME(sc), ccb->ccb_buf.b_blkno);
			sr_wu_release_ccbs(wu);
			wu->swu_state = SR_WU_RESTART;
			if (sd->sd_scsi_rw(wu) == 0)
				goto done;
			xs->error = XS_DRIVER_STUFFUP;
		} else {
			printf("%s: permanently fail write on block %lld\n",
			    DEVNAME(sc), ccb->ccb_buf.b_blkno);
			xs->error = XS_DRIVER_STUFFUP;
		}
d733 10
a742 20
	TAILQ_FOREACH(wup, &sd->sd_wu_pendq, swu_link)
		if (wu == wup)
			break;

	if (wup == NULL)
		panic("%s: wu %p not on pending queue",
		    DEVNAME(sd->sd_sc), wu);

	TAILQ_REMOVE(&sd->sd_wu_pendq, wu, swu_link);

	if (wu->swu_collider) {
		if (wu->swu_ios_failed)
			sr_raid_recreate_wu(wu->swu_collider);

		/* XXX Should the collider be failed if this xs failed? */
		/* restart deferred wu */
		wu->swu_collider->swu_state = SR_WU_INPROGRESS;
		TAILQ_REMOVE(&sd->sd_wu_defq, wu->swu_collider, swu_link);
		if (sr_failio(wu->swu_collider) == 0)
			sr_raid_startwu(wu->swu_collider);
d745 2
a746 8
	if (wu->swu_flags & SR_WUF_REBUILD)
		wu->swu_flags |= SR_WUF_REBUILDIOCOMP;
	if (wu->swu_flags & SR_WUF_WAKEUP)
		wakeup(wu);
	if (wu->swu_flags & SR_WUF_DISCIPLINE)
		sr_scsi_wu_put(sd, wu);
	else if (!(wu->swu_flags & SR_WUF_REBUILD))
		sr_scsi_done(sd, xs);
d748 1
a748 2
done:
	splx(s);
@


1.47
log
@Convert RAID6 to new ccb handling.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.46 2013/04/23 13:13:11 jsing Exp $ */
d401 1
a401 2
	if (xs->flags & SCSI_DATA_OUT)
		/* create write workunit */
d406 2
d768 4
a771 7
	if (!(wu->swu_flags & SR_WUF_REBUILD)) {
		if (xs == NULL) {
			sr_scsi_wu_put(sd, wu);
		} else {
			sr_scsi_done(sd, xs);
		}
	}
@


1.46
log
@Do not pass SR_CCBF_FREEBUF unless we are passing an already allocated
buffer that we want freed; set SR_CCBF_FREEBUF when a buffer is allocated
by the addio function.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.45 2013/04/23 12:49:52 jsing Exp $ */
d780 3
a782 2
sr_raid6_addio(struct sr_workunit *wu, int dsk, daddr64_t blk, daddr64_t len,
    void *data, int flag, int ccbflags, void *pbuf, void *qbuf, int gn)
d788 3
a790 3
	ccb = sr_ccb_get(sd);
	if (!ccb)
		return (-1);
d792 1
a792 1
	/* allocate temporary buffer */
d800 6
a805 34
	DNPRINTF(0, "%sio: %d.%llx %llx %p:%p\n",
	    flag & SCSI_DATA_IN ? "read" : "write",
	    dsk, blk, len, pbuf, qbuf);

	ccb->ccb_flags = ccbflags;
	if (flag & SCSI_POLL) {
		ccb->ccb_buf.b_flags = 0;
		ccb->ccb_buf.b_iodone = NULL;
	} else {
		ccb->ccb_buf.b_flags = B_CALL;
		ccb->ccb_buf.b_iodone = sr_raid6_intr;
	}
	if (flag & SCSI_DATA_IN)
		ccb->ccb_buf.b_flags |= B_READ;
	else
		ccb->ccb_buf.b_flags |= B_WRITE;

	/* add offset for metadata */
	ccb->ccb_buf.b_flags |= B_PHYS;
	ccb->ccb_buf.b_blkno = blk;
	ccb->ccb_buf.b_bcount = len;
	ccb->ccb_buf.b_bufsize = len;
	ccb->ccb_buf.b_resid = len;
	ccb->ccb_buf.b_data = data;
	ccb->ccb_buf.b_error = 0;
	ccb->ccb_buf.b_proc = curproc;
	ccb->ccb_buf.b_dev = sd->sd_vol.sv_chunks[dsk]->src_dev_mm;
	ccb->ccb_buf.b_vp = sd->sd_vol.sv_chunks[dsk]->src_vn;
	ccb->ccb_buf.b_bq = NULL;
	if ((ccb->ccb_buf.b_flags & B_READ) == 0)
		ccb->ccb_buf.b_vp->v_numoutput++;

	ccb->ccb_wu = wu;
	ccb->ccb_target = dsk;
d807 1
d811 3
a813 1
		pqbuf = malloc(sizeof(struct sr_raid6_opaque), M_DEVBUF, M_ZERO | M_NOWAIT);
d823 1
a823 11

	LIST_INIT(&ccb->ccb_buf.b_dep);
	TAILQ_INSERT_TAIL(&wu->swu_ccb, ccb, ccb_link);

	DNPRINTF(SR_D_DIS, "%s: %s: sr_raid6: b_bcount: %d "
	    "b_blkno: %x b_flags 0x%0x b_data %p\n",
	    DEVNAME(sd->sd_sc), sd->sd_meta->ssd_devname,
	    ccb->ccb_buf.b_bcount, ccb->ccb_buf.b_blkno,
	    ccb->ccb_buf.b_flags, ccb->ccb_buf.b_data);

	wu->swu_io_count++;
@


1.45
log
@Rename ccb_flag to ccb_flags.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.44 2013/03/31 15:44:52 jsing Exp $ */
d86 1
a86 1
	int      gn;
d368 1
a368 1
 *		SR_CCBF_FREEBUF, qbuf, NULL, 0);
d370 1
a370 1
 *		SR_CCBF_FREEBUF, pbuf, NULL, 0);
d372 1
a372 1
 *		SR_CCBF_FREEBUF, pbuf, qbuf, gf_pow[i]);
d478 2
a479 3
				if (sr_raid6_addio(wu, qchunk, lba, length, NULL,
				    SCSI_DATA_IN, SR_CCBF_FREEBUF, NULL, data,
				    gxinv))
d487 3
a489 4
					if (sr_raid6_addio(wu, i, lba,
					   length, NULL, SCSI_DATA_IN,
					   SR_CCBF_FREEBUF, NULL,
					   data, gf_mul(gf_pow[i], gxinv)))
d504 2
a505 4
				if (sr_raid6_addio(wu, qchunk, lba,
				    length,  NULL, SCSI_DATA_IN,
				    SR_CCBF_FREEBUF, NULL,
				    data, gxinv))
d509 2
a510 4
				if (sr_raid6_addio(wu, pchunk, lba,
				    length,  NULL, SCSI_DATA_IN,
				    SR_CCBF_FREEBUF, NULL,
				    data, pxinv))
d525 2
a526 3
					if (sr_raid6_addio(wu, i, lba,
					    length, NULL, SCSI_DATA_IN,
					    SR_CCBF_FREEBUF, NULL, data,
d548 1
a548 2
						    SR_CCBF_FREEBUF, data,
						    NULL, 0))
d582 1
a582 2
				SCSI_DATA_IN, SR_CCBF_FREEBUF, pbuf, qbuf,
				gf_pow[chunk]))
d587 1
a587 1
				SCSI_DATA_IN, SR_CCBF_FREEBUF, pbuf, NULL, 0))
d592 1
a592 1
				SCSI_DATA_IN, SR_CCBF_FREEBUF, qbuf, NULL, 0))
d651 1
d796 1
@


1.44
log
@Use consistent error handling when validating the number of chunks
provided.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.43 2013/03/31 11:12:06 jsing Exp $ */
d716 1
a716 1
	if (ccb->ccb_flag & SR_CCBF_FREEBUF) {
d789 1
a789 1
    void *data, int flag, int ccbflag, void *pbuf, void *qbuf, int gn)
d810 1
a810 1
	ccb->ccb_flag = ccbflag;
@


1.43
log
@Provide default resource allocation and free functions. Convert all
disciplines except for AOE and CRYPTO, which require custom handlers.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.42 2013/03/31 10:41:16 jsing Exp $ */
d119 3
a121 2

	if (no_chunk < 4)
d123 1
@


1.42
log
@Pull the initialisation of runtime values out into a separate init
function, rather than having it spread across create/assemble/alloc.
Also handle strip size errors appropriately, rather than failing silently.

ok krw@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.41 2013/03/30 14:41:37 jsing Exp $ */
a56 2
int	sr_raid6_alloc_resources(struct sr_discipline *);
int	sr_raid6_free_resources(struct sr_discipline *);
a105 1
	sd->sd_alloc_resources = sr_raid6_alloc_resources;
a107 1
	sd->sd_free_resources = sr_raid6_free_resources;
a162 33
}

int
sr_raid6_alloc_resources(struct sr_discipline *sd)
{
	int			rv = EINVAL;

	DNPRINTF(SR_D_DIS, "%s: sr_raid6_alloc_resources\n",
	    DEVNAME(sd->sd_sc));

	if (sr_wu_alloc(sd))
		goto bad;
	if (sr_ccb_alloc(sd))
		goto bad;

	rv = 0;
bad:
	return (rv);
}

int
sr_raid6_free_resources(struct sr_discipline *sd)
{
	int			rv = EINVAL;

	DNPRINTF(SR_D_DIS, "%s: sr_raid6_free_resources\n",
	    DEVNAME(sd->sd_sc));

	sr_wu_free(sd);
	sr_ccb_free(sd);

	rv = 0;
	return (rv);
@


1.41
log
@Provide wrappers for scsi_io_get() and scsi_io_put(), that also include
the sd_sync check/wakeup. Remove some unnecessary NULL checks whilst here.

ok krw@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.40 2013/03/29 15:26:45 jsing Exp $ */
d56 1
d131 2
a132 2
        sd->sd_meta->ssdi.ssd_strip_size = MAXPHYS;
        sd->sd_meta->ssdi.ssd_size = (coerced_size &
d136 1
a136 4
	/* only if stripsize <= MAXPHYS */
	sd->sd_max_ccb_per_wu = max(6, 2 * no_chunk);

	return 0;
d143 13
a181 6
	/* setup runtime values */
	sd->mds.mdd_raid6.sr6_strip_bits =
	    sr_validate_stripsize(sd->sd_meta->ssdi.ssd_strip_size);
	if (sd->mds.mdd_raid6.sr6_strip_bits == -1)
		goto bad;

d403 1
a403 1
 *	        SR_CCBF_FREEBUF, qbuf, NULL, 0);
d421 1
a421 1
	void		        *pbuf, *data, *qbuf;
@


1.40
log
@Properly release ccbs when restarting a work unit.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.39 2013/03/29 13:05:47 jsing Exp $ */
d433 1
a433 1
		if ((wu_r = scsi_io_get(&sd->sd_iopool, SCSI_NOSLEEP)) == NULL){
d692 1
a692 1
		scsi_io_put(&sd->sd_iopool, wu_r);
d807 1
a807 3
			scsi_io_put(&sd->sd_iopool, wu);
			if (sd->sd_sync && sd->sd_wu_pending == 0)
				wakeup(sd);
@


1.39
log
@Convert RAID 4/5/6 to new ccb completion code.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.38 2013/03/29 12:00:59 jsing Exp $ */
d767 1
a767 2
			sr_ccb_put(ccb);
			TAILQ_INIT(&wu->swu_ccb);
@


1.38
log
@Decouple wakeups on work unit completion from the type of I/O being
performed.

ok krw@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.37 2013/03/29 11:46:45 jsing Exp $ */
d724 1
a724 1
	DNPRINTF(SR_D_INTR, "%s: sr_intr bp %p xs %p\n",
d727 1
a727 4
	DNPRINTF(SR_D_INTR, "%s: sr_intr: b_bcount: %d b_resid: %d"
	    " b_flags: 0x%0x block: %lld target: %d\n", DEVNAME(sc),
	    ccb->ccb_buf.b_bcount, ccb->ccb_buf.b_resid, ccb->ccb_buf.b_flags,
	    ccb->ccb_buf.b_blkno, ccb->ccb_target);
d729 1
a729 1
	s = splbio();
d731 12
a742 28
	if (ccb->ccb_buf.b_flags & B_ERROR) {
		DNPRINTF(SR_D_INTR, "%s: i/o error on block %lld target: %d\n",
		    DEVNAME(sc), ccb->ccb_buf.b_blkno, ccb->ccb_target);
		printf("io error: disk %x\n", ccb->ccb_target);
		wu->swu_ios_failed++;
		ccb->ccb_state = SR_CCB_FAILED;
		if (ccb->ccb_target != -1)
			sd->sd_set_chunk_state(sd, ccb->ccb_target,
			    BIOC_SDOFFLINE);
		else
			panic("%s: invalid target on wu: %p", DEVNAME(sc), wu);
	} else {
		ccb->ccb_state = SR_CCB_OK;
		wu->swu_ios_succeeded++;

		/* XOR data to result */
		if (pq) {
			if (pq->pbuf)
				/* Calculate xor-parity */
				sr_raid6_xorp(pq->pbuf, ccb->ccb_buf.b_data,
				    ccb->ccb_buf.b_bcount);
			if (pq->qbuf)
				/* Calculate q-parity */
				sr_raid6_xorq(pq->qbuf, ccb->ccb_buf.b_data,
				    ccb->ccb_buf.b_bcount, pq->gn);
			free(pq, M_DEVBUF);
			ccb->ccb_opaque = NULL;
		}
d745 1
a745 1
	/* free allocated data buffer */
a749 1
	wu->swu_ios_complete++;
@


1.37
log
@sd_wu_pending is only decremented when scsi_done() or scsi_io_put() are
called. As a result, factor out the the sd_sync check/wakeup code and move
it to after the scsi_done() call in sr_scsi_done(). Perform the same
sd_sync check/wakeup after scsi_io_put() calls (including the addition of
some that were previously missed).

ok krw@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.36 2013/03/27 14:30:11 jsing Exp $ */
d822 5
a826 7
	if (wu->swu_flags & SR_WUF_REBUILD) {
		/* XXX - decouple from SCSI_DATA_OUT. */
		if (wu->swu_xs->flags & SCSI_DATA_OUT) {
			wu->swu_flags |= SR_WUF_REBUILDIOCOMP;
			wakeup(wu);
		}
	} else {
@


1.36
log
@Rewrite the work unit handling code in the RAID 1/4/5/6 interrupt handlers.
This simplifies the code and will allow for easier conversion to the workq
based work unit completion routines. It also ensures that work units are
always removed from the pending queue and that colliders are started, even
in the event of an I/O failure.

ok krw@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.35 2013/03/25 16:01:49 jsing Exp $ */
d829 5
a833 1
		if (xs != NULL)
d835 1
a835 2
		else
			scsi_io_put(&sd->sd_iopool, wu);
a836 3

	if (sd->sd_sync && sd->sd_wu_pending == 0)
		wakeup(sd);
@


1.35
log
@Factor out the code that is used to recreate work units - one copy of the
code is sufficient.

ok krw@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.34 2013/03/02 12:50:01 jsing Exp $ */
d722 1
a722 1
	int			s, pend;
d775 2
a776 1
	if (wu->swu_ios_complete >= wu->swu_io_count) {
d778 2
a779 20
		/* if all ios failed, retry reads and give up on writes */
		if (wu->swu_ios_failed == wu->swu_ios_complete) {
			if (xs->flags & SCSI_DATA_IN) {
				printf("%s: retrying read on block %lld\n",
				    DEVNAME(sc), ccb->ccb_buf.b_blkno);
				sr_ccb_put(ccb);
				TAILQ_INIT(&wu->swu_ccb);
				wu->swu_state = SR_WU_RESTART;
				if (sd->sd_scsi_rw(wu))
					goto bad;
				else
					goto retry;
			} else {
				printf("%s: permanently fail write on block "
				    "%lld\n", DEVNAME(sc),
				    ccb->ccb_buf.b_blkno);
				xs->error = XS_DRIVER_STUFFUP;
				goto bad;
			}
		}
d781 16
a796 25
		if (xs != NULL)
			xs->error = XS_NOERROR;

		pend = 0;
		TAILQ_FOREACH(wup, &sd->sd_wu_pendq, swu_link) {
			if (wu == wup) {
				/* wu on pendq, remove */
				TAILQ_REMOVE(&sd->sd_wu_pendq, wu, swu_link);
				pend = 1;

				if (wu->swu_collider) {
					if (wu->swu_ios_failed)
						/* toss all ccbs and recreate */
						sr_raid_recreate_wu(wu->swu_collider);

					/* restart deferred wu */
					wu->swu_collider->swu_state =
					    SR_WU_INPROGRESS;
					TAILQ_REMOVE(&sd->sd_wu_defq,
					    wu->swu_collider, swu_link);
					if (sr_failio(wu->swu_collider) == 0)
						sr_raid_startwu(wu->swu_collider);
				}
				break;
			}
d798 1
d800 3
a802 15
		if (!pend)
			printf("%s: wu: %p not on pending queue\n",
			    DEVNAME(sc), wu);

		if (wu->swu_flags & SR_WUF_REBUILD) {
			if (wu->swu_xs->flags & SCSI_DATA_OUT) {
				wu->swu_flags |= SR_WUF_REBUILDIOCOMP;
				wakeup(wu);
			}
		} else {
			if (xs != NULL)
				sr_scsi_done(sd, xs);
			else
				scsi_io_put(&sd->sd_iopool, wu);
		}
d804 16
a819 2
		if (sd->sd_sync && sd->sd_wu_pending == 0)
			wakeup(sd);
a821 5
retry:
	splx(s);
	return;
bad:
	xs->error = XS_DRIVER_STUFFUP;
d823 5
a827 2
		wu->swu_flags |= SR_WUF_REBUILDIOCOMP;
		wakeup(wu);
d829 4
a832 1
		sr_scsi_done(sd, xs);
d835 4
@


1.34
log
@sr_alloc_resources() and sr_free_resources() can never be called without
a valid struct sr_discipline. Remove redundant NULL pointer checks.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.33 2013/01/16 09:21:50 jsing Exp $ */
a60 1
void	sr_raid6_recreate_wu(struct sr_workunit *);
d811 1
a811 1
						sr_raid6_recreate_wu(wu->swu_collider);
a857 21
}

void
sr_raid6_recreate_wu(struct sr_workunit *wu)
{
	struct sr_discipline	*sd = wu->swu_dis;
	struct sr_workunit	*wup = wu;

	do {
		DNPRINTF(SR_D_INTR, "%s: sr_raid6_recreate_wu: %p\n", wup);

		/* toss all ccbs */
		sr_wu_release_ccbs(wup);

		/* recreate ccbs */
		wup->swu_state = SR_WU_REQUEUE;
		if (sd->sd_scsi_rw(wup))
			panic("could not requeue io");

		wup = wup->swu_collider;
	} while (wup);
@


1.33
log
@Consistently call sr_scsi_done instead of scsi_done.

ok krw@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.32 2013/01/16 07:06:29 jsing Exp $ */
a163 3
	if (!sd)
		return (rv);

a186 3

	if (!sd)
		return (rv);
@


1.32
log
@Add a new capability flag to identify disciplines where read failures are
not necessarily terminal (i.e. we have redundancy).

ok krw@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.31 2013/01/16 06:42:22 jsing Exp $ */
d843 1
a843 1
				scsi_done(xs);
d861 1
a861 1
		scsi_done(xs);
@


1.31
log
@Set resid to zero if the scsi transfer completed without error.

ok krw@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.30 2013/01/16 06:29:14 jsing Exp $ */
d103 2
a104 1
	sd->sd_capabilities = SR_CAP_SYSTEM_DISK | SR_CAP_AUTO_ASSEMBLE;
@


1.30
log
@Factor out code used to release ccbs from a workunit.

ok krw@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.29 2013/01/15 09:28:29 jsing Exp $ */
d804 1
a804 1
		if (xs != NULL) {
a805 2
			xs->resid = 0;
		}
@


1.29
log
@Always initialise the discipline name, not just when we are doing a create.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.28 2013/01/15 04:03:01 jsing Exp $ */
a872 1
	struct sr_ccb		*ccb;
d878 1
a878 5
		while ((ccb = TAILQ_FIRST(&wup->swu_ccb)) != NULL) {
			TAILQ_REMOVE(&wup->swu_ccb, ccb, ccb_link);
			sr_ccb_put(ccb);
		}
		TAILQ_INIT(&wup->swu_ccb);
@


1.28
log
@Keep a function pointer to the per-discipline I/O interrupt handler in the
discipline data structure. To be used with an upcoming diff.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.27 2012/12/31 10:07:51 miod Exp $ */
a96 1

d102 1
a124 2

	strlcpy(sd->sd_name, "RAID 6", sizeof(sd->sd_name));
@


1.27
log
@Spell `calculation' correctly.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.26 2012/10/08 14:22:41 jsing Exp $ */
d113 1
@


1.26
log
@Provide a mechanism for the kernel to pass data through to the discipline
during volume assembly.
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.23 2011/04/08 04:30:11 jordan Exp $ */
d619 1
a619 1
			/* Calulate P = Dn; Q = gn * Dn */
@


1.25
log
@Initialise discipline function pointers with defaults and only override
those that are needed by a specific discipline.
@
text
@d55 1
a55 1
	    int);
d144 1
a144 1
    int no_chunk)
@


1.24
log
@Speedup XORP/XORQ operations in RAID6, do 32-bits at a time
@
text
@d98 1
a98 1
	/* Initialize GF256 tables */
d101 1
a101 1
	/* fill out discipline members. */
d106 3
a108 1
	/* setup discipline pointers. */
a109 2
	sd->sd_assemble = sr_raid6_assemble;
	sd->sd_alloc_resources = sr_raid6_alloc_resources;
d111 1
a111 7
	sd->sd_start_discipline = NULL;
	sd->sd_scsi_inquiry = sr_raid_inquiry;
	sd->sd_scsi_read_cap = sr_raid_read_cap;
	sd->sd_scsi_tur = sr_raid_tur;
	sd->sd_scsi_req_sense = sr_raid_request_sense;
	sd->sd_scsi_start_stop = sr_raid_start_stop;
	sd->sd_scsi_sync = sr_raid_sync;
a114 1
	sd->sd_openings = sr_raid6_openings;
@


1.23
log
@Remove unused code/array
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.22 2011/04/08 00:12:54 jordan Exp $ */
d989 1
a989 1
	uint8_t *pbuf = p, *data = d;
d991 1
d993 1
a993 1
		pbuf[len] ^= data[len];
d999 2
a1000 2
	uint8_t		*qbuf = q, *data = d;
	uint8_t		*gn_map = gf_map[gn];
d1002 8
a1009 4
	/* Have to do this a byte at a time */
	/* Faster multiply.. gn is always constant */
	while (len--)
		qbuf[len] ^= gn_map[data[len]];
@


1.22
log
@Fix raidp/raid6 to work with new iopool code, needed to swap wu's
Update to use dma_malloc for I/O blocks
ok marco@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.21 2011/04/06 02:45:55 marco Exp $ */
a86 35
#define M_FAIL 0x00

#define M_RX   0x01
#define M_RXP  0x02
#define M_RXQ  0x03
#define M_RXY  0x04
#define M_RFLG 0x0F

#define M_WXPQ 0x10
#define M_WXY  0x20
#define M_WPQ  0x30
#define M_WFLG 0xF0

/* Mapping of Failure Flags to Read/Write state */
uint8_t sr_rwmode[16] = {
	[SR_FAILX+SR_FAILY+SR_FAILP] = M_FAIL,
	[SR_FAILX+SR_FAILY+SR_FAILQ] = M_FAIL,
	[SR_FAILX+SR_FAILP+SR_FAILQ] = M_FAIL,
	[SR_FAILY+SR_FAILP+SR_FAILQ] = M_FAIL,
	[SR_FAILX+SR_FAILY+SR_FAILP+SR_FAILQ] = M_FAIL,

	[SR_NOFAIL]         = M_RX | M_WXPQ,
	[SR_FAILY]          = M_RX | M_WXPQ,
	[SR_FAILP]          = M_RX | M_WXPQ,
	[SR_FAILQ]          = M_RX | M_WXPQ,
	[SR_FAILY+SR_FAILP] = M_RX | M_WXPQ,
	[SR_FAILY+SR_FAILQ] = M_RX | M_WXPQ,
	[SR_FAILP+SR_FAILQ] = M_RX | M_WXPQ,

	[SR_FAILX]          = M_RXQ | M_WPQ,
	[SR_FAILX+SR_FAILQ] = M_RXQ | M_WPQ,
	[SR_FAILX+SR_FAILP] = M_RXP | M_WPQ,
	[SR_FAILX+SR_FAILY] = M_RXY | M_WXY,
};

d426 1
a426 1
	int			s, fail, i, rwmode, gxinv, pxinv;
a444 1
	rwmode = (xs->flags & SCSI_DATA_IN) ? M_RFLG : M_WFLG;
@


1.21
log
@fix some spaces while looking for bigmem shiz
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.20 2011/04/05 19:52:02 krw Exp $ */
d74 1
a74 1
void	sr_put_block(struct sr_discipline *, void *);
d457 1
a457 1
	struct sr_workunit	*wu_w = NULL;
d483 2
a484 2
		if ((wu_w = scsi_io_get(&sd->sd_iopool, SCSI_NOSLEEP)) == NULL){
			printf("%s: can't get wu_w", DEVNAME(sd->sd_sc));
d669 1
a669 1
			if (sr_raid6_addio(wu, chunk, lba, length, NULL,
d675 1
a675 1
			if (sr_raid6_addio(wu, pchunk, lba, length, NULL,
d680 1
a680 1
			if (sr_raid6_addio(wu, qchunk, lba, length, NULL,
d685 1
a685 1
			if (sr_raid6_addio(wu_w, chunk, lba, length, data,
d690 1
a690 1
			if (sr_raid6_addio(wu_w, pchunk, lba, length, pbuf,
d695 1
a695 1
			if (sr_raid6_addio(wu_w, qchunk, lba, length, qbuf,
d707 1
a707 1
	if (wu_w) {
d709 2
a710 2
		wu_w->swu_blk_start = wu->swu_blk_start;
		wu_w->swu_blk_end = wu->swu_blk_end;
d712 5
a716 10
		/*
		 * put xs block in write request (scsi_done not called till
		 * write completes)
		 */
		wu_w->swu_xs = wu->swu_xs;
		wu->swu_xs = NULL;

		wu_w->swu_state = SR_WU_DEFERRED;
		wu->swu_collider = wu_w;
		TAILQ_INSERT_TAIL(&sd->sd_wu_defq, wu_w, swu_link);
d741 2
a742 2
	if (wu_w)
		scsi_io_put(&sd->sd_iopool, wu_w);
d816 1
a816 1
		sr_put_block(sd, ccb->ccb_buf.b_data);
d995 1
a995 1
		pqbuf = malloc(sizeof(struct sr_raid6_opaque), M_DEVBUF, M_CANFAIL);
d1080 1
a1080 1
	if ((gf_map[gn] = malloc(256, M_DEVBUF, M_CANFAIL)) == NULL)
@


1.20
log
@Iopoolification. Testing by marco@@.

ok dlg@@ marco@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.19 2010/08/07 03:50:01 krw Exp $ */
d69 1
a69 1
void 	sr_dump(void *, int);
d446 1
a446 1
 *   readq: sr_raid6_addio(i, lba, length, NULL, SCSI_DATA_IN, 
d499 1
a499 1
		/* map disk offset to parity/data drive */	
d513 1
a513 1
	
d543 1
a543 1
		if (xs->flags & SCSI_DATA_IN) {	
d562 1
a562 1
			
d565 1
a565 1
					if  (i == qchunk || i == pchunk || i == chunk) 
d568 1
a568 1
					if (sr_raid6_addio(wu, i, lba, 
d572 1
a572 1
					   	goto bad;
d586 1
a586 1
				if (sr_raid6_addio(wu, qchunk, lba, 
d590 1
a590 1
				    	goto bad;
d597 1
a597 1
				    	goto bad;
d615 1
a615 1
					    	goto bad;
d619 1
a619 1
				 *   Dx = Dz ^ P (same as RAID5) 
d622 1
a622 1
				    "regenerating Dx%s\n", chunk, 
d626 2
a627 2
 				 *   P:  sr_raid6_xorp(data, ---, length); 
 				 *   Dz: sr_raid6_xorp(data, ---, length); 
d633 1
a633 1
						if (sr_raid6_addio(wu, i, lba, 
d635 1
a635 1
						    SR_CCBF_FREEBUF, data, 
d637 1
a637 1
	 				    	    	goto bad;
d670 1
a670 1
				SCSI_DATA_IN, SR_CCBF_FREEBUF, pbuf, qbuf, 
d762 1
a762 1
	TAILQ_INSERT_TAIL(&sd->sd_wu_pendq, wu, swu_link);	
d947 1
a947 1
	struct sr_discipline 	*sd = wu->swu_dis;
@


1.19
log
@No "\n" needed at the end of panic() strings.

Bogus chunks pointed out by matthew@@ and miod@@. No cookies for
marco@@ and jasper@@.

ok deraadt@@ miod@@ matthew@@ jasper@@ macro@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.18 2010/07/02 09:20:26 jsing Exp $ */
d483 1
a483 1
		if ((wu_w = sr_wu_get(sd, 0)) == NULL) {
d747 1
a747 1
		sr_wu_put(wu_w);
a891 2
			/* do not change the order of these 2 functions */
			sr_wu_put(wu);
d894 2
a910 2
		/* do not change the order of these 2 functions */
		sr_wu_put(wu);
@


1.18
log
@Determine the data offset using a variable specified within the softraid
metadata. This allows us to implement seamless transitions from the
previous metadata version to the current version, avoiding the need to
recreate the softraid volume.

Joint work with marco@@ during c2k10.

ok marco@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.16 2010/03/26 11:20:34 jsing Exp $ */
d306 1
a306 1
		    "%d -> %d\n", DEVNAME(sd->sd_sc),
d436 1
a436 1
		panic("%s: %s: invalid volume state transition %d -> %d\n",
@


1.17
log
@make sure that buf's on the stack set the b_bq to NULL.
one memset -> bzero.

ok marco@@, jsing@@
@
text
@d494 1
a494 1
		    (SR_DATA_OFFSET << DEV_BSHIFT);
@


1.16
log
@Add storage for the boot block and boot loader to the softraid metadata.
Also add a new optional metadata type for boot data. This is the first
step (of many) towards being able to boot from softraid volumes.

WARNING: This version of the softraid metadata is not compatible with
previous versions. As a result, any softraid volumes created with older
kernels will not assemble. Data on existing softraid volumes should be
backed up before upgrading. The volume should then be recreated and the
data restored.

ok marco@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.14 2010/02/04 07:30:27 jordan Exp $ */
d992 1
@


1.15
log
@XY Failure reads no longer require temp buffer or WUF_FAIL
@
text
@d493 2
a494 2
		phys_offs = chunk_offs + strip_offs + 
		    ((SR_META_OFFSET + SR_META_SIZE) << DEV_BSHIFT);
@


1.14
log
@Added optimization for XY reads, requires only one temp buffer
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.13 2010/02/04 03:34:05 jordan Exp $ */
d461 1
a461 1
	int			s, fail, i, rwmode, gxinv;
a579 3
				pbuf = sr_get_block(sd, length);
				if (pbuf == NULL)
					goto bad;
d582 1
d592 1
a592 1
				/* read P */
d595 2
a596 2
				    SR_CCBF_FREEBUF, pbuf, 
				    NULL, 0))
d610 1
a610 1
					/* read Dz * gz */
d613 2
a614 2
					    SR_CCBF_FREEBUF, pbuf,
					    data, gf_mul(gf_pow[i], gxinv)))
a616 11

				/* run fake wu when read i/o is complete */
				if (wu_w == NULL && 
				    (wu_w = sr_wu_get(sd, 0)) == NULL)
					goto bad;

				wu_w->swu_flags |= SR_WUF_FAIL;
				if (sr_raid6_addio(wu_w, 0, 0, length, pbuf, 0,
				    SR_CCBF_FREEBUF, NULL, data,
				    gf_mul(gf_pow[fchunk], gxinv)))
					goto bad;
@


1.13
log
@Optimized failure handing for Read with X/P failures
Does not require additional temporary buffer
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.12 2010/01/20 19:55:15 jordan Exp $ */
d79 1
d461 1
a461 1
	int			s, fail, i, rwmode;
d554 2
d560 1
a560 1
				    gf_inv(gf_pow[chunk])))
d571 1
a571 1
					   data, gf_pow[i+255-chunk]))
a579 3
				qbuf = sr_get_block(sd, length);
				if (qbuf == NULL)
					goto bad;
d584 17
a606 1
				memset(data, 0, length);
d608 10
a617 22
					if (i == qchunk) {
						/* read Q */
						if (sr_raid6_addio(wu, i, lba, 
						    length,  NULL, SCSI_DATA_IN,
						    SR_CCBF_FREEBUF, qbuf, 
						    NULL, 0))
						    	goto bad;
					} else if (i == pchunk) {
						/* read P */
						if (sr_raid6_addio(wu, i, lba,
						    length,  NULL, SCSI_DATA_IN,
						    SR_CCBF_FREEBUF, pbuf, 
						    NULL, 0))
						    	goto bad;
					} else if (i != chunk) {
						/* read Dz * gz */
						if (sr_raid6_addio(wu, i, lba,
						    length, NULL, SCSI_DATA_IN,
						    SR_CCBF_FREEBUF, pbuf,
						    qbuf, gf_pow[i]))
						    	goto bad;
					}
d628 1
a628 5
				    gf_inv(gf_pow[255+chunk-fchunk] ^ 1)))
					goto bad;
				if (sr_raid6_addio(wu_w, 0, 0, length, qbuf, 0,
				    SR_CCBF_FREEBUF, NULL, data,
				    gf_inv(gf_pow[chunk] ^ gf_pow[fchunk])))
d1082 6
@


1.12
log
@Fix collider offsets to correct LBA.
Thanks to Niklas
ok @@marco
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.11 2010/01/09 23:15:06 krw Exp $ */
d553 5
a557 2
				qbuf = sr_get_block(sd, length);
				if (qbuf == NULL)
d559 5
d565 5
a569 21
				/* Calculate: Dx*gx = Q^(Dz*gz)
				 *   Q:  sr_raid6_xorp(data, --, length);
				 *   Dz: sr_raid6_xorq(data, --, length, gf_pow[i]);
				 */
				memset(data, 0, length);
				for (i = 0; i < no_chunk+2; i++) {
					if  (i == qchunk) {
						/* Read Q */
						if (sr_raid6_addio(wu, i, lba, 
						    length, NULL, SCSI_DATA_IN, 
						    SR_CCBF_FREEBUF, qbuf, 
						    NULL, 0))
						    	goto bad;
					} else if (i != chunk && i != pchunk) {
						/* Read Dz * gz */
						if (sr_raid6_addio(wu, i, lba, 
						   length, NULL, SCSI_DATA_IN,
						   SR_CCBF_FREEBUF, NULL,
						   qbuf, gf_pow[i]))
						   	goto bad;
					}
d572 1
a572 10
				/* run fake wu when read i/o is complete */
				if (wu_w == NULL && 
				    (wu_w = sr_wu_get(sd, 0)) == NULL)
					goto bad;

				wu_w->swu_flags |= SR_WUF_FAIL;
				if (sr_raid6_addio(wu_w, 0, 0, length, qbuf, 0,
				    SR_CCBF_FREEBUF, NULL, data,
				    gf_inv(gf_pow[chunk])))
					goto bad;
@


1.11
log
@Zap all setting of ITSDONE in drivers that don't look at it. Nobody
else cares so it's just noise. Drivers that actually look at ITSDONE
are unchanged.

ok marco@@ (for his files) dlg@@ beck@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.10 2009/12/15 13:19:37 jsing Exp $ */
d463 1
a463 1
	daddr64_t		strip_bits, length, strip_offs, datalen;
d473 1
d515 2
a516 2
			wu->swu_blk_start = chunk_offs >> DEV_BSHIFT;
		wu->swu_blk_end = ((chunk_offs + (no_chunk << strip_bits)) >> DEV_BSHIFT) - 1;
@


1.10
log
@Factor out discipline specific create/assemble code.

"in, in, in!" marco@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.8 2009/12/07 14:27:12 jsing Exp $ */
a884 1
			xs->flags |= ITSDONE;
a935 1
	xs->flags |= ITSDONE;
@


1.9
log
@Cleanup discipline initialisation.

ok marco@@
@
text
@d52 4
a137 1
	sd->sd_max_ccb_per_wu = max(6, 2 * sd->sd_meta->ssdi.ssd_chunk_no); /* only if stripsize <= MAXPHYS */
d141 2
d156 36
@


1.8
log
@Define discipline capabilities using a set of flags.

"shiny!!" marco@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.6 2009/08/26 20:14:44 jordan Exp $ */
d132 1
@


1.7
log
@Added mapping for failure flags for read/write mode (not yet used).
@
text
@d127 1
d132 1
a134 1
	sd->sd_rebuild = 0;
@


1.6
log
@Speedup on raid6 writes, precalculate xor lookup
ok marco@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.5 2009/08/12 22:01:15 jordan Exp $ */
d82 35
d417 1
a417 1
	int			s, fail, i;
d435 1
@


1.5
log
@Optimize Syndrome calculation, 30% speedup on writes
ok marco@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.4 2009/08/09 14:12:25 marco Exp $ */
d47 1
d74 1
d613 2
d950 3
d993 1
a993 1
	uint8_t		*gn_pow = gf_pow + gf_log[gn];
d998 1
a998 1
		qbuf[len] ^= gn_pow[gf_log[data[len]]];
d1023 16
@


1.4
log
@Switch softraid to vnodes to prevent bad things from happening when using
d_open/d_close.

tested by many, ok jsing, thib, krw
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.3 2009/08/06 22:39:40 jordan Exp $ */
d47 2
a48 1
uint8_t	gf_pow[512], gf_log[256];
a71 1
uint8_t	gf_mul(uint8_t, uint8_t);
d986 1
d989 1
d991 1
a991 1
		qbuf[len] ^= gf_mul(data[len], gn);
d1007 1
a1007 10
}

/* GF256 multiplication using exponent/logarithm table */
uint8_t
gf_mul(uint8_t a, uint8_t b)
{
	/* g^a * g^b = g^(a+b) */
	if (!a || !b)
		return (0);
	return gf_pow[gf_log[a] + gf_log[b]];
@


1.3
log
@Handle failed disk I/O for RAID6
RAID6 still disabled in softraid.c
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.2 2009/08/04 20:17:14 jordan Exp $ */
d939 3
a941 1
	ccb->ccb_buf.b_vp = NULL;
@


1.2
log
@Fix volume state transitions for RAID4/5/6
ok marco@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.1 2009/07/23 15:15:26 jordan Exp $ */
d65 1
d437 1
d439 20
a458 8
		/* Get P-fail flag */
		scp = sd->sd_vol.sv_chunks[pchunk];
		switch (scp->src_meta.scm_status) {
		case BIOC_SDOFFLINE:
		case BIOC_SDREBUILD:
		case BIOC_SDHOTSPARE:
			fail |= SR_FAILP;
			break;
a459 26

		/* Get Q-fail flag */
		scp = sd->sd_vol.sv_chunks[qchunk];
		switch (scp->src_meta.scm_status) {
		case BIOC_SDOFFLINE:
		case BIOC_SDREBUILD:
		case BIOC_SDHOTSPARE:
			fail |= SR_FAILQ;
			break;
		}

		/* Get disk-fail flag */	
		scp = sd->sd_vol.sv_chunks[chunk];
		switch (scp->src_meta.scm_status) {
		case BIOC_SDOFFLINE:
		case BIOC_SDREBUILD:
		case BIOC_SDHOTSPARE:
			fail |= SR_FAILX;

			/* Check for dual-drive failure */
			if (!(fail & (SR_FAILP|SR_FAILQ)) && 
			    (sd->sd_vol_status == BIOC_SVDEGRADED))
			    fail |= SR_FAILY;
			break;
		}

d461 1
a461 2
			switch (fail) {
			case SR_NOFAIL:
d466 1
a466 23
				break;
			case SR_FAILX:
			case SR_FAILX+SR_FAILQ:
				/* Dx, (Q) failed: Dx = Dz ^ P (same as RAID5) */
				printf("Disk %llx offline, "
				    "regenerating Dx+Q\n", chunk);

				/* Calculate: Dx = P^Dz
 				 *   P:  sr_raid6_xorp(data, ---, length); 
 				 *   Dz: sr_raid6_xorp(data, ---, length); 
				 */
				memset(data, 0, length);
				for (i = 0; i < no_chunk+2; i++) {
					if (i != chunk && i != qchunk) {
						/* Read Dz */
						if (sr_raid6_addio(wu, i, lba, length,
					    	    NULL, SCSI_DATA_IN, SR_CCBF_FREEBUF, 
					    	    data, NULL, 0))
	 				    	    goto bad;
					}
				}
				break;
			case SR_FAILX+SR_FAILP:
d471 2
a472 2
				pbuf = sr_get_block(sd, length);
				if (pbuf == NULL)
d483 5
a487 4
						if (sr_raid6_addio(wu, i, lba, length,
						    NULL, SCSI_DATA_IN, SR_CCBF_FREEBUF,
						    pbuf, NULL, 0))
						    goto bad;
d490 5
a494 4
						if (sr_raid6_addio(wu, i, lba, length,
						   NULL, SCSI_DATA_IN, SR_CCBF_FREEBUF,
						   NULL, pbuf, gf_pow[i]))
						   goto bad;
d498 4
a501 6
				/* XXX: bag of fail */
				wu->swu_flags |= SR_WUF_FAIL;
				sr_raid_startwu(wu);
				while ((wu->swu_flags & SR_WUF_FAILIOCOMP) == 0) {
					tsleep(wu, PRIBIO, "sr_getdata", 0);
				}
d503 6
a508 10
				/* On completion, pbuf = Dx*gx */
				sr_raid6_xorq(data, pbuf, length, gf_inv(gf_pow[chunk]));
				sr_put_block(sd, pbuf);

				sr_wu_put(wu);
				scsi_done(xs);
				return(0);

				break;
			case SR_FAILX+SR_FAILY:
a509 7

				/* cheat.. get other failed drive */
				for (fchunk=0; fchunk<no_chunk+2; fchunk++) {
					if (fchunk != chunk && fchunk != qchunk && fchunk != pchunk)
						break;
				}

d529 5
a533 4
						if (sr_raid6_addio(wu, i, lba, length,
						    NULL, SCSI_DATA_IN, SR_CCBF_FREEBUF,
						    qbuf, NULL, 0))
						    goto bad;
d536 5
a540 4
						if (sr_raid6_addio(wu, i, lba, length,
						    NULL, SCSI_DATA_IN, SR_CCBF_FREEBUF,
						    pbuf, NULL, 0))
						    goto bad;
d543 5
a547 4
						if (sr_raid6_addio(wu, i, lba, length,
						    NULL, SCSI_DATA_IN, SR_CCBF_FREEBUF,
						    pbuf, qbuf, gf_pow[i]))
						    goto bad;
d551 4
d556 31
a586 5
				/* XXX: bag of fail */
				wu->swu_flags |= SR_WUF_FAIL;
				sr_raid_startwu(wu);
				while ((wu->swu_flags & SR_WUF_FAILIOCOMP) == 0) {
					tsleep(wu, PRIBIO, "sr_getdata", 0);
d589 1
a589 18
				/* On completion, pbuf = Dx ^ Dy; qbuf = Dx*gx ^ Dy*gy */
				sr_raid6_xorq(data, qbuf, length, 
				    gf_inv(gf_pow[chunk] ^ gf_pow[fchunk]));
				sr_raid6_xorq(data, pbuf, length,
				    gf_inv(gf_pow[255+chunk-fchunk] ^ 1));	// Dx

				sr_put_block(sd, pbuf);
				sr_put_block(sd, qbuf);

				sr_wu_put(wu);
				scsi_done(xs);
				return(0);

				break;
			default:
				printf("%s: is offline, can't read\n",
				    DEVNAME(sd->sd_sc));
				goto bad;
d593 1
a593 1
			if (scp->src_meta.scm_status == BIOC_SDOFFLINE)
d697 17
d822 2
a823 1
					sr_raid_startwu(wu->swu_collider);
d833 1
a833 5
		if (wu->swu_flags & SR_WUF_FAIL) {
			wu->swu_flags |= SR_WUF_FAILIOCOMP;
			wakeup(wu);
		}
		else if (wu->swu_flags & SR_WUF_REBUILD) {
d974 1
a974 1
	uint32_t	*pbuf = p, *data = d;
a975 2
	/* Faster, X bytes at a time */
	len >>= 4;
@


1.1
log
@Adding disabled framework for RAID6
ok marco@@
@
text
@d1 1
a1 1
/* $OpenBSD: softraid_raid6.c,v 1.5 2009/06/17 22:45:41 jordan Exp $ */
a270 2
	else if (states[BIOC_SDOFFLINE] == nd - 2)
		new_state = BIOC_SVDEGRADED;
d275 2
@

