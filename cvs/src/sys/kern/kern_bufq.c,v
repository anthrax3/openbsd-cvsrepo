head	1.31;
access;
symbols
	OPENBSD_6_0:1.31.0.4
	OPENBSD_6_0_BASE:1.31
	OPENBSD_5_9:1.31.0.2
	OPENBSD_5_9_BASE:1.31
	OPENBSD_5_8:1.30.0.4
	OPENBSD_5_8_BASE:1.30
	OPENBSD_5_7:1.29.0.2
	OPENBSD_5_7_BASE:1.29
	OPENBSD_5_6:1.28.0.4
	OPENBSD_5_6_BASE:1.28
	OPENBSD_5_5:1.26.0.4
	OPENBSD_5_5_BASE:1.26
	OPENBSD_5_4:1.25.0.2
	OPENBSD_5_4_BASE:1.25
	OPENBSD_5_3:1.23.0.2
	OPENBSD_5_3_BASE:1.23
	OPENBSD_5_2:1.19.0.8
	OPENBSD_5_2_BASE:1.19
	OPENBSD_5_1_BASE:1.19
	OPENBSD_5_1:1.19.0.6
	OPENBSD_5_0:1.19.0.4
	OPENBSD_5_0_BASE:1.19
	OPENBSD_4_9:1.19.0.2
	OPENBSD_4_9_BASE:1.19
	OPENBSD_4_8:1.14.0.2
	OPENBSD_4_8_BASE:1.14;
locks; strict;
comment	@ * @;


1.31
date	2015.08.28.00.03.53;	author deraadt;	state Exp;
branches;
next	1.30;
commitid	NdgfPIGUgJxQPnT7;

1.30
date	2015.03.14.03.38.50;	author jsg;	state Exp;
branches;
next	1.29;
commitid	p4LJxGKbi0BU2cG6;

1.29
date	2015.01.09.05.04.22;	author tedu;	state Exp;
branches;
next	1.28;
commitid	9zgEJHeOLE2yUxI8;

1.28
date	2014.07.12.18.43.32;	author tedu;	state Exp;
branches;
next	1.27;
commitid	QlVV51SZgNFxsXxC;

1.27
date	2014.06.27.16.38.03;	author miod;	state Exp;
branches;
next	1.26;
commitid	6zz73J4UJPYkT4rZ;

1.26
date	2013.11.20.23.52.42;	author dlg;	state Exp;
branches;
next	1.25;

1.25
date	2013.04.10.01.35.55;	author guenther;	state Exp;
branches;
next	1.24;

1.24
date	2013.03.18.22.13.04;	author tedu;	state Exp;
branches;
next	1.23;

1.23
date	2012.10.17.23.58.25;	author beck;	state Exp;
branches;
next	1.22;

1.22
date	2012.10.09.16.44.15;	author beck;	state Exp;
branches;
next	1.21;

1.21
date	2012.10.09.15.36.50;	author beck;	state Exp;
branches;
next	1.20;

1.20
date	2012.10.09.15.12.15;	author beck;	state Exp;
branches;
next	1.19;

1.19
date	2010.09.03.10.51.53;	author dlg;	state Exp;
branches;
next	1.18;

1.18
date	2010.09.02.07.05.39;	author matthew;	state Exp;
branches;
next	1.17;

1.17
date	2010.09.01.19.30.59;	author kettenis;	state Exp;
branches;
next	1.16;

1.16
date	2010.09.01.19.23.05;	author kettenis;	state Exp;
branches;
next	1.15;

1.15
date	2010.09.01.01.38.12;	author dlg;	state Exp;
branches;
next	1.14;

1.14
date	2010.07.19.21.39.15;	author kettenis;	state Exp;
branches;
next	1.13;

1.13
date	2010.07.08.23.18.55;	author dlg;	state Exp;
branches;
next	1.12;

1.12
date	2010.07.07.10.50.50;	author dlg;	state Exp;
branches;
next	1.11;

1.11
date	2010.06.30.02.29.18;	author matthew;	state Exp;
branches;
next	1.10;

1.10
date	2010.06.30.02.26.58;	author matthew;	state Exp;
branches;
next	1.9;

1.9
date	2010.06.29.18.52.20;	author kettenis;	state Exp;
branches;
next	1.8;

1.8
date	2010.06.27.22.05.28;	author thib;	state Exp;
branches;
next	1.7;

1.7
date	2010.06.27.04.29.31;	author kettenis;	state Exp;
branches;
next	1.6;

1.6
date	2010.06.21.07.01.51;	author thib;	state Exp;
branches;
next	1.5;

1.5
date	2010.05.30.21.23.44;	author krw;	state Exp;
branches;
next	1.4;

1.4
date	2010.05.26.16.38.20;	author thib;	state Exp;
branches;
next	1.3;

1.3
date	2009.06.17.01.30.30;	author thib;	state dead;
branches;
next	1.2;

1.2
date	2009.06.04.19.16.13;	author thib;	state Exp;
branches;
next	1.1;

1.1
date	2009.06.03.22.09.30;	author thib;	state Exp;
branches;
next	;


desc
@@


1.31
log
@fairly simple sizes for free(); ok tedu
@
text
@/*	$OpenBSD: kern_bufq.c,v 1.30 2015/03/14 03:38:50 jsg Exp $	*/
/*
 * Copyright (c) 2010 Thordur I. Bjornsson <thib@@openbsd.org>
 * Copyright (c) 2010 David Gwynne <dlg@@openbsd.org>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/kernel.h>
#include <sys/malloc.h>
#include <sys/mount.h>
#include <sys/mutex.h>
#include <sys/buf.h>
#include <sys/errno.h>
#include <sys/queue.h>

SLIST_HEAD(, bufq)	bufqs = SLIST_HEAD_INITIALIZER(bufqs);
struct mutex		bufqs_mtx = MUTEX_INITIALIZER(IPL_NONE);
int			bufqs_stop;

struct bufq_impl {
	void		*(*impl_create)(void);
	void		 (*impl_destroy)(void *);

	void		 (*impl_queue)(void *, struct buf *);
	struct buf	*(*impl_dequeue)(void *);
	void		 (*impl_requeue)(void *, struct buf *);
	int		 (*impl_peek)(void *);
};

void		*bufq_fifo_create(void);
void		 bufq_fifo_destroy(void *);
void		 bufq_fifo_queue(void *, struct buf *);
struct buf	*bufq_fifo_dequeue(void *);
void		 bufq_fifo_requeue(void *, struct buf *);
int		 bufq_fifo_peek(void *);

void		*bufq_nscan_create(void);
void		 bufq_nscan_destroy(void *);
void		 bufq_nscan_queue(void *, struct buf *);
struct buf	*bufq_nscan_dequeue(void *);
void		 bufq_nscan_requeue(void *, struct buf *);
int		 bufq_nscan_peek(void *);

const struct bufq_impl bufq_impls[BUFQ_HOWMANY] = {
	{
		bufq_fifo_create,
		bufq_fifo_destroy,
		bufq_fifo_queue,
		bufq_fifo_dequeue,
		bufq_fifo_requeue,
		bufq_fifo_peek
	},
	{
		bufq_nscan_create,
		bufq_nscan_destroy,
		bufq_nscan_queue,
		bufq_nscan_dequeue,
		bufq_nscan_requeue,
		bufq_nscan_peek
	}
};

int
bufq_init(struct bufq *bq, int type)
{
	u_int hi = BUFQ_HI, low = BUFQ_LOW;

	if (type > BUFQ_HOWMANY)
		panic("bufq_init: type %i unknown", type);

	/*
	 * Ensure that writes can't consume the entire amount of kva
	 * available the buffer cache if we only have a limited amount
	 * of kva available to us.
	 */
	if (hi >= (bcstats.kvaslots / 16)) {
		hi = bcstats.kvaslots / 16;
		if (hi < 2)
			hi = 2;
		low = hi / 2;
	}

	mtx_init(&bq->bufq_mtx, IPL_BIO);
	bq->bufq_hi = hi;
	bq->bufq_low = low;
	bq->bufq_type = type;
	bq->bufq_impl = &bufq_impls[type];
	bq->bufq_data = bq->bufq_impl->impl_create();
	if (bq->bufq_data == NULL) {
		/*
		 * we should actually return failure so disks attaching after
		 * boot in low memory situations dont panic the system.
		 */
		panic("bufq init fail");
	}

	mtx_enter(&bufqs_mtx);
	while (bufqs_stop) {
		msleep(&bufqs_stop, &bufqs_mtx, PRIBIO, "bqinit", 0);
	}
	SLIST_INSERT_HEAD(&bufqs, bq, bufq_entries);
	mtx_leave(&bufqs_mtx);

	return (0);
}

int
bufq_switch(struct bufq *bq, int type)
{
	void		*data;
	void		*odata;
	int		otype;
	struct buf	*bp;
	int		ret;

	mtx_enter(&bq->bufq_mtx);
	ret = (bq->bufq_type == type);
	mtx_leave(&bq->bufq_mtx);
	if (ret)
		return (0);

	data = bufq_impls[type].impl_create();
	if (data == NULL)
		return (ENOMEM);

	mtx_enter(&bq->bufq_mtx);
	if (bq->bufq_type != type) { /* might have changed during create */
		odata = bq->bufq_data;
		otype = bq->bufq_type;

		while ((bp = bufq_impls[otype].impl_dequeue(odata)) != NULL)
			bufq_impls[type].impl_queue(data, bp);

		bq->bufq_data = data;
		bq->bufq_type = type;
		bq->bufq_impl = &bufq_impls[type];
	} else {
		otype = type;
		odata = data;
	}
	mtx_leave(&bq->bufq_mtx);

	bufq_impls[otype].impl_destroy(odata);

	return (0);
}

void
bufq_destroy(struct bufq *bq)
{
	bufq_drain(bq);

	bq->bufq_impl->impl_destroy(bq->bufq_data);
	bq->bufq_data = NULL;

	mtx_enter(&bufqs_mtx);
	while (bufqs_stop) {
		msleep(&bufqs_stop, &bufqs_mtx, PRIBIO, "bqdest", 0);
	}
	SLIST_REMOVE(&bufqs, bq, bufq, bufq_entries);
	mtx_leave(&bufqs_mtx);
}


void
bufq_queue(struct bufq *bq, struct buf *bp)
{
	mtx_enter(&bq->bufq_mtx);
	while (bq->bufq_stop) {
		msleep(&bq->bufq_stop, &bq->bufq_mtx, PRIBIO, "bqqueue", 0);
	}

	bp->b_bq = bq;
	bq->bufq_outstanding++;
	bq->bufq_impl->impl_queue(bq->bufq_data, bp);
	mtx_leave(&bq->bufq_mtx);
}

struct buf *
bufq_dequeue(struct bufq *bq)
{
	struct buf	*bp;

	mtx_enter(&bq->bufq_mtx);
	bp = bq->bufq_impl->impl_dequeue(bq->bufq_data);
	mtx_leave(&bq->bufq_mtx);

	return (bp);
}

void
bufq_requeue(struct bufq *bq, struct buf *bp)
{
	mtx_enter(&bq->bufq_mtx);
	bq->bufq_impl->impl_requeue(bq->bufq_data, bp);
	mtx_leave(&bq->bufq_mtx);
}

int
bufq_peek(struct bufq *bq)
{
	int		rv;

	mtx_enter(&bq->bufq_mtx);
	rv = bq->bufq_impl->impl_peek(bq->bufq_data);
	mtx_leave(&bq->bufq_mtx);

	return (rv);
}

void
bufq_drain(struct bufq *bq)
{
	struct buf	*bp;
	int		 s;

	while ((bp = bufq_dequeue(bq)) != NULL) {
		bp->b_error = ENXIO;
		bp->b_flags |= B_ERROR;
		s = splbio();
		biodone(bp);
		splx(s);
	}
}

void
bufq_wait(struct bufq *bq)
{
	if (bq->bufq_hi) {
		assertwaitok();
		mtx_enter(&bq->bufq_mtx);
		while (bq->bufq_outstanding >= bq->bufq_hi) {
			bq->bufq_waiting++;
			msleep(&bq->bufq_waiting, &bq->bufq_mtx,
			    PRIBIO, "bqwait", 0);
			bq->bufq_waiting--;
		}
		mtx_leave(&bq->bufq_mtx);
	}
}

void
bufq_done(struct bufq *bq, struct buf *bp)
{
	mtx_enter(&bq->bufq_mtx);
	KASSERT(bq->bufq_outstanding > 0);
	bq->bufq_outstanding--;
	if (bq->bufq_stop && bq->bufq_outstanding == 0)
		wakeup(&bq->bufq_outstanding);
	if (bq->bufq_waiting && bq->bufq_outstanding < bq->bufq_low)
		wakeup(&bq->bufq_waiting);
	mtx_leave(&bq->bufq_mtx);
	bp->b_bq = NULL;
}

void
bufq_quiesce(void)
{
	struct bufq		*bq;

	mtx_enter(&bufqs_mtx);
	bufqs_stop = 1;
	mtx_leave(&bufqs_mtx);
	/*
	 * We can safely walk the list since it can't be modified as
	 * long as bufqs_stop is non-zero.
	 */
	SLIST_FOREACH(bq, &bufqs, bufq_entries) {
		mtx_enter(&bq->bufq_mtx);
		bq->bufq_stop = 1;
		while (bq->bufq_outstanding) {
			msleep(&bq->bufq_outstanding, &bq->bufq_mtx,
			    PRIBIO, "bqquies", 0);
		}
		mtx_leave(&bq->bufq_mtx);
	}
}

void
bufq_restart(void)
{
	struct bufq		*bq;

	mtx_enter(&bufqs_mtx);
	SLIST_FOREACH(bq, &bufqs, bufq_entries) {
		mtx_enter(&bq->bufq_mtx);
		bq->bufq_stop = 0;
		wakeup(&bq->bufq_stop);
		mtx_leave(&bq->bufq_mtx);
	}
	bufqs_stop = 0;
	wakeup(&bufqs_stop);
	mtx_leave(&bufqs_mtx);
}


/*
 * fifo implementation
 */

void *
bufq_fifo_create(void)
{
	struct bufq_fifo_head	*head;

	head = malloc(sizeof(*head), M_DEVBUF, M_NOWAIT | M_ZERO);
	if (head == NULL)
		return (NULL);

	SIMPLEQ_INIT(head);

	return (head);
}

void
bufq_fifo_destroy(void *data)
{
	struct bufq_fifo_head	*head = data;
	
	free(head, M_DEVBUF, sizeof(*head));
}

void
bufq_fifo_queue(void *data, struct buf *bp)
{
	struct bufq_fifo_head	*head = data;

	SIMPLEQ_INSERT_TAIL(head, bp, b_bufq.bufq_data_fifo.bqf_entries);
}

struct buf *
bufq_fifo_dequeue(void *data)
{
	struct bufq_fifo_head	*head = data;
	struct buf		*bp;

	bp = SIMPLEQ_FIRST(head);
	if (bp != NULL)
		SIMPLEQ_REMOVE_HEAD(head, b_bufq.bufq_data_fifo.bqf_entries);

	return (bp);
}

void
bufq_fifo_requeue(void *data, struct buf *bp)
{
	struct bufq_fifo_head	*head = data;

	SIMPLEQ_INSERT_HEAD(head, bp, b_bufq.bufq_data_fifo.bqf_entries);
}

int
bufq_fifo_peek(void *data)
{
	struct bufq_fifo_head	*head = data;

	return (SIMPLEQ_FIRST(head) != NULL);
}

/*
 * nscan implementation
 */

#define BUF_INORDER(ba, bb) ((ba)->b_blkno < (bb)->b_blkno)

#define dsentries b_bufq.bufq_data_nscan.bqf_entries

struct bufq_nscan_data {
	struct bufq_nscan_head sorted;
	struct bufq_nscan_head fifo;
	int leftoverroom; /* Remaining number of buffer inserts allowed  */
};

void bufq_nscan_resort(struct bufq_nscan_data *data);
void bufq_simple_nscan(struct bufq_nscan_head *, struct buf *);

void
bufq_simple_nscan(struct bufq_nscan_head *head, struct buf *bp)
{
	struct buf *cur, *prev;

	prev = NULL;
	/*
	 * We look for the first slot where we would fit, then insert
	 * after the element we just passed.
	 */
	SIMPLEQ_FOREACH(cur, head, dsentries) {
		if (BUF_INORDER(bp, cur))
			break;
		prev = cur;
	}
	if (prev)
		SIMPLEQ_INSERT_AFTER(head, prev, bp, dsentries);
	else
		SIMPLEQ_INSERT_HEAD(head, bp, dsentries);

}

/*
 * Take N elements from the fifo queue and sort them
 */
void
bufq_nscan_resort(struct bufq_nscan_data *data)
{
	struct bufq_nscan_head *fifo = &data->fifo;
	struct bufq_nscan_head *sorted = &data->sorted;
	int count, segmentsize = BUFQ_NSCAN_N;
	struct buf *bp;

	for (count = 0; count < segmentsize; count++) {
		bp = SIMPLEQ_FIRST(fifo);
		if (!bp)
			break;
		SIMPLEQ_REMOVE_HEAD(fifo, dsentries);
		bufq_simple_nscan(sorted, bp);
	}
	data->leftoverroom = segmentsize - count;
}

void *
bufq_nscan_create(void)
{
	struct bufq_nscan_data *data;

	data = malloc(sizeof(*data), M_DEVBUF, M_NOWAIT | M_ZERO);
	if (!data)
		return NULL;
	SIMPLEQ_INIT(&data->sorted);
	SIMPLEQ_INIT(&data->fifo);

	return data;
}

void
bufq_nscan_destroy(void *vdata)
{
	struct bufq_nscan_data *data = vdata;

	free(data, M_DEVBUF, sizeof(*data));
}

void
bufq_nscan_queue(void *vdata, struct buf *bp)
{
	struct bufq_nscan_data *data = vdata;

	/*
	 * If the previous sorted segment was small, we will continue
	 * packing in bufs as long as they're in order.
	 */
	if (data->leftoverroom) {
		struct buf *next = SIMPLEQ_FIRST(&data->sorted);
		if (next && BUF_INORDER(next, bp)) {
			bufq_simple_nscan(&data->sorted, bp);
			data->leftoverroom--;
			return;
		}
	}

	SIMPLEQ_INSERT_TAIL(&data->fifo, bp, dsentries);

}

struct buf *
bufq_nscan_dequeue(void *vdata)
{
	struct bufq_nscan_data *data = vdata;
	struct bufq_nscan_head *sorted = &data->sorted;
	struct buf	*bp;

	if (SIMPLEQ_FIRST(sorted) == NULL)
		bufq_nscan_resort(data);

	bp = SIMPLEQ_FIRST(sorted);
	if (bp != NULL)
		SIMPLEQ_REMOVE_HEAD(sorted, dsentries);

	return (bp);
}

void
bufq_nscan_requeue(void *vdata, struct buf *bp)
{
	struct bufq_nscan_data *data = vdata;

	SIMPLEQ_INSERT_HEAD(&data->fifo, bp, dsentries);
}

int
bufq_nscan_peek(void *vdata)
{
	struct bufq_nscan_data *data = vdata;

	return (SIMPLEQ_FIRST(&data->sorted) != NULL) ||
	    (SIMPLEQ_FIRST(&data->fifo) != NULL);
}
@


1.30
log
@Remove some includes include-what-you-use claims don't
have any direct symbols used.  Tested for indirect use by compiling
amd64/i386/sparc64 kernels.

ok tedu@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_bufq.c,v 1.29 2015/01/09 05:04:22 tedu Exp $	*/
d331 3
a333 1
	free(data, M_DEVBUF, 0);
d450 3
a452 1
	free(vdata, M_DEVBUF, 0);
@


1.29
log
@save the bufq pointer from the buf before we turn it loose so it won't
change on us. also, remove unused second arg to bufq_wait.
from pedro at bitrig via david hill.
ok beck kettenis
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_bufq.c,v 1.28 2014/07/12 18:43:32 tedu Exp $	*/
a27 2

#include <sys/disklabel.h>
@


1.28
log
@add a size argument to free. will be used soon, but for now default to 0.
after discussions with beck deraadt kettenis.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_bufq.c,v 1.27 2014/06/27 16:38:03 miod Exp $	*/
d242 1
a242 1
bufq_wait(struct bufq *bq, struct buf *bp)
@


1.27
log
@Do not KASSERT an unsigned value being >= 0 after decrementing it; instead,
KASSERT it being > 0 before decrementing.
ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_bufq.c,v 1.26 2013/11/20 23:52:42 dlg Exp $	*/
d333 1
a333 1
	free(data, M_DEVBUF);
d450 1
a450 1
	free(vdata, M_DEVBUF);
@


1.26
log
@now that all the direct users of disksort have been removed, we can now
safely remove disksort.

most hardware and pretty much all of the kernel has moved to logical
block addressing when dealing with disks, so the assumptions disksort
was built against arent useful these days. it also has bad edge cases
with lots of sequential writes being able to starve other io requests
in the system. these issues have been addressed by becks nscan
implementation, which disksort was previously deprecated in favour
of.

this removes the guts of disksort and the bufq wrapper around it.

ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_bufq.c,v 1.25 2013/04/10 01:35:55 guenther Exp $	*/
d261 1
a262 1
	KASSERT(bq->bufq_outstanding >= 0);
@


1.25
log
@Fix various glitches in queue macro usage.

ok millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_bufq.c,v 1.24 2013/03/18 22:13:04 tedu Exp $	*/
a44 7
void		*bufq_disksort_create(void);
void		 bufq_disksort_destroy(void *);
void		 bufq_disksort_queue(void *, struct buf *);
struct buf	*bufq_disksort_dequeue(void *);
void		 bufq_disksort_requeue(void *, struct buf *);
int		 bufq_disksort_peek(void *);

a60 8
		bufq_disksort_create,
		bufq_disksort_destroy,
		bufq_disksort_queue,
		bufq_disksort_dequeue,
		bufq_disksort_requeue,
		bufq_disksort_peek
	},
	{
a310 55
/*
 * disksort implementation.
 */

void *
bufq_disksort_create(void)
{
	return (malloc(sizeof(struct buf), M_DEVBUF, M_NOWAIT | M_ZERO));
}

void
bufq_disksort_destroy(void *data)
{
	free(data, M_DEVBUF);
}

void
bufq_disksort_queue(void *data, struct buf *bp)
{
	disksort((struct buf *)data, bp);
}

struct buf *
bufq_disksort_dequeue(void *data)
{
	struct buf	*bufq = data;
	struct buf	*bp;

	bp = bufq->b_actf;
	if (bp != NULL)
		bufq->b_actf = bp->b_actf;
	if (bufq->b_actf == NULL)
		bufq->b_actb = &bufq->b_actf;

	return (bp);
}

void
bufq_disksort_requeue(void *data, struct buf *bp)
{
	struct buf	*bufq = data;

	bp->b_actf = bufq->b_actf;
	bufq->b_actf = bp;
	if (bp->b_actf == NULL)
		bufq->b_actb = &bp->b_actf;
}

int
bufq_disksort_peek(void *data)
{
	struct buf	*bufq = data;

	return (bufq->b_actf != NULL);
}
d377 1
a377 3
#define BUF_INORDER(ba, bb)			 \
    (((ba)->b_cylinder < (bb)->b_cylinder) || \
    ((ba)->b_cylinder == (bb)->b_cylinder && (ba)->b_blkno < (bb)->b_blkno))
@


1.24
log
@nscan only operates in a single direction, remove leftover dir variable.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_bufq.c,v 1.23 2012/10/17 23:58:25 beck Exp $	*/
d31 1
a31 1
SLIST_HEAD(, bufq)	bufqs = SLIST_HEAD_INITIALIZER(&bufq);
@


1.23
log
@use wakeup here, not wakeup_one - avoids problem of not waking up writers
when there are more of them than size of queue waiting, and nothing else
going on.

ok miod@@ kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_bufq.c,v 1.22 2012/10/09 16:44:15 beck Exp $	*/
a455 1
	int dir;
@


1.22
log
@Capilization in comment, and document leftoverroom, + knf nit, spotted by theo
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_bufq.c,v 1.21 2012/10/09 15:36:50 beck Exp $	*/
d281 1
a281 1
		wakeup_one(&bq->bufq_waiting);
@


1.21
log
@Add nscan as a disk queueing algorithm, and make it the default with
n = 128.

Nscan is essentially, the disksort() style elevator algorithm for ordering
disk io operations. The difference is that we will re-order in chunks of
128 operations before continuing with the rest of the work. This avoids
the problem that the basic SCAN (aka elevator algorithm) has where continued
inserts can cause starvation, where requests can sit for a long time. This
solves problems where usb sticks could be unusable while long sequential
writes happened, and systems would become unresponsive while dumping core.

hacked upon (and this version largely rewritten by) tedu and myself.

Note, can be "backed out" by changing BUFQ_DEFAULT back to disksort in
buf.h

ok kettenis@@, tedu@@, krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_bufq.c,v 1.20 2012/10/09 15:12:15 beck Exp $	*/
d457 1
a457 1
	int leftoverroom;
d532 1
a532 1
	 * if the previous sorted segment was small, we will continue
d539 1
a539 1
			data->leftoverroom -= 1;
@


1.20
log
@bufq write limiting

This change ensures that writes in flight from the buffer cache via bufq
are limited to a high water mark - when the limit is reached the writes sleep
until the amount of IO in flight reaches a low water mark. This avoids the
problem where userland can queue an unlimited amount of asynchronous writes
resulting in the consumption of all/most of our available buffer mapping kva,
and a long queue of writes to the disk.

ok kettenis@@, krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_bufq.c,v 1.19 2010/09/03 10:51:53 dlg Exp $	*/
d59 7
d82 8
d441 139
@


1.19
log
@thib insists i take responsibility too
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_bufq.c,v 1.18 2010/09/02 07:05:39 matthew Exp $	*/
d23 1
d81 2
d86 12
d99 2
d242 16
d265 2
@


1.18
log
@Inline bufq_impl_disksort and bufq_impl_fifo's definitions into
bufq_impls.  Also, make bufq_impls const.

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_bufq.c,v 1.17 2010/09/01 19:30:59 kettenis Exp $	*/
d4 1
@


1.17
log
@There is no point doing wakeups in bufq_done() unless we're actually in the
process of quiescing I/O.

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_bufq.c,v 1.16 2010/09/01 19:23:05 kettenis Exp $	*/
a49 9
struct bufq_impl bufq_impl_disksort = {
	bufq_disksort_create,
	bufq_disksort_destroy,
	bufq_disksort_queue,
	bufq_disksort_dequeue,
	bufq_disksort_requeue,
	bufq_disksort_peek
};

d57 17
a73 12
struct bufq_impl bufq_impl_fifo = {
	bufq_fifo_create,
	bufq_fifo_destroy,
	bufq_fifo_queue,
	bufq_fifo_dequeue,
	bufq_fifo_requeue,
	bufq_fifo_peek
};

struct bufq_impl *bufq_impls[BUFQ_HOWMANY] = {
	&bufq_impl_disksort,
	&bufq_impl_fifo
d84 1
a84 1
	bq->bufq_impl = bufq_impls[type];
d119 1
a119 1
	data = bufq_impls[type]->impl_create();
d128 2
a129 2
		while ((bp = bufq_impls[otype]->impl_dequeue(odata)) != NULL)
			bufq_impls[type]->impl_queue(data, bp);
d133 1
a133 1
		bq->bufq_impl = bufq_impls[type];
d140 1
a140 1
	bufq_impls[otype]->impl_destroy(odata);
@


1.16
log
@Clarify why we can walk the list of bufqs without holding a mutex with a
comment.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_bufq.c,v 1.15 2010/09/01 01:38:12 dlg Exp $	*/
d233 1
a233 1
	if (bq->bufq_outstanding == 0 /* XXX and quiesced */)
@


1.15
log
@make struct bufq a member of the softc for devices that use it,
rather than it being a pointer to something that needs to be allocated
at attach. since all these devices need a bufq to operate, it makes
sense to have it allocated as part of the softc and get bufq_init
to just initialise all its fields. it also gets rid of the possibility
that you wont be able to allocate the bufq struct during attach,
which is something you dont want to happen.

secondly, it consistently implements a split between wrapper functions
and the per discipline implementation of the bufq handlers. it
consistently does the locking in the wrappers rather than doing
half in the wrappers and the other half in the implementations.

it also consistently handles the outstanding bufq bq pointer in the
wrappers.

this hides most of the implementation inside kern_bufq.c. the only
stuff left in buf.h is for the bits each implementation needs to
put inside struct buf.

tested by thib@@ krw@@ and me
ok thib@@ matthew@@
no objection from krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_bufq.c,v 1.14 2010/07/19 21:39:15 kettenis Exp $	*/
d247 5
a251 1
	SLIST_FOREACH(bq, &bufqs, bufq_entries) { /* XXX */
@


1.14
log
@Avoid interleaving of mutexes that would leave is with the wrong spl after
calling bufq_quiesce().  Problem spotted by matthew@@.

ok matthew@@, thib@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_bufq.c,v 1.13 2010/07/08 23:18:55 dlg Exp $	*/
d33 8
a40 3
struct buf *(*bufq_dequeuev[BUFQ_HOWMANY])(struct bufq *, int) = {
	bufq_disksort_dequeue,
	bufq_fifo_dequeue
d42 11
a52 1
void (*bufq_queuev[BUFQ_HOWMANY])(struct bufq *, struct buf *) = {
d54 3
a56 1
	bufq_fifo_queue
d58 15
a72 3
void (*bufq_requeuev[BUFQ_HOWMANY])(struct bufq *, struct buf *) = {
	bufq_disksort_requeue,
	bufq_fifo_requeue
d75 4
d80 2
a81 2
struct bufq *
bufq_init(int type)
d83 2
a84 5
	struct bufq	*bq;
	int		 error;

	bq = malloc(sizeof(*bq), M_DEVBUF, M_NOWAIT|M_ZERO);
	KASSERT(bq != NULL);
d88 9
a96 14

	switch (type) {
	case BUFQ_DISKSORT:
		error = bufq_disksort_init(bq);
		break;
	case BUFQ_FIFO:
		error = bufq_fifo_init(bq);
		break;
	default:
		panic("bufq_init: type %i unknown", type);
		break;
	};

	KASSERT(error == 0);
d105 42
a146 1
	return (bq);
d154 2
a155 2
	if (bq->bufq_data != NULL)
		free(bq->bufq_data, M_DEVBUF);
d163 1
a164 2
	free(bq, M_DEVBUF);
}
d173 4
a176 1
	bufq_queuev[bq->bufq_type](bq, bp);
d180 12
d196 1
a196 1
	bufq_requeuev[bq->bufq_type](bq, bp);
d200 12
d218 1
a218 1
	while ((bp = BUFQ_DEQUEUE(bq)) != NULL) {
d233 1
a233 1
	if (bq->bufq_outstanding == 0)
d247 1
a247 1
	SLIST_FOREACH(bq, &bufqs, bufq_entries) {
d275 10
d286 13
a298 1
bufq_disksort_queue(struct bufq *bq, struct buf *bp)
d300 2
a301 1
	struct buf	*bufq;
d303 5
a307 1
	bufq = (struct buf *)bq->bufq_data;
d309 1
a309 3
	bq->bufq_outstanding++;
	bp->b_bq = bq;
	disksort(bufq, bp);
d313 1
a313 1
bufq_disksort_requeue(struct bufq *bq, struct buf *bp)
d315 1
a315 3
	struct buf	*bufq;

	bufq = (struct buf *)bq->bufq_data;
d323 2
a324 2
struct buf *
bufq_disksort_dequeue(struct bufq *bq, int peeking)
d326 1
a326 1
	struct buf	*bufq, *bp;
d328 2
a329 10
	mtx_enter(&bq->bufq_mtx);
	bufq = (struct buf *)bq->bufq_data;
	bp = bufq->b_actf;
	if (!peeking) {
		if (bp != NULL)
			bufq->b_actf = bp->b_actf;
		if (bufq->b_actf == NULL)
			bufq->b_actb = &bufq->b_actf;
	}
	mtx_leave(&bq->bufq_mtx);
d331 3
a333 2
	return (bp);
}
d335 2
a336 2
int
bufq_disksort_init(struct bufq *bq)
d338 1
a338 1
	int	error = 0;
d340 3
a342 2
	bq->bufq_data = malloc(sizeof(struct buf), M_DEVBUF,
	    M_NOWAIT|M_ZERO);
d344 1
a344 2
	if (bq->bufq_data == NULL)
		error = ENOMEM;
d346 1
a346 1
	return (error);
d350 1
a350 1
bufq_fifo_queue(struct bufq *bq, struct buf *bp)
d352 1
a352 5
	struct bufq_fifo_head	*head = bq->bufq_data;

	bq->bufq_outstanding++;
	bp->b_bq = bq;
	SIMPLEQ_INSERT_TAIL(head, bp, b_bufq.bufq_data_fifo.bqf_entries);
d356 1
a356 1
bufq_fifo_requeue(struct bufq *bq, struct buf *bp)
d358 1
a358 1
	struct bufq_fifo_head	*head = bq->bufq_data;
d360 1
a360 1
	SIMPLEQ_INSERT_HEAD(head, bp, b_bufq.bufq_data_fifo.bqf_entries);
d364 1
a364 1
bufq_fifo_dequeue(struct bufq *bq, int peeking)
d366 2
a367 2
	struct	bufq_fifo_head	*head = bq->bufq_data;
	struct	buf		*bp;
a368 1
	mtx_enter(&bq->bufq_mtx);
d370 1
a370 1
	if (bp != NULL && !peeking)
a371 1
	mtx_leave(&bq->bufq_mtx);
d376 2
a377 2
int
bufq_fifo_init(struct bufq *bq)
d379 1
a379 1
	struct bufq_fifo_head	*head;
d381 2
a382 3
	head = malloc(sizeof(*head), M_DEVBUF, M_NOWAIT);
	if (head == NULL)
		return (ENOMEM);
d384 4
a387 2
	SIMPLEQ_INIT(head);
	bq->bufq_data = head;
d389 1
a389 1
	return (0);
@


1.13
log
@dont count requeued io as outstanding io. there is a 1:1 mapping
between calls to bufq_enqueue and bufq_done calls, but bufq_requeue
can be called multiple times on an io in between the enqueue and
done. if you keep incrementing outstanding you'll never stop sleeping
for suspend.

bufq_requeue can be called via interrupts, so we cannot sleep
there.

the problems fixed by this diff were never hit cos the adapters
people are testing/running with do not cause bufq_requeue to be
called.

thanks to thib@@ for helping me understand the code better
ok thib@@ deraadt@@ kettenis@@ tedu@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_bufq.c,v 1.12 2010/07/07 10:50:50 dlg Exp $	*/
d30 1
a30 1
struct mutex		bufqs_mtx = MUTEX_INITIALIZER(IPL_BIO);
d74 3
d93 1
a93 1
		msleep(&bufqs_stop, &bufqs_mtx, PRIBIO, "bufqstop", 0);
d106 1
a106 1
		msleep(&bq->bufq_stop, &bq->bufq_mtx, PRIBIO, "bufqstop", 0);
a151 1
restart:
d154 1
d158 1
a158 2
		if (bq->bufq_outstanding) {
			mtx_leave(&bufqs_mtx);
d160 1
a160 2
			    PRIBIO | PNORELOCK, "bufqqui", 0);
			goto restart;
a163 1
	mtx_leave(&bufqs_mtx);
@


1.12
log
@minor whitespace tweaks and clean up extra ;
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_bufq.c,v 1.11 2010/06/30 02:29:18 matthew Exp $	*/
a112 3
	while (bq->bufq_stop) {
		msleep(&bq->bufq_stop, &bq->bufq_mtx, PRIBIO, "bufqstop", 0);
	}
a201 2
	bq->bufq_outstanding++;
	bp->b_bq = bq;
a255 2
	bq->bufq_outstanding++;
	bp->b_bq = bq;
@


1.11
log
@Call msleep(9) with PNORELOCK rather than calling mtx_leave()
immediately afterwards.

ok thib@@, tedu@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_bufq.c,v 1.10 2010/06/30 02:26:58 matthew Exp $	*/
d191 1
a191 1
	bufq = (struct buf  *)bq->bufq_data;
d206 1
a206 1
	bp->b_bq = bq; 
d262 1
a262 1
	bp->b_bq = bq;;
@


1.10
log
@Switch bufq FIFO disclipline from using TAILQs to SIMPLEQs.

ok thib@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_bufq.c,v 1.9 2010/06/29 18:52:20 kettenis Exp $	*/
d160 2
a161 3
			msleep(&bq->bufq_outstanding, &bq->bufq_mtx, PRIBIO,
			    "bufqqui", 0);
			mtx_leave(&bq->bufq_mtx);
@


1.9
log
@Introduce bufq_quiesce(), which will block I/O ifrom getting on the queues,
and waits until all I/O currently on the queues has been completed.  To get
I/O going again, call bufq_restart().

To be used for suspend/resume.

Joint effort with thib@@, tedu@@; tested by mlarkin@@, marco@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_bufq.c,v 1.8 2010/06/27 22:05:28 thib Exp $	*/
d254 1
a254 1
	TAILQ_INSERT_TAIL(head, bp, b_bufq.bufq_data_fifo.bqf_entries);
d264 1
a264 1
	TAILQ_INSERT_HEAD(head, bp, b_bufq.bufq_data_fifo.bqf_entries);
d274 1
a274 1
	bp = TAILQ_FIRST(head);
d276 1
a276 1
		TAILQ_REMOVE(head, bp, b_bufq.bufq_data_fifo.bqf_entries);
d291 1
a291 1
	TAILQ_INIT(head);
@


1.8
log
@garbage collect the debugging goo
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_bufq.c,v 1.7 2010/06/27 04:29:31 kettenis Exp $	*/
d29 5
a33 1
struct buf *(*bufq_dequeue[BUFQ_HOWMANY])(struct bufq *, int) = {
d37 1
a37 1
void (*bufq_queue[BUFQ_HOWMANY])(struct bufq *, struct buf *) = {
d41 1
a41 1
void (*bufq_requeue[BUFQ_HOWMANY])(struct bufq *, struct buf *) = {
d73 4
d88 7
d99 22
d136 52
d194 2
a195 1
	mtx_enter(&bq->bufq_mtx);
a196 1
	mtx_leave(&bq->bufq_mtx);
d206 2
a207 1
	mtx_enter(&bq->bufq_mtx);
a211 1
	mtx_leave(&bq->bufq_mtx);
d252 2
a253 1
	mtx_enter(&bq->bufq_mtx);
a254 1
	mtx_leave(&bq->bufq_mtx);
d262 2
a263 1
	mtx_enter(&bq->bufq_mtx);
a264 1
	mtx_leave(&bq->bufq_mtx);
@


1.7
log
@Add missing $OpenBSD$.
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
a28 13
#ifdef BUFQ_DEBUG
#define	BUFQDBG_INIT		0x0001
#define	BUFQDBG_DRAIN		0x0002
#define	BUFQDBG_DISKSORT	0x0004
#define	BUFQDBG_FIFO		0x0008
int	bqdebug = 0;
#define	DPRINTF(p...)		do { if (bqdebug) printf(p); } while (0)
#define	DNPRINTF(n, p...)	do { if ((n) & bqdebug) printf(p); } while (0)
#else
#define	DPRINTF(p...)		/* p */
#define	DNPRINTF(n, p...)	/* n, p */
#endif

a51 3
	DNPRINTF(BUFQDBG_INIT, "%s: initing bufq %p of type %i\n",
	    __func__, bq, type);

a76 2
	DNPRINTF(BUFQDBG_INIT, "%s: destroying bufq %p\n", __func__, bq);

a88 3
	DNPRINTF(BUFQDBG_DRAIN, "%s: draining bufq %p\n",
	    __func__, bq);

a104 3
	DNPRINTF(BUFQDBG_DISKSORT, "%s: queueing bp %p in bufq %p\n",
	    __func__, bp, bq);

a116 3
	DNPRINTF(BUFQDBG_DISKSORT, "%s: requeueing bp % in bufq %p\n",
	    __func__, bp, bufq);

a140 3
	DNPRINTF(BUFQDBG_DISKSORT, "%s: %s buf %p from bufq %p\n", __func__, 
	    peeking ? "peeking at" : "dequeueing", bp, bq);

a162 3
	DNPRINTF(BUFQDBG_FIFO, "%s: queueing bp %p in bufq %p\n",
	    __func__, bp, bq);

a172 3
	DNPRINTF(BUFQDBG_FIFO, "%s: requeueing bp % in bufq %p\n",
	    __func__, bp, bq);

a188 3

	DNPRINTF(BUFQDBG_FIFO, "%s: %s buf %p from bufq %p\n", __func__, 
	    peeking ? "peeking at" : "dequeueing", bp, bq);
@


1.6
log
@No need to include mutex.h twice.
Pointed out by Jung <moorang at gmail dot com>
@
text
@d1 1
@


1.5
log
@Tweak bufq code to handle corner cases. Makes upcoming cd(4)
conversion to bufq work. Taken from n2k10 scsi buf queueing code.

ok thib@@
@
text
@a23 1
#include <sys/mutex.h>
@


1.4
log
@Trying this again. Mixing anoncvs with cvs is _not_ a good idea.

Reintroduce bufqs. A few changes since it was backed out after some good
comments from dlg@@.

No need for a separate bufq.h, keep all of in buf.h; As requested by kittens
and deraadt.

Only sd(4) and wd(4) for now. The rest of the drivers will be converted soon,
also other goodies like heuristics for sd(4) for selecting the bufq type and
the death of disksort() are forthcoming.

Tested on: i386, amd64, sparc64, macppc, loongson and alpha by myself and
phessler.

OK art@@, beck@@, kettenis@@, oga@@
@
text
@d146 1
d160 5
a164 3
	if (bp == NULL) {
		mtx_leave(&bq->bufq_mtx);
		return (NULL);
a165 2
	if (!peeking)
		bufq->b_actf = bp->b_actf;
@


1.3
log
@Revert bufq's. this is inline with the major midlayer reverts that
have been going on. this appears to bring us back to stable state.

lots of testing by oga and ariane and my self.
@
text
@a0 2
/*	$OpenBSD: kern_bufq.c,v 1.2 2009/06/04 19:16:13 thib Exp $ */

d2 1
a2 2
 * Copyright (c) 2008, 2009	Thordur I. Bjornsson <thib@@openbsd.org>
 * Copyright (c) 2004		Ted Unangst <tedu@@openbsd.org>
d16 1
d21 1
a21 2
#include <sys/pool.h>
#include <sys/proc.h>
d24 2
d29 26
a54 4
/* plain old disksort. */
struct buf	*bufq_disksort_get(struct bufq *, int);
void		 bufq_disksort_add(struct bufq *, struct buf *);
int		 bufq_disksort_init(struct bufq *);
d59 2
a60 2
	struct bufq		*bq;
	int			 error;
d62 2
a63 1
	KASSERT(type = BUFQ_DISKSORT);
d65 2
a66 3
	bq = malloc(sizeof(*bq), M_DEVBUF, M_NOWAIT|M_ZERO);
	if (bq == NULL)
		return (NULL);
d68 1
a68 1
	/* For now, only plain old disksort. */
a69 2
	bq->bufq_get = bufq_disksort_get;
	bq->bufq_add = bufq_disksort_add;
d71 13
a83 5
	error = bufq_disksort_init(bq);
	if (error) {
		free(bq, M_DEVBUF);
		return (NULL);
	}
d93 2
d107 4
a110 2
	s = splbio();
	while ((bp = BUFQ_GET(bq)) != NULL) {
d113 1
d115 1
d117 11
a127 1
	splx(s);
d129 3
d135 1
a135 1
bufq_disksort_add(struct bufq *bq, struct buf *bp)
d137 1
a137 1
	struct buf		*bufq;
d139 1
a139 1
	splassert(IPL_BIO);
d141 2
a142 1
	bufq = (struct buf  *)bq->bufq_data;
d144 5
a148 1
	disksort(bufq, bp);
d152 1
a152 1
bufq_disksort_get(struct bufq *bq, int peeking)
d154 1
a154 3
	struct buf		*bufq, *bp;

	splassert(IPL_BIO);
d156 1
d159 2
a160 1
	if (bp == NULL)
d162 1
d165 5
d179 1
a179 1
	    M_WAITOK|M_ZERO);
d187 12
a198 4
#ifdef DDB
#include <machine/db_machdep.h>
#include <ddb/db_interface.h>
#include <ddb/db_output.h>
d201 14
a214 1
db_bufq_print(struct bufq *bq, int full, int (*pr)(const char *, ...))
d216 2
a217 1
	struct buf		*bp, *dp;
d219 5
d225 2
a226 2
	(*pr)(" type %i\n bufq_add %p bufq_get %p bufq_data %p",
	    bq->bufq_type, bq->bufq_add, bq->bufq_get, bq->bufq_data);
d228 1
a228 8
	if (full) {
		printf("bufs on queue:\n");
		bp = (struct buf *)bq->bufq_data;
		while ((dp = bp->b_actf) != NULL) {
			printf("%p\n", bp);
			bp = dp;
		}
	}
d231 14
a244 1
#endif
@


1.2
log
@add $OpenBSD$ tag
@
text
@d1 1
a1 1
/*	$OpenBSD$ */
@


1.1
log
@add a flexible buffer queue (bufq) api, based on the never used
one by tedu@@. It doesn't do anything smart yet, it just uses
plain old disksort. we also keep the old method of queueing bufs
since some miods have crazy MD drivers that need some love.

ok beck@@, art@@
tested by many on many archs.
@
text
@d1 2
@

