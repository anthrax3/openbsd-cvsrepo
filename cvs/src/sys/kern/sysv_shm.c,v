head	1.69;
access;
symbols
	OPENBSD_6_2:1.69.0.2
	OPENBSD_6_2_BASE:1.69
	OPENBSD_6_1:1.69.0.4
	OPENBSD_6_1_BASE:1.69
	OPENBSD_6_0:1.67.0.4
	OPENBSD_6_0_BASE:1.67
	OPENBSD_5_9:1.67.0.2
	OPENBSD_5_9_BASE:1.67
	OPENBSD_5_8:1.66.0.4
	OPENBSD_5_8_BASE:1.66
	OPENBSD_5_7:1.65.0.2
	OPENBSD_5_7_BASE:1.65
	OPENBSD_5_6:1.58.0.4
	OPENBSD_5_6_BASE:1.58
	OPENBSD_5_5:1.55.0.10
	OPENBSD_5_5_BASE:1.55
	OPENBSD_5_4:1.55.0.6
	OPENBSD_5_4_BASE:1.55
	OPENBSD_5_3:1.55.0.4
	OPENBSD_5_3_BASE:1.55
	OPENBSD_5_2:1.55.0.2
	OPENBSD_5_2_BASE:1.55
	OPENBSD_5_1_BASE:1.54
	OPENBSD_5_1:1.54.0.2
	OPENBSD_5_0:1.53.0.2
	OPENBSD_5_0_BASE:1.53
	OPENBSD_4_9:1.51.0.4
	OPENBSD_4_9_BASE:1.51
	OPENBSD_4_8:1.51.0.2
	OPENBSD_4_8_BASE:1.51
	OPENBSD_4_7:1.50.0.2
	OPENBSD_4_7_BASE:1.50
	OPENBSD_4_6:1.50.0.4
	OPENBSD_4_6_BASE:1.50
	OPENBSD_4_5:1.49.0.6
	OPENBSD_4_5_BASE:1.49
	OPENBSD_4_4:1.49.0.4
	OPENBSD_4_4_BASE:1.49
	OPENBSD_4_3:1.49.0.2
	OPENBSD_4_3_BASE:1.49
	OPENBSD_4_2:1.47.0.2
	OPENBSD_4_2_BASE:1.47
	OPENBSD_4_1:1.46.0.12
	OPENBSD_4_1_BASE:1.46
	OPENBSD_4_0:1.46.0.10
	OPENBSD_4_0_BASE:1.46
	OPENBSD_3_9:1.46.0.8
	OPENBSD_3_9_BASE:1.46
	OPENBSD_3_8:1.46.0.6
	OPENBSD_3_8_BASE:1.46
	OPENBSD_3_7:1.46.0.4
	OPENBSD_3_7_BASE:1.46
	OPENBSD_3_6:1.46.0.2
	OPENBSD_3_6_BASE:1.46
	SMP_SYNC_A:1.43
	SMP_SYNC_B:1.43
	OPENBSD_3_5:1.41.0.2
	OPENBSD_3_5_BASE:1.41
	OPENBSD_3_4:1.38.0.2
	OPENBSD_3_4_BASE:1.38
	UBC_SYNC_A:1.35
	OPENBSD_3_3:1.33.0.2
	OPENBSD_3_3_BASE:1.33
	OPENBSD_3_2:1.27.0.2
	OPENBSD_3_2_BASE:1.27
	OPENBSD_3_1:1.25.0.2
	OPENBSD_3_1_BASE:1.25
	UBC_SYNC_B:1.27
	UBC:1.23.0.2
	UBC_BASE:1.23
	OPENBSD_3_0:1.20.0.2
	OPENBSD_3_0_BASE:1.20
	OPENBSD_2_9_BASE:1.14
	OPENBSD_2_9:1.14.0.8
	OPENBSD_2_8:1.14.0.6
	OPENBSD_2_8_BASE:1.14
	OPENBSD_2_7:1.14.0.4
	OPENBSD_2_7_BASE:1.14
	SMP:1.14.0.2
	SMP_BASE:1.14
	kame_19991208:1.14
	OPENBSD_2_6:1.13.0.2
	OPENBSD_2_6_BASE:1.13
	OPENBSD_2_5:1.11.0.2
	OPENBSD_2_5_BASE:1.11
	OPENBSD_2_4:1.9.0.2
	OPENBSD_2_4_BASE:1.9
	OPENBSD_2_3:1.6.0.6
	OPENBSD_2_3_BASE:1.6
	OPENBSD_2_2:1.6.0.4
	OPENBSD_2_2_BASE:1.6
	OPENBSD_2_1:1.6.0.2
	OPENBSD_2_1_BASE:1.6
	OPENBSD_2_0:1.5.0.2
	OPENBSD_2_0_BASE:1.5
	netbsd_1_1:1.1.1.1;
locks; strict;
comment	@ * @;


1.69
date	2016.09.15.02.00.16;	author dlg;	state Exp;
branches;
next	1.68;
commitid	RlO92XR575sygHqm;

1.68
date	2016.08.30.07.40.35;	author dlg;	state Exp;
branches;
next	1.67;
commitid	JbWQykeZEbgGzoLE;

1.67
date	2015.10.07.14.49.04;	author deraadt;	state Exp;
branches;
next	1.66;
commitid	a9ZaMLuMuLRnJvUh;

1.66
date	2015.03.14.03.38.50;	author jsg;	state Exp;
branches;
next	1.65;
commitid	p4LJxGKbi0BU2cG6;

1.65
date	2015.01.15.20.36.17;	author millert;	state Exp;
branches;
next	1.64;
commitid	6SqWntuTHjGhOtMI;

1.64
date	2014.12.19.05.59.21;	author tedu;	state Exp;
branches;
next	1.63;
commitid	zdJTCwdpqRUwO1SL;

1.63
date	2014.12.17.06.58.11;	author guenther;	state Exp;
branches;
next	1.62;
commitid	DImukoCWyTxwdbuh;

1.62
date	2014.12.15.02.24.23;	author guenther;	state Exp;
branches;
next	1.61;
commitid	ZxaujiOM0aYQRjFY;

1.61
date	2014.12.10.02.44.47;	author tedu;	state Exp;
branches;
next	1.60;
commitid	tsoJBlEBSyYO22RG;

1.60
date	2014.12.09.07.05.06;	author doug;	state Exp;
branches;
next	1.59;
commitid	zM5ckwX4kwwmipG0;

1.59
date	2014.11.16.12.31.00;	author deraadt;	state Exp;
branches;
next	1.58;
commitid	yv0ECmCdICvq576h;

1.58
date	2014.07.13.15.29.04;	author tedu;	state Exp;
branches;
next	1.57;
commitid	bFFVdS3JEaMhyZxJ;

1.57
date	2014.07.12.18.43.32;	author tedu;	state Exp;
branches;
next	1.56;
commitid	QlVV51SZgNFxsXxC;

1.56
date	2014.03.18.06.59.00;	author guenther;	state Exp;
branches;
next	1.55;

1.55
date	2012.03.09.13.01.28;	author ariane;	state Exp;
branches;
next	1.54;

1.54
date	2011.10.27.07.56.28;	author robert;	state Exp;
branches;
next	1.53;

1.53
date	2011.06.06.17.10.23;	author ariane;	state Exp;
branches;
next	1.52;

1.52
date	2011.05.24.15.27.36;	author ariane;	state Exp;
branches;
next	1.51;

1.51
date	2010.07.03.03.04.55;	author tedu;	state Exp;
branches;
next	1.50;

1.50
date	2009.06.02.12.11.16;	author guenther;	state Exp;
branches;
next	1.49;

1.49
date	2007.09.15.10.10.37;	author martin;	state Exp;
branches;
next	1.48;

1.48
date	2007.09.07.15.00.20;	author art;	state Exp;
branches;
next	1.47;

1.47
date	2007.05.29.10.44.28;	author sturm;	state Exp;
branches;
next	1.46;

1.46
date	2004.07.15.11.24.46;	author millert;	state Exp;
branches;
next	1.45;

1.45
date	2004.07.14.23.40.27;	author millert;	state Exp;
branches;
next	1.44;

1.44
date	2004.06.21.23.50.36;	author tholo;	state Exp;
branches;
next	1.43;

1.43
date	2004.05.03.17.38.48;	author millert;	state Exp;
branches;
next	1.42;

1.42
date	2004.04.16.17.55.13;	author tedu;	state Exp;
branches;
next	1.41;

1.41
date	2004.02.05.21.13.58;	author millert;	state Exp;
branches
	1.41.2.1;
next	1.40;

1.40
date	2003.12.22.00.35.57;	author millert;	state Exp;
branches;
next	1.39;

1.39
date	2003.10.12.23.44.39;	author millert;	state Exp;
branches;
next	1.38;

1.38
date	2003.08.21.05.20.07;	author kevlo;	state Exp;
branches
	1.38.2.1;
next	1.37;

1.37
date	2003.06.17.21.56.25;	author millert;	state Exp;
branches;
next	1.36;

1.36
date	2003.06.03.01.52.41;	author millert;	state Exp;
branches;
next	1.35;

1.35
date	2003.05.12.00.48.52;	author jason;	state Exp;
branches;
next	1.34;

1.34
date	2003.04.14.04.53.50;	author art;	state Exp;
branches;
next	1.33;

1.33
date	2003.01.07.00.34.41;	author millert;	state Exp;
branches
	1.33.2.1;
next	1.32;

1.32
date	2003.01.06.20.11.28;	author millert;	state Exp;
branches;
next	1.31;

1.31
date	2002.12.17.23.32.31;	author millert;	state Exp;
branches;
next	1.30;

1.30
date	2002.12.17.23.11.31;	author millert;	state Exp;
branches;
next	1.29;

1.29
date	2002.11.06.00.17.28;	author art;	state Exp;
branches;
next	1.28;

1.28
date	2002.10.29.18.30.21;	author art;	state Exp;
branches;
next	1.27;

1.27
date	2002.07.16.23.06.05;	author art;	state Exp;
branches;
next	1.26;

1.26
date	2002.07.12.01.42.54;	author art;	state Exp;
branches;
next	1.25;

1.25
date	2002.03.14.01.27.05;	author millert;	state Exp;
branches;
next	1.24;

1.24
date	2001.12.19.08.58.06;	author art;	state Exp;
branches;
next	1.23;

1.23
date	2001.11.28.13.47.39;	author art;	state Exp;
branches
	1.23.2.1;
next	1.22;

1.22
date	2001.11.07.01.18.01;	author art;	state Exp;
branches;
next	1.21;

1.21
date	2001.11.06.19.53.20;	author miod;	state Exp;
branches;
next	1.20;

1.20
date	2001.08.12.22.50.12;	author millert;	state Exp;
branches;
next	1.19;

1.19
date	2001.06.27.04.49.47;	author art;	state Exp;
branches;
next	1.18;

1.18
date	2001.06.22.14.14.09;	author deraadt;	state Exp;
branches;
next	1.17;

1.17
date	2001.05.16.17.14.36;	author millert;	state Exp;
branches;
next	1.16;

1.16
date	2001.05.05.21.26.44;	author art;	state Exp;
branches;
next	1.15;

1.15
date	2001.05.05.20.57.00;	author art;	state Exp;
branches;
next	1.14;

1.14
date	99.11.25.13.41.30;	author art;	state Exp;
branches
	1.14.2.1;
next	1.13;

1.13
date	99.07.08.05.05.23;	author weingart;	state Exp;
branches;
next	1.12;

1.12
date	99.06.23.09.44.28;	author art;	state Exp;
branches;
next	1.11;

1.11
date	99.02.22.00.43.55;	author art;	state Exp;
branches;
next	1.10;

1.10
date	99.02.07.22.09.07;	author art;	state Exp;
branches;
next	1.9;

1.9
date	98.06.14.18.57.09;	author matthieu;	state Exp;
branches;
next	1.8;

1.8
date	98.06.11.18.32.17;	author deraadt;	state Exp;
branches;
next	1.7;

1.7
date	98.05.11.06.13.48;	author deraadt;	state Exp;
branches;
next	1.6;

1.6
date	97.02.21.08.52.23;	author deraadt;	state Exp;
branches;
next	1.5;

1.5
date	96.09.02.05.25.06;	author deraadt;	state Exp;
branches;
next	1.4;

1.4
date	96.04.21.22.27.26;	author deraadt;	state Exp;
branches;
next	1.3;

1.3
date	96.03.03.17.20.08;	author niklas;	state Exp;
branches;
next	1.2;

1.2
date	95.12.14.04.13.58;	author deraadt;	state Exp;
branches;
next	1.1;

1.1
date	95.10.18.08.52.46;	author deraadt;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	95.10.18.08.52.46;	author deraadt;	state Exp;
branches;
next	;

1.14.2.1
date	2001.07.04.10.48.40;	author niklas;	state Exp;
branches;
next	1.14.2.2;

1.14.2.2
date	2001.10.31.03.26.29;	author nate;	state Exp;
branches;
next	1.14.2.3;

1.14.2.3
date	2001.11.13.23.04.23;	author niklas;	state Exp;
branches;
next	1.14.2.4;

1.14.2.4
date	2001.12.05.01.02.39;	author niklas;	state Exp;
branches;
next	1.14.2.5;

1.14.2.5
date	2002.03.06.02.13.23;	author niklas;	state Exp;
branches;
next	1.14.2.6;

1.14.2.6
date	2002.03.28.11.43.04;	author niklas;	state Exp;
branches;
next	1.14.2.7;

1.14.2.7
date	2003.03.28.00.41.27;	author niklas;	state Exp;
branches;
next	1.14.2.8;

1.14.2.8
date	2003.05.13.19.21.28;	author ho;	state Exp;
branches;
next	1.14.2.9;

1.14.2.9
date	2003.06.07.11.03.40;	author ho;	state Exp;
branches;
next	1.14.2.10;

1.14.2.10
date	2004.02.19.10.56.38;	author niklas;	state Exp;
branches;
next	1.14.2.11;

1.14.2.11
date	2004.06.05.23.13.02;	author niklas;	state Exp;
branches;
next	;

1.23.2.1
date	2002.06.11.03.29.40;	author art;	state Exp;
branches;
next	1.23.2.2;

1.23.2.2
date	2002.10.29.00.36.44;	author art;	state Exp;
branches;
next	1.23.2.3;

1.23.2.3
date	2003.05.19.22.31.57;	author tedu;	state Exp;
branches;
next	;

1.33.2.1
date	2004.02.05.23.05.38;	author brad;	state Exp;
branches;
next	;

1.38.2.1
date	2004.02.05.23.04.40;	author brad;	state Exp;
branches;
next	;

1.41.2.1
date	2004.04.30.21.41.40;	author brad;	state Exp;
branches;
next	;


desc
@@


1.69
log
@all pools have their ipl set via pool_setipl, so fold it into pool_init.

the ioff argument to pool_init() is unused and has been for many
years, so this replaces it with an ipl argument. because the ipl
will be set on init we no longer need pool_setipl.

most of these changes have been done with coccinelle using the spatch
below. cocci sucks at formatting code though, so i fixed that by hand.

the manpage and subr_pool.c bits i did myself.

ok tedu@@ jmatthew@@

@@ipl@@
expression pp;
expression ipl;
expression s, a, o, f, m, p;
@@@@
-pool_init(pp, s, a, o, f, m, p);
-pool_setipl(pp, ipl);
+pool_init(pp, s, a, ipl, f, m, p);
@
text
@/*	$OpenBSD: sysv_shm.c,v 1.68 2016/08/30 07:40:35 dlg Exp $	*/
/*	$NetBSD: sysv_shm.c,v 1.50 1998/10/21 22:24:29 tron Exp $	*/

/*
 * Copyright (c) 2002 Todd C. Miller <Todd.Miller@@courtesan.com>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 *
 * Sponsored in part by the Defense Advanced Research Projects
 * Agency (DARPA) and Air Force Research Laboratory, Air Force
 * Materiel Command, USAF, under agreement number F39502-99-1-0512.
 */
/*
 * Copyright (c) 1994 Adam Glass and Charles M. Hannum.  All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by Adam Glass and Charles M.
 *	Hannum.
 * 4. The names of the authors may not be used to endorse or promote products
 *    derived from this software without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE AUTHORS ``AS IS'' AND ANY EXPRESS OR
 * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
 * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
 * IN NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY DIRECT, INDIRECT,
 * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
 * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
 * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

#include <sys/param.h>
#include <sys/shm.h>
#include <sys/proc.h>
#include <sys/uio.h>
#include <sys/time.h>
#include <sys/malloc.h>
#include <sys/mman.h>
#include <sys/pool.h>
#include <sys/systm.h>
#include <sys/sysctl.h>
#include <sys/stat.h>

#include <sys/mount.h>
#include <sys/syscallargs.h>

#include <uvm/uvm_extern.h>

extern struct shminfo shminfo;
struct shmid_ds **shmsegs;	/* linear mapping of shmid -> shmseg */
struct pool shm_pool;
unsigned short *shmseqs;	/* array of shm sequence numbers */

struct shmid_ds *shm_find_segment_by_shmid(int);

/*
 * Provides the following externally accessible functions:
 *
 * shminit(void);		                 initialization
 * shmexit(struct vmspace *)                     cleanup
 * shmfork(struct vmspace *, struct vmspace *)   fork handling
 * shmsys(arg1, arg2, arg3, arg4);         shm{at,ctl,dt,get}(arg2, arg3, arg4)
 *
 * Structures:
 * shmsegs (an array of 'struct shmid_ds *')
 * per proc 'struct shmmap_head' with an array of 'struct shmmap_state'
 */

#define	SHMSEG_REMOVED  	0x0200		/* can't overlap ACCESSPERMS */

int shm_last_free, shm_nused, shm_committed;

struct shm_handle {
	struct uvm_object *shm_object;
};

struct shmmap_state {
	vaddr_t va;
	int shmid;
};

struct shmmap_head {
	int shmseg;
	struct shmmap_state state[1];
};

int shm_find_segment_by_key(key_t);
void shm_deallocate_segment(struct shmid_ds *);
int shm_delete_mapping(struct vmspace *, struct shmmap_state *);
int shmget_existing(struct proc *, struct sys_shmget_args *,
			 int, int, register_t *);
int shmget_allocate_segment(struct proc *, struct sys_shmget_args *,
				 int, register_t *);

int
shm_find_segment_by_key(key_t key)
{
	struct shmid_ds *shmseg;
	int i;

	for (i = 0; i < shminfo.shmmni; i++) {
		shmseg = shmsegs[i];
		if (shmseg != NULL && shmseg->shm_perm.key == key)
			return (i);
	}
	return (-1);
}

struct shmid_ds *
shm_find_segment_by_shmid(int shmid)
{
	int segnum;
	struct shmid_ds *shmseg;

	segnum = IPCID_TO_IX(shmid);
	if (segnum < 0 || segnum >= shminfo.shmmni ||
	    (shmseg = shmsegs[segnum]) == NULL ||
	    shmseg->shm_perm.seq != IPCID_TO_SEQ(shmid))
		return (NULL);
	return (shmseg);
}

void
shm_deallocate_segment(struct shmid_ds *shmseg)
{
	struct shm_handle *shm_handle;
	size_t size;

	shm_handle = shmseg->shm_internal;
	size = round_page(shmseg->shm_segsz);
	uao_detach(shm_handle->shm_object);
	pool_put(&shm_pool, shmseg);
	shm_committed -= atop(size);
	shm_nused--;
}

int
shm_delete_mapping(struct vmspace *vm, struct shmmap_state *shmmap_s)
{
	struct shmid_ds *shmseg;
	int segnum;
	size_t size;

	segnum = IPCID_TO_IX(shmmap_s->shmid);
	if (segnum < 0 || segnum >= shminfo.shmmni ||
	    (shmseg = shmsegs[segnum]) == NULL)
		return (EINVAL);
	size = round_page(shmseg->shm_segsz);
	uvm_deallocate(&vm->vm_map, shmmap_s->va, size);
	shmmap_s->shmid = -1;
	shmseg->shm_dtime = time_second;
	if ((--shmseg->shm_nattch <= 0) &&
	    (shmseg->shm_perm.mode & SHMSEG_REMOVED)) {
		shm_deallocate_segment(shmseg);
		shm_last_free = segnum;
		shmsegs[shm_last_free] = NULL;
	}
	return (0);
}

int
sys_shmdt(struct proc *p, void *v, register_t *retval)
{
	struct sys_shmdt_args /* {
		syscallarg(const void *) shmaddr;
	} */ *uap = v;
	struct shmmap_head *shmmap_h;
	struct shmmap_state *shmmap_s;
	int i;

	shmmap_h = (struct shmmap_head *)p->p_vmspace->vm_shm;
	if (shmmap_h == NULL)
		return (EINVAL);

	for (i = 0, shmmap_s = shmmap_h->state; i < shmmap_h->shmseg;
	    i++, shmmap_s++)
		if (shmmap_s->shmid != -1 &&
		    shmmap_s->va == (vaddr_t)SCARG(uap, shmaddr))
			break;
	if (i == shmmap_h->shmseg)
		return (EINVAL);
	return (shm_delete_mapping(p->p_vmspace, shmmap_s));
}

int
sys_shmat(struct proc *p, void *v, register_t *retval)
{
	struct sys_shmat_args /* {
		syscallarg(int) shmid;
		syscallarg(const void *) shmaddr;
		syscallarg(int) shmflg;
	} */ *uap = v;
	int error, i, flags = 0;
	struct ucred *cred = p->p_ucred;
	struct shmid_ds *shmseg;
	struct shmmap_head *shmmap_h;
	struct shmmap_state *shmmap_s;
	struct shm_handle *shm_handle;
	vaddr_t attach_va;
	vm_prot_t prot;
	vsize_t size;

	shmmap_h = (struct shmmap_head *)p->p_vmspace->vm_shm;
	if (shmmap_h == NULL) {
		size = sizeof(int) +
		    shminfo.shmseg * sizeof(struct shmmap_state);
		shmmap_h = malloc(size, M_SHM, M_WAITOK);
		shmmap_h->shmseg = shminfo.shmseg;
		for (i = 0, shmmap_s = shmmap_h->state; i < shmmap_h->shmseg;
		    i++, shmmap_s++)
			shmmap_s->shmid = -1;
		p->p_vmspace->vm_shm = (caddr_t)shmmap_h;
	}
	shmseg = shm_find_segment_by_shmid(SCARG(uap, shmid));
	if (shmseg == NULL)
		return (EINVAL);
	error = ipcperm(cred, &shmseg->shm_perm,
		    (SCARG(uap, shmflg) & SHM_RDONLY) ? IPC_R : IPC_R|IPC_W);
	if (error)
		return (error);
	for (i = 0, shmmap_s = shmmap_h->state; i < shmmap_h->shmseg; i++) {
		if (shmmap_s->shmid == -1)
			break;
		shmmap_s++;
	}
	if (i >= shmmap_h->shmseg)
		return (EMFILE);
	size = round_page(shmseg->shm_segsz);
	prot = PROT_READ;
	if ((SCARG(uap, shmflg) & SHM_RDONLY) == 0)
		prot |= PROT_WRITE;
	if (SCARG(uap, shmaddr)) {
		flags |= UVM_FLAG_FIXED;
		if (SCARG(uap, shmflg) & SHM_RND) 
			attach_va =
			    (vaddr_t)SCARG(uap, shmaddr) & ~(SHMLBA-1);
		else if (((vaddr_t)SCARG(uap, shmaddr) & (SHMLBA-1)) == 0)
			attach_va = (vaddr_t)SCARG(uap, shmaddr);
		else
			return (EINVAL);
	} else
		attach_va = 0;
	shm_handle = shmseg->shm_internal;
	uao_reference(shm_handle->shm_object);
	error = uvm_map(&p->p_vmspace->vm_map, &attach_va, size,
	    shm_handle->shm_object, 0, 0, UVM_MAPFLAG(prot, prot,
	    MAP_INHERIT_SHARE, MADV_RANDOM, flags));
	if (error) {
		uao_detach(shm_handle->shm_object);
		return (error);
	}

	shmmap_s->va = attach_va;
	shmmap_s->shmid = SCARG(uap, shmid);
	shmseg->shm_lpid = p->p_p->ps_pid;
	shmseg->shm_atime = time_second;
	shmseg->shm_nattch++;
	*retval = attach_va;
	return (0);
}

int
sys_shmctl(struct proc *p, void *v, register_t *retval)
{
	struct sys_shmctl_args /* {
		syscallarg(int) shmid;
		syscallarg(int) cmd;
		syscallarg(struct shmid_ds *) buf;
	} */ *uap = v;

	return (shmctl1(p, SCARG(uap, shmid), SCARG(uap, cmd),
	    (caddr_t)SCARG(uap, buf), copyin, copyout));
}

int
shmctl1(struct proc *p, int shmid, int cmd, caddr_t buf,
    int (*ds_copyin)(const void *, void *, size_t),
    int (*ds_copyout)(const void *, void *, size_t))
{
	struct ucred *cred = p->p_ucred;
	struct shmid_ds inbuf, *shmseg;
	int error;

	shmseg = shm_find_segment_by_shmid(shmid);
	if (shmseg == NULL)
		return (EINVAL);
	switch (cmd) {
	case IPC_STAT:
		if ((error = ipcperm(cred, &shmseg->shm_perm, IPC_R)) != 0)
			return (error);
		error = ds_copyout(shmseg, buf, sizeof(inbuf));
		if (error)
			return (error);
		break;
	case IPC_SET:
		if ((error = ipcperm(cred, &shmseg->shm_perm, IPC_M)) != 0)
			return (error);
		error = ds_copyin(buf, &inbuf, sizeof(inbuf));
		if (error)
			return (error);
		shmseg->shm_perm.uid = inbuf.shm_perm.uid;
		shmseg->shm_perm.gid = inbuf.shm_perm.gid;
		shmseg->shm_perm.mode =
		    (shmseg->shm_perm.mode & ~ACCESSPERMS) |
		    (inbuf.shm_perm.mode & ACCESSPERMS);
		shmseg->shm_ctime = time_second;
		break;
	case IPC_RMID:
		if ((error = ipcperm(cred, &shmseg->shm_perm, IPC_M)) != 0)
			return (error);
		shmseg->shm_perm.key = IPC_PRIVATE;
		shmseg->shm_perm.mode |= SHMSEG_REMOVED;
		if (shmseg->shm_nattch <= 0) {
			shm_deallocate_segment(shmseg);
			shm_last_free = IPCID_TO_IX(shmid);
			shmsegs[shm_last_free] = NULL;
		}
		break;
	case SHM_LOCK:
	case SHM_UNLOCK:
	default:
		return (EINVAL);
	}
	return (0);
}

int
shmget_existing(struct proc *p,
	struct sys_shmget_args /* {
		syscallarg(key_t) key;
		syscallarg(size_t) size;
		syscallarg(int) shmflg;
	} */ *uap,
	int mode, int segnum, register_t *retval)
{
	struct shmid_ds *shmseg;
	struct ucred *cred = p->p_ucred;
	int error;

	shmseg = shmsegs[segnum];	/* We assume the segnum is valid */
	if ((error = ipcperm(cred, &shmseg->shm_perm, mode)) != 0)
		return (error);
	if (SCARG(uap, size) && SCARG(uap, size) > shmseg->shm_segsz)
		return (EINVAL);
	if ((SCARG(uap, shmflg) & (IPC_CREAT | IPC_EXCL)) ==
	    (IPC_CREAT | IPC_EXCL))
		return (EEXIST);
	*retval = IXSEQ_TO_IPCID(segnum, shmseg->shm_perm);
	return (0);
}

int
shmget_allocate_segment(struct proc *p,
	struct sys_shmget_args /* {
		syscallarg(key_t) key;
		syscallarg(size_t) size;
		syscallarg(int) shmflg;
	} */ *uap,
	int mode, register_t *retval)
{
	size_t size;
	key_t key;
	int segnum;
	struct ucred *cred = p->p_ucred;
	struct shmid_ds *shmseg;
	struct shm_handle *shm_handle;
	int error = 0;
	
	if (SCARG(uap, size) < shminfo.shmmin ||
	    SCARG(uap, size) > shminfo.shmmax)
		return (EINVAL);
	if (shm_nused >= shminfo.shmmni) /* any shmids left? */
		return (ENOSPC);
	size = round_page(SCARG(uap, size));
	if (shm_committed + atop(size) > shminfo.shmall)
		return (ENOMEM);
	shm_nused++;
	shm_committed += atop(size);

	/*
	 * If a key has been specified and we had to wait for memory
	 * to be freed up we need to verify that no one has allocated
	 * the key we want in the meantime.  Yes, this is ugly.
	 */
	key = SCARG(uap, key);
	shmseg = pool_get(&shm_pool, key == IPC_PRIVATE ? PR_WAITOK :
	    PR_NOWAIT);
	if (shmseg == NULL) {
		shmseg = pool_get(&shm_pool, PR_WAITOK);
		if (shm_find_segment_by_key(key) != -1) {
			pool_put(&shm_pool, shmseg);
			shm_nused--;
			shm_committed -= atop(size);
			return (EAGAIN);
		}
	}

	/* XXX - hash shmids instead */
	if (shm_last_free < 0) {
		for (segnum = 0; segnum < shminfo.shmmni && shmsegs[segnum];
		    segnum++)
			;
		if (segnum == shminfo.shmmni)
			panic("shmseg free count inconsistent");
	} else {
		segnum = shm_last_free;
		if (++shm_last_free >= shminfo.shmmni || shmsegs[shm_last_free])
			shm_last_free = -1;
	}
	shmsegs[segnum] = shmseg;

	shm_handle = (struct shm_handle *)((caddr_t)shmseg + sizeof(*shmseg));
	shm_handle->shm_object = uao_create(size, 0);

	shmseg->shm_perm.cuid = shmseg->shm_perm.uid = cred->cr_uid;
	shmseg->shm_perm.cgid = shmseg->shm_perm.gid = cred->cr_gid;
	shmseg->shm_perm.mode = (mode & ACCESSPERMS);
	shmseg->shm_perm.seq = shmseqs[segnum] = (shmseqs[segnum] + 1) & 0x7fff;
	shmseg->shm_perm.key = key;
	shmseg->shm_segsz = SCARG(uap, size);
	shmseg->shm_cpid = p->p_p->ps_pid;
	shmseg->shm_lpid = shmseg->shm_nattch = 0;
	shmseg->shm_atime = shmseg->shm_dtime = 0;
	shmseg->shm_ctime = time_second;
	shmseg->shm_internal = shm_handle;

	*retval = IXSEQ_TO_IPCID(segnum, shmseg->shm_perm);
	return (error);
}

int
sys_shmget(struct proc *p, void *v, register_t *retval)
{
	struct sys_shmget_args /* {
		syscallarg(key_t) key;
		syscallarg(size_t) size;
		syscallarg(int) shmflg;
	} */ *uap = v;
	int segnum, mode, error;

	mode = SCARG(uap, shmflg) & ACCESSPERMS;

	if (SCARG(uap, key) != IPC_PRIVATE) {
	again:
		segnum = shm_find_segment_by_key(SCARG(uap, key));
		if (segnum >= 0)
			return (shmget_existing(p, uap, mode, segnum, retval));
		if ((SCARG(uap, shmflg) & IPC_CREAT) == 0) 
			return (ENOENT);
	}
	error = shmget_allocate_segment(p, uap, mode, retval);
	if (error == EAGAIN)
		goto again;
	return (error);
}

void
shmfork(struct vmspace *vm1, struct vmspace *vm2)
{
	struct shmmap_head *shmmap_h;
	struct shmmap_state *shmmap_s;
	struct shmid_ds *shmseg;
	size_t size;
	int i;

	if (vm1->vm_shm == NULL) {
		vm2->vm_shm = NULL;
		return;
	}

	shmmap_h = (struct shmmap_head *)vm1->vm_shm;
	size = sizeof(int) + shmmap_h->shmseg * sizeof(struct shmmap_state);
	vm2->vm_shm = malloc(size, M_SHM, M_WAITOK);
	memcpy(vm2->vm_shm, vm1->vm_shm, size);
	for (i = 0, shmmap_s = shmmap_h->state; i < shmmap_h->shmseg;
	    i++, shmmap_s++) {
		if (shmmap_s->shmid != -1 &&
		    (shmseg = shmsegs[IPCID_TO_IX(shmmap_s->shmid)]) != NULL)
			shmseg->shm_nattch++;
	}
}

void
shmexit(struct vmspace *vm)
{
	struct shmmap_head *shmmap_h;
	struct shmmap_state *shmmap_s;
	int i;

	shmmap_h = (struct shmmap_head *)vm->vm_shm;
	if (shmmap_h == NULL)
		return;
	for (i = 0, shmmap_s = shmmap_h->state; i < shmmap_h->shmseg;
	    i++, shmmap_s++)
		if (shmmap_s->shmid != -1)
			shm_delete_mapping(vm, shmmap_s);
	free(vm->vm_shm, M_SHM, 0);
	vm->vm_shm = NULL;
}

void
shminit(void)
{

	pool_init(&shm_pool,
	    sizeof(struct shmid_ds) + sizeof(struct shm_handle), 0,
	    IPL_NONE, PR_WAITOK, "shmpl", NULL);
	shmsegs = mallocarray(shminfo.shmmni, sizeof(struct shmid_ds *),
	    M_SHM, M_WAITOK|M_ZERO);
	shmseqs = mallocarray(shminfo.shmmni, sizeof(unsigned short),
	    M_SHM, M_WAITOK|M_ZERO);

	shminfo.shmmax *= PAGE_SIZE;	/* actually in pages */
	shm_last_free = 0;
	shm_nused = 0;
	shm_committed = 0;
}

/*
 * Userland access to struct shminfo.
 */
int
sysctl_sysvshm(int *name, u_int namelen, void *oldp, size_t *oldlenp,
	void *newp, size_t newlen)
{
	int error, val;
	struct shmid_ds **newsegs;
	unsigned short *newseqs;

	if (namelen != 2) {
		switch (name[0]) {
		case KERN_SHMINFO_SHMMAX:
		case KERN_SHMINFO_SHMMIN:
		case KERN_SHMINFO_SHMMNI:
		case KERN_SHMINFO_SHMSEG:
		case KERN_SHMINFO_SHMALL:
			break;
		default:
                        return (ENOTDIR);       /* overloaded */
                }
        }

	switch (name[0]) {
	case KERN_SHMINFO_SHMMAX:
		if ((error = sysctl_int(oldp, oldlenp, newp, newlen,
		    &shminfo.shmmax)) || newp == NULL)
			return (error);

		/* If new shmmax > shmall, crank shmall */
		if (atop(round_page(shminfo.shmmax)) > shminfo.shmall)
			shminfo.shmall = atop(round_page(shminfo.shmmax));
		return (0);
	case KERN_SHMINFO_SHMMIN:
		val = shminfo.shmmin;
		if ((error = sysctl_int(oldp, oldlenp, newp, newlen, &val)) ||
		    val == shminfo.shmmin)
			return (error);
		if (val <= 0)
			return (EINVAL);	/* shmmin must be >= 1 */
		shminfo.shmmin = val;
		return (0);
	case KERN_SHMINFO_SHMMNI:
		val = shminfo.shmmni;
		if ((error = sysctl_int(oldp, oldlenp, newp, newlen, &val)) ||
		    val == shminfo.shmmni)
			return (error);

		if (val < shminfo.shmmni || val > 0xffff)
			return (EINVAL);

		/* Expand shmsegs and shmseqs arrays */
		newsegs = mallocarray(val, sizeof(struct shmid_ds *),
		    M_SHM, M_WAITOK|M_ZERO);
		memcpy(newsegs, shmsegs,
		    shminfo.shmmni * sizeof(struct shmid_ds *));
		free(shmsegs, M_SHM, 0);
		shmsegs = newsegs;
		newseqs = mallocarray(val, sizeof(unsigned short), M_SHM,
		    M_WAITOK|M_ZERO);
		memcpy(newseqs, shmseqs,
		    shminfo.shmmni * sizeof(unsigned short));
		free(shmseqs, M_SHM, shminfo.shmmni * sizeof(unsigned short));
		shmseqs = newseqs;
		shminfo.shmmni = val;
		return (0);
	case KERN_SHMINFO_SHMSEG:
		val = shminfo.shmseg;
		if ((error = sysctl_int(oldp, oldlenp, newp, newlen, &val)) ||
		    val == shminfo.shmseg)
			return (error);
		if (val <= 0)
			return (EINVAL);	/* shmseg must be >= 1 */
		shminfo.shmseg = val;
		return (0);
	case KERN_SHMINFO_SHMALL:
		val = shminfo.shmall;
		if ((error = sysctl_int(oldp, oldlenp, newp, newlen, &val)) ||
		    val == shminfo.shmall)
			return (error);
		if (val < shminfo.shmall)
			return (EINVAL);	/* can't decrease shmall */
		shminfo.shmall = val;
		return (0);
	default:
		return (EOPNOTSUPP);
	}
	/* NOTREACHED */
}
@


1.68
log
@pool_setipl

ok natano@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.67 2015/10/07 14:49:04 deraadt Exp $	*/
d526 3
a528 3
	pool_init(&shm_pool, sizeof(struct shmid_ds) +
	    sizeof(struct shm_handle), 0, 0, PR_WAITOK, "shmpl", NULL);
	pool_setipl(&shm_pool, IPL_NONE);
@


1.67
log
@easy free sizes; ok mpi
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.66 2015/03/14 03:38:50 jsg Exp $	*/
d528 1
@


1.66
log
@Remove some includes include-what-you-use claims don't
have any direct symbols used.  Tested for indirect use by compiling
amd64/i386/sparc64 kernels.

ok tedu@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.65 2015/01/15 20:36:17 millert Exp $	*/
d602 1
a602 1
		free(shmseqs, M_SHM, 0);
@


1.65
log
@The flags variable in shmat was not actually used.  We need UVM_FLAG_*
flags, not mmap-style flags for UVM_MAPFLAG().  Remove the nonsensical
MAP_ANON|MAP_SHARED value and convert MAP_FIXED to UVM_FLAG_FIXED.
OK guenther@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.64 2014/12/19 05:59:21 tedu Exp $	*/
a53 1
#include <sys/kernel.h>
@


1.64
log
@start retiring the nointr allocator. specify PR_WAITOK as a flag as a
marker for which pools are not interrupt safe. ok dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.63 2014/12/17 06:58:11 guenther Exp $	*/
d215 1
a215 1
	int error, i, flags;
a253 1
	flags = MAP_ANON | MAP_SHARED;
d255 1
a255 1
		flags |= MAP_FIXED;
d269 1
a269 1
	    MAP_INHERIT_SHARE, MADV_RANDOM, 0));
@


1.63
log
@Prefer MADV_* over POSIX_MADV_* in kernel for consistency: the latter
doesn't have all the values and therefore can't be used everywhere.

ok deraadt@@ kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.62 2014/12/15 02:24:23 guenther Exp $	*/
d529 1
a529 2
	    sizeof(struct shm_handle), 0, 0, 0, "shmpl",
	    &pool_allocator_nointr);
@


1.62
log
@Use MAP_INHERIT_* for the 'inh' argument to the UMV_MAPFLAG() macro,
eliminating the must-be-kept-in-sync UVM_INH_* macros

ok deraadt@@ tedu@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.61 2014/12/10 02:44:47 tedu Exp $	*/
d270 1
a270 1
	    MAP_INHERIT_SHARE, POSIX_MADV_RANDOM, 0));
@


1.61
log
@convert bcopy to memcpy. ok millert
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.60 2014/12/09 07:05:06 doug Exp $	*/
d270 1
a270 1
	    UVM_INH_SHARE, POSIX_MADV_RANDOM, 0));
@


1.60
log
@More malloc() -> mallocarray() in the kernel.

ok deraadt@@ tedu@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.59 2014/11/16 12:31:00 deraadt Exp $	*/
d497 1
a497 1
	bcopy(vm1->vm_shm, vm2->vm_shm, size);
d597 1
a597 1
		bcopy(shmsegs, newsegs,
d603 1
a603 1
		bcopy(shmseqs, newseqs,
@


1.59
log
@Replace a plethora of historical protection options with just
PROT_NONE, PROT_READ, PROT_WRITE, and PROT_EXEC from mman.h.
PROT_MASK is introduced as the one true way of extracting those bits.
Remove UVM_ADV_* wrapper, using the standard names.
ok doug guenther kettenis
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.58 2014/07/13 15:29:04 tedu Exp $	*/
d531 1
a531 1
	shmsegs = malloc(shminfo.shmmni * sizeof(struct shmid_ds *),
d533 1
a533 1
	shmseqs = malloc(shminfo.shmmni * sizeof(unsigned short),
@


1.58
log
@use mallocarray where arguments are multipled. ok deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.57 2014/07/12 18:43:32 tedu Exp $	*/
d251 1
a251 1
	prot = VM_PROT_READ;
d253 1
a253 1
		prot |= VM_PROT_WRITE;
d270 1
a270 1
	    UVM_INH_SHARE, UVM_ADV_RANDOM, 0));
@


1.57
log
@add a size argument to free. will be used soon, but for now default to 0.
after discussions with beck deraadt kettenis.
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.56 2014/03/18 06:59:00 guenther Exp $	*/
d595 1
a595 1
		newsegs = malloc(val * sizeof(struct shmid_ds *),
d601 1
a601 1
		newseqs = malloc(val * sizeof(unsigned short), M_SHM,
@


1.56
log
@In prep for killing ps_mainproc, use pr->ps_pid instead of
pr->ps_mainproc->p_pid to get the PID.

ok matthew@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.55 2012/03/09 13:01:28 ariane Exp $	*/
d520 1
a520 1
	free(vm->vm_shm, M_SHM);
d599 1
a599 1
		free(shmsegs, M_SHM);
d605 1
a605 1
		free(shmseqs, M_SHM);
@


1.55
log
@New vmmap implementation.

no oks (it is really a pain to review properly)
extensively tested, I'm confident it'll be stable
'now is the time' from several icb inhabitants

Diff provides:
- ability to specify different allocators for different regions/maps
- a simpler implementation of the current allocator
- currently in compatibility mode: it will generate similar addresses
  as the old allocator
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.54 2011/10/27 07:56:28 robert Exp $	*/
d278 1
a278 1
	shmseg->shm_lpid = p->p_p->ps_mainproc->p_pid;
d444 1
a444 1
	shmseg->shm_cpid = p->p_p->ps_mainproc->p_pid;
@


1.54
log
@Allow segments to be used even after they were marked for deletion with
the IPC_RMID flag.
This is permitted as an extension beyond the standards and this is similar
to what other operating systems like linux do.

Because compat_linux(8) was emulating this already, remove that code
since now this is the default.

input from oga@@, guenther@@, jmc@@, deraadt@@
ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.53 2011/06/06 17:10:23 ariane Exp $	*/
d264 2
a265 4
	} else {
		/* This is just a hint to uvm_map() about where to put it. */
		attach_va = uvm_map_hint(p, prot);
	}
@


1.53
log
@Backout vmmap in order to repair virtual address selection algorithms
outside the tree.
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.52 2011/05/24 15:27:36 ariane Exp $	*/
a91 1
#define	SHMSEG_RMLINGER		0x0400
a141 2
	if ((shmseg->shm_perm.mode & (SHMSEG_REMOVED|SHMSEG_RMLINGER)) == SHMSEG_REMOVED)
		return (NULL);
d165 1
a165 1
	
d442 1
a442 1
	shmseg->shm_perm.mode = (mode & (ACCESSPERMS|SHMSEG_RMLINGER));
a466 2
	if (SCARG(uap, shmflg) & _SHM_RMLINGER)
		mode |= SHMSEG_RMLINGER;
@


1.52
log
@Reimplement uvm/uvm_map.

vmmap is designed to perform address space randomized allocations,
without letting fragmentation of the address space go through the roof.

Some highlights:
- kernel address space randomization
- proper implementation of guardpages
- roughly 10% system time reduction during kernel build

Tested by alot of people on tech@@ and developers.
Theo's machines are still happy.
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.51 2010/07/03 03:04:55 tedu Exp $	*/
d267 3
@


1.51
log
@explicitly specify flags to malloc and pool_get instead of relying on 0.
This is more clear, and as thib pointed out, the default in softraid was
wrong.  ok thib.
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.50 2009/06/02 12:11:16 guenther Exp $	*/
a266 3
	} else {
		/* This is just a hint to uvm_map() about where to put it. */
		attach_va = uvm_map_hint(p, prot);
@


1.50
log
@msgctl(), shmctl(), semctl() all have operations that are supposed
to return pids, not thread ids, so record the former when performing
operations.

ok blambert
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.49 2007/09/15 10:10:37 martin Exp $	*/
d414 2
a415 1
	shmseg = pool_get(&shm_pool, key == IPC_PRIVATE ? PR_WAITOK : 0);
@


1.49
log
@replace ctob and btoc with ptoa and atop respectively

help and ok miod@@ thib@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.48 2007/09/07 15:00:20 art Exp $	*/
d283 1
a283 1
	shmseg->shm_lpid = p->p_pid;
d448 1
a448 1
	shmseg->shm_cpid = p->p_pid;
@


1.48
log
@Use M_ZERO in a few more places to shave bytes from the kernel.

eyeballed and ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.47 2007/05/29 10:44:28 sturm Exp $	*/
d158 1
a158 1
	shm_committed -= btoc(size);
d403 1
a403 1
	if (shm_committed + btoc(size) > shminfo.shmall)
d406 1
a406 1
	shm_committed += btoc(size);
d420 1
a420 1
			shm_committed -= btoc(size);
d579 2
a580 2
		if (btoc(round_page(shminfo.shmmax)) > shminfo.shmall)
			shminfo.shmall = btoc(round_page(shminfo.shmmax));
@


1.47
log
@adapt from netbsd:
fold sys_shmat1() back into sys_shmat(), instead add flag for shmget(2)
to specify that later shmat(2) for the shared memory segment should succeed
even if the segment would be marked removed; use this to implement the
Linux-compatible semantics of shmat(2)

this fixes current opera with shm

ok millert
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.46 2004/07/15 11:24:46 millert Exp $	*/
d538 1
a538 2
	    M_SHM, M_WAITOK);
	bzero(shmsegs, shminfo.shmmni * sizeof(struct shmid_ds *));
d540 1
a540 2
	    M_SHM, M_WAITOK);
	bzero(shmseqs, shminfo.shmmni * sizeof(unsigned short));
d602 1
a602 1
		    M_SHM, M_WAITOK);
a604 2
		bzero(newsegs + shminfo.shmmni,
		    (val - shminfo.shmmni) * sizeof(struct shmid_ds *));
d607 2
a608 1
		newseqs = malloc(val * sizeof(unsigned short), M_SHM, M_WAITOK);
a610 2
		bzero(newseqs + shminfo.shmmni,
		    (val - shminfo.shmmni) * sizeof(unsigned short));
@


1.46
log
@Rename structs oipc_perm, omsqid_ds, osemid_ds, oshmid_ds to ipc_perm23,
etc to avoid confusion and for consistency with the *35 ones.
Remove *n2o functions that don't belong outside of compat.
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.45 2004/07/14 23:40:27 millert Exp $	*/
d76 1
a76 1
struct shmid_ds *shm_find_segment_by_shmid(int, int);
d92 1
d133 1
a133 1
shm_find_segment_by_shmid(int shmid, int findremoved)
d143 1
a143 1
	if (!findremoved && (shmseg->shm_perm.mode & SHMSEG_REMOVED))
a212 6
	return (sys_shmat1(p, v, retval, 0));
}

int
sys_shmat1(struct proc *p, void *v, register_t *retval, int findremoved)
{
d239 1
a239 1
	shmseg = shm_find_segment_by_shmid(SCARG(uap, shmid), findremoved);
d312 1
a312 1
	shmseg = shm_find_segment_by_shmid(shmid, 1);
d444 1
a444 1
	shmseg->shm_perm.mode = (mode & ACCESSPERMS);
d469 3
@


1.45
log
@Move the guts of the {sem,msg,shm}ctl system calls into a new function
which also takes two function pointers for copyin/copyout.  For the
real syscalls these are just the normal copyin/copyout functions.
For the compat routines, these are funtions that convert between
the new and old foo_ds structs automagically.  OK deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.44 2004/06/21 23:50:36 tholo Exp $	*/
a549 15
}

void
shmid_n2o(struct shmid_ds *n, struct oshmid_ds *o)
{

	o->shm_segsz = n->shm_segsz;
	o->shm_lpid = n->shm_lpid;
	o->shm_cpid = n->shm_cpid;
	o->shm_nattch = n->shm_nattch;
	o->shm_atime = n->shm_atime;
	o->shm_dtime = n->shm_dtime;
	o->shm_ctime = n->shm_ctime;
	o->shm_internal = n->shm_internal;
	ipc_n2o(&n->shm_perm, &o->shm_perm);
@


1.44
log
@First step towards more sane time handling in the kernel -- this changes
things such that code that only need a second-resolution uptime or wall
time, and used to get that from time.tv_secs or mono_time.tv_secs now get
this from separate time_t globals time_second and time_uptime.

ok art@@ niklas@@ nordin@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.43 2004/05/03 17:38:48 millert Exp $	*/
d303 12
a315 3
	struct ucred *cred = p->p_ucred;
	struct shmid_ds inbuf;
	struct shmid_ds *shmseg;
d317 1
a317 1
	shmseg = shm_find_segment_by_shmid(SCARG(uap, shmid), 1);
d320 1
a320 1
	switch (SCARG(uap, cmd)) {
d324 1
a324 2
		error = copyout((caddr_t)shmseg, SCARG(uap, buf),
				sizeof(inbuf));
d331 1
a331 2
		error = copyin(SCARG(uap, buf), (caddr_t)&inbuf,
		    sizeof(inbuf));
d348 1
a348 1
			shm_last_free = IPCID_TO_IX(SCARG(uap, shmid));
@


1.43
log
@POSIX says the length parameter for semop(2) and shmget(2) should be size_t.
Create new syscalls with the correct parameters and add compat versions
for the old ones under COMPAT_35.
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.42 2004/04/16 17:55:13 tedu Exp $	*/
d175 1
a175 1
	shmseg->shm_dtime = time.tv_sec;
d289 1
a289 1
	shmseg->shm_atime = time.tv_sec;
d332 1
a332 1
		shmseg->shm_ctime = time.tv_sec;
d449 1
a449 1
	shmseg->shm_ctime = time.tv_sec;
@


1.42
log
@not a pasto.  ok millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.41 2004/02/05 21:13:58 millert Exp $	*/
d387 1
d389 1
a389 1
	int segnum, size;
d461 1
a461 1
		syscallarg(int) size;
@


1.41
log
@Correct a reference counting bug in shmat(2); adapted from FreeBSD.
OK deraadt@@ tedu@@ dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.40 2003/12/22 00:35:57 millert Exp $	*/
d618 2
d625 1
a625 1
		free(shmsegs, M_SHM);
@


1.41.2.1
log
@MFC:
Fix by tedu@@

not a pasto.

ok deraadt@@ millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.41 2004/02/05 21:13:58 millert Exp $	*/
a617 2
		free(shmsegs, M_SHM);
		shmsegs = newsegs;
d623 1
a623 1
		free(shmseqs, M_SHM);
@


1.40
log
@Remove duplicated code (pasto)
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.39 2003/10/12 23:44:39 millert Exp $	*/
d281 2
a282 1
	if (error)
d284 1
@


1.39
log
@Linux shmat allows lookup of segments that are marked as removed so
our Linux compat should too.  From marius aamodt eriksen
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.38 2003/08/21 05:20:07 kevlo Exp $	*/
a621 2
		free(shmseqs, M_SHM);
		shmsegs = newsegs;
@


1.38
log
@sys/types.h is not really needed with sys/param.h; ok mickey@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.37 2003/06/17 21:56:25 millert Exp $	*/
d212 6
d244 1
a244 1
	shmseg = shm_find_segment_by_shmid(SCARG(uap, shmid), 0);
@


1.38.2.1
log
@MFC:
Fix by millert@@

Correct a reference counting bug in shmat(2); adapted from FreeBSD.

ok millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.38 2003/08/21 05:20:07 kevlo Exp $	*/
d275 1
a275 2
	if (error) {
		uao_detach(shm_handle->shm_object);
a276 1
	}
@


1.37
log
@Sync with share/misc/license.template and add missing DARPA credit
where applicable.
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.36 2003/06/03 01:52:41 millert Exp $	*/
a52 1
#include <sys/types.h>
@


1.36
log
@Use an ISC-tyle license for all my code; it is simpler and more permissive.
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.35 2003/05/12 00:48:52 jason Exp $	*/
d11 11
a21 7
 * THE SOFTWARE IS PROVIDED "AS IS" AND TODD C. MILLER DISCLAIMS ALL
 * WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES
 * OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL TODD C. MILLER BE LIABLE
 * FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
 * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
 * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
@


1.35
log
@Nuke a whole bunch of commons; ok tedu (still more to come *sigh*)
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.34 2003/04/14 04:53:50 art Exp $	*/
a5 1
 * All rights reserved.
d7 3
a9 10
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. The name of the author may not be used to endorse or promote products
 *    derived from this software without specific prior written permission.
d11 7
a17 10
 * THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES,
 * INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY
 * AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL
 * THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;
 * OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
 * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
 * OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF
 * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
@


1.34
log
@There are two related changes.

The first one is an mquery(2) syscall. It's for asking the VM system
about where to map things. It will be used by ld.so, read the man page
for details.

The second change is related and is a centralization of uvm_map hint
that all callers of uvm_map calculated. This will allow us to adjust
this hint on architectures that have segments for non-exec mappings.

deraadt@@ drahn@@ ok.
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.33 2003/01/07 00:34:41 millert Exp $	*/
d79 1
a79 1
struct shminfo shminfo;
@


1.33
log
@xerxes [/home/src/local/millert/sudo/sudo-1.6.7] % vi /usr/src/local/TiVo/Linux/Don't allow s{e,h}mmni to be set > 0xffff via sysctl since that could
cause id collisions (the macros in <sys/ipc.h> limit the index to 0xffff).
Prompted by a conversation with weingart@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.32 2003/01/06 20:11:28 millert Exp $	*/
d276 1
a276 2
		attach_va = round_page((vaddr_t)p->p_vmspace->vm_taddr +
		    MAXTSIZ + MAXDSIZ);
@


1.33.2.1
log
@MFC:
Fix by millert@@

Correct a reference counting bug in shmat(2); adapted from FreeBSD.

ok millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.33 2003/01/07 00:34:41 millert Exp $	*/
d284 1
a284 2
	if (error) {
		uao_detach(shm_handle->shm_object);
a285 1
	}
@


1.32
log
@Add a "findremoved" arg to shm_find_segment_by_shmid() similar to
NetBSD and allow shmctl() to operate on shm segments that have been
marked for removal like other OSes do.
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.31 2002/12/17 23:32:31 millert Exp $	*/
d609 2
a610 2
		if (val < shminfo.shmmni)
			return (EINVAL);	/* can't decrease shmmni */
@


1.31
log
@Add my copyright notice.
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.30 2002/12/17 23:11:31 millert Exp $	*/
d84 1
a84 1
struct shmid_ds *shm_find_segment_by_shmid(int);
d140 1
a140 1
shm_find_segment_by_shmid(int shmid)
d147 2
a148 1
	    (shmseg = shmsegs[segnum]) == NULL)
d150 1
a150 2
	if ((shmseg->shm_perm.mode & SHMSEG_REMOVED) ||
	    shmseg->shm_perm.seq != IPCID_TO_SEQ(shmid))
d246 1
a246 1
	shmseg = shm_find_segment_by_shmid(SCARG(uap, shmid));
d309 1
a309 1
	shmseg = shm_find_segment_by_shmid(SCARG(uap, shmid));
@


1.30
log
@Make SysV-style shared memory and semaphore limits sysctl'able.
Instead of allocating a static amount of memory for the data
structures via valloc() in allocsys(), allocate things dynamically
using pool(9) when possible and malloc(9) when not.  The various
members of struct seminfo and struct shminfo are in kern.seminfo
and kern.shminfo respectively (not all members of kern.seminfo are
changable).

The data structures used still leave something to be desired but
things are not made worse in that respect by this commit.
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.29 2002/11/06 00:17:28 art Exp $	*/
d4 26
@


1.29
log
@Eliminate the use of KERN_SUCCESS outside of uvm/

Also uvm_map returns KERN_* codes that are directly mapped to
errnos, so we can return them instead of doing some attempt to
translation.

drahn@@ "I see no problem" pval@@ "makes sense"
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.28 2002/10/29 18:30:21 art Exp $	*/
d43 1
d45 1
d54 3
a56 1
struct shmid_ds *shmsegs;
d69 2
a70 2
 * shmsegs (an array of 'struct shmid_ds')
 * per proc array of 'struct shmmap_state'
d73 1
a73 4
#define	SHMSEG_FREE		0x0200
#define	SHMSEG_REMOVED  	0x0400
#define	SHMSEG_ALLOCATED	0x0800
#define	SHMSEG_WANTED		0x1000
d86 5
d100 1
a100 2
shm_find_segment_by_key(key)
	key_t key;
d102 1
d105 6
a110 5
	for (i = 0; i < shminfo.shmmni; i++)
		if ((shmsegs[i].shm_perm.mode & SHMSEG_ALLOCATED) &&
		    shmsegs[i].shm_perm.key == key)
			return i;
	return -1;
d114 1
a114 2
shm_find_segment_by_shmid(shmid)
	int shmid;
d120 4
a123 5
	if (segnum < 0 || segnum >= shminfo.shmmni)
		return NULL;
	shmseg = &shmsegs[segnum];
	if ((shmseg->shm_perm.mode & (SHMSEG_ALLOCATED | SHMSEG_REMOVED))
	    != SHMSEG_ALLOCATED ||
d125 2
a126 2
		return NULL;
	return shmseg;
d130 1
a130 2
shm_deallocate_segment(shmseg)
	struct shmid_ds *shmseg;
d138 1
a138 2
	free((caddr_t)shm_handle, M_SHM);
	shmseg->shm_internal = NULL;
a139 1
	shmseg->shm_perm.mode = SHMSEG_FREE;
d144 1
a144 3
shm_delete_mapping(vm, shmmap_s)
	struct vmspace *vm;
	struct shmmap_state *shmmap_s;
d151 3
a153 1
	shmseg = &shmsegs[segnum];
d162 1
d164 1
a164 1
	return 0;
d168 1
a168 4
sys_shmdt(p, v, retval)
	struct proc *p;
	void *v;
	register_t *retval;
d173 1
d177 3
a179 3
	shmmap_s = (struct shmmap_state *)p->p_vmspace->vm_shm;
	if (shmmap_s == NULL)
		return EINVAL;
d181 2
a182 1
	for (i = 0; i < shminfo.shmseg; i++, shmmap_s++)
d186 3
a188 3
	if (i == shminfo.shmseg)
		return EINVAL;
	return shm_delete_mapping(p->p_vmspace, shmmap_s);
d192 1
a192 4
sys_shmat(p, v, retval)
	struct proc *p;
	void *v;
	register_t *retval;
d202 2
a203 1
	struct shmmap_state *shmmap_s = NULL;
d209 10
a218 7
	shmmap_s = (struct shmmap_state *)p->p_vmspace->vm_shm;
	if (shmmap_s == NULL) {
		size = shminfo.shmseg * sizeof(struct shmmap_state);
		shmmap_s = malloc(size, M_SHM, M_WAITOK);
		for (i = 0; i < shminfo.shmseg; i++)
			shmmap_s[i].shmid = -1;
		p->p_vmspace->vm_shm = (caddr_t)shmmap_s;
d222 1
a222 1
		return EINVAL;
d226 2
a227 2
		return error;
	for (i = 0; i < shminfo.shmseg; i++) {
d232 2
a233 2
	if (i >= shminfo.shmseg)
		return EMFILE;
d247 1
a247 1
			return EINVAL;
d267 1
a267 1
	return 0;
d271 1
a271 4
sys_shmctl(p, v, retval)
	struct proc *p;
	void *v;
	register_t *retval;
d285 1
a285 1
		return EINVAL;
d289 1
a289 1
			return error;
d293 1
a293 1
			return error;
d297 1
a297 1
			return error;
d301 1
a301 1
			return error;
d311 1
a311 1
			return error;
d317 1
d323 1
a323 1
		return EINVAL;
d325 1
a325 1
	return 0;
d329 1
a329 2
shmget_existing(p, uap, mode, segnum, retval)
	struct proc *p;
d334 2
a335 4
	} */ *uap;
	int mode;
	int segnum;
	register_t *retval;
d341 1
a341 13
	shmseg = &shmsegs[segnum];
	if (shmseg->shm_perm.mode & SHMSEG_REMOVED) {
		/*
		 * This segment is in the process of being allocated.  Wait
		 * until it's done, and look the key up again (in case the
		 * allocation failed or it was freed).
		 */
		shmseg->shm_perm.mode |= SHMSEG_WANTED;
		error = tsleep((caddr_t)shmseg, PLOCK | PCATCH, "shmget", 0);
		if (error)
			return error;
		return EAGAIN;
	}
d343 1
a343 1
		return error;
d345 1
a345 1
		return EINVAL;
d348 1
a348 1
		return EEXIST;
d350 1
a350 1
	return 0;
d354 1
a354 2
shmget_allocate_segment(p, uap, mode, retval)
	struct proc *p;
d359 2
a360 3
	} */ *uap;
	int mode;
	register_t *retval;
d362 2
a363 1
	int i, segnum, shmid, size;
d371 1
a371 1
		return EINVAL;
d373 1
a373 1
		return ENOSPC;
d376 22
a397 1
		return ENOMEM;
d399 4
a402 4
		for (i = 0; i < shminfo.shmmni; i++)
			if (shmsegs[i].shm_perm.mode & SHMSEG_FREE)
				break;
		if (i == shminfo.shmmni)
d404 1
a404 2
		segnum = i;
	} else  {
d406 2
a407 1
		shm_last_free = -1;
d409 1
a409 12
	shmseg = &shmsegs[segnum];
	/*
	 * In case we sleep in malloc(), mark the segment present but deleted
	 * so that noone else tries to create the same key.
	 */
	shmseg->shm_perm.mode = SHMSEG_ALLOCATED | SHMSEG_REMOVED;
	shmseg->shm_perm.key = SCARG(uap, key);
	shmseg->shm_perm.seq = (shmseg->shm_perm.seq + 1) & 0x7fff;
	shm_handle = (struct shm_handle *)
	    malloc(sizeof(struct shm_handle), M_SHM, M_WAITOK);
	shmid = IXSEQ_TO_IPCID(segnum, shmseg->shm_perm);
	
d411 1
a413 1
	shmseg->shm_internal = shm_handle;
d416 3
a418 2
	shmseg->shm_perm.mode = (shmseg->shm_perm.mode & SHMSEG_WANTED) |
	    (mode & ACCESSPERMS) | SHMSEG_ALLOCATED;
d424 1
a424 2
	shm_committed += btoc(size);
	shm_nused++;
d426 2
a427 10
	*retval = shmid;
	if (shmseg->shm_perm.mode & SHMSEG_WANTED) {
		/*
		 * Somebody else wanted this key while we were asleep.  Wake
		 * them up now.
		 */
		shmseg->shm_perm.mode &= ~SHMSEG_WANTED;
		wakeup((caddr_t)shmseg);
	}
	return error;
d431 1
a431 4
sys_shmget(p, v, retval)
	struct proc *p;
	void *v;
	register_t *retval;
d444 2
a445 6
		if (segnum >= 0) {
			error = shmget_existing(p, uap, mode, segnum, retval);
			if (error == EAGAIN)
				goto again;
			return error;
		}
d447 1
a447 1
			return ENOENT;
d449 4
a452 1
	return shmget_allocate_segment(p, uap, mode, retval);
d456 1
a456 2
shmfork(vm1, vm2)
	struct vmspace *vm1, *vm2;
d458 1
d460 1
d469 10
a478 7
	size = shminfo.shmseg * sizeof(struct shmmap_state);
	shmmap_s = malloc(size, M_SHM, M_WAITOK);
	bcopy(vm1->vm_shm, shmmap_s, size);
	vm2->vm_shm = (caddr_t)shmmap_s;
	for (i = 0; i < shminfo.shmseg; i++, shmmap_s++)
		if (shmmap_s->shmid != -1)
			shmsegs[IPCID_TO_IX(shmmap_s->shmid)].shm_nattch++;
d482 1
a482 2
shmexit(vm)
	struct vmspace *vm;
d484 1
d488 2
a489 2
	shmmap_s = (struct shmmap_state *)vm->vm_shm;
	if (shmmap_s == NULL)
d491 2
a492 1
	for (i = 0; i < shminfo.shmseg; i++, shmmap_s++)
d500 1
a500 1
shminit()
a501 1
	int i;
d503 9
a511 1
	shminfo.shmmax *= PAGE_SIZE;
d513 1
a513 4
	for (i = 0; i < shminfo.shmmni; i++) {
		shmsegs[i].shm_perm.mode = SHMSEG_FREE;
		shmsegs[i].shm_perm.seq = 0;
	}
d520 1
a520 3
shmid_n2o(n, o)
	struct shmid_ds *n;
	struct oshmid_ds *o;
d522 1
d532 94
@


1.28
log
@Since memory deallocation can't fail, remove the error return from
uvm_unmap, uvm_deallocate and a few other functions.
Simplifies some code and reduces diff to the UBC branch.
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.27 2002/07/16 23:06:05 art Exp $	*/
a207 1
	int rv;
d252 1
a252 1
	rv = uvm_map(&p->p_vmspace->vm_map, &attach_va, size,
d255 2
a256 3
	if (rv != KERN_SUCCESS) {
		return ENOMEM;
	}
@


1.27
log
@minor formatting.
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.26 2002/07/12 01:42:54 art Exp $	*/
d147 1
a147 1
	int segnum, result;
d153 1
a153 3
	result = uvm_deallocate(&vm->vm_map, shmmap_s->va, size);
	if (result != KERN_SUCCESS)
		return EINVAL;
@


1.26
log
@Fix vm -> uvm in a comment.
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.25 2002/03/14 01:27:05 millert Exp $	*/
d259 1
a259 1
	    return ENOMEM;
@


1.25
log
@First round of __P removal in sys
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.24 2001/12/19 08:58:06 art Exp $	*/
d249 1
a249 1
		/* This is just a hint to vm_mmap() about where to put it. */
@


1.24
log
@UBC was a disaster. It worked very good when it worked, but on some
machines or some configurations or in some phase of the moon (we actually
don't know when or why) files disappeared. Since we've not been able to
track down the problem in two weeks intense debugging and we need -current
to be stable, back out everything to a state it had before UBC.

We apologise for the inconvenience.
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.23 2001/11/28 13:47:39 art Exp $	*/
d54 1
a54 1
struct shmid_ds *shm_find_segment_by_shmid __P((int));
d85 7
a91 7
int shm_find_segment_by_key __P((key_t));
void shm_deallocate_segment __P((struct shmid_ds *));
int shm_delete_mapping __P((struct vmspace *, struct shmmap_state *));
int shmget_existing __P((struct proc *, struct sys_shmget_args *,
			 int, int, register_t *));
int shmget_allocate_segment __P((struct proc *, struct sys_shmget_args *,
				 int, register_t *));
@


1.23
log
@Sync in more uvm changes from NetBSD.
This time we're getting rid of KERN_* and VM_PAGER_* error codes and
use errnos instead.
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.22 2001/11/07 01:18:01 art Exp $	*/
d147 1
a147 1
	int segnum;
d153 3
a155 1
	uvm_deallocate(&vm->vm_map, shmmap_s->va, size);
d210 1
d255 1
a255 1
	error = uvm_map(&p->p_vmspace->vm_map, &attach_va, size,
d258 2
a259 2
	if (error) {
		return error;
@


1.23.2.1
log
@Sync UBC branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.23 2001/11/28 13:47:39 art Exp $	*/
d54 1
a54 1
struct shmid_ds *shm_find_segment_by_shmid(int);
d85 7
a91 7
int shm_find_segment_by_key(key_t);
void shm_deallocate_segment(struct shmid_ds *);
int shm_delete_mapping(struct vmspace *, struct shmmap_state *);
int shmget_existing(struct proc *, struct sys_shmget_args *,
			 int, int, register_t *);
int shmget_allocate_segment(struct proc *, struct sys_shmget_args *,
				 int, register_t *);
@


1.23.2.2
log
@sync to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.23.2.1 2002/06/11 03:29:40 art Exp $	*/
d246 1
a246 1
		/* This is just a hint to uvm_map() about where to put it. */
@


1.23.2.3
log
@sync
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
a4 26
 * Copyright (c) 2002 Todd C. Miller <Todd.Miller@@courtesan.com>
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. The name of the author may not be used to endorse or promote products
 *    derived from this software without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES,
 * INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY
 * AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL
 * THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;
 * OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
 * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
 * OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF
 * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */
/*
a42 1
#include <sys/pool.h>
a43 1
#include <sys/sysctl.h>
d51 2
a52 4
extern struct shminfo shminfo;
struct shmid_ds **shmsegs;	/* linear mapping of shmid -> shmseg */
struct pool shm_pool;
unsigned short *shmseqs;	/* array of shm sequence numbers */
d54 1
a54 1
struct shmid_ds *shm_find_segment_by_shmid(int, int);
d65 2
a66 2
 * shmsegs (an array of 'struct shmid_ds *')
 * per proc 'struct shmmap_head' with an array of 'struct shmmap_state'
d69 4
a72 1
#define	SHMSEG_REMOVED  	0x0200		/* can't overlap ACCESSPERMS */
a84 5
struct shmmap_head {
	int shmseg;
	struct shmmap_state state[1];
};

d94 2
a95 1
shm_find_segment_by_key(key_t key)
a96 1
	struct shmid_ds *shmseg;
d99 5
a103 6
	for (i = 0; i < shminfo.shmmni; i++) {
		shmseg = shmsegs[i];
		if (shmseg != NULL && shmseg->shm_perm.key == key)
			return (i);
	}
	return (-1);
d107 2
a108 1
shm_find_segment_by_shmid(int shmid, int findremoved)
d114 5
a118 2
	if (segnum < 0 || segnum >= shminfo.shmmni ||
	    (shmseg = shmsegs[segnum]) == NULL ||
d120 2
a121 4
		return (NULL);
	if (!findremoved && (shmseg->shm_perm.mode & SHMSEG_REMOVED))
		return (NULL);
	return (shmseg);
d125 2
a126 1
shm_deallocate_segment(struct shmid_ds *shmseg)
d134 2
a135 1
	pool_put(&shm_pool, shmseg);
d137 1
d142 3
a144 1
shm_delete_mapping(struct vmspace *vm, struct shmmap_state *shmmap_s)
d151 1
a151 3
	if (segnum < 0 || segnum >= shminfo.shmmni ||
	    (shmseg = shmsegs[segnum]) == NULL)
		return (EINVAL);
a159 1
		shmsegs[shm_last_free] = NULL;
d161 1
a161 1
	return (0);
d165 4
a168 1
sys_shmdt(struct proc *p, void *v, register_t *retval)
a172 1
	struct shmmap_head *shmmap_h;
d176 3
a178 3
	shmmap_h = (struct shmmap_head *)p->p_vmspace->vm_shm;
	if (shmmap_h == NULL)
		return (EINVAL);
d180 1
a180 2
	for (i = 0, shmmap_s = shmmap_h->state; i < shmmap_h->shmseg;
	    i++, shmmap_s++)
d184 3
a186 3
	if (i == shmmap_h->shmseg)
		return (EINVAL);
	return (shm_delete_mapping(p->p_vmspace, shmmap_s));
d190 4
a193 1
sys_shmat(struct proc *p, void *v, register_t *retval)
d203 1
a203 2
	struct shmmap_head *shmmap_h;
	struct shmmap_state *shmmap_s;
d209 7
a215 10
	shmmap_h = (struct shmmap_head *)p->p_vmspace->vm_shm;
	if (shmmap_h == NULL) {
		size = sizeof(int) +
		    shminfo.shmseg * sizeof(struct shmmap_state);
		shmmap_h = malloc(size, M_SHM, M_WAITOK);
		shmmap_h->shmseg = shminfo.shmseg;
		for (i = 0, shmmap_s = shmmap_h->state; i < shmmap_h->shmseg;
		    i++, shmmap_s++)
			shmmap_s->shmid = -1;
		p->p_vmspace->vm_shm = (caddr_t)shmmap_h;
d217 1
a217 1
	shmseg = shm_find_segment_by_shmid(SCARG(uap, shmid), 0);
d219 1
a219 1
		return (EINVAL);
d223 2
a224 2
		return (error);
	for (i = 0, shmmap_s = shmmap_h->state; i < shmmap_h->shmseg; i++) {
d229 2
a230 2
	if (i >= shmmap_h->shmseg)
		return (EMFILE);
d244 1
a244 1
			return (EINVAL);
d247 2
a248 1
		attach_va = uvm_map_hint(p, prot);
d255 3
a257 2
	if (error)
		return (error);
d265 1
a265 1
	return (0);
d269 4
a272 1
sys_shmctl(struct proc *p, void *v, register_t *retval)
d284 1
a284 1
	shmseg = shm_find_segment_by_shmid(SCARG(uap, shmid), 1);
d286 1
a286 1
		return (EINVAL);
d290 1
a290 1
			return (error);
d294 1
a294 1
			return (error);
d298 1
a298 1
			return (error);
d302 1
a302 1
			return (error);
d312 1
a312 1
			return (error);
a317 1
			shmsegs[shm_last_free] = NULL;
d323 1
a323 1
		return (EINVAL);
d325 1
a325 1
	return (0);
d329 2
a330 1
shmget_existing(struct proc *p,
d335 4
a338 2
	} */ *uap,
	int mode, int segnum, register_t *retval)
d344 13
a356 1
	shmseg = shmsegs[segnum];	/* We assume the segnum is valid */
d358 1
a358 1
		return (error);
d360 1
a360 1
		return (EINVAL);
d363 1
a363 1
		return (EEXIST);
d365 1
a365 1
	return (0);
d369 2
a370 1
shmget_allocate_segment(struct proc *p,
d375 3
a377 2
	} */ *uap,
	int mode, register_t *retval)
d379 1
a379 2
	key_t key;
	int segnum, size;
d387 1
a387 1
		return (EINVAL);
d389 1
a389 1
		return (ENOSPC);
d392 1
a392 22
		return (ENOMEM);
	shm_nused++;
	shm_committed += btoc(size);

	/*
	 * If a key has been specified and we had to wait for memory
	 * to be freed up we need to verify that no one has allocated
	 * the key we want in the meantime.  Yes, this is ugly.
	 */
	key = SCARG(uap, key);
	shmseg = pool_get(&shm_pool, key == IPC_PRIVATE ? PR_WAITOK : 0);
	if (shmseg == NULL) {
		shmseg = pool_get(&shm_pool, PR_WAITOK);
		if (shm_find_segment_by_key(key) != -1) {
			pool_put(&shm_pool, shmseg);
			shm_nused--;
			shm_committed -= btoc(size);
			return (EAGAIN);
		}
	}

	/* XXX - hash shmids instead */
d394 4
a397 4
		for (segnum = 0; segnum < shminfo.shmmni && shmsegs[segnum];
		    segnum++)
			;
		if (segnum == shminfo.shmmni)
d399 2
a400 1
	} else {
d402 1
a402 2
		if (++shm_last_free >= shminfo.shmmni || shmsegs[shm_last_free])
			shm_last_free = -1;
d404 12
a415 1
	shmsegs[segnum] = shmseg;
a416 1
	shm_handle = (struct shm_handle *)((caddr_t)shmseg + sizeof(*shmseg));
d419 1
d422 2
a423 3
	shmseg->shm_perm.mode = (mode & ACCESSPERMS);
	shmseg->shm_perm.seq = shmseqs[segnum] = (shmseqs[segnum] + 1) & 0x7fff;
	shmseg->shm_perm.key = key;
d429 2
a430 1
	shmseg->shm_internal = shm_handle;
d432 10
a441 2
	*retval = IXSEQ_TO_IPCID(segnum, shmseg->shm_perm);
	return (error);
d445 4
a448 1
sys_shmget(struct proc *p, void *v, register_t *retval)
d461 6
a466 2
		if (segnum >= 0)
			return (shmget_existing(p, uap, mode, segnum, retval));
d468 1
a468 1
			return (ENOENT);
d470 1
a470 4
	error = shmget_allocate_segment(p, uap, mode, retval);
	if (error == EAGAIN)
		goto again;
	return (error);
d474 2
a475 1
shmfork(struct vmspace *vm1, struct vmspace *vm2)
a476 1
	struct shmmap_head *shmmap_h;
a477 1
	struct shmid_ds *shmseg;
d486 7
a492 10
	shmmap_h = (struct shmmap_head *)vm1->vm_shm;
	size = sizeof(int) + shmmap_h->shmseg * sizeof(struct shmmap_state);
	vm2->vm_shm = malloc(size, M_SHM, M_WAITOK);
	bcopy(vm1->vm_shm, vm2->vm_shm, size);
	for (i = 0, shmmap_s = shmmap_h->state; i < shmmap_h->shmseg;
	    i++, shmmap_s++) {
		if (shmmap_s->shmid != -1 &&
		    (shmseg = shmsegs[IPCID_TO_IX(shmmap_s->shmid)]) != NULL)
			shmseg->shm_nattch++;
	}
d496 2
a497 1
shmexit(struct vmspace *vm)
a498 1
	struct shmmap_head *shmmap_h;
d502 2
a503 2
	shmmap_h = (struct shmmap_head *)vm->vm_shm;
	if (shmmap_h == NULL)
d505 1
a505 2
	for (i = 0, shmmap_s = shmmap_h->state; i < shmmap_h->shmseg;
	    i++, shmmap_s++)
d513 1
a513 1
shminit(void)
d515 1
d517 1
a517 9
	pool_init(&shm_pool, sizeof(struct shmid_ds) +
	    sizeof(struct shm_handle), 0, 0, 0, "shmpl",
	    &pool_allocator_nointr);
	shmsegs = malloc(shminfo.shmmni * sizeof(struct shmid_ds *),
	    M_SHM, M_WAITOK);
	bzero(shmsegs, shminfo.shmmni * sizeof(struct shmid_ds *));
	shmseqs = malloc(shminfo.shmmni * sizeof(unsigned short),
	    M_SHM, M_WAITOK);
	bzero(shmseqs, shminfo.shmmni * sizeof(unsigned short));
d519 4
a522 1
	shminfo.shmmax *= PAGE_SIZE;	/* actually in pages */
d529 3
a531 1
shmid_n2o(struct shmid_ds *n, struct oshmid_ds *o)
a532 1

a541 94
}

/*
 * Userland access to struct shminfo.
 */
int
sysctl_sysvshm(int *name, u_int namelen, void *oldp, size_t *oldlenp,
	void *newp, size_t newlen)
{
	int error, val;
	struct shmid_ds **newsegs;
	unsigned short *newseqs;

	if (namelen != 2) {
		switch (name[0]) {
		case KERN_SHMINFO_SHMMAX:
		case KERN_SHMINFO_SHMMIN:
		case KERN_SHMINFO_SHMMNI:
		case KERN_SHMINFO_SHMSEG:
		case KERN_SHMINFO_SHMALL:
			break;
		default:
                        return (ENOTDIR);       /* overloaded */
                }
        }

	switch (name[0]) {
	case KERN_SHMINFO_SHMMAX:
		if ((error = sysctl_int(oldp, oldlenp, newp, newlen,
		    &shminfo.shmmax)) || newp == NULL)
			return (error);

		/* If new shmmax > shmall, crank shmall */
		if (btoc(round_page(shminfo.shmmax)) > shminfo.shmall)
			shminfo.shmall = btoc(round_page(shminfo.shmmax));
		return (0);
	case KERN_SHMINFO_SHMMIN:
		val = shminfo.shmmin;
		if ((error = sysctl_int(oldp, oldlenp, newp, newlen, &val)) ||
		    val == shminfo.shmmin)
			return (error);
		if (val <= 0)
			return (EINVAL);	/* shmmin must be >= 1 */
		shminfo.shmmin = val;
		return (0);
	case KERN_SHMINFO_SHMMNI:
		val = shminfo.shmmni;
		if ((error = sysctl_int(oldp, oldlenp, newp, newlen, &val)) ||
		    val == shminfo.shmmni)
			return (error);

		if (val < shminfo.shmmni || val > 0xffff)
			return (EINVAL);

		/* Expand shmsegs and shmseqs arrays */
		newsegs = malloc(val * sizeof(struct shmid_ds *),
		    M_SHM, M_WAITOK);
		bcopy(shmsegs, newsegs,
		    shminfo.shmmni * sizeof(struct shmid_ds *));
		bzero(newsegs + shminfo.shmmni,
		    (val - shminfo.shmmni) * sizeof(struct shmid_ds *));
		newseqs = malloc(val * sizeof(unsigned short), M_SHM, M_WAITOK);
		bcopy(shmseqs, newseqs,
		    shminfo.shmmni * sizeof(unsigned short));
		bzero(newseqs + shminfo.shmmni,
		    (val - shminfo.shmmni) * sizeof(unsigned short));
		free(shmsegs, M_SHM);
		free(shmseqs, M_SHM);
		shmsegs = newsegs;
		shmseqs = newseqs;
		shminfo.shmmni = val;
		return (0);
	case KERN_SHMINFO_SHMSEG:
		val = shminfo.shmseg;
		if ((error = sysctl_int(oldp, oldlenp, newp, newlen, &val)) ||
		    val == shminfo.shmseg)
			return (error);
		if (val <= 0)
			return (EINVAL);	/* shmseg must be >= 1 */
		shminfo.shmseg = val;
		return (0);
	case KERN_SHMINFO_SHMALL:
		val = shminfo.shmall;
		if ((error = sysctl_int(oldp, oldlenp, newp, newlen, &val)) ||
		    val == shminfo.shmall)
			return (error);
		if (val < shminfo.shmall)
			return (EINVAL);	/* can't decrease shmall */
		shminfo.shmall = val;
		return (0);
	default:
		return (EOPNOTSUPP);
	}
	/* NOTREACHED */
@


1.22
log
@Add an alignment argument to uvm_map that specifies an alignment hint
for the virtual address.
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.21 2001/11/06 19:53:20 miod Exp $	*/
d147 1
a147 1
	int segnum, result;
d153 1
a153 3
	result = uvm_deallocate(&vm->vm_map, shmmap_s->va, size);
	if (result != KERN_SUCCESS)
		return EINVAL;
a207 1
	int rv;
d252 1
a252 1
	rv = uvm_map(&p->p_vmspace->vm_map, &attach_va, size,
d255 2
a256 2
	if (rv != KERN_SUCCESS) {
	    return ENOMEM;
@


1.21
log
@Replace inclusion of <vm/foo.h> with the correct <uvm/bar.h> when necessary.
(Look ma, I might have broken the tree)
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.20 2001/08/12 22:50:12 millert Exp $	*/
d256 1
a256 1
	    shm_handle->shm_object, 0, UVM_MAPFLAG(prot, prot,
@


1.20
log
@Don't allocate globals in include files, use extern declarations.
Move the actual variables into their respective .c files.
As a bonus, remove semmap which is not used.
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.19 2001/06/27 04:49:47 art Exp $	*/
a48 1
#include <vm/vm.h>
@


1.19
log
@remove old vm
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.18 2001/06/22 14:14:09 deraadt Exp $	*/
d51 3
@


1.18
log
@KNF
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.17 2001/05/16 17:14:36 millert Exp $	*/
a49 1
#ifdef UVM
a50 4
#else
#include <vm/vm_map.h>
#include <vm/vm_kern.h>
#endif
a74 1
#ifdef UVM
a75 3
#else
	vm_object_t shm_object;
#endif
a130 1
#ifdef UVM
a131 3
#else
	vm_object_deallocate(shm_handle->shm_object);
#endif
a150 1
#ifdef UVM
a151 4
#else
	result = vm_map_remove(&vm->vm_map, shmmap_s->va,
	    shmmap_s->va + size);
#endif
a251 1
#ifdef UVM
a258 12
#else
	vm_object_reference(shm_handle->shm_object);
	rv = vm_map_find(&p->p_vmspace->vm_map, shm_handle->shm_object,
		0, &attach_va, size, (flags & MAP_FIXED)?0:1);
	if (rv != KERN_SUCCESS) {
		return ENOMEM;
	}
	vm_map_protect(&p->p_vmspace->vm_map, attach_va, attach_va + size,
	    prot, 0);
	vm_map_inherit(&p->p_vmspace->vm_map,
		attach_va, attach_va + size, VM_INHERIT_SHARE);
#endif
a383 3
#ifndef UVM
	vm_pager_t pager;
#endif
a417 1
#ifdef UVM
a418 18
#else
	shm_handle->shm_object = vm_object_allocate(size);
	if (shm_handle->shm_object == NULL) {
		/* XXX cannot happen */
		error = ENOMEM;
		goto out;
	}
	/*
	 * We make sure that we have allocated a pager before we need
	 * to.
	 */
	pager = vm_pager_allocate(PG_DFLT, 0, size, VM_PROT_DEFAULT, 0);
	if (pager == NULL) {
		error = ENOMEM;
		goto out;
	}
	vm_object_setpager(shm_handle->shm_object, pager, 0, 0);
#endif
d433 1
a433 11
#ifndef UVM
out:
	if (error) {
		if (shm_handle->shm_object != NULL)
			vm_object_deallocate(shm_handle->shm_object);
		free(shm_handle, M_SHM);
		shmseg->shm_perm.mode = (shmseg->shm_perm.mode & SHMSEG_WANTED)
		    | SHMSEG_FREE;
	} else
#endif
		*retval = shmid;
@


1.17
log
@Create COMPAT_25 and move ogetfsstat, ostatfs and ostatfs into it.
Create COMPAT_23 and move __osemctl, omsgctl, oshmctl there.
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.16 2001/05/05 21:26:44 art Exp $	*/
d72 1
a72 1
#define	SHMSEG_FREE     	0x0200
d167 2
a168 2
	result = vm_map_remove(&vm->vm_map,
			       shmmap_s->va, shmmap_s->va + size);
d266 2
a267 3
		attach_va =
		    round_page((vaddr_t)p->p_vmspace->vm_taddr + MAXTSIZ +
			       MAXDSIZ);
d273 2
a274 3
		     shm_handle->shm_object, 0,
		     UVM_MAPFLAG(prot, prot, UVM_INH_SHARE,
				 UVM_ADV_RANDOM, 0));
d286 1
a286 1
		       prot, 0);
d332 1
a332 1
			       sizeof(inbuf));
@


1.16
log
@Remove the (vaddr_t) casts inside the round_page and trunc_page macros.
We might want to use them on types that are bigger than vaddr_t.

Fix all callers that pass pointers without casts.
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.15 2001/05/05 20:57:00 art Exp $	*/
d92 7
a98 7
static int shm_find_segment_by_key __P((key_t));
static void shm_deallocate_segment __P((struct shmid_ds *));
static int shm_delete_mapping __P((struct vmspace *, struct shmmap_state *));
static int shmget_existing __P((struct proc *, struct sys_shmget_args *,
				int, int, register_t *));
static int shmget_allocate_segment __P((struct proc *, struct sys_shmget_args *,
					int, register_t *));
d100 1
a100 1
static int
d131 1
a131 1
static void
d152 1
a152 1
static int
d362 1
a362 1
static int
d402 1
a402 1
static int
a607 62
}


int
sys_oshmctl(p, v, retval)
	struct proc *p;
	void *v;
	register_t *retval;
{
	struct sys_shmctl_args /* {
		syscallarg(int) shmid;
		syscallarg(int) cmd;
		syscallarg(struct shmid_ds *) buf;
	} */ *uap = v;
	int error;
	struct ucred *cred = p->p_ucred;
	struct oshmid_ds oinbuf;
	struct shmid_ds *shmseg;

	shmseg = shm_find_segment_by_shmid(SCARG(uap, shmid));
	if (shmseg == NULL)
		return EINVAL;
	switch (SCARG(uap, cmd)) {
	case IPC_STAT:
		if ((error = ipcperm(cred, &shmseg->shm_perm, IPC_R)) != 0)
			return error;
		shmid_n2o(shmseg, &oinbuf);
		error = copyout((caddr_t)&oinbuf, SCARG(uap, buf),
		    sizeof(oinbuf));
		if (error)
			return error;
		break;
	case IPC_SET:
		if ((error = ipcperm(cred, &shmseg->shm_perm, IPC_M)) != 0)
			return error;
		error = copyin(SCARG(uap, buf), (caddr_t)&oinbuf,
		    sizeof(oinbuf));
		if (error)
			return error;
		shmseg->shm_perm.uid = oinbuf.shm_perm.uid;
		shmseg->shm_perm.gid = oinbuf.shm_perm.gid;
		shmseg->shm_perm.mode =
		    (shmseg->shm_perm.mode & ~ACCESSPERMS) |
		    (oinbuf.shm_perm.mode & ACCESSPERMS);
		shmseg->shm_ctime = time.tv_sec;
		break;
	case IPC_RMID:
		if ((error = ipcperm(cred, &shmseg->shm_perm, IPC_M)) != 0)
			return error;
		shmseg->shm_perm.key = IPC_PRIVATE;
		shmseg->shm_perm.mode |= SHMSEG_REMOVED;
		if (shmseg->shm_nattch <= 0) {
			shm_deallocate_segment(shmseg);
			shm_last_free = IPCID_TO_IX(SCARG(uap, shmid));
		}
		break;
	case SHM_LOCK:
	case SHM_UNLOCK:
	default:
		return EINVAL;
	}
	return 0;
@


1.15
log
@Get rid of CLSIZE and all related stuff.
CLSIZE -> 1
CLBYTES -> PAGE_SIZE
OLOFSET -> PAGE_MASK
etc.
At the same time some archs needed some cleaning in vmparam.h so that
goes in at the same time.
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.14 1999/11/25 13:41:30 art Exp $	*/
d267 2
a268 1
		    round_page(p->p_vmspace->vm_taddr + MAXTSIZ + MAXDSIZ);
@


1.14
log
@Use PAGE_SIZE instead of NBPG.
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.13 1999/07/08 05:05:23 weingart Exp $	*/
d139 1
a139 1
	size = (shmseg->shm_segsz + CLOFSET) & ~CLOFSET;
d163 1
a163 1
	size = (shmseg->shm_segsz + CLOFSET) & ~CLOFSET;
d250 1
a250 1
	size = (shmseg->shm_segsz + CLOFSET) & ~CLOFSET;
d426 1
a426 1
	size = (SCARG(uap, size) + CLOFSET) & ~CLOFSET;
@


1.14.2.1
log
@Merge in -current from two days ago in the SMP branch.
As usual with merges, they do not indicate progress, so do not hold
your breath for working SMP, and do not mail me and ask about the
state of it.  It has not changed.  There is work ongoing, but very, very
slowly.  The commit is done in parts as to not lock up the tree in too
big chunks at a time.
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.14 1999/11/25 13:41:30 art Exp $	*/
d50 1
d52 4
d72 1
a72 1
#define	SHMSEG_FREE		0x0200
d80 1
d82 3
d92 7
a98 7
int shm_find_segment_by_key __P((key_t));
void shm_deallocate_segment __P((struct shmid_ds *));
int shm_delete_mapping __P((struct vmspace *, struct shmmap_state *));
int shmget_existing __P((struct proc *, struct sys_shmget_args *,
			 int, int, register_t *));
int shmget_allocate_segment __P((struct proc *, struct sys_shmget_args *,
				 int, register_t *));
d100 1
a100 1
int
d131 1
a131 1
void
d139 2
a140 1
	size = round_page(shmseg->shm_segsz);
d142 3
d152 1
a152 1
int
d163 2
a164 1
	size = round_page(shmseg->shm_segsz);
d166 4
d250 1
a250 1
	size = round_page(shmseg->shm_segsz);
d266 2
a267 2
		attach_va = round_page((vaddr_t)p->p_vmspace->vm_taddr +
		    MAXTSIZ + MAXDSIZ);
d270 1
d273 3
a275 2
	    shm_handle->shm_object, 0, UVM_MAPFLAG(prot, prot,
	    UVM_INH_SHARE, UVM_ADV_RANDOM, 0));
d279 12
d333 1
a333 1
		    sizeof(inbuf));
d361 1
a361 1
int
d401 1
a401 1
int
d416 3
d426 1
a426 1
	size = round_page(SCARG(uap, size));
d453 1
d455 18
d487 11
a497 1
	*retval = shmid;
d607 62
@


1.14.2.2
log
@Sync the SMP branch to something just after 3.0
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.14.2.1 2001/07/04 10:48:40 niklas Exp $	*/
a50 3

struct shminfo shminfo;
struct shmid_ds *shmsegs;
@


1.14.2.3
log
@merge in -current
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d49 1
d257 1
a257 1
	    shm_handle->shm_object, 0, 0, UVM_MAPFLAG(prot, prot,
@


1.14.2.4
log
@Merge in -current
@
text
@d147 1
a147 1
	int segnum;
d153 3
a155 1
	uvm_deallocate(&vm->vm_map, shmmap_s->va, size);
d210 1
d255 1
a255 1
	error = uvm_map(&p->p_vmspace->vm_map, &attach_va, size,
d258 2
a259 2
	if (error) {
		return error;
@


1.14.2.5
log
@Merge in trunk
@
text
@d147 1
a147 1
	int segnum, result;
d153 1
a153 3
	result = uvm_deallocate(&vm->vm_map, shmmap_s->va, size);
	if (result != KERN_SUCCESS)
		return EINVAL;
a207 1
	int rv;
d252 1
a252 1
	rv = uvm_map(&p->p_vmspace->vm_map, &attach_va, size,
d255 2
a256 2
	if (rv != KERN_SUCCESS) {
	    return ENOMEM;
@


1.14.2.6
log
@Merge in -current from about a week ago
@
text
@d54 1
a54 1
struct shmid_ds *shm_find_segment_by_shmid(int);
d85 7
a91 7
int shm_find_segment_by_key(key_t);
void shm_deallocate_segment(struct shmid_ds *);
int shm_delete_mapping(struct vmspace *, struct shmmap_state *);
int shmget_existing(struct proc *, struct sys_shmget_args *,
			 int, int, register_t *);
int shmget_allocate_segment(struct proc *, struct sys_shmget_args *,
				 int, register_t *);
@


1.14.2.7
log
@Sync the SMP branch with 3.3
@
text
@a4 26
 * Copyright (c) 2002 Todd C. Miller <Todd.Miller@@courtesan.com>
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. The name of the author may not be used to endorse or promote products
 *    derived from this software without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES,
 * INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY
 * AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL
 * THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;
 * OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
 * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
 * OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF
 * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */
/*
a42 1
#include <sys/pool.h>
a43 1
#include <sys/sysctl.h>
d52 1
a52 3
struct shmid_ds **shmsegs;	/* linear mapping of shmid -> shmseg */
struct pool shm_pool;
unsigned short *shmseqs;	/* array of shm sequence numbers */
d54 1
a54 1
struct shmid_ds *shm_find_segment_by_shmid(int, int);
d65 2
a66 2
 * shmsegs (an array of 'struct shmid_ds *')
 * per proc 'struct shmmap_head' with an array of 'struct shmmap_state'
d69 4
a72 1
#define	SHMSEG_REMOVED  	0x0200		/* can't overlap ACCESSPERMS */
a84 5
struct shmmap_head {
	int shmseg;
	struct shmmap_state state[1];
};

d94 2
a95 1
shm_find_segment_by_key(key_t key)
a96 1
	struct shmid_ds *shmseg;
d99 5
a103 6
	for (i = 0; i < shminfo.shmmni; i++) {
		shmseg = shmsegs[i];
		if (shmseg != NULL && shmseg->shm_perm.key == key)
			return (i);
	}
	return (-1);
d107 2
a108 1
shm_find_segment_by_shmid(int shmid, int findremoved)
d114 5
a118 2
	if (segnum < 0 || segnum >= shminfo.shmmni ||
	    (shmseg = shmsegs[segnum]) == NULL ||
d120 2
a121 4
		return (NULL);
	if (!findremoved && (shmseg->shm_perm.mode & SHMSEG_REMOVED))
		return (NULL);
	return (shmseg);
d125 2
a126 1
shm_deallocate_segment(struct shmid_ds *shmseg)
d134 2
a135 1
	pool_put(&shm_pool, shmseg);
d137 1
d142 3
a144 1
shm_delete_mapping(struct vmspace *vm, struct shmmap_state *shmmap_s)
d147 1
a147 1
	int segnum;
d151 1
a151 3
	if (segnum < 0 || segnum >= shminfo.shmmni ||
	    (shmseg = shmsegs[segnum]) == NULL)
		return (EINVAL);
d153 3
a155 1
	uvm_deallocate(&vm->vm_map, shmmap_s->va, size);
a161 1
		shmsegs[shm_last_free] = NULL;
d163 1
a163 1
	return (0);
d167 4
a170 1
sys_shmdt(struct proc *p, void *v, register_t *retval)
a174 1
	struct shmmap_head *shmmap_h;
d178 3
a180 3
	shmmap_h = (struct shmmap_head *)p->p_vmspace->vm_shm;
	if (shmmap_h == NULL)
		return (EINVAL);
d182 1
a182 2
	for (i = 0, shmmap_s = shmmap_h->state; i < shmmap_h->shmseg;
	    i++, shmmap_s++)
d186 3
a188 3
	if (i == shmmap_h->shmseg)
		return (EINVAL);
	return (shm_delete_mapping(p->p_vmspace, shmmap_s));
d192 4
a195 1
sys_shmat(struct proc *p, void *v, register_t *retval)
d205 1
a205 2
	struct shmmap_head *shmmap_h;
	struct shmmap_state *shmmap_s;
d210 1
d212 7
a218 10
	shmmap_h = (struct shmmap_head *)p->p_vmspace->vm_shm;
	if (shmmap_h == NULL) {
		size = sizeof(int) +
		    shminfo.shmseg * sizeof(struct shmmap_state);
		shmmap_h = malloc(size, M_SHM, M_WAITOK);
		shmmap_h->shmseg = shminfo.shmseg;
		for (i = 0, shmmap_s = shmmap_h->state; i < shmmap_h->shmseg;
		    i++, shmmap_s++)
			shmmap_s->shmid = -1;
		p->p_vmspace->vm_shm = (caddr_t)shmmap_h;
d220 1
a220 1
	shmseg = shm_find_segment_by_shmid(SCARG(uap, shmid), 0);
d222 1
a222 1
		return (EINVAL);
d226 2
a227 2
		return (error);
	for (i = 0, shmmap_s = shmmap_h->state; i < shmmap_h->shmseg; i++) {
d232 2
a233 2
	if (i >= shmmap_h->shmseg)
		return (EMFILE);
d247 1
a247 1
			return (EINVAL);
d249 1
a249 1
		/* This is just a hint to uvm_map() about where to put it. */
d255 1
a255 1
	error = uvm_map(&p->p_vmspace->vm_map, &attach_va, size,
d258 3
a260 2
	if (error)
		return (error);
d268 1
a268 1
	return (0);
d272 4
a275 1
sys_shmctl(struct proc *p, void *v, register_t *retval)
d287 1
a287 1
	shmseg = shm_find_segment_by_shmid(SCARG(uap, shmid), 1);
d289 1
a289 1
		return (EINVAL);
d293 1
a293 1
			return (error);
d297 1
a297 1
			return (error);
d301 1
a301 1
			return (error);
d305 1
a305 1
			return (error);
d315 1
a315 1
			return (error);
a320 1
			shmsegs[shm_last_free] = NULL;
d326 1
a326 1
		return (EINVAL);
d328 1
a328 1
	return (0);
d332 2
a333 1
shmget_existing(struct proc *p,
d338 4
a341 2
	} */ *uap,
	int mode, int segnum, register_t *retval)
d347 13
a359 1
	shmseg = shmsegs[segnum];	/* We assume the segnum is valid */
d361 1
a361 1
		return (error);
d363 1
a363 1
		return (EINVAL);
d366 1
a366 1
		return (EEXIST);
d368 1
a368 1
	return (0);
d372 2
a373 1
shmget_allocate_segment(struct proc *p,
d378 3
a380 2
	} */ *uap,
	int mode, register_t *retval)
d382 1
a382 2
	key_t key;
	int segnum, size;
d390 1
a390 1
		return (EINVAL);
d392 1
a392 1
		return (ENOSPC);
d395 1
a395 22
		return (ENOMEM);
	shm_nused++;
	shm_committed += btoc(size);

	/*
	 * If a key has been specified and we had to wait for memory
	 * to be freed up we need to verify that no one has allocated
	 * the key we want in the meantime.  Yes, this is ugly.
	 */
	key = SCARG(uap, key);
	shmseg = pool_get(&shm_pool, key == IPC_PRIVATE ? PR_WAITOK : 0);
	if (shmseg == NULL) {
		shmseg = pool_get(&shm_pool, PR_WAITOK);
		if (shm_find_segment_by_key(key) != -1) {
			pool_put(&shm_pool, shmseg);
			shm_nused--;
			shm_committed -= btoc(size);
			return (EAGAIN);
		}
	}

	/* XXX - hash shmids instead */
d397 4
a400 4
		for (segnum = 0; segnum < shminfo.shmmni && shmsegs[segnum];
		    segnum++)
			;
		if (segnum == shminfo.shmmni)
d402 2
a403 1
	} else {
d405 1
a405 2
		if (++shm_last_free >= shminfo.shmmni || shmsegs[shm_last_free])
			shm_last_free = -1;
d407 12
a418 1
	shmsegs[segnum] = shmseg;
a419 1
	shm_handle = (struct shm_handle *)((caddr_t)shmseg + sizeof(*shmseg));
d422 1
d425 2
a426 3
	shmseg->shm_perm.mode = (mode & ACCESSPERMS);
	shmseg->shm_perm.seq = shmseqs[segnum] = (shmseqs[segnum] + 1) & 0x7fff;
	shmseg->shm_perm.key = key;
d432 2
a433 1
	shmseg->shm_internal = shm_handle;
d435 10
a444 2
	*retval = IXSEQ_TO_IPCID(segnum, shmseg->shm_perm);
	return (error);
d448 4
a451 1
sys_shmget(struct proc *p, void *v, register_t *retval)
d464 6
a469 2
		if (segnum >= 0)
			return (shmget_existing(p, uap, mode, segnum, retval));
d471 1
a471 1
			return (ENOENT);
d473 1
a473 4
	error = shmget_allocate_segment(p, uap, mode, retval);
	if (error == EAGAIN)
		goto again;
	return (error);
d477 2
a478 1
shmfork(struct vmspace *vm1, struct vmspace *vm2)
a479 1
	struct shmmap_head *shmmap_h;
a480 1
	struct shmid_ds *shmseg;
d489 7
a495 10
	shmmap_h = (struct shmmap_head *)vm1->vm_shm;
	size = sizeof(int) + shmmap_h->shmseg * sizeof(struct shmmap_state);
	vm2->vm_shm = malloc(size, M_SHM, M_WAITOK);
	bcopy(vm1->vm_shm, vm2->vm_shm, size);
	for (i = 0, shmmap_s = shmmap_h->state; i < shmmap_h->shmseg;
	    i++, shmmap_s++) {
		if (shmmap_s->shmid != -1 &&
		    (shmseg = shmsegs[IPCID_TO_IX(shmmap_s->shmid)]) != NULL)
			shmseg->shm_nattch++;
	}
d499 2
a500 1
shmexit(struct vmspace *vm)
a501 1
	struct shmmap_head *shmmap_h;
d505 2
a506 2
	shmmap_h = (struct shmmap_head *)vm->vm_shm;
	if (shmmap_h == NULL)
d508 1
a508 2
	for (i = 0, shmmap_s = shmmap_h->state; i < shmmap_h->shmseg;
	    i++, shmmap_s++)
d516 1
a516 1
shminit(void)
d518 1
d520 1
a520 9
	pool_init(&shm_pool, sizeof(struct shmid_ds) +
	    sizeof(struct shm_handle), 0, 0, 0, "shmpl",
	    &pool_allocator_nointr);
	shmsegs = malloc(shminfo.shmmni * sizeof(struct shmid_ds *),
	    M_SHM, M_WAITOK);
	bzero(shmsegs, shminfo.shmmni * sizeof(struct shmid_ds *));
	shmseqs = malloc(shminfo.shmmni * sizeof(unsigned short),
	    M_SHM, M_WAITOK);
	bzero(shmseqs, shminfo.shmmni * sizeof(unsigned short));
d522 4
a525 1
	shminfo.shmmax *= PAGE_SIZE;	/* actually in pages */
d532 3
a534 1
shmid_n2o(struct shmid_ds *n, struct oshmid_ds *o)
a535 1

a544 94
}

/*
 * Userland access to struct shminfo.
 */
int
sysctl_sysvshm(int *name, u_int namelen, void *oldp, size_t *oldlenp,
	void *newp, size_t newlen)
{
	int error, val;
	struct shmid_ds **newsegs;
	unsigned short *newseqs;

	if (namelen != 2) {
		switch (name[0]) {
		case KERN_SHMINFO_SHMMAX:
		case KERN_SHMINFO_SHMMIN:
		case KERN_SHMINFO_SHMMNI:
		case KERN_SHMINFO_SHMSEG:
		case KERN_SHMINFO_SHMALL:
			break;
		default:
                        return (ENOTDIR);       /* overloaded */
                }
        }

	switch (name[0]) {
	case KERN_SHMINFO_SHMMAX:
		if ((error = sysctl_int(oldp, oldlenp, newp, newlen,
		    &shminfo.shmmax)) || newp == NULL)
			return (error);

		/* If new shmmax > shmall, crank shmall */
		if (btoc(round_page(shminfo.shmmax)) > shminfo.shmall)
			shminfo.shmall = btoc(round_page(shminfo.shmmax));
		return (0);
	case KERN_SHMINFO_SHMMIN:
		val = shminfo.shmmin;
		if ((error = sysctl_int(oldp, oldlenp, newp, newlen, &val)) ||
		    val == shminfo.shmmin)
			return (error);
		if (val <= 0)
			return (EINVAL);	/* shmmin must be >= 1 */
		shminfo.shmmin = val;
		return (0);
	case KERN_SHMINFO_SHMMNI:
		val = shminfo.shmmni;
		if ((error = sysctl_int(oldp, oldlenp, newp, newlen, &val)) ||
		    val == shminfo.shmmni)
			return (error);

		if (val < shminfo.shmmni || val > 0xffff)
			return (EINVAL);

		/* Expand shmsegs and shmseqs arrays */
		newsegs = malloc(val * sizeof(struct shmid_ds *),
		    M_SHM, M_WAITOK);
		bcopy(shmsegs, newsegs,
		    shminfo.shmmni * sizeof(struct shmid_ds *));
		bzero(newsegs + shminfo.shmmni,
		    (val - shminfo.shmmni) * sizeof(struct shmid_ds *));
		newseqs = malloc(val * sizeof(unsigned short), M_SHM, M_WAITOK);
		bcopy(shmseqs, newseqs,
		    shminfo.shmmni * sizeof(unsigned short));
		bzero(newseqs + shminfo.shmmni,
		    (val - shminfo.shmmni) * sizeof(unsigned short));
		free(shmsegs, M_SHM);
		free(shmseqs, M_SHM);
		shmsegs = newsegs;
		shmseqs = newseqs;
		shminfo.shmmni = val;
		return (0);
	case KERN_SHMINFO_SHMSEG:
		val = shminfo.shmseg;
		if ((error = sysctl_int(oldp, oldlenp, newp, newlen, &val)) ||
		    val == shminfo.shmseg)
			return (error);
		if (val <= 0)
			return (EINVAL);	/* shmseg must be >= 1 */
		shminfo.shmseg = val;
		return (0);
	case KERN_SHMINFO_SHMALL:
		val = shminfo.shmall;
		if ((error = sysctl_int(oldp, oldlenp, newp, newlen, &val)) ||
		    val == shminfo.shmall)
			return (error);
		if (val < shminfo.shmall)
			return (EINVAL);	/* can't decrease shmall */
		shminfo.shmall = val;
		return (0);
	default:
		return (EOPNOTSUPP);
	}
	/* NOTREACHED */
@


1.14.2.8
log
@Sync the SMP branch to -current. This includes moving to ELF.
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.14.2.7 2003/03/28 00:41:27 niklas Exp $	*/
d79 1
a79 1
extern struct shminfo shminfo;
d276 2
a277 1
		attach_va = uvm_map_hint(p, prot);
@


1.14.2.9
log
@Sync SMP branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.14.2.8 2003/05/13 19:21:28 ho Exp $	*/
d6 1
d8 10
a17 3
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
d19 10
a28 7
 * THE SOFTWARE IS PROVIDED "AS IS" AND TODD C. MILLER DISCLAIMS ALL
 * WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES
 * OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL TODD C. MILLER BE LIABLE
 * FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
 * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
 * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
@


1.14.2.10
log
@Merge of current from two weeks agointo the SMP branch
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d11 7
a17 11
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 *
 * Sponsored in part by the Defense Advanced Research Projects
 * Agency (DARPA) and Air Force Research Laboratory, Air Force
 * Materiel Command, USAF, under agreement number F39502-99-1-0512.
d49 1
a208 6
	return (sys_shmat1(p, v, retval, 0));
}

int
sys_shmat1(struct proc *p, void *v, register_t *retval, int findremoved)
{
d235 1
a235 1
	shmseg = shm_find_segment_by_shmid(SCARG(uap, shmid), findremoved);
d613 2
@


1.14.2.11
log
@Merge with the trunk
@
text
@d281 1
a281 2
	if (error) {
		uao_detach(shm_handle->shm_object);
a282 1
	}
a384 1
	size_t size;
d386 1
a386 1
	int segnum;
d458 1
a458 1
		syscallarg(size_t) size;
a615 2
		free(shmsegs, M_SHM);
		shmsegs = newsegs;
d621 1
a621 1
		free(shmseqs, M_SHM);
@


1.13
log
@Non UVM vaddr_t/paddr_t fixup
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.12 1999/06/23 09:44:28 art Exp $	*/
d582 1
a582 1
	shminfo.shmmax *= NBPG;
@


1.12
log
@Improved sysv shared memory. Works with UVM.
Original work done in FreeBSD, but this code was ported from NetBSD by
Chuck Cranor.
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
a85 5

#ifndef UVM
typedef vm_offset_t vaddr_t;	/* XXXCDC: tmp, yuck */
typedef vm_offset_t vsize_t;	/* XXXCDC: tmp, yuck */
#endif
@


1.11
log
@We don't need a second prototype for shmexit
@
text
@d1 2
a2 2
/*	$OpenBSD: sysv_shm.c,v 1.10 1999/02/07 22:09:07 art Exp $	*/
/*	$NetBSD: sysv_shm.c,v 1.37 1996/03/16 23:17:13 christos Exp $	*/
d5 1
a5 1
 * Copyright (c) 1994 Adam Glass and Charles Hannum.  All rights reserved.
d17 1
a17 1
 *	This product includes software developed by Adam Glass and Charles
d50 3
d55 1
d62 3
a64 3
 * shminit(void);		           initialization
 * shmexit(struct proc *)                  cleanup
 * shmfork(struct proc *, struct proc *)   fork handling
a76 1
vm_map_t sysvshm_map;
d80 5
a84 1
	vm_offset_t kva;
d87 5
d93 1
a93 1
	vm_offset_t va;
d99 1
a99 1
static int shm_delete_mapping __P((struct proc *, struct shmmap_state *));
d145 5
a149 1
	vm_deallocate(sysvshm_map, shm_handle->kva, size);
d158 2
a159 2
shm_delete_mapping(p, shmmap_s)
	struct proc *p;
d169 6
a174 1
	result = vm_deallocate(&p->p_vmspace->vm_map, shmmap_s->va, size);
d202 1
d205 1
a205 1
		    shmmap_s->va == (vm_offset_t)SCARG(uap, shmaddr))
d209 1
a209 1
	return shm_delete_mapping(p, shmmap_s);
d227 2
a228 1
	vm_offset_t attach_va;
d230 2
a231 1
	vm_size_t size;
d264 3
a266 3
			    (vm_offset_t)SCARG(uap, shmaddr) & ~(SHMLBA-1);
		else if (((vm_offset_t)SCARG(uap, shmaddr) & (SHMLBA-1)) == 0)
			attach_va = (vm_offset_t)SCARG(uap, shmaddr);
d274 23
a296 4
	error = vm_mmap(&p->p_vmspace->vm_map, &attach_va, size, prot,
	    VM_PROT_DEFAULT, flags, (caddr_t)(long)SCARG(uap, shmid), 0);
	if (error)
		return error;
a305 77
void
shmid_n2o(n, o)
	struct shmid_ds *n;
	struct oshmid_ds *o;
{
	o->shm_segsz = n->shm_segsz;
	o->shm_lpid = n->shm_lpid;
	o->shm_cpid = n->shm_cpid;
	o->shm_nattch = n->shm_nattch;
	o->shm_atime = n->shm_atime;
	o->shm_dtime = n->shm_dtime;
	o->shm_ctime = n->shm_ctime;
	o->shm_internal = n->shm_internal;
	ipc_n2o(&n->shm_perm, &o->shm_perm);
}

int
sys_oshmctl(p, v, retval)
	struct proc *p;
	void *v;
	register_t *retval;
{
	struct sys_shmctl_args /* {
		syscallarg(int) shmid;
		syscallarg(int) cmd;
		syscallarg(struct shmid_ds *) buf;
	} */ *uap = v;
	int error;
	struct ucred *cred = p->p_ucred;
	struct oshmid_ds oinbuf;
	struct shmid_ds *shmseg;

	shmseg = shm_find_segment_by_shmid(SCARG(uap, shmid));
	if (shmseg == NULL)
		return EINVAL;
	switch (SCARG(uap, cmd)) {
	case IPC_STAT:
		if ((error = ipcperm(cred, &shmseg->shm_perm, IPC_R)) != 0)
			return error;
		shmid_n2o(shmseg, &oinbuf);
		error = copyout((caddr_t)&oinbuf, SCARG(uap, buf),
		    sizeof(oinbuf));
		if (error)
			return error;
		break;
	case IPC_SET:
		if ((error = ipcperm(cred, &shmseg->shm_perm, IPC_M)) != 0)
			return error;
		error = copyin(SCARG(uap, buf), (caddr_t)&oinbuf,
		    sizeof(oinbuf));
		if (error)
			return error;
		shmseg->shm_perm.uid = oinbuf.shm_perm.uid;
		shmseg->shm_perm.gid = oinbuf.shm_perm.gid;
		shmseg->shm_perm.mode =
		    (shmseg->shm_perm.mode & ~ACCESSPERMS) |
		    (oinbuf.shm_perm.mode & ACCESSPERMS);
		shmseg->shm_ctime = time.tv_sec;
		break;
	case IPC_RMID:
		if ((error = ipcperm(cred, &shmseg->shm_perm, IPC_M)) != 0)
			return error;
		shmseg->shm_perm.key = IPC_PRIVATE;
		shmseg->shm_perm.mode |= SHMSEG_REMOVED;
		if (shmseg->shm_nattch <= 0) {
			shm_deallocate_segment(shmseg);
			shm_last_free = IPCID_TO_IX(SCARG(uap, shmid));
		}
		break;
	case SHM_LOCK:
	case SHM_UNLOCK:
	default:
		return EINVAL;
	}
	return 0;
}

d371 1
a371 1
		syscallarg(int) size;
d411 1
a411 1
		syscallarg(int) size;
d417 1
a417 1
	int i, segnum, result, shmid, size;
d421 4
d456 19
a474 9
	result = vm_mmap(sysvshm_map, &shm_handle->kva, size, VM_PROT_ALL,
	    VM_PROT_DEFAULT, MAP_ANON, (caddr_t)(long)shmid, 0);
	if (result != KERN_SUCCESS) {
		shmseg->shm_perm.mode = SHMSEG_FREE;
		shm_last_free = segnum;
		free((caddr_t)shm_handle, M_SHM);
		/* Just in case. */
		wakeup((caddr_t)shmseg);
		return ENOMEM;
d476 3
d491 12
d511 1
a511 2
	*retval = shmid;
	return 0;
d544 2
a545 2
shmfork(p1, p2)
	struct proc *p1, *p2;
d551 2
a552 2
	if (p1->p_vmspace->vm_shm == NULL) {
		p2->p_vmspace->vm_shm = NULL;
d558 2
a559 2
	bcopy((caddr_t)p1->p_vmspace->vm_shm, (caddr_t)shmmap_s, size);
	p2->p_vmspace->vm_shm = (caddr_t)shmmap_s;
d566 2
a567 2
shmexit(p)
	struct proc *p;
d572 1
a572 1
	shmmap_s = (struct shmmap_state *)p->p_vmspace->vm_shm;
d577 3
a579 3
			shm_delete_mapping(p, shmmap_s);
	free((caddr_t)p->p_vmspace->vm_shm, M_SHM);
	p->p_vmspace->vm_shm = NULL;
a585 1
	vm_offset_t garbage1, garbage2;
a588 3
	/* actually this *should* be pageable.  SHM_{LOCK,UNLOCK} */
	sysvshm_map = kmem_suballoc(kernel_map, &garbage1, &garbage2,
				    shminfo.shmall * NBPG, TRUE);
d596 78
@


1.10
log
@don't include vm_map.h twice
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.9 1998/06/14 18:57:09 matthieu Exp $	*/
a53 1
void shmexit __P((struct proc *));
@


1.9
log
@fix compat shmctl/IPC_STAT
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.8 1998/06/11 18:32:17 deraadt Exp $	*/
a49 1
#include <vm/vm_map.h>
@


1.8
log
@change ipc.h to use uid_t and friends, and then build compat system calls for the old ushort based ipc.h
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.7 1998/05/11 06:13:48 deraadt Exp $	*/
d305 1
a305 1
		error = copyout((caddr_t)shmseg, SCARG(uap, buf),
@


1.7
log
@const a few more calls
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.6 1997/02/21 08:52:23 deraadt Exp $	*/
d262 77
@


1.6
log
@shmdt before shmdt (in child) fix
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.5 1996/09/02 05:25:06 deraadt Exp $	*/
d175 1
a175 1
		syscallarg(void *) shmaddr;
d200 1
a200 1
		syscallarg(void *) shmaddr;
@


1.5
log
@shmdt when no mapping is ok, found by christos
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.4 1996/04/21 22:27:26 deraadt Exp $	*/
d482 5
d504 2
@


1.4
log
@partial sync with netbsd 960418, more to come
@
text
@d1 1
a1 1
/*	$OpenBSD: sysv_shm.c,v 1.3 1996/03/03 17:20:08 niklas Exp $	*/
d181 2
@


1.3
log
@From NetBSD: 960217 merge
@
text
@d1 2
a2 2
/*	$OpenBSD$	*/
/*	$NetBSD: sysv_shm.c,v 1.36 1996/02/09 19:00:29 christos Exp $	*/
d356 1
a356 1
	if (SCARG(uap, shmflg) & (IPC_CREAT | IPC_EXCL) ==
@


1.2
log
@from netbsd; shmfork does not need to know about vfork
@
text
@d1 2
a2 1
/*	$NetBSD: sysv_shm.c,v 1.34 1995/12/09 04:12:56 mycroft Exp $	*/
d54 3
d87 1
a88 2
static int shm_find_segment_by_key __P((key_t));
struct shmid_ds *shm_find_segment_by_shmid __P((int));
d90 4
d199 1
a199 1
		syscallarg(int) shmflag;
d220 3
a222 2
	if (error = ipcperm(cred, &shmseg->shm_perm,
	    (SCARG(uap, shmflg) & SHM_RDONLY) ? IPC_R : IPC_R|IPC_W))
d274 1
a274 1
	int error, segnum;
d284 1
a284 1
		if (error = ipcperm(cred, &shmseg->shm_perm, IPC_R))
d286 3
a288 2
		if (error = copyout((caddr_t)shmseg, SCARG(uap, buf),
		    sizeof(inbuf)))
d292 1
a292 1
		if (error = ipcperm(cred, &shmseg->shm_perm, IPC_M))
d294 3
a296 2
		if (error = copyin(SCARG(uap, buf), (caddr_t)&inbuf,
		    sizeof(inbuf)))
d306 1
a306 1
		if (error = ipcperm(cred, &shmseg->shm_perm, IPC_M))
d329 1
a329 1
		syscallarg(int) shmflag;
d347 2
a348 2
		if (error =
		    tsleep((caddr_t)shmseg, PLOCK | PCATCH, "shmget", 0))
d352 1
a352 1
	if (error = ipcperm(cred, &shmseg->shm_perm, mode))
d369 1
a369 1
		syscallarg(int) shmflag;
d452 1
a452 1
		syscallarg(int) shmflag;
a454 1
	struct shmid_ds *shmseg;
a493 1
	struct shmid_ds *shmseg;
@


1.1
log
@Initial revision
@
text
@d1 1
a1 1
/*	$NetBSD: sysv_shm.c,v 1.33 1995/10/07 06:28:44 mycroft Exp $	*/
d58 1
a58 1
 * shmfork(struct proc *, struct proc *, int) fork handling
d464 1
a464 1
shmfork(p1, p2, isvfork)
a465 1
	int isvfork;
@


1.1.1.1
log
@initial import of NetBSD tree
@
text
@@
