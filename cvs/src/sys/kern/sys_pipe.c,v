head	1.76;
access;
symbols
	OPENBSD_6_1:1.76.0.4
	OPENBSD_6_1_BASE:1.76
	OPENBSD_6_0:1.72.0.4
	OPENBSD_6_0_BASE:1.72
	OPENBSD_5_9:1.72.0.2
	OPENBSD_5_9_BASE:1.72
	OPENBSD_5_8:1.69.0.6
	OPENBSD_5_8_BASE:1.69
	OPENBSD_5_7:1.69.0.2
	OPENBSD_5_7_BASE:1.69
	OPENBSD_5_6:1.65.0.6
	OPENBSD_5_6_BASE:1.65
	OPENBSD_5_5:1.65.0.4
	OPENBSD_5_5_BASE:1.65
	OPENBSD_5_4:1.63.0.6
	OPENBSD_5_4_BASE:1.63
	OPENBSD_5_3:1.63.0.4
	OPENBSD_5_3_BASE:1.63
	OPENBSD_5_2:1.63.0.2
	OPENBSD_5_2_BASE:1.63
	OPENBSD_5_1_BASE:1.61
	OPENBSD_5_1:1.61.0.4
	OPENBSD_5_0:1.61.0.2
	OPENBSD_5_0_BASE:1.61
	OPENBSD_4_9:1.58.0.6
	OPENBSD_4_9_BASE:1.58
	OPENBSD_4_8:1.58.0.4
	OPENBSD_4_8_BASE:1.58
	OPENBSD_4_7:1.58.0.2
	OPENBSD_4_7_BASE:1.58
	OPENBSD_4_6:1.55.0.6
	OPENBSD_4_6_BASE:1.55
	OPENBSD_4_5:1.55.0.2
	OPENBSD_4_5_BASE:1.55
	OPENBSD_4_4:1.54.0.2
	OPENBSD_4_4_BASE:1.54
	OPENBSD_4_3:1.53.0.2
	OPENBSD_4_3_BASE:1.53
	OPENBSD_4_2:1.52.0.2
	OPENBSD_4_2_BASE:1.52
	OPENBSD_4_1:1.51.0.2
	OPENBSD_4_1_BASE:1.51
	OPENBSD_4_0:1.50.0.4
	OPENBSD_4_0_BASE:1.50
	OPENBSD_3_9:1.50.0.2
	OPENBSD_3_9_BASE:1.50
	OPENBSD_3_8:1.49.0.6
	OPENBSD_3_8_BASE:1.49
	OPENBSD_3_7:1.49.0.4
	OPENBSD_3_7_BASE:1.49
	OPENBSD_3_6:1.49.0.2
	OPENBSD_3_6_BASE:1.49
	SMP_SYNC_A:1.46
	SMP_SYNC_B:1.46
	OPENBSD_3_5:1.46.0.2
	OPENBSD_3_5_BASE:1.46
	OPENBSD_3_4:1.43.0.8
	OPENBSD_3_4_BASE:1.43
	UBC_SYNC_A:1.43
	OPENBSD_3_3:1.43.0.6
	OPENBSD_3_3_BASE:1.43
	OPENBSD_3_2:1.43.0.4
	OPENBSD_3_2_BASE:1.43
	OPENBSD_3_1:1.43.0.2
	OPENBSD_3_1_BASE:1.43
	UBC_SYNC_B:1.43
	UBC:1.40.0.2
	UBC_BASE:1.40
	OPENBSD_3_0:1.38.0.2
	OPENBSD_3_0_BASE:1.38
	OPENBSD_2_9_BASE:1.26
	OPENBSD_2_9:1.26.0.2
	OPENBSD_2_8:1.24.0.4
	OPENBSD_2_8_BASE:1.24
	OPENBSD_2_7:1.24.0.2
	OPENBSD_2_7_BASE:1.24
	SMP:1.23.0.2
	SMP_BASE:1.23
	kame_19991208:1.22
	OPENBSD_2_6:1.17.0.2
	OPENBSD_2_6_BASE:1.17
	OPENBSD_2_5:1.10.0.2
	OPENBSD_2_5_BASE:1.10
	OPENBSD_2_4:1.8.0.4
	OPENBSD_2_4_BASE:1.8
	OPENBSD_2_3:1.8.0.2
	OPENBSD_2_3_BASE:1.8
	OPENBSD_2_2:1.7.0.2
	OPENBSD_2_2_BASE:1.7
	OPENBSD_2_1:1.5.0.2
	OPENBSD_2_1_BASE:1.5
	OPENBSD_2_0:1.3.0.2
	OPENBSD_2_0_BASE:1.3;
locks; strict;
comment	@ * @;


1.76
date	2017.02.11.19.51.06;	author guenther;	state Exp;
branches;
next	1.75;
commitid	dp1qF9REvzwtzfTw;

1.75
date	2016.10.08.02.16.43;	author guenther;	state Exp;
branches;
next	1.74;
commitid	MFxpqYD0syIKuFdZ;

1.74
date	2016.09.15.02.00.16;	author dlg;	state Exp;
branches;
next	1.73;
commitid	RlO92XR575sygHqm;

1.73
date	2016.08.30.07.40.35;	author dlg;	state Exp;
branches;
next	1.72;
commitid	JbWQykeZEbgGzoLE;

1.72
date	2016.01.15.18.10.48;	author stefan;	state Exp;
branches;
next	1.71;
commitid	8a7iIj0sJxKGqDTq;

1.71
date	2016.01.06.17.59.30;	author tedu;	state Exp;
branches;
next	1.70;
commitid	vtbNHxTkwTC4OW91;

1.70
date	2015.12.05.10.11.53;	author tedu;	state Exp;
branches;
next	1.69;
commitid	Cl55DD2g2xm69E6W;

1.69
date	2015.02.10.21.56.10;	author miod;	state Exp;
branches;
next	1.68;
commitid	C5iGb36LQxjM60Q3;

1.68
date	2014.12.19.05.59.21;	author tedu;	state Exp;
branches;
next	1.67;
commitid	zdJTCwdpqRUwO1SL;

1.67
date	2014.09.28.18.52.04;	author kettenis;	state Exp;
branches;
next	1.66;
commitid	p4obyg5p6bHyWTFt;

1.66
date	2014.08.31.01.42.36;	author guenther;	state Exp;
branches;
next	1.65;
commitid	zF5A8BuuSSyqaDyM;

1.65
date	2014.01.24.06.00.01;	author guenther;	state Exp;
branches;
next	1.64;

1.64
date	2014.01.21.01.48.45;	author tedu;	state Exp;
branches;
next	1.63;

1.63
date	2012.05.06.09.45.26;	author mikeb;	state Exp;
branches;
next	1.62;

1.62
date	2012.04.22.05.43.14;	author guenther;	state Exp;
branches;
next	1.61;

1.61
date	2011.07.08.19.00.09;	author tedu;	state Exp;
branches;
next	1.60;

1.60
date	2011.07.08.05.01.27;	author matthew;	state Exp;
branches;
next	1.59;

1.59
date	2011.05.27.08.53.15;	author nicm;	state Exp;
branches;
next	1.58;

1.58
date	2010.01.14.23.12.11;	author schwarze;	state Exp;
branches;
next	1.57;

1.57
date	2009.11.09.17.53.39;	author nicm;	state Exp;
branches;
next	1.56;

1.56
date	2009.10.30.18.03.34;	author deraadt;	state Exp;
branches;
next	1.55;

1.55
date	2009.01.29.22.08.45;	author guenther;	state Exp;
branches;
next	1.54;

1.54
date	2008.07.11.14.12.57;	author blambert;	state Exp;
branches;
next	1.53;

1.53
date	2007.11.28.15.19.43;	author miod;	state Exp;
branches;
next	1.52;

1.52
date	2007.08.07.11.30.53;	author millert;	state Exp;
branches;
next	1.51;

1.51
date	2006.11.17.09.21.52;	author jmc;	state Exp;
branches;
next	1.50;

1.50
date	2005.12.13.10.33.14;	author jsg;	state Exp;
branches;
next	1.49;

1.49
date	2004.07.22.06.13.08;	author tedu;	state Exp;
branches;
next	1.48;

1.48
date	2004.07.21.17.05.40;	author art;	state Exp;
branches;
next	1.47;

1.47
date	2004.06.24.19.35.24;	author tholo;	state Exp;
branches;
next	1.46;

1.46
date	2004.01.06.04.18.18;	author tedu;	state Exp;
branches;
next	1.45;

1.45
date	2003.10.03.16.38.01;	author miod;	state Exp;
branches;
next	1.44;

1.44
date	2003.09.23.16.51.12;	author millert;	state Exp;
branches;
next	1.43;

1.43
date	2002.03.14.01.27.04;	author millert;	state Exp;
branches;
next	1.42;

1.42
date	2002.02.08.13.53.28;	author art;	state Exp;
branches;
next	1.41;

1.41
date	2002.01.23.00.39.47;	author art;	state Exp;
branches;
next	1.40;

1.40
date	2001.11.06.19.53.20;	author miod;	state Exp;
branches
	1.40.2.1;
next	1.39;

1.39
date	2001.10.26.12.03.27;	author art;	state Exp;
branches;
next	1.38;

1.38
date	2001.09.19.20.50.58;	author mickey;	state Exp;
branches;
next	1.37;

1.37
date	2001.07.05.07.15.07;	author art;	state Exp;
branches;
next	1.36;

1.36
date	2001.06.27.04.49.46;	author art;	state Exp;
branches;
next	1.35;

1.35
date	2001.06.23.06.34.37;	author art;	state Exp;
branches;
next	1.34;

1.34
date	2001.06.23.06.09.16;	author art;	state Exp;
branches;
next	1.33;

1.33
date	2001.06.23.06.04.34;	author art;	state Exp;
branches;
next	1.32;

1.32
date	2001.06.05.18.28.18;	author provos;	state Exp;
branches;
next	1.31;

1.31
date	2001.05.26.04.16.08;	author art;	state Exp;
branches;
next	1.30;

1.30
date	2001.05.14.13.43.53;	author art;	state Exp;
branches;
next	1.29;

1.29
date	2001.05.14.12.38.47;	author art;	state Exp;
branches;
next	1.28;

1.28
date	2001.05.14.10.51.26;	author art;	state Exp;
branches;
next	1.27;

1.27
date	2001.05.14.10.35.42;	author art;	state Exp;
branches;
next	1.26;

1.26
date	2001.03.01.20.54.33;	author provos;	state Exp;
branches
	1.26.2.1;
next	1.25;

1.25
date	2000.11.16.20.02.17;	author provos;	state Exp;
branches;
next	1.24;

1.24
date	2000.04.19.08.34.54;	author csapuntz;	state Exp;
branches;
next	1.23;

1.23
date	2000.01.27.18.56.13;	author art;	state Exp;
branches
	1.23.2.1;
next	1.22;

1.22
date	99.11.25.13.39.38;	author art;	state Exp;
branches;
next	1.21;

1.21
date	99.11.21.17.40.26;	author deraadt;	state Exp;
branches;
next	1.20;

1.20
date	99.10.29.14.08.49;	author art;	state Exp;
branches;
next	1.19;

1.19
date	99.10.29.14.01.44;	author art;	state Exp;
branches;
next	1.18;

1.18
date	99.10.27.07.38.19;	author niklas;	state Exp;
branches;
next	1.17;

1.17
date	99.07.15.14.07.41;	author art;	state Exp;
branches;
next	1.16;

1.16
date	99.07.13.15.17.50;	author provos;	state Exp;
branches;
next	1.15;

1.15
date	99.06.08.16.05.22;	author deraadt;	state Exp;
branches;
next	1.14;

1.14
date	99.06.07.20.46.09;	author deraadt;	state Exp;
branches;
next	1.13;

1.13
date	99.06.07.07.17.42;	author deraadt;	state Exp;
branches;
next	1.12;

1.12
date	99.06.07.01.41.01;	author deraadt;	state Exp;
branches;
next	1.11;

1.11
date	99.06.07.01.38.44;	author deraadt;	state Exp;
branches;
next	1.10;

1.10
date	99.02.26.05.12.18;	author art;	state Exp;
branches;
next	1.9;

1.9
date	99.02.16.21.27.37;	author art;	state Exp;
branches;
next	1.8;

1.8
date	97.11.06.05.58.21;	author csapuntz;	state Exp;
branches;
next	1.7;

1.7
date	97.10.06.20.20.02;	author deraadt;	state Exp;
branches;
next	1.6;

1.6
date	97.10.06.15.12.29;	author csapuntz;	state Exp;
branches;
next	1.5;

1.5
date	97.02.24.14.19.58;	author niklas;	state Exp;
branches;
next	1.4;

1.4
date	96.10.12.14.34.42;	author niklas;	state Exp;
branches;
next	1.3;

1.3
date	96.09.05.12.31.14;	author mickey;	state Exp;
branches;
next	1.2;

1.2
date	96.09.04.22.23.28;	author niklas;	state Exp;
branches;
next	1.1;

1.1
date	96.08.27.14.47.00;	author shawn;	state Exp;
branches;
next	;

1.23.2.1
date	2001.05.14.22.32.43;	author niklas;	state Exp;
branches;
next	1.23.2.2;

1.23.2.2
date	2001.07.04.10.48.34;	author niklas;	state Exp;
branches;
next	1.23.2.3;

1.23.2.3
date	2001.10.31.03.26.29;	author nate;	state Exp;
branches;
next	1.23.2.4;

1.23.2.4
date	2001.11.13.23.04.23;	author niklas;	state Exp;
branches;
next	1.23.2.5;

1.23.2.5
date	2002.03.06.02.13.23;	author niklas;	state Exp;
branches;
next	1.23.2.6;

1.23.2.6
date	2002.03.28.11.43.04;	author niklas;	state Exp;
branches;
next	1.23.2.7;

1.23.2.7
date	2004.02.19.10.56.38;	author niklas;	state Exp;
branches;
next	;

1.26.2.1
date	2001.06.07.04.45.04;	author jason;	state Exp;
branches;
next	;

1.40.2.1
date	2002.01.31.22.55.41;	author niklas;	state Exp;
branches;
next	1.40.2.2;

1.40.2.2
date	2002.06.11.03.29.40;	author art;	state Exp;
branches;
next	;


desc
@@


1.76
log
@Add a flags argument to falloc() that lets it optionally set the
close-on-exec flag on the newly allocated fd.  Make falloc()'s
return arguments non-optional: assert that they're not NULL.

ok mpi@@ millert@@
@
text
@/*	$OpenBSD: sys_pipe.c,v 1.75 2016/10/08 02:16:43 guenther Exp $	*/

/*
 * Copyright (c) 1996 John S. Dyson
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice immediately at the beginning of the file, without modification,
 *    this list of conditions, and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. Absolutely no warranty of function or purpose is made by the author
 *    John S. Dyson.
 * 4. Modifications may be freely made to this file if the above conditions
 *    are met.
 */

/*
 * This file contains a high-performance replacement for the socket-based
 * pipes scheme originally used in FreeBSD/4.4Lite.  It does not support
 * all features of sockets, but does do everything that pipes normally
 * do.
 */

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/proc.h>
#include <sys/file.h>
#include <sys/filedesc.h>
#include <sys/pool.h>
#include <sys/ioctl.h>
#include <sys/stat.h>
#include <sys/signalvar.h>
#include <sys/mount.h>
#include <sys/syscallargs.h>
#include <sys/event.h>
#include <sys/lock.h>
#include <sys/poll.h>
#ifdef KTRACE
#include <sys/ktrace.h>
#endif

#include <uvm/uvm_extern.h>

#include <sys/pipe.h>

/*
 * interfaces to the outside world
 */
int	pipe_read(struct file *, off_t *, struct uio *, struct ucred *);
int	pipe_write(struct file *, off_t *, struct uio *, struct ucred *);
int	pipe_close(struct file *, struct proc *);
int	pipe_poll(struct file *, int events, struct proc *);
int	pipe_kqfilter(struct file *fp, struct knote *kn);
int	pipe_ioctl(struct file *, u_long, caddr_t, struct proc *);
int	pipe_stat(struct file *fp, struct stat *ub, struct proc *p);

static struct fileops pipeops = {
	pipe_read, pipe_write, pipe_ioctl, pipe_poll, pipe_kqfilter,
	pipe_stat, pipe_close 
};

void	filt_pipedetach(struct knote *kn);
int	filt_piperead(struct knote *kn, long hint);
int	filt_pipewrite(struct knote *kn, long hint);

struct filterops pipe_rfiltops =
	{ 1, NULL, filt_pipedetach, filt_piperead };
struct filterops pipe_wfiltops =
	{ 1, NULL, filt_pipedetach, filt_pipewrite };

/*
 * Default pipe buffer size(s), this can be kind-of large now because pipe
 * space is pageable.  The pipe code will try to maintain locality of
 * reference for performance reasons, so small amounts of outstanding I/O
 * will not wipe the cache.
 */
#define MINPIPESIZE (PIPE_SIZE/3)

/*
 * Limit the number of "big" pipes
 */
#define LIMITBIGPIPES	32
int nbigpipe;
static int amountpipekva;

struct pool pipe_pool;

int	dopipe(struct proc *, int *, int);
void	pipeclose(struct pipe *);
void	pipe_free_kmem(struct pipe *);
int	pipe_create(struct pipe *);
int	pipelock(struct pipe *);
void	pipeunlock(struct pipe *);
void	pipeselwakeup(struct pipe *);
int	pipespace(struct pipe *, u_int);

/*
 * The pipe system call for the DTYPE_PIPE type of pipes
 */

int
sys_pipe(struct proc *p, void *v, register_t *retval)
{
	struct sys_pipe_args /* {
		syscallarg(int *) fdp;
	} */ *uap = v;

	return (dopipe(p, SCARG(uap, fdp), 0));
}

int
sys_pipe2(struct proc *p, void *v, register_t *retval)
{
	struct sys_pipe2_args /* {
		syscallarg(int *) fdp;
		syscallarg(int) flags;
	} */ *uap = v;

	if (SCARG(uap, flags) & ~(O_CLOEXEC | FNONBLOCK))
		return (EINVAL);

	return (dopipe(p, SCARG(uap, fdp), SCARG(uap, flags)));
}

int
dopipe(struct proc *p, int *ufds, int flags)
{
	struct filedesc *fdp = p->p_fd;
	struct file *rf, *wf;
	struct pipe *rpipe, *wpipe = NULL;
	int fds[2], cloexec, error;

	cloexec = (flags & O_CLOEXEC) ? UF_EXCLOSE : 0;

	rpipe = pool_get(&pipe_pool, PR_WAITOK);
	error = pipe_create(rpipe);
	if (error != 0)
		goto free1;
	wpipe = pool_get(&pipe_pool, PR_WAITOK);
	error = pipe_create(wpipe);
	if (error != 0)
		goto free1;

	fdplock(fdp);

	error = falloc(p, cloexec, &rf, &fds[0]);
	if (error != 0)
		goto free2;
	rf->f_flag = FREAD | FWRITE | (flags & FNONBLOCK);
	rf->f_type = DTYPE_PIPE;
	rf->f_data = rpipe;
	rf->f_ops = &pipeops;

	error = falloc(p, cloexec, &wf, &fds[1]);
	if (error != 0)
		goto free3;
	wf->f_flag = FREAD | FWRITE | (flags & FNONBLOCK);
	wf->f_type = DTYPE_PIPE;
	wf->f_data = wpipe;
	wf->f_ops = &pipeops;

	rpipe->pipe_peer = wpipe;
	wpipe->pipe_peer = rpipe;

	FILE_SET_MATURE(rf, p);
	FILE_SET_MATURE(wf, p);

	error = copyout(fds, ufds, sizeof(fds));
	if (error != 0) {
		fdrelease(p, fds[0]);
		fdrelease(p, fds[1]);
	}
#ifdef KTRACE
	else if (KTRPOINT(p, KTR_STRUCT))
		ktrfds(p, fds, 2);
#endif
	fdpunlock(fdp);
	return (error);

free3:
	fdremove(fdp, fds[0]);
	closef(rf, p);
	rpipe = NULL;
free2:
	fdpunlock(fdp);
free1:
	pipeclose(wpipe);
	pipeclose(rpipe);
	return (error);
}

/*
 * Allocate kva for pipe circular buffer, the space is pageable.
 * This routine will 'realloc' the size of a pipe safely, if it fails
 * it will retain the old buffer.
 * If it fails it will return ENOMEM.
 */
int
pipespace(struct pipe *cpipe, u_int size)
{
	caddr_t buffer;

	buffer = km_alloc(size, &kv_any, &kp_pageable, &kd_waitok);
	if (buffer == NULL) {
		return (ENOMEM);
	}

	/* free old resources if we are resizing */
	pipe_free_kmem(cpipe);
	cpipe->pipe_buffer.buffer = buffer;
	cpipe->pipe_buffer.size = size;
	cpipe->pipe_buffer.in = 0;
	cpipe->pipe_buffer.out = 0;
	cpipe->pipe_buffer.cnt = 0;

	amountpipekva += cpipe->pipe_buffer.size;

	return (0);
}

/*
 * initialize and allocate VM and memory for pipe
 */
int
pipe_create(struct pipe *cpipe)
{
	int error;

	/* so pipe_free_kmem() doesn't follow junk pointer */
	cpipe->pipe_buffer.buffer = NULL;
	/*
	 * protect so pipeclose() doesn't follow a junk pointer
	 * if pipespace() fails.
	 */
	memset(&cpipe->pipe_sel, 0, sizeof(cpipe->pipe_sel));
	cpipe->pipe_state = 0;
	cpipe->pipe_peer = NULL;
	cpipe->pipe_busy = 0;

	error = pipespace(cpipe, PIPE_SIZE);
	if (error != 0)
		return (error);

	getnanotime(&cpipe->pipe_ctime);
	cpipe->pipe_atime = cpipe->pipe_ctime;
	cpipe->pipe_mtime = cpipe->pipe_ctime;
	cpipe->pipe_pgid = NO_PID;

	return (0);
}


/*
 * lock a pipe for I/O, blocking other access
 */
int
pipelock(struct pipe *cpipe)
{
	int error;
	while (cpipe->pipe_state & PIPE_LOCK) {
		cpipe->pipe_state |= PIPE_LWANT;
		if ((error = tsleep(cpipe, PRIBIO|PCATCH, "pipelk", 0)))
			return error;
	}
	cpipe->pipe_state |= PIPE_LOCK;
	return 0;
}

/*
 * unlock a pipe I/O lock
 */
void
pipeunlock(struct pipe *cpipe)
{
	cpipe->pipe_state &= ~PIPE_LOCK;
	if (cpipe->pipe_state & PIPE_LWANT) {
		cpipe->pipe_state &= ~PIPE_LWANT;
		wakeup(cpipe);
	}
}

void
pipeselwakeup(struct pipe *cpipe)
{
	if (cpipe->pipe_state & PIPE_SEL) {
		cpipe->pipe_state &= ~PIPE_SEL;
		selwakeup(&cpipe->pipe_sel);
	} else
		KNOTE(&cpipe->pipe_sel.si_note, 0);
	if ((cpipe->pipe_state & PIPE_ASYNC) && cpipe->pipe_pgid != NO_PID)
		gsignal(cpipe->pipe_pgid, SIGIO);
}

int
pipe_read(struct file *fp, off_t *poff, struct uio *uio, struct ucred *cred)
{
	struct pipe *rpipe = fp->f_data;
	int error;
	size_t size, nread = 0;

	error = pipelock(rpipe);
	if (error)
		return (error);

	++rpipe->pipe_busy;

	while (uio->uio_resid) {
		/*
		 * normal pipe buffer receive
		 */
		if (rpipe->pipe_buffer.cnt > 0) {
			size = rpipe->pipe_buffer.size - rpipe->pipe_buffer.out;
			if (size > rpipe->pipe_buffer.cnt)
				size = rpipe->pipe_buffer.cnt;
			if (size > uio->uio_resid)
				size = uio->uio_resid;
			error = uiomove(&rpipe->pipe_buffer.buffer[rpipe->pipe_buffer.out],
					size, uio);
			if (error) {
				break;
			}
			rpipe->pipe_buffer.out += size;
			if (rpipe->pipe_buffer.out >= rpipe->pipe_buffer.size)
				rpipe->pipe_buffer.out = 0;

			rpipe->pipe_buffer.cnt -= size;
			/*
			 * If there is no more to read in the pipe, reset
			 * its pointers to the beginning.  This improves
			 * cache hit stats.
			 */
			if (rpipe->pipe_buffer.cnt == 0) {
				rpipe->pipe_buffer.in = 0;
				rpipe->pipe_buffer.out = 0;
			}
			nread += size;
		} else {
			/*
			 * detect EOF condition
			 * read returns 0 on EOF, no need to set error
			 */
			if (rpipe->pipe_state & PIPE_EOF)
				break;

			/*
			 * If the "write-side" has been blocked, wake it up now.
			 */
			if (rpipe->pipe_state & PIPE_WANTW) {
				rpipe->pipe_state &= ~PIPE_WANTW;
				wakeup(rpipe);
			}

			/*
			 * Break if some data was read.
			 */
			if (nread > 0)
				break;

			/*
			 * Unlock the pipe buffer for our remaining processing.
			 * We will either break out with an error or we will
			 * sleep and relock to loop.
			 */
			pipeunlock(rpipe);

			/*
			 * Handle non-blocking mode operation or
			 * wait for more data.
			 */
			if (fp->f_flag & FNONBLOCK) {
				error = EAGAIN;
			} else {
				rpipe->pipe_state |= PIPE_WANTR;
				if ((error = tsleep(rpipe, PRIBIO|PCATCH, "piperd", 0)) == 0)
					error = pipelock(rpipe);
			}
			if (error)
				goto unlocked_error;
		}
	}
	pipeunlock(rpipe);

	if (error == 0)
		getnanotime(&rpipe->pipe_atime);
unlocked_error:
	--rpipe->pipe_busy;

	/*
	 * PIPE_WANT processing only makes sense if pipe_busy is 0.
	 */
	if ((rpipe->pipe_busy == 0) && (rpipe->pipe_state & PIPE_WANT)) {
		rpipe->pipe_state &= ~(PIPE_WANT|PIPE_WANTW);
		wakeup(rpipe);
	} else if (rpipe->pipe_buffer.cnt < MINPIPESIZE) {
		/*
		 * Handle write blocking hysteresis.
		 */
		if (rpipe->pipe_state & PIPE_WANTW) {
			rpipe->pipe_state &= ~PIPE_WANTW;
			wakeup(rpipe);
		}
	}

	if ((rpipe->pipe_buffer.size - rpipe->pipe_buffer.cnt) >= PIPE_BUF)
		pipeselwakeup(rpipe);

	return (error);
}

int
pipe_write(struct file *fp, off_t *poff, struct uio *uio, struct ucred *cred)
{
	int error = 0;
	size_t orig_resid;
	struct pipe *wpipe, *rpipe;

	rpipe = fp->f_data;
	wpipe = rpipe->pipe_peer;

	/*
	 * detect loss of pipe read side, issue SIGPIPE if lost.
	 */
	if ((wpipe == NULL) || (wpipe->pipe_state & PIPE_EOF)) {
		return (EPIPE);
	}
	++wpipe->pipe_busy;

	/*
	 * If it is advantageous to resize the pipe buffer, do
	 * so.
	 */
	if ((uio->uio_resid > PIPE_SIZE) &&
	    (nbigpipe < LIMITBIGPIPES) &&
	    (wpipe->pipe_buffer.size <= PIPE_SIZE) &&
	    (wpipe->pipe_buffer.cnt == 0)) {

		if ((error = pipelock(wpipe)) == 0) {
			if (pipespace(wpipe, BIG_PIPE_SIZE) == 0)
				nbigpipe++;
			pipeunlock(wpipe);
		}
	}

	/*
	 * If an early error occurred unbusy and return, waking up any pending
	 * readers.
	 */
	if (error) {
		--wpipe->pipe_busy;
		if ((wpipe->pipe_busy == 0) &&
		    (wpipe->pipe_state & PIPE_WANT)) {
			wpipe->pipe_state &= ~(PIPE_WANT | PIPE_WANTR);
			wakeup(wpipe);
		}
		return (error);
	}

	orig_resid = uio->uio_resid;

	while (uio->uio_resid) {
		size_t space;

retrywrite:
		if (wpipe->pipe_state & PIPE_EOF) {
			error = EPIPE;
			break;
		}

		space = wpipe->pipe_buffer.size - wpipe->pipe_buffer.cnt;

		/* Writes of size <= PIPE_BUF must be atomic. */
		if ((space < uio->uio_resid) && (orig_resid <= PIPE_BUF))
			space = 0;

		if (space > 0) {
			if ((error = pipelock(wpipe)) == 0) {
				size_t size;	/* Transfer size */
				size_t segsize;	/* first segment to transfer */

				/*
				 * If a process blocked in uiomove, our
				 * value for space might be bad.
				 *
				 * XXX will we be ok if the reader has gone
				 * away here?
				 */
				if (space > wpipe->pipe_buffer.size -
				    wpipe->pipe_buffer.cnt) {
					pipeunlock(wpipe);
					goto retrywrite;
				}

				/*
				 * Transfer size is minimum of uio transfer
				 * and free space in pipe buffer.
				 */
				if (space > uio->uio_resid)
					size = uio->uio_resid;
				else
					size = space;
				/*
				 * First segment to transfer is minimum of
				 * transfer size and contiguous space in
				 * pipe buffer.  If first segment to transfer
				 * is less than the transfer size, we've got
				 * a wraparound in the buffer.
				 */
				segsize = wpipe->pipe_buffer.size -
					wpipe->pipe_buffer.in;
				if (segsize > size)
					segsize = size;

				/* Transfer first segment */

				error = uiomove(&wpipe->pipe_buffer.buffer[wpipe->pipe_buffer.in],
						segsize, uio);

				if (error == 0 && segsize < size) {
					/*
					 * Transfer remaining part now, to
					 * support atomic writes.  Wraparound
					 * happened.
					 */
#ifdef DIAGNOSTIC
					if (wpipe->pipe_buffer.in + segsize !=
					    wpipe->pipe_buffer.size)
						panic("Expected pipe buffer wraparound disappeared");
#endif

					error = uiomove(&wpipe->pipe_buffer.buffer[0],
							size - segsize, uio);
				}
				if (error == 0) {
					wpipe->pipe_buffer.in += size;
					if (wpipe->pipe_buffer.in >=
					    wpipe->pipe_buffer.size) {
#ifdef DIAGNOSTIC
						if (wpipe->pipe_buffer.in != size - segsize + wpipe->pipe_buffer.size)
							panic("Expected wraparound bad");
#endif
						wpipe->pipe_buffer.in = size - segsize;
					}

					wpipe->pipe_buffer.cnt += size;
#ifdef DIAGNOSTIC
					if (wpipe->pipe_buffer.cnt > wpipe->pipe_buffer.size)
						panic("Pipe buffer overflow");
#endif
				}
				pipeunlock(wpipe);
			}
			if (error)
				break;
		} else {
			/*
			 * If the "read-side" has been blocked, wake it up now.
			 */
			if (wpipe->pipe_state & PIPE_WANTR) {
				wpipe->pipe_state &= ~PIPE_WANTR;
				wakeup(wpipe);
			}

			/*
			 * don't block on non-blocking I/O
			 */
			if (fp->f_flag & FNONBLOCK) {
				error = EAGAIN;
				break;
			}

			/*
			 * We have no more space and have something to offer,
			 * wake up select/poll.
			 */
			pipeselwakeup(wpipe);

			wpipe->pipe_state |= PIPE_WANTW;
			error = tsleep(wpipe, (PRIBIO + 1)|PCATCH,
			    "pipewr", 0);
			if (error)
				break;
			/*
			 * If read side wants to go away, we just issue a
			 * signal to ourselves.
			 */
			if (wpipe->pipe_state & PIPE_EOF) {
				error = EPIPE;
				break;
			}	
		}
	}

	--wpipe->pipe_busy;

	if ((wpipe->pipe_busy == 0) && (wpipe->pipe_state & PIPE_WANT)) {
		wpipe->pipe_state &= ~(PIPE_WANT | PIPE_WANTR);
		wakeup(wpipe);
	} else if (wpipe->pipe_buffer.cnt > 0) {
		/*
		 * If we have put any characters in the buffer, we wake up
		 * the reader.
		 */
		if (wpipe->pipe_state & PIPE_WANTR) {
			wpipe->pipe_state &= ~PIPE_WANTR;
			wakeup(wpipe);
		}
	}

	/*
	 * Don't return EPIPE if I/O was successful
	 */
	if ((wpipe->pipe_buffer.cnt == 0) &&
	    (uio->uio_resid == 0) &&
	    (error == EPIPE)) {
		error = 0;
	}

	if (error == 0)
		getnanotime(&wpipe->pipe_mtime);
	/*
	 * We have something to offer, wake up select/poll.
	 */
	if (wpipe->pipe_buffer.cnt)
		pipeselwakeup(wpipe);

	return (error);
}

/*
 * we implement a very minimal set of ioctls for compatibility with sockets.
 */
int
pipe_ioctl(struct file *fp, u_long cmd, caddr_t data, struct proc *p)
{
	struct pipe *mpipe = fp->f_data;

	switch (cmd) {

	case FIONBIO:
		return (0);

	case FIOASYNC:
		if (*(int *)data) {
			mpipe->pipe_state |= PIPE_ASYNC;
		} else {
			mpipe->pipe_state &= ~PIPE_ASYNC;
		}
		return (0);

	case FIONREAD:
		*(int *)data = mpipe->pipe_buffer.cnt;
		return (0);

	case SIOCSPGRP:
		mpipe->pipe_pgid = *(int *)data;
		return (0);

	case SIOCGPGRP:
		*(int *)data = mpipe->pipe_pgid;
		return (0);

	}
	return (ENOTTY);
}

int
pipe_poll(struct file *fp, int events, struct proc *p)
{
	struct pipe *rpipe = fp->f_data;
	struct pipe *wpipe;
	int revents = 0;

	wpipe = rpipe->pipe_peer;
	if (events & (POLLIN | POLLRDNORM)) {
		if ((rpipe->pipe_buffer.cnt > 0) ||
		    (rpipe->pipe_state & PIPE_EOF))
			revents |= events & (POLLIN | POLLRDNORM);
	}

	/* NOTE: POLLHUP and POLLOUT/POLLWRNORM are mutually exclusive */
	if ((rpipe->pipe_state & PIPE_EOF) ||
	    (wpipe == NULL) ||
	    (wpipe->pipe_state & PIPE_EOF))
		revents |= POLLHUP;
	else if (events & (POLLOUT | POLLWRNORM)) {
		if ((wpipe->pipe_buffer.size - wpipe->pipe_buffer.cnt) >= PIPE_BUF)
			revents |= events & (POLLOUT | POLLWRNORM);
	}

	if (revents == 0) {
		if (events & (POLLIN | POLLRDNORM)) {
			selrecord(p, &rpipe->pipe_sel);
			rpipe->pipe_state |= PIPE_SEL;
		}
		if (events & (POLLOUT | POLLWRNORM)) {
			selrecord(p, &wpipe->pipe_sel);
			wpipe->pipe_state |= PIPE_SEL;
		}
	}
	return (revents);
}

int
pipe_stat(struct file *fp, struct stat *ub, struct proc *p)
{
	struct pipe *pipe = fp->f_data;

	memset(ub, 0, sizeof(*ub));
	ub->st_mode = S_IFIFO;
	ub->st_blksize = pipe->pipe_buffer.size;
	ub->st_size = pipe->pipe_buffer.cnt;
	ub->st_blocks = (ub->st_size + ub->st_blksize - 1) / ub->st_blksize;
	ub->st_atim.tv_sec  = pipe->pipe_atime.tv_sec;
	ub->st_atim.tv_nsec = pipe->pipe_atime.tv_nsec;
	ub->st_mtim.tv_sec  = pipe->pipe_mtime.tv_sec;
	ub->st_mtim.tv_nsec = pipe->pipe_mtime.tv_nsec;
	ub->st_ctim.tv_sec  = pipe->pipe_ctime.tv_sec;
	ub->st_ctim.tv_nsec = pipe->pipe_ctime.tv_nsec;
	ub->st_uid = fp->f_cred->cr_uid;
	ub->st_gid = fp->f_cred->cr_gid;
	/*
	 * Left as 0: st_dev, st_ino, st_nlink, st_rdev, st_flags, st_gen.
	 * XXX (st_dev, st_ino) should be unique.
	 */
	return (0);
}

int
pipe_close(struct file *fp, struct proc *p)
{
	struct pipe *cpipe = fp->f_data;

	fp->f_ops = NULL;
	fp->f_data = NULL;
	pipeclose(cpipe);
	return (0);
}

void
pipe_free_kmem(struct pipe *cpipe)
{
	if (cpipe->pipe_buffer.buffer != NULL) {
		if (cpipe->pipe_buffer.size > PIPE_SIZE)
			--nbigpipe;
		amountpipekva -= cpipe->pipe_buffer.size;
		km_free(cpipe->pipe_buffer.buffer, cpipe->pipe_buffer.size,
		    &kv_any, &kp_pageable);
		cpipe->pipe_buffer.buffer = NULL;
	}
}

/*
 * shutdown the pipe
 */
void
pipeclose(struct pipe *cpipe)
{
	struct pipe *ppipe;
	if (cpipe) {
		
		pipeselwakeup(cpipe);

		/*
		 * If the other side is blocked, wake it up saying that
		 * we want to close it down.
		 */
		cpipe->pipe_state |= PIPE_EOF;
		while (cpipe->pipe_busy) {
			wakeup(cpipe);
			cpipe->pipe_state |= PIPE_WANT;
			tsleep(cpipe, PRIBIO, "pipecl", 0);
		}

		/*
		 * Disconnect from peer
		 */
		if ((ppipe = cpipe->pipe_peer) != NULL) {
			pipeselwakeup(ppipe);

			ppipe->pipe_state |= PIPE_EOF;
			wakeup(ppipe);
			ppipe->pipe_peer = NULL;
		}

		/*
		 * free resources
		 */
		pipe_free_kmem(cpipe);
		pool_put(&pipe_pool, cpipe);
	}
}

int
pipe_kqfilter(struct file *fp, struct knote *kn)
{
	struct pipe *rpipe = kn->kn_fp->f_data;
	struct pipe *wpipe = rpipe->pipe_peer;

	switch (kn->kn_filter) {
	case EVFILT_READ:
		kn->kn_fop = &pipe_rfiltops;
		SLIST_INSERT_HEAD(&rpipe->pipe_sel.si_note, kn, kn_selnext);
		break;
	case EVFILT_WRITE:
		if (wpipe == NULL) {
			/* other end of pipe has been closed */
			return (EPIPE);
		}
		kn->kn_fop = &pipe_wfiltops;
		SLIST_INSERT_HEAD(&wpipe->pipe_sel.si_note, kn, kn_selnext);
		break;
	default:
		return (EINVAL);
	}

	return (0);
}

void
filt_pipedetach(struct knote *kn)
{
	struct pipe *rpipe = kn->kn_fp->f_data;
	struct pipe *wpipe = rpipe->pipe_peer;

	switch (kn->kn_filter) {
	case EVFILT_READ:
		SLIST_REMOVE(&rpipe->pipe_sel.si_note, kn, knote, kn_selnext);
		break;
	case EVFILT_WRITE:
		if (wpipe == NULL)
			return;
		SLIST_REMOVE(&wpipe->pipe_sel.si_note, kn, knote, kn_selnext);
		break;
	}
}

int
filt_piperead(struct knote *kn, long hint)
{
	struct pipe *rpipe = kn->kn_fp->f_data;
	struct pipe *wpipe = rpipe->pipe_peer;

	kn->kn_data = rpipe->pipe_buffer.cnt;

	if ((rpipe->pipe_state & PIPE_EOF) ||
	    (wpipe == NULL) || (wpipe->pipe_state & PIPE_EOF)) {
		kn->kn_flags |= EV_EOF; 
		return (1);
	}
	return (kn->kn_data > 0);
}

int
filt_pipewrite(struct knote *kn, long hint)
{
	struct pipe *rpipe = kn->kn_fp->f_data;
	struct pipe *wpipe = rpipe->pipe_peer;

	if ((wpipe == NULL) || (wpipe->pipe_state & PIPE_EOF)) {
		kn->kn_data = 0;
		kn->kn_flags |= EV_EOF; 
		return (1);
	}
	kn->kn_data = wpipe->pipe_buffer.size - wpipe->pipe_buffer.cnt;

	return (kn->kn_data >= PIPE_BUF);
}

void
pipe_init(void)
{
	pool_init(&pipe_pool, sizeof(struct pipe), 0, IPL_NONE, PR_WAITOK,
	    "pipepl", NULL);
}

@


1.75
log
@Add ktracing of the fds returned by pipe() and socketpair()

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.74 2016/09/15 02:00:16 dlg Exp $	*/
d136 3
a138 1
	int fds[2], error;
d151 1
a151 1
	error = falloc(p, &rf, &fds[0]);
d159 1
a159 1
	error = falloc(p, &wf, &fds[1]);
a165 5

	if (flags & O_CLOEXEC) {
		fdp->fd_ofileflags[fds[0]] |= UF_EXCLOSE;
		fdp->fd_ofileflags[fds[1]] |= UF_EXCLOSE;
	}
@


1.74
log
@all pools have their ipl set via pool_setipl, so fold it into pool_init.

the ioff argument to pool_init() is unused and has been for many
years, so this replaces it with an ipl argument. because the ipl
will be set on init we no longer need pool_setipl.

most of these changes have been done with coccinelle using the spatch
below. cocci sucks at formatting code though, so i fixed that by hand.

the manpage and subr_pool.c bits i did myself.

ok tedu@@ jmatthew@@

@@ipl@@
expression pp;
expression ipl;
expression s, a, o, f, m, p;
@@@@
-pool_init(pp, s, a, o, f, m, p);
-pool_setipl(pp, ipl);
+pool_init(pp, s, a, ipl, f, m, p);
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.73 2016/08/30 07:40:35 dlg Exp $	*/
d43 3
d181 4
@


1.73
log
@pool_setipl

ok natano@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.72 2016/01/15 18:10:48 stefan Exp $	*/
d873 2
a874 3
	pool_init(&pipe_pool, sizeof(struct pipe), 0, 0, PR_WAITOK, "pipepl",
	    NULL);
	pool_setipl(&pipe_pool, IPL_NONE);
@


1.72
log
@Convert to uiomove(); from Martin Natano

ok millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.71 2016/01/06 17:59:30 tedu Exp $	*/
d875 1
@


1.71
log
@remove unnecessary casts where the incoming type is void *.
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.70 2015/12/05 10:11:53 tedu Exp $	*/
d300 1
a300 2
	int nread = 0;
	int size;
d318 1
a318 1
			error = uiomovei(&rpipe->pipe_buffer.buffer[rpipe->pipe_buffer.out],
d415 1
a415 1
	int orig_resid;
d462 1
a462 1
		int space;
d478 2
a479 2
				int size;	/* Transfer size */
				int segsize;	/* first segment to transfer */
d516 1
a516 1
				error = uiomovei(&wpipe->pipe_buffer.buffer[wpipe->pipe_buffer.in], 
d531 1
a531 1
					error = uiomovei(&wpipe->pipe_buffer.buffer[0],
@


1.70
log
@remove stale lint annotations
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.69 2015/02/10 21:56:10 miod Exp $	*/
d298 1
a298 1
	struct pipe *rpipe = (struct pipe *) fp->f_data;
a416 1

d419 1
a419 1
	rpipe = (struct pipe *) fp->f_data;
d637 1
a637 1
	struct pipe *mpipe = (struct pipe *)fp->f_data;
d671 1
a671 1
	struct pipe *rpipe = (struct pipe *)fp->f_data;
d708 1
a708 1
	struct pipe *pipe = (struct pipe *)fp->f_data;
d733 1
a733 1
	struct pipe *cpipe = (struct pipe *)fp->f_data;
d798 1
a798 1
	struct pipe *rpipe = (struct pipe *)kn->kn_fp->f_data;
d824 1
a824 1
	struct pipe *rpipe = (struct pipe *)kn->kn_fp->f_data;
d842 1
a842 1
	struct pipe *rpipe = (struct pipe *)kn->kn_fp->f_data;
d858 1
a858 1
	struct pipe *rpipe = (struct pipe *)kn->kn_fp->f_data;
@


1.69
log
@First step towards making uiomove() take a size_t size argument:
- rename uiomove() to uiomovei() and update all its users.
- introduce uiomove(), which is similar to uiomovei() but with a size_t.
- rewrite uiomovei() as an uiomove() wrapper.
ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.68 2014/12/19 05:59:21 tedu Exp $	*/
a294 1
/* ARGSUSED */
a730 1
/* ARGSUSED */
a839 1
/*ARGSUSED*/
a855 1
/*ARGSUSED*/
@


1.68
log
@start retiring the nointr allocator. specify PR_WAITOK as a flag as a
marker for which pools are not interrupt safe. ok dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.67 2014/09/28 18:52:04 kettenis Exp $	*/
d320 1
a320 1
			error = uiomove(&rpipe->pipe_buffer.buffer[rpipe->pipe_buffer.out],
d519 1
a519 1
				error = uiomove(&wpipe->pipe_buffer.buffer[wpipe->pipe_buffer.in], 
d534 1
a534 1
					error = uiomove(&wpipe->pipe_buffer.buffer[0],
@


1.67
log
@Replace uvm_km_alloc(9) and uvm_km_free(9) with the equivalent km_alooc(9)
and km_free(9) calls.

ok tedu@@, mlarkin@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.66 2014/08/31 01:42:36 guenther Exp $	*/
d879 2
a880 2
	pool_init(&pipe_pool, sizeof(struct pipe), 0, 0, 0, "pipepl",
	    &pool_allocator_nointr);
@


1.66
log
@Add additional kernel interfaces for setting close-on-exec on fds
when creating them: pipe2(), dup3(), accept4(), MSG_CMSG_CLOEXEC,
SOCK_CLOEXEC.  Includes SOCK_NONBLOCK support.

ok matthew@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.65 2014/01/24 06:00:01 guenther Exp $	*/
d204 1
a204 1
	buffer = (caddr_t)uvm_km_valloc(kernel_map, size);
d751 2
a752 2
		uvm_km_free(kernel_map, (vaddr_t)cpipe->pipe_buffer.buffer,
		    cpipe->pipe_buffer.size);
@


1.65
log
@Copy timespecs member by member in fo_stat callback functions, to avoid
leaking values in the padding bytes on LP64.  Also, vn_stat() was lacking
the zero-fill to clean its padding.

ok kettenis@@ deraadt@@ phessler@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.64 2014/01/21 01:48:45 tedu Exp $	*/
d90 1
a102 1
/* ARGSUSED */
d109 21
d149 1
a149 1
	rf->f_flag = FREAD | FWRITE;
d157 1
a157 1
	wf->f_flag = FREAD | FWRITE;
d162 5
d173 1
a173 1
	error = copyout(fds, SCARG(uap, fdp), sizeof(fds));
@


1.64
log
@bzero -> memset
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.63 2012/05/06 09:45:26 mikeb Exp $	*/
d691 6
a696 3
	ub->st_atim = pipe->pipe_atime;
	ub->st_mtim = pipe->pipe_mtime;
	ub->st_ctim = pipe->pipe_ctime;
@


1.63
log
@take a file descriptor table lock after allocating pipe structures
and buffers;  ok guenther
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.62 2012/04/22 05:43:14 guenther Exp $	*/
d210 1
a210 1
	bzero(&cpipe->pipe_sel, sizeof cpipe->pipe_sel);
d686 1
a686 1
	bzero(ub, sizeof(*ub));
@


1.62
log
@Add struct proc * argument to FRELE() and FILE_SET_MATURE() in
anticipation of further changes to closef().  No binary change.

ok krw@@ miod@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.61 2011/07/08 19:00:09 tedu Exp $	*/
d111 1
a111 1
	struct pipe *rpipe, *wpipe;
a113 2
	fdplock(fdp);

d121 3
a123 1
		goto free2;
d160 1
a160 1
	(void)pipeclose(wpipe);
d162 2
a163 3
	if (rpipe != NULL)
		(void)pipeclose(rpipe);
	fdpunlock(fdp);
@


1.61
log
@keep the fdplock around copyout in pipe.  ok matthew
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.60 2011/07/08 05:01:27 matthew Exp $	*/
d144 2
a145 2
	FILE_SET_MATURE(rf);
	FILE_SET_MATURE(wf);
@


1.60
log
@Remove the sys_opipe() kernel entry point.  sys_pipe() is the future.

While here, switch compat_linux to just use sys_pipe() rather than
incorrectly wrapping sys_opipe().

ok tedu@@, miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.59 2011/05/27 08:53:15 nicm Exp $	*/
a146 2
	fdpunlock(fdp);

a148 1
		fdplock(fdp);
a150 1
		fdpunlock(fdp);
d152 1
@


1.59
log
@Fix the return values from pipe_kqfilter - kqfilters should return an
errno not 0/1.

ok guenther
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.58 2010/01/14 23:12:11 schwarze Exp $	*/
d104 1
a104 1
sys_opipe(struct proc *p, void *v, register_t *retval)
d106 3
d112 1
a112 1
	int fd, error;
d125 1
a125 1
	error = falloc(p, &rf, &fd);
a131 1
	retval[0] = fd;
d133 1
a133 1
	error = falloc(p, &wf, &fd);
a139 1
	retval[1] = fd;
d148 9
a156 1
	return (0);
d159 1
a159 1
	fdremove(fdp, retval[0]);
@


1.58
log
@fix typos in comments, no code changes;
from Brad Tilley <brad at 16systems dot com>;
ok oga@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.57 2009/11/09 17:53:39 nicm Exp $	*/
d776 1
a776 1
		if (wpipe == NULL)
d778 2
a779 1
			return (1);
d784 1
a784 1
		return (1);
d786 1
a786 1
	
@


1.57
log
@Every selwakeup() should have a matching KNOTE() (even if kqueue isn't
supported it doesn't do any harm), so put the KNOTE() in selwakeup() itself and
remove it from any occurences where both are used, except one for kqueue itself
and one in sys_pipe.c (where the selwakeup is under a PIPE_SEL flag).

Based on a diff from tedu.

ok deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.56 2009/10/30 18:03:34 deraadt Exp $	*/
d418 1
a418 1
	 * If an early error occured unbusy and return, waking up any pending
@


1.56
log
@pipeclose() calls pileseltimeout() which does the KNOTE(); therefore calling
KNOTE() a second time is not needed (and perhaps bad)
ok claudio millert
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.55 2009/01/29 22:08:45 guenther Exp $	*/
d258 2
a259 1
	}
a261 1
	KNOTE(&cpipe->pipe_sel.si_note, 0);
@


1.55
log
@Switch struct stat's timespec members to the names standardized in
POSIX 1003.1-2008, with compatibility macros for the names used in
previous version of OpenBSD.  Update all the references in the
kernel to use the new, standard member names.

ok'ed by miod@@, otto@@; ports build test by naddy@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.54 2008/07/11 14:12:57 blambert Exp $	*/
a752 1
			KNOTE(&ppipe->pipe_sel.si_note, 0);
@


1.54
log
@de-__inline a trio of functions to shave some space.

ok art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.53 2007/11/28 15:19:43 miod Exp $	*/
d686 3
a688 3
	ub->st_atimespec = pipe->pipe_atime;
	ub->st_mtimespec = pipe->pipe_mtime;
	ub->st_ctimespec = pipe->pipe_ctime;
@


1.53
log
@When updating the timestamps on pipes, use getnanotime() instead of more
accurate but more expensive nanotime(), the loss of precision shouldn't matter.
Inspired from the other *BSD which did a similar change.

ok tedu@@ millert@@ henning@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.52 2007/08/07 11:30:53 millert Exp $	*/
d93 3
a95 3
static __inline int pipelock(struct pipe *);
static __inline void pipeunlock(struct pipe *);
static __inline void pipeselwakeup(struct pipe *);
d226 1
a226 1
static __inline int
d242 1
a242 1
static __inline void
d252 1
a252 1
static __inline void
@


1.52
log
@Correctly deal with EOF on pipe wrt kqueue.  Based on a fix present
in FreeBSD and NetBSD.  OK art@@ beck@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.51 2006/11/17 09:21:52 jmc Exp $	*/
d214 1
a214 1
	nanotime(&cpipe->pipe_ctime);
d356 1
a356 1
		nanotime(&rpipe->pipe_atime);
d592 1
a592 1
		nanotime(&wpipe->pipe_mtime);
@


1.51
log
@missing punctuation in comments; from bret lambert
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.50 2005/12/13 10:33:14 jsg Exp $	*/
d738 1
d741 1
a741 1
			cpipe->pipe_state |= PIPE_WANT | PIPE_EOF;
@


1.50
log
@ansi/deregister. No binary change.
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.49 2004/07/22 06:13:08 tedu Exp $	*/
d163 1
a163 1
 * Allocate kva for pipe circular buffer, the space is pageable
@


1.49
log
@remove p arg from fdplock
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.48 2004/07/21 17:05:40 art Exp $	*/
d104 1
a104 4
sys_opipe(p, v, retval)
	struct proc *p;
	void *v;
	register_t *retval;
d169 1
a169 3
pipespace(cpipe, size)
	struct pipe *cpipe;
	u_int size;
d195 1
a195 2
pipe_create(cpipe)
	struct pipe *cpipe;
d227 1
a227 2
pipelock(cpipe)
	struct pipe *cpipe;
d243 1
a243 2
pipeunlock(cpipe)
	struct pipe *cpipe;
d253 1
a253 2
pipeselwakeup(cpipe)
	struct pipe *cpipe;
d266 1
a266 5
pipe_read(fp, poff, uio, cred)
	struct file *fp;
	off_t *poff;
	struct uio *uio;
	struct ucred *cred;
d383 1
a383 5
pipe_write(fp, poff, uio, cred)
	struct file *fp;
	off_t *poff;
	struct uio *uio;
	struct ucred *cred;
d606 1
a606 5
pipe_ioctl(fp, cmd, data, p)
	struct file *fp;
	u_long cmd;
	caddr_t data;
	struct proc *p;
d640 1
a640 4
pipe_poll(fp, events, p)
	struct file *fp;
	int events;
	struct proc *p;
d677 1
a677 4
pipe_stat(fp, ub, p)
	struct file *fp;
	struct stat *ub;
	struct proc *p;
d700 1
a700 3
pipe_close(fp, p)
	struct file *fp;
	struct proc *p;
d711 1
a711 2
pipe_free_kmem(cpipe)
	struct pipe *cpipe;
d727 1
a727 2
pipeclose(cpipe)
	struct pipe *cpipe;
d842 1
a842 1
pipe_init()
@


1.48
log
@In pipe_read, when the pipelock fails (most likely because we catch a
signal), don't jump to unlocked_error: and do things that we don't need
to do (including messing up the internal state of the pipe). Just return.

ok niklas@@ miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.47 2004/06/24 19:35:24 tholo Exp $	*/
d114 1
a114 1
	fdplock(fdp, p);
@


1.47
log
@This moves access to wall and uptime variables in MI code,
encapsulating all such access into wall-defined functions
that makes sure locking is done as needed.

It also cleans up some uses of wall time vs. uptime some
places, but there is sure to be more of these needed as
well, particularily in MD code.  Also, many current calls
to microtime() should probably be changed to getmicrotime(),
or to the {,get}microuptime() versions.

ok art@@ deraadt@@ aaron@@ matthieu@@ beck@@ sturm@@ millert@@ others
"Oh, that is not your problem!" from miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.46 2004/01/06 04:18:18 tedu Exp $	*/
d288 1
a288 1
		goto unlocked_error;
@


1.46
log
@lock filedesc before manipulating.  avoids some rare races.
testing for quite some time by brad + otto
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.45 2003/10/03 16:38:01 miod Exp $	*/
d220 1
a220 1
	microtime(&cpipe->pipe_ctime);
d369 1
a369 1
		microtime(&rpipe->pipe_atime);
d609 1
a609 1
		microtime(&wpipe->pipe_mtime);
d713 3
a715 3
	TIMEVAL_TO_TIMESPEC(&pipe->pipe_atime, &ub->st_atimespec);
	TIMEVAL_TO_TIMESPEC(&pipe->pipe_mtime, &ub->st_mtimespec);
	TIMEVAL_TO_TIMESPEC(&pipe->pipe_ctime, &ub->st_ctimespec);
@


1.45
log
@Bring several fixes from FreeBSD to our current pipe implementation:
- when allocating or growing a pipe buffer is not possible, do not panic
  but report the error and handle it correctly. (1.73)
- "The pipe_write() code was locking the pipe without busying it first
  in certain cases, and a close() by another process could potentially rip
  the pipe out from under the (blocked) locking operation." (from Al Viro,
  1.81)
- "Remove test in pipe_write() which causes write(2) to return EAGAIN
  on a non-blocking pipe in cases where select(2) returns the file
  descriptor as ready for write. This in turns causes libc_r, for
  one, to busy wait in such cases.
  Note: it is a quick performance fix, a more complex fix might be
  required in case this turns out to have unexpected side effects."
  (1.141)
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.44 2003/09/23 16:51:12 millert Exp $	*/
d114 2
d148 2
d151 1
d161 1
@


1.44
log
@Replace select backends with poll backends.  selscan() and pollscan()
now call the poll backend.  With this change we implement greater
poll(2) functionality instead of emulating it via the select backend.
Adapted from NetBSD and including some changes from FreeBSD.
Tested by many, deraadt@@ OK
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.43 2002/03/14 01:27:04 millert Exp $	*/
a32 2
#include <sys/protosw.h>
#include <sys/stat.h>
a33 1
#include <sys/malloc.h>
a36 1
#include <sys/select.h>
a37 3
#include <sys/errno.h>
#include <sys/queue.h>
#include <sys/kernel.h>
d91 2
a92 1
void	pipeinit(struct pipe *);
d96 1
a96 1
void	pipespace(struct pipe *);
d115 3
a117 1
	pipeinit(rpipe);
d119 3
a121 1
	pipeinit(wpipe);
d124 1
a124 1
	if (error)
d128 1
a129 1
	rf->f_data = (caddr_t)rpipe;
d133 1
a133 1
	if (error)
d137 1
a138 1
	wf->f_data = (caddr_t)wpipe;
d153 1
d161 3
d165 2
a166 2
void
pipespace(cpipe)
d168 1
d170 14
a183 4
	cpipe->pipe_buffer.buffer = (caddr_t) uvm_km_valloc(kernel_map,
						cpipe->pipe_buffer.size);
	if (cpipe->pipe_buffer.buffer == NULL)
		panic("pipespace: out of kvm");
d186 2
d193 2
a194 2
void
pipeinit(cpipe)
d197 1
d199 1
a199 6
	cpipe->pipe_buffer.in = 0;
	cpipe->pipe_buffer.out = 0;
	cpipe->pipe_buffer.cnt = 0;
	cpipe->pipe_buffer.size = PIPE_SIZE;

	/* Buffer kva gets dynamically allocated */
d201 5
a205 2
	/* cpipe->pipe_buffer.object = invalid */

d209 5
a216 1
	bzero(&cpipe->pipe_sel, sizeof cpipe->pipe_sel);
d218 2
a305 1

d319 1
d321 1
a321 2
			if (rpipe->pipe_state & PIPE_EOF) {
				/* XXX error = ? */
a322 1
			}
d349 1
a349 1
			if (fp->f_flag & FNONBLOCK)
d351 1
a351 1
			else {
d386 1
a386 1
	return error;
d408 1
a408 1
		return EPIPE;
d410 1
d421 4
a424 5
		if (wpipe->pipe_buffer.buffer) {
			amountpipekva -= wpipe->pipe_buffer.size;
			uvm_km_free(kernel_map,
				(vaddr_t)wpipe->pipe_buffer.buffer,
				wpipe->pipe_buffer.size);
a425 7

		wpipe->pipe_buffer.in = 0;
		wpipe->pipe_buffer.out = 0;
		wpipe->pipe_buffer.cnt = 0;
		wpipe->pipe_buffer.size = BIG_PIPE_SIZE;
		wpipe->pipe_buffer.buffer = NULL;
		++nbigpipe;
a426 1
		
d428 10
a437 6
	if (wpipe->pipe_buffer.buffer == NULL) {
		if ((error = pipelock(wpipe)) == 0) {
			pipespace(wpipe);
			pipeunlock(wpipe);
		} else {
			return error;
d439 1
a441 1
	++wpipe->pipe_busy;
a443 1
retrywrite:
d447 1
d459 1
a459 2
		if (space > 0 &&
		    (wpipe->pipe_buffer.cnt < wpipe->pipe_buffer.size)) {
d578 3
a580 3
	if ((wpipe->pipe_busy == 0) &&
	    (wpipe->pipe_state & PIPE_WANT)) {
		wpipe->pipe_state &= ~(PIPE_WANT|PIPE_WANTR);
d598 1
a598 1
	    (error == EPIPE))
d600 1
d610 1
a610 1
	return error;
d702 1
a702 1
	bzero((caddr_t)ub, sizeof (*ub));
d716 1
a716 1
	return 0;
d727 2
d730 15
a744 2
	fp->f_data = NULL;
	return 0;
d765 1
a765 1
			cpipe->pipe_state |= PIPE_WANT|PIPE_EOF;
d777 1
d784 1
a784 8
		if (cpipe->pipe_buffer.buffer) {
			if (cpipe->pipe_buffer.size > PIPE_SIZE)
				--nbigpipe;
			amountpipekva -= cpipe->pipe_buffer.size;
			uvm_km_free(kernel_map,
				(vaddr_t)cpipe->pipe_buffer.buffer,
				cpipe->pipe_buffer.size);
		}
d802 1
@


1.43
log
@First round of __P removal in sys
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.42 2002/02/08 13:53:28 art Exp $	*/
d49 1
d61 1
a61 1
int	pipe_select(struct file *, int which, struct proc *);
d67 1
a67 1
	pipe_read, pipe_write, pipe_ioctl, pipe_select, pipe_kqfilter,
d544 1
a544 1
			 * wake up selects.
d591 1
a591 2
	 * We have something to offer,
	 * wake up select.
d641 1
a641 1
pipe_select(fp, which, p)
d643 1
a643 1
	int which;
d648 1
d651 15
a665 1
	switch (which) {
d667 4
a670 14
	case FREAD:
		if ((rpipe->pipe_buffer.cnt > 0) ||
		    (rpipe->pipe_state & PIPE_EOF)) {
			return (1);
		}
		selrecord(p, &rpipe->pipe_sel);
		rpipe->pipe_state |= PIPE_SEL;
		break;

	case FWRITE:
		if ((wpipe == NULL) ||
		    (wpipe->pipe_state & PIPE_EOF) ||
		    ((wpipe->pipe_buffer.size - wpipe->pipe_buffer.cnt) >= PIPE_BUF)) {
			return (1);
d672 3
a674 9
		selrecord(p, &wpipe->pipe_sel);
		wpipe->pipe_state |= PIPE_SEL;
		break;

	case 0:
		if ((rpipe->pipe_state & PIPE_EOF) ||
		    (wpipe == NULL) ||
		    (wpipe->pipe_state & PIPE_EOF)) {
			return (1);
a675 4
			
		selrecord(p, &rpipe->pipe_sel);
		rpipe->pipe_state |= PIPE_SEL;
		break;
d677 1
a677 1
	return (0);
@


1.42
log
@- Rename FILE_{,UN}USE to FREF and FRELE. USE is a bad verb and we don't have
  the same semantics as NetBSD anyway, so it's good to avoid name collissions.
- Always fdremove before freeing the file, not the other way around.
- falloc FREFs the file.
- have FILE_SET_MATURE FRELE the file (It feels like a good ortogonality to
  falloc FREFing the file).
- Use closef as much as possible instead of ffree in error paths of
  falloc:ing functions. closef is much more careful with the fd and can
  deal with the fd being forcibly closed by dup2. Also try to avoid
  manually calling *fo_close when closef can do that for us (this makes
  some error paths mroe complicated (sys_socketpair and sys_pipe), but
  others become simpler (sys_open)).
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.41 2002/01/23 00:39:47 art Exp $	*/
d57 7
a63 7
int	pipe_read __P((struct file *, off_t *, struct uio *, struct ucred *));
int	pipe_write __P((struct file *, off_t *, struct uio *, struct ucred *));
int	pipe_close __P((struct file *, struct proc *));
int	pipe_select __P((struct file *, int which, struct proc *));
int	pipe_kqfilter __P((struct file *fp, struct knote *kn));
int	pipe_ioctl __P((struct file *, u_long, caddr_t, struct proc *));
int	pipe_stat __P((struct file *fp, struct stat *ub, struct proc *p));
d96 6
a101 6
void	pipeclose __P((struct pipe *));
void	pipeinit __P((struct pipe *));
static __inline int pipelock __P((struct pipe *));
static __inline void pipeunlock __P((struct pipe *));
static __inline void pipeselwakeup __P((struct pipe *));
void	pipespace __P((struct pipe *));
@


1.41
log
@Pool deals fairly well with physical memory shortage, but it doesn't deal
well (not at all) with shortages of the vm_map where the pages are mapped
(usually kmem_map).

Try to deal with it:
 - group all information the backend allocator for a pool in a separate
   struct. The pool will only have a pointer to that struct.
 - change the pool_init API to reflect that.
 - link all pools allocating from the same allocator on a linked list.
 - Since an allocator is responsible to wait for physical memory it will
   only fail (waitok) when it runs out of its backing vm_map, carefully
   drain pools using the same allocator so that va space is freed.
   (see comments in code for caveats and details).
 - change pool_reclaim to return if it actually succeeded to free some
   memory, use that information to make draining easier and more efficient.
 - get rid of PR_URGENT, noone uses it.
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.40 2001/11/06 19:53:20 miod Exp $	*/
a148 1
	ffree(rf);
d150 2
d154 2
a155 1
	(void)pipeclose(rpipe);
@


1.40
log
@Replace inclusion of <vm/foo.h> with the correct <uvm/bar.h> when necessary.
(Look ma, I might have broken the tree)
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.39 2001/10/26 12:03:27 art Exp $	*/
d849 1
a849 2
		0, pool_page_alloc_nointr, pool_page_free_nointr,
		M_PIPE);
@


1.40.2.1
log
@Merge in -current, builds on i386, otherwise untested
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.41 2002/01/23 00:39:47 art Exp $	*/
d849 2
a850 1
	    &pool_allocator_nointr);
@


1.40.2.2
log
@Sync UBC branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.40.2.1 2002/01/31 22:55:41 niklas Exp $	*/
d57 7
a63 7
int	pipe_read(struct file *, off_t *, struct uio *, struct ucred *);
int	pipe_write(struct file *, off_t *, struct uio *, struct ucred *);
int	pipe_close(struct file *, struct proc *);
int	pipe_select(struct file *, int which, struct proc *);
int	pipe_kqfilter(struct file *fp, struct knote *kn);
int	pipe_ioctl(struct file *, u_long, caddr_t, struct proc *);
int	pipe_stat(struct file *fp, struct stat *ub, struct proc *p);
d96 6
a101 6
void	pipeclose(struct pipe *);
void	pipeinit(struct pipe *);
static __inline int pipelock(struct pipe *);
static __inline void pipeunlock(struct pipe *);
static __inline void pipeselwakeup(struct pipe *);
void	pipespace(struct pipe *);
d149 1
a150 2
	closef(rf, p);
	rpipe = NULL;
d153 1
a153 2
	if (rpipe != NULL)
		(void)pipeclose(rpipe);
@


1.39
log
@ - every new fd created by falloc() is marked as larval and should not be used
   any anyone. Every caller of falloc matures the fd when it's usable.
 - Since every lookup in the fd table must now check this flag and all of
   them do the same thing, move all the necessary checks into a function -
   fd_getfile.
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.38 2001/09/19 20:50:58 mickey Exp $	*/
a49 1
#include <vm/vm.h>
@


1.38
log
@merge vm/vm_kern.h into uvm/uvm_extern.h; art@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.37 2001/07/05 07:15:07 art Exp $	*/
d146 2
@


1.37
log
@Get rid of unnecessary includes.
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.36 2001/06/27 04:49:46 art Exp $	*/
a50 2
#include <vm/vm_kern.h>

@


1.36
log
@remove old vm
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.35 2001/06/23 06:34:37 art Exp $	*/
d48 1
a50 4
#include <vm/vm_prot.h>
#include <vm/vm_param.h>
#include <sys/lock.h>
#include <vm/vm_object.h>
a51 4
#include <vm/vm_extern.h>
#include <vm/pmap.h>
#include <vm/vm_map.h>
#include <vm/vm_page.h>
@


1.35
log
@pool_init, not pool_create
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.34 2001/06/23 06:09:16 art Exp $	*/
a59 1
#if defined(UVM)
a60 1
#endif
a171 1
#if defined(UVM)
a175 10
#else
	int npages, error;

	npages = round_page(cpipe->pipe_buffer.size)/PAGE_SIZE;
	/*
	 * Create an object, I don't like the idea of paging to/from
	 * kernel_object.
	 */
	cpipe->pipe_buffer.object = vm_object_allocate(npages);
	cpipe->pipe_buffer.buffer = (caddr_t) vm_map_min(kernel_map);
a176 10
	/*
	 * Insert the object into the kernel map, and allocate kva for it.
	 * The map entry is, by default, pageable.
	 */
	error = vm_map_find(kernel_map, cpipe->pipe_buffer.object, 0,
		(vaddr_t *) &cpipe->pipe_buffer.buffer,
		cpipe->pipe_buffer.size, 1);
	if (error != KERN_SUCCESS)
		panic("pipespace: out of kvm");
#endif
a408 1
#if defined(UVM)
a411 5
#else
			kmem_free(kernel_map,
				(vaddr_t)wpipe->pipe_buffer.buffer,
				wpipe->pipe_buffer.size);
#endif
a768 1
#if defined(UVM)
a771 5
#else
			kmem_free(kernel_map,
				(vaddr_t)cpipe->pipe_buffer.buffer,
				cpipe->pipe_buffer.size);
#endif
@


1.34
log
@pipe_stat isn't referenced from outside sys_pipe.c anymore
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.33 2001/06/23 06:04:34 art Exp $	*/
d106 1
a106 1
struct pool *pipe_pool;
d131 1
a131 1
	rpipe = pool_get(pipe_pool, PR_WAITOK);
d133 1
a133 1
	wpipe = pool_get(pipe_pool, PR_WAITOK);
d808 1
a808 1
		pool_put(pipe_pool, cpipe);
d891 1
a891 1
	pipe_pool = pool_create(sizeof(struct pipe), 0, 0, 0, "pipepl",
@


1.33
log
@Add pipe_init, call it from main, move the pool initialization into it.
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.32 2001/06/05 18:28:18 provos Exp $	*/
d75 1
@


1.32
log
@fix kqueue EVFILT_WRITE; okay art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.31 2001/05/26 04:16:08 art Exp $	*/
a129 5
	if (pipe_pool == NULL)
		pipe_pool = pool_create(sizeof(struct pipe), 0, 0, 0, "pipepl",
			0, pool_page_alloc_nointr, pool_page_free_nointr,
			M_PIPE);

d886 9
@


1.31
log
@Sync in some improvements from FreeBSD + my own improvements.

 - use pool for allocating pipe structures.
 - use microtime instead of splhigh and time.
 - improve locking.
 - better handling of nonblocking.
 - various efficiency fixes.
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.30 2001/05/14 13:43:53 art Exp $	*/
d820 1
d825 1
d828 2
d831 1
a836 1
	SLIST_INSERT_HEAD(&rpipe->pipe_sel.si_note, kn, kn_selnext);
d844 1
d846 10
a855 1
	SLIST_REMOVE(&rpipe->pipe_sel.si_note, kn, knote, kn_selnext);
@


1.30
log
@gc OLD_PIPE.
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.29 2001/05/14 12:38:47 art Exp $	*/
d37 1
d60 4
a89 1
 
d103 1
d105 1
a105 1
static int amountpipekva;
d109 1
a109 1
static __inline int pipelock __P((struct pipe *, int));
d130 6
a135 1
	rpipe = malloc(sizeof(*rpipe), M_PIPE, M_WAITOK);
d137 1
a137 1
	wpipe = malloc(sizeof(*wpipe), M_PIPE, M_WAITOK);
a178 1
	/* XXX - this is wrong, use an aobj instead */
a213 1
	int s;
d227 3
a229 5
	s = splhigh();
	cpipe->pipe_ctime = time;
	cpipe->pipe_atime = time;
	cpipe->pipe_mtime = time;
	splx(s);
d239 1
a239 1
pipelock(cpipe, catch)
a240 1
	int catch;
d245 1
a245 3
		error = tsleep(cpipe, catch ? PRIBIO|PCATCH : PRIBIO,
		    "pipelk", 0);
		if (error)
d288 1
a288 1
	int error = 0;
d292 4
d297 1
d308 1
a308 2
			if ((error = pipelock(rpipe,1)) == 0) {
				error = uiomove(&rpipe->pipe_buffer.buffer[rpipe->pipe_buffer.out], 
a309 2
				pipeunlock(rpipe);
			}
d318 10
d337 1
d345 4
d352 6
a357 4
			if (fp->f_flag & FNONBLOCK) {
				error = EAGAIN;
				break;
			}
d360 2
a361 3
			 * If there is no more to read in the pipe, reset
			 * its pointers to the beginning.  This improves
			 * cache hit stats.
d363 6
a368 14
		
			if ((error = pipelock(rpipe,1)) == 0) {
				if (rpipe->pipe_buffer.cnt == 0) {
					rpipe->pipe_buffer.in = 0;
					rpipe->pipe_buffer.out = 0;
				}
				pipeunlock(rpipe);
			} else {
				break;
			}

			if (rpipe->pipe_state & PIPE_WANTW) {
				rpipe->pipe_state &= ~PIPE_WANTW;
				wakeup(rpipe);
a369 3

			rpipe->pipe_state |= PIPE_WANTR;
			error = tsleep(rpipe, PRIBIO|PCATCH, "piperd", 0);
d371 1
a371 1
				break;
d374 1
d376 4
a379 5
	if (error == 0) {
		int s = splhigh();
		rpipe->pipe_atime = time;
		splx(s);
	}
d381 3
a383 1
	--rpipe->pipe_busy;
d389 1
a389 14
		 * If there is no more to read in the pipe, reset
		 * its pointers to the beginning.  This improves
		 * cache hit stats.
		 */
		if (rpipe->pipe_buffer.cnt == 0) {
			if ((error == 0) && (error = pipelock(rpipe,1)) == 0) {
				rpipe->pipe_buffer.in = 0;
				rpipe->pipe_buffer.out = 0;
				pipeunlock(rpipe);
			}
		}

		/*
		 * If the "write-side" has been blocked, wake it up now.
d457 1
a457 1
		if ((error = pipelock(wpipe,1)) == 0) {
d467 2
d471 6
a479 1
		/* XXX perhaps they need to be contiguous to be atomic? */
d485 39
a523 16
			/*
			 * This set the maximum transfer as a segment of
			 * the buffer.
			 */
			int size = wpipe->pipe_buffer.size - wpipe->pipe_buffer.in;
			/*
			 * space is the size left in the buffer
			 */
			if (size > space)
				size = space;
			/*
			 * now limit it to the size of the uio transfer
			 */
			if (size > uio->uio_resid)
				size = uio->uio_resid;
			if ((error = pipelock(wpipe,1)) == 0) {
d525 34
a558 1
					size, uio);
a562 6

			wpipe->pipe_buffer.in += size;
			if (wpipe->pipe_buffer.in >= wpipe->pipe_buffer.size)
				wpipe->pipe_buffer.in = 0;

			wpipe->pipe_buffer.cnt += size;
d626 2
a627 5
	if (error == 0) {
		int s = splhigh();
		wpipe->pipe_mtime = time;
		splx(s);
	}
d740 2
d743 1
a743 2
	 * Left as 0: st_dev, st_ino, st_nlink, st_uid, st_gid, st_rdev,
	 * st_flags, st_gen.
d812 1
a812 1
		free(cpipe, M_PIPE);
@


1.29
log
@Add a fo_stat member to struct fileops. Used soon.
Also add a stat function for kqueue from FreeBSD.
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.28 2001/05/14 10:51:26 art Exp $	*/
a21 2
#ifndef OLD_PIPE

a760 1
#endif
@


1.28
log
@More generic arguments to pipe_stat.
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.27 2001/05/14 10:35:42 art Exp $	*/
d75 1
a75 1
	pipe_close 
@


1.27
log
@We already have a prototype for pipe_stat in sys/pipe.h
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.26 2001/03/01 20:54:33 provos Exp $	*/
d674 2
a675 2
pipe_stat(pipe, ub)
	struct pipe *pipe;
d677 1
d679 2
@


1.26
log
@port kqueue changes from freebsd, plus all required openbsd glue.
okay deraadt@@, millert@@
from jlemon@@freebsd.org:
extend kqueue down to the device layer, backwards compatible approach
suggested by peter@@freebsd.org
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.25 2000/11/16 20:02:17 provos Exp $	*/
a105 1
int	pipe_stat __P((struct pipe *, struct stat *));
@


1.26.2.1
log
@Pull in patch from current:
Fix (provos):
fix kqueue EVFILT_WRITE; okay art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.26 2001/03/01 20:54:33 provos Exp $	*/
a766 1
	struct pipe *wpipe = rpipe->pipe_peer;
a770 1
		SLIST_INSERT_HEAD(&rpipe->pipe_sel.si_note, kn, kn_selnext);
a772 2
		if (wpipe == NULL)
			return (1);
a773 1
		SLIST_INSERT_HEAD(&wpipe->pipe_sel.si_note, kn, kn_selnext);
d779 1
a786 1
	struct pipe *wpipe = rpipe->pipe_peer;
d788 1
a788 10
	switch (kn->kn_filter) {
	case EVFILT_READ:
		SLIST_REMOVE(&rpipe->pipe_sel.si_note, kn, knote, kn_selnext);
		break;
	case EVFILT_WRITE:
		if (wpipe == NULL)
			return;
		SLIST_REMOVE(&wpipe->pipe_sel.si_note, kn, knote, kn_selnext);
		break;
	}
@


1.25
log
@support kernel event queues, from FreeBSD by Jonathan Lemon,
okay art@@, millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.24 2000/04/19 08:34:54 csapuntz Exp $	*/
d70 1
d73 4
a76 2
static struct fileops pipeops =
    { pipe_read, pipe_write, pipe_ioctl, pipe_select, pipe_close };
a77 1
int	filt_pipeattach(struct knote *kn);
d82 4
a85 4
struct filterops pipe_rwfiltops[] = {
	{ 1, filt_pipeattach, filt_pipedetach, filt_piperead },
	{ 1, filt_pipeattach, filt_pipedetach, filt_pipewrite },
};
d87 1
d764 1
a764 1
filt_pipeattach(struct knote *kn)
d768 11
@


1.24
log
@

Change struct file interface methods read and write to pass file offset in
and out.

Make pread/pwrite in netbsd & linux thread safe - which is the whole point
anyway.
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.23 2000/01/27 18:56:13 art Exp $	*/
d48 1
d75 9
d273 1
d759 51
@


1.23
log
@No need to include sys/vmmeter.h
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.22 1999/11/25 13:39:38 art Exp $	*/
d65 2
a66 2
int	pipe_read __P((struct file *, struct uio *, struct ucred *));
int	pipe_write __P((struct file *, struct uio *, struct ucred *));
d267 1
a267 1
pipe_read(fp, uio, cred)
d269 1
d394 1
a394 1
pipe_write(fp, uio, cred)
d396 1
@


1.23.2.1
log
@merge in approximately 2.9 into SMP branch
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.26 2001/03/01 20:54:33 provos Exp $	*/
a47 1
#include <sys/event.h>
d65 2
a66 2
int	pipe_read __P((struct file *, off_t *, struct uio *, struct ucred *));
int	pipe_write __P((struct file *, off_t *, struct uio *, struct ucred *));
a68 1
int	pipe_kqfilter __P((struct file *fp, struct knote *kn));
d71 3
a73 13
static struct fileops pipeops = {
	pipe_read, pipe_write, pipe_ioctl, pipe_select, pipe_kqfilter,
	pipe_close 
};

void	filt_pipedetach(struct knote *kn);
int	filt_piperead(struct knote *kn, long hint);
int	filt_pipewrite(struct knote *kn, long hint);

struct filterops pipe_rfiltops =
	{ 1, NULL, filt_pipedetach, filt_piperead };
struct filterops pipe_wfiltops =
	{ 1, NULL, filt_pipedetach, filt_pipewrite };
a74 1
 
a262 1
	KNOTE(&cpipe->pipe_sel.si_note, 0);
d267 1
a267 1
pipe_read(fp, poff, uio, cred)
a268 1
	off_t *poff;
d393 1
a393 1
pipe_write(fp, poff, uio, cred)
a394 1
	off_t *poff;
a745 62

int
pipe_kqfilter(struct file *fp, struct knote *kn)
{
	struct pipe *rpipe = (struct pipe *)kn->kn_fp->f_data;

	switch (kn->kn_filter) {
	case EVFILT_READ:
		kn->kn_fop = &pipe_rfiltops;
		break;
	case EVFILT_WRITE:
		kn->kn_fop = &pipe_wfiltops;
		break;
	default:
		return (1);
	}
	
	SLIST_INSERT_HEAD(&rpipe->pipe_sel.si_note, kn, kn_selnext);
	return (0);
}

void
filt_pipedetach(struct knote *kn)
{
	struct pipe *rpipe = (struct pipe *)kn->kn_fp->f_data;

	SLIST_REMOVE(&rpipe->pipe_sel.si_note, kn, knote, kn_selnext);
}

/*ARGSUSED*/
int
filt_piperead(struct knote *kn, long hint)
{
	struct pipe *rpipe = (struct pipe *)kn->kn_fp->f_data;
	struct pipe *wpipe = rpipe->pipe_peer;

	kn->kn_data = rpipe->pipe_buffer.cnt;

	if ((rpipe->pipe_state & PIPE_EOF) ||
	    (wpipe == NULL) || (wpipe->pipe_state & PIPE_EOF)) {
		kn->kn_flags |= EV_EOF; 
		return (1);
	}
	return (kn->kn_data > 0);
}

/*ARGSUSED*/
int
filt_pipewrite(struct knote *kn, long hint)
{
	struct pipe *rpipe = (struct pipe *)kn->kn_fp->f_data;
	struct pipe *wpipe = rpipe->pipe_peer;

	if ((wpipe == NULL) || (wpipe->pipe_state & PIPE_EOF)) {
		kn->kn_data = 0;
		kn->kn_flags |= EV_EOF; 
		return (1);
	}
	kn->kn_data = wpipe->pipe_buffer.size - wpipe->pipe_buffer.cnt;

	return (kn->kn_data >= PIPE_BUF);
}
@


1.23.2.2
log
@Merge in -current from two days ago in the SMP branch.
As usual with merges, they do not indicate progress, so do not hold
your breath for working SMP, and do not mail me and ask about the
state of it.  It has not changed.  There is work ongoing, but very, very
slowly.  The commit is done in parts as to not lock up the tree in too
big chunks at a time.
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.23.2.1 2001/05/14 22:32:43 niklas Exp $	*/
d22 2
a38 1
#include <sys/pool.h>
a60 2
#include <uvm/uvm_extern.h>

a71 1
int	pipe_stat __P((struct file *fp, struct stat *ub, struct proc *p));
d75 1
a75 1
	pipe_stat, pipe_close 
d87 1
d101 1
a103 2
struct pool pipe_pool;

d106 2
a107 1
static __inline int pipelock __P((struct pipe *));
d128 1
a128 1
	rpipe = pool_get(&pipe_pool, PR_WAITOK);
d130 1
a130 1
	wpipe = pool_get(&pipe_pool, PR_WAITOK);
d171 2
d177 2
d180 18
d208 1
d222 5
a226 3
	microtime(&cpipe->pipe_ctime);
	cpipe->pipe_atime = cpipe->pipe_ctime;
	cpipe->pipe_mtime = cpipe->pipe_ctime;
d236 1
a236 1
pipelock(cpipe)
d238 1
d243 3
a245 1
		if ((error = tsleep(cpipe, PRIBIO|PCATCH, "pipelk", 0)))
d288 1
a288 1
	int error;
a291 4
	error = pipelock(rpipe);
	if (error)
		goto unlocked_error;

a292 1

d303 2
a304 1
			error = uiomove(&rpipe->pipe_buffer.buffer[rpipe->pipe_buffer.out],
d306 2
a315 10

			/*
			 * If there is no more to read in the pipe, reset
			 * its pointers to the beginning.  This improves
			 * cache hit stats.
			 */
			if (rpipe->pipe_buffer.cnt == 0) {
				rpipe->pipe_buffer.in = 0;
				rpipe->pipe_buffer.out = 0;
			}
a324 1

d332 2
d335 2
a336 4
			/*
			 * Break if some data was read.
			 */
			if (nread > 0)
d338 1
d341 3
a343 3
			 * Unlock the pipe buffer for our remaining processing.
			 * We will either break out with an error or we will
			 * sleep and relock to loop.
d345 10
a354 1
			pipeunlock(rpipe);
d356 3
a358 10
			/*
			 * Handle non-blocking mode operation or
			 * wait for more data.
			 */
			if (fp->f_flag & FNONBLOCK)
				error = EAGAIN;
			else {
				rpipe->pipe_state |= PIPE_WANTR;
				if ((error = tsleep(rpipe, PRIBIO|PCATCH, "piperd", 0)) == 0)
					error = pipelock(rpipe);
d360 3
d364 1
a364 1
				goto unlocked_error;
a366 1
	pipeunlock(rpipe);
d368 6
a373 3
	if (error == 0)
		microtime(&rpipe->pipe_atime);
unlocked_error:
a374 4

	/*
	 * PIPE_WANT processing only makes sense if pipe_busy is 0.
	 */
d380 14
a393 1
		 * Handle write blocking hysteresis.
d440 1
d444 5
d461 1
a461 1
		if ((error = pipelock(wpipe)) == 0) {
a470 2

retrywrite:
a472 6

		if (wpipe->pipe_state & PIPE_EOF) {
			error = EPIPE;
			break;
		}

d476 1
d482 16
a497 39
			if ((error = pipelock(wpipe)) == 0) {
				int size;	/* Transfer size */
				int segsize;	/* first segment to transfer */

				/*
				 * If a process blocked in uiomove, our
				 * value for space might be bad.
				 *
				 * XXX will we be ok if the reader has gone
				 * away here?
				 */
				if (space > wpipe->pipe_buffer.size -
				    wpipe->pipe_buffer.cnt) {
					pipeunlock(wpipe);
					goto retrywrite;
				}

				/*
				 * Transfer size is minimum of uio transfer
				 * and free space in pipe buffer.
				 */
				if (space > uio->uio_resid)
					size = uio->uio_resid;
				else
					size = space;
				/*
				 * First segment to transfer is minimum of
				 * transfer size and contiguous space in
				 * pipe buffer.  If first segment to transfer
				 * is less than the transfer size, we've got
				 * a wraparound in the buffer.
				 */
				segsize = wpipe->pipe_buffer.size -
					wpipe->pipe_buffer.in;
				if (segsize > size)
					segsize = size;

				/* Transfer first segment */

d499 1
a499 34
						segsize, uio);

				if (error == 0 && segsize < size) {
					/*
					 * Transfer remaining part now, to
					 * support atomic writes.  Wraparound
					 * happened.
					 */
#ifdef DIAGNOSTIC
					if (wpipe->pipe_buffer.in + segsize !=
					    wpipe->pipe_buffer.size)
						panic("Expected pipe buffer wraparound disappeared");
#endif

					error = uiomove(&wpipe->pipe_buffer.buffer[0],
							size - segsize, uio);
				}
				if (error == 0) {
					wpipe->pipe_buffer.in += size;
					if (wpipe->pipe_buffer.in >=
					    wpipe->pipe_buffer.size) {
#ifdef DIAGNOSTIC
						if (wpipe->pipe_buffer.in != size - segsize + wpipe->pipe_buffer.size)
							panic("Expected wraparound bad");
#endif
						wpipe->pipe_buffer.in = size - segsize;
					}

					wpipe->pipe_buffer.cnt += size;
#ifdef DIAGNOSTIC
					if (wpipe->pipe_buffer.cnt > wpipe->pipe_buffer.size)
						panic("Pipe buffer overflow");
#endif
				}
d504 6
d573 5
a577 2
	if (error == 0)
		microtime(&wpipe->pipe_mtime);
d675 2
a676 2
pipe_stat(fp, ub, p)
	struct file *fp;
a677 1
	struct proc *p;
a678 2
	struct pipe *pipe = (struct pipe *)fp->f_data;

a686 2
	ub->st_uid = fp->f_cred->cr_uid;
	ub->st_gid = fp->f_cred->cr_gid;
d688 2
a689 1
	 * Left as 0: st_dev, st_ino, st_nlink, st_rdev, st_flags, st_gen.
d748 1
d752 5
d758 1
a758 1
		pool_put(&pipe_pool, cpipe);
d761 1
a766 1
	struct pipe *wpipe = rpipe->pipe_peer;
a770 1
		SLIST_INSERT_HEAD(&rpipe->pipe_sel.si_note, kn, kn_selnext);
a772 2
		if (wpipe == NULL)
			return (1);
a773 1
		SLIST_INSERT_HEAD(&wpipe->pipe_sel.si_note, kn, kn_selnext);
d779 1
a786 1
	struct pipe *wpipe = rpipe->pipe_peer;
d788 1
a788 10
	switch (kn->kn_filter) {
	case EVFILT_READ:
		SLIST_REMOVE(&rpipe->pipe_sel.si_note, kn, knote, kn_selnext);
		break;
	case EVFILT_WRITE:
		if (wpipe == NULL)
			return;
		SLIST_REMOVE(&wpipe->pipe_sel.si_note, kn, knote, kn_selnext);
		break;
	}
a823 9

void
pipe_init()
{
	pool_init(&pipe_pool, sizeof(struct pipe), 0, 0, 0, "pipepl",
		0, pool_page_alloc_nointr, pool_page_free_nointr,
		M_PIPE);
}

@


1.23.2.3
log
@Sync the SMP branch to something just after 3.0
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.23.2.2 2001/07/04 10:48:34 niklas Exp $	*/
d48 4
d53 6
a59 1
#include <vm/vm.h>
a154 2
	FILE_SET_MATURE(rf);
	FILE_SET_MATURE(wf);
@


1.23.2.4
log
@merge in -current
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d50 1
@


1.23.2.5
log
@Merge in trunk
@
text
@d149 1
a150 2
	closef(rf, p);
	rpipe = NULL;
d153 1
a153 2
	if (rpipe != NULL)
		(void)pipeclose(rpipe);
d849 2
a850 1
	    &pool_allocator_nointr);
@


1.23.2.6
log
@Merge in -current from about a week ago
@
text
@d57 7
a63 7
int	pipe_read(struct file *, off_t *, struct uio *, struct ucred *);
int	pipe_write(struct file *, off_t *, struct uio *, struct ucred *);
int	pipe_close(struct file *, struct proc *);
int	pipe_select(struct file *, int which, struct proc *);
int	pipe_kqfilter(struct file *fp, struct knote *kn);
int	pipe_ioctl(struct file *, u_long, caddr_t, struct proc *);
int	pipe_stat(struct file *fp, struct stat *ub, struct proc *p);
d96 6
a101 6
void	pipeclose(struct pipe *);
void	pipeinit(struct pipe *);
static __inline int pipelock(struct pipe *);
static __inline void pipeunlock(struct pipe *);
static __inline void pipeselwakeup(struct pipe *);
void	pipespace(struct pipe *);
@


1.23.2.7
log
@Merge of current from two weeks agointo the SMP branch
@
text
@d33 2
d36 1
d40 1
d42 3
a48 1
#include <sys/poll.h>
d60 1
a60 1
int	pipe_poll(struct file *, int events, struct proc *);
d66 1
a66 1
	pipe_read, pipe_write, pipe_ioctl, pipe_poll, pipe_kqfilter,
d97 1
a97 2
void	pipe_free_kmem(struct pipe *);
int	pipe_create(struct pipe *);
d101 1
a101 1
int	pipespace(struct pipe *, u_int);
a118 2
	fdplock(fdp, p);

d120 1
a120 3
	error = pipe_create(rpipe);
	if (error != 0)
		goto free1;
d122 1
a122 3
	error = pipe_create(wpipe);
	if (error != 0)
		goto free2;
d125 1
a125 1
	if (error != 0)
a128 1
	rf->f_data = rpipe;
d130 1
d134 1
a134 1
	if (error != 0)
a137 1
	wf->f_data = wpipe;
d139 1
a146 2

	fdpunlock(fdp);
a147 1

a153 1
free1:
a155 1
	fdpunlock(fdp);
a160 3
 * This routine will 'realloc' the size of a pipe safely, if it fails
 * it will retain the old buffer.
 * If it fails it will return ENOMEM.
d162 2
a163 2
int
pipespace(cpipe, size)
a164 1
	u_int size;
d166 4
a169 14
	caddr_t buffer;

	buffer = (caddr_t)uvm_km_valloc(kernel_map, size);
	if (buffer == NULL) {
		return (ENOMEM);
	}

	/* free old resources if we are resizing */
	pipe_free_kmem(cpipe);
	cpipe->pipe_buffer.buffer = buffer;
	cpipe->pipe_buffer.size = size;
	cpipe->pipe_buffer.in = 0;
	cpipe->pipe_buffer.out = 0;
	cpipe->pipe_buffer.cnt = 0;
a171 2

	return (0);
d177 2
a178 2
int
pipe_create(cpipe)
a180 1
	int error;
d182 6
a187 1
	/* so pipe_free_kmem() doesn't follow junk pointer */
d189 2
a190 5
	/*
	 * protect so pipeclose() doesn't follow a junk pointer
	 * if pipespace() fails.
	 */
	bzero(&cpipe->pipe_sel, sizeof cpipe->pipe_sel);
a193 5

	error = pipespace(cpipe, PIPE_SIZE);
	if (error != 0)
		return (error);

d197 1
a198 2

	return (0);
d285 1
a298 1
			 * read returns 0 on EOF, no need to set error
d300 2
a301 1
			if (rpipe->pipe_state & PIPE_EOF)
d303 1
d330 1
a330 1
			if (fp->f_flag & FNONBLOCK) {
d332 1
a332 1
			} else {
d367 1
a367 1
	return (error);
d389 1
a389 1
		return (EPIPE);
a390 1
	++wpipe->pipe_busy;
d401 5
a405 4
		if ((error = pipelock(wpipe)) == 0) {
			if (pipespace(wpipe, BIG_PIPE_SIZE) == 0)
				nbigpipe++;
			pipeunlock(wpipe);
d407 7
d415 1
d417 6
a422 10
	/*
	 * If an early error occured unbusy and return, waking up any pending
	 * readers.
	 */
	if (error) {
		--wpipe->pipe_busy;
		if ((wpipe->pipe_busy == 0) &&
		    (wpipe->pipe_state & PIPE_WANT)) {
			wpipe->pipe_state &= ~(PIPE_WANT | PIPE_WANTR);
			wakeup(wpipe);
a423 1
		return (error);
d426 1
d429 1
a432 1
retrywrite:
d444 2
a445 1
		if (space > 0) {
d543 1
a543 1
			 * wake up select/poll.
d564 3
a566 3

	if ((wpipe->pipe_busy == 0) && (wpipe->pipe_state & PIPE_WANT)) {
		wpipe->pipe_state &= ~(PIPE_WANT | PIPE_WANTR);
d584 1
a584 1
	    (error == EPIPE)) {
a585 1
	}
d590 2
a591 1
	 * We have something to offer, wake up select/poll.
d596 1
a596 1
	return (error);
d641 1
a641 1
pipe_poll(fp, events, p)
d643 1
a643 1
	int events;
a647 1
	int revents = 0;
d650 3
a652 1
	if (events & (POLLIN | POLLRDNORM)) {
d654 6
a659 3
		    (rpipe->pipe_state & PIPE_EOF))
			revents |= events & (POLLIN | POLLRDNORM);
	}
d661 9
a669 9
	/* NOTE: POLLHUP and POLLOUT/POLLWRNORM are mutually exclusive */
	if ((rpipe->pipe_state & PIPE_EOF) ||
	    (wpipe == NULL) ||
	    (wpipe->pipe_state & PIPE_EOF))
		revents |= POLLHUP;
	else if (events & (POLLOUT | POLLWRNORM)) {
		if ((wpipe->pipe_buffer.size - wpipe->pipe_buffer.cnt) >= PIPE_BUF)
			revents |= events & (POLLOUT | POLLWRNORM);
	}
d671 10
a680 9
	if (revents == 0) {
		if (events & (POLLIN | POLLRDNORM)) {
			selrecord(p, &rpipe->pipe_sel);
			rpipe->pipe_state |= PIPE_SEL;
		}
		if (events & (POLLOUT | POLLWRNORM)) {
			selrecord(p, &wpipe->pipe_sel);
			wpipe->pipe_state |= PIPE_SEL;
		}
d682 1
a682 1
	return (revents);
d693 1
a693 1
	bzero(ub, sizeof(*ub));
d707 1
a707 1
	return (0);
d718 1
a718 1
	fp->f_ops = NULL;
d720 1
a720 16
	pipeclose(cpipe);
	return (0);
}

void
pipe_free_kmem(cpipe)
	struct pipe *cpipe;
{
	if (cpipe->pipe_buffer.buffer != NULL) {
		if (cpipe->pipe_buffer.size > PIPE_SIZE)
			--nbigpipe;
		amountpipekva -= cpipe->pipe_buffer.size;
		uvm_km_free(kernel_map, (vaddr_t)cpipe->pipe_buffer.buffer,
		    cpipe->pipe_buffer.size);
		cpipe->pipe_buffer.buffer = NULL;
	}
d741 1
a741 1
			cpipe->pipe_state |= PIPE_WANT | PIPE_EOF;
a752 1
			KNOTE(&ppipe->pipe_sel.si_note, 0);
d759 8
a766 1
		pipe_free_kmem(cpipe);
a783 1
			/* other end of pipe has been closed */
@


1.22
log
@Annoying unnecessary space.
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.21 1999/11/21 17:40:26 deraadt Exp $	*/
a44 1
#include <sys/vmmeter.h>
@


1.21
log
@if select returns writable on a pipe, the write should not return
EWOULDBLOCK.  turns out the two checking conditions were not the same,
and a certain use of rsync uncovered the bug by chewing all available
cpu time; fix from art
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.20 1999/10/29 14:08:49 art Exp $	*/
d483 1
a483 1
				error = uiomove( &wpipe->pipe_buffer.buffer[wpipe->pipe_buffer.in], 
@


1.20
log
@Use M_PIPE instead of M_TEMP.
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.19 1999/10/29 14:01:44 art Exp $	*/
d465 2
a466 1
		if (space > 0 && (wpipe->pipe_buffer.cnt < PIPE_SIZE)) {
@


1.19
log
@Remove the "Direct write" code.
We never used it and some parts of it slowed the code down.
Generally clean up the pipe code.
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.18 1999/10/27 07:38:19 niklas Exp $	*/
d116 1
a116 1
	rpipe = malloc(sizeof(*rpipe), M_TEMP, M_WAITOK);
d118 1
a118 1
	wpipe = malloc(sizeof(*wpipe), M_TEMP, M_WAITOK);
d742 1
a742 1
		free(cpipe, M_TEMP);
@


1.18
log
@Actually make ASYNC pipes generate SIGIO.
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.17 1999/07/15 14:07:41 art Exp $	*/
a30 23
/*
 * This code has two modes of operation, a small write mode and a large
 * write mode.  The small write mode acts like conventional pipes with
 * a kernel buffer.  If the buffer is less than PIPE_MINDIRECT, then the
 * "normal" pipe buffering is done.  If the buffer is between PIPE_MINDIRECT
 * and PIPE_SIZE in size, it is fully mapped and wired into the kernel, and
 * the receiving process can copy it directly from the pages in the sending
 * process.
 *
 * If the sending process receives a signal, it is possible that it will
 * go away, and certainly its address space can change, because control
 * is returned back to the user-mode side.  In that case, the pipe code
 * arranges to copy the buffer supplied by the user process, to a pageable
 * kernel buffer, and the receiving process will grab the data from the
 * pageable kernel buffer.  Since signals don't happen all that often,
 * the copy operation is normally eliminated.
 *
 * The constant PIPE_MINDIRECT is chosen to make sure that buffering will
 * happen for small transfers so that the system will not spend all of
 * its time context switching.  PIPE_SIZE is constrained by the
 * amount of kernel virtual memory.
 */

a46 3
#if defined(__FreeBSD__)
#include <sys/sysproto.h>
#else /* defined(__NetBSD__) || defined(__OpenBSD__) */
a48 1
#endif
a69 3
#if defined(__FreeBSD__)
int	pipe_ioctl __P((struct file *, int, caddr_t, struct proc *));
#else /* defined(__NetBSD__) || defined(__OpenBSD__) */
a70 1
#endif
a82 13
#define MAXPIPESIZE (2*PIPE_SIZE/3)

/*
 * Maximum amount of kva for pipes -- this is kind-of a soft limit, but
 * is there so that on large systems, we don't exhaust it.
 */
#define MAXPIPEKVA (8*1024*1024)

/*
 * Limit for direct transfers, we cannot, of course limit
 * the amount of kva for pipes in general though.
 */
#define LIMITPIPEKVA (16*1024*1024)
a97 6
#ifndef PIPE_NODIRECT
int	pipe_build_write_buffer __P((struct pipe *, struct uio *));
void	pipe_destroy_write_buffer __P((struct pipe *));
int	pipe_direct_write __P((struct pipe *, struct uio *));
void	pipe_clone_write_buffer __P((struct pipe *));
#endif
a105 3
#if defined(__FreeBSD__)
pipe(p, uap, retval)
#else /* (__NetBSD__) || (__OpenBSD__) */
a106 1
#endif
a108 3
#if defined(__FreeBSD__)
	int retval[];
#else /* (__NetBSD__) || (__OpenBSD__) */
a109 1
#endif
d111 1
a111 1
	register struct filedesc *fdp = p->p_fd;
d116 1
a116 1
	rpipe = malloc( sizeof (*rpipe), M_TEMP, M_WAITOK);
d118 1
a118 2
	rpipe->pipe_state |= PIPE_DIRECTOK;
	wpipe = malloc( sizeof (*wpipe), M_TEMP, M_WAITOK);
a119 1
	wpipe->pipe_state |= PIPE_DIRECTOK;
a123 1
	retval[0] = fd;
d128 2
d160 1
a171 1
	 * XXX -- minor change needed here for NetBSD/OpenBSD VM systems.
a172 3
#if defined(__FreeBSD__)
	cpipe->pipe_buffer.object = vm_object_allocate(OBJT_DEFAULT, npages);
#else /* (__NetBSD__) || (__OpenBSD__) */
a173 1
#endif
a178 1
	 * XXX -- minor change needed here for NetBSD/OpenBSD VM systems.
a179 6
#if defined(__FreeBSD__)
	error = vm_map_find(kernel_map, cpipe->pipe_buffer.object, 0,
		(vaddr_t *) &cpipe->pipe_buffer.buffer, 
		cpipe->pipe_buffer.size, 1,
		VM_PROT_ALL, VM_PROT_ALL, 0);
#else /* (__NetBSD__) || (__OpenBSD__) */
a182 2
#endif

d184 1
a184 1
		panic("pipeinit: cannot allocate pipe -- out of kvm -- code = %d", error);
a216 11

#ifndef PIPE_NODIRECT
	/*
	 * pipe data structure initializations to support direct pipe I/O
	 */
	cpipe->pipe_map.cnt = 0;
	cpipe->pipe_map.kva = 0;
	cpipe->pipe_map.pos = 0;
	cpipe->pipe_map.npages = 0;
	/* cpipe->pipe_map.ms[] = invalid */
#endif
a272 1

d284 1
a284 2
			size = rpipe->pipe_buffer.size -
			    rpipe->pipe_buffer.out;
d290 1
a290 1
				error = uiomove( &rpipe->pipe_buffer.buffer[rpipe->pipe_buffer.out], 
a302 24
#ifndef PIPE_NODIRECT
		/*
		 * Direct copy, bypassing a kernel buffer.
		 */
		} else if ((size = rpipe->pipe_map.cnt) &&
			(rpipe->pipe_state & PIPE_DIRECTW)) {
			caddr_t va;
			if (size > uio->uio_resid)
				size = uio->uio_resid;
			if ((error = pipelock(rpipe,1)) == 0) {
				va = (caddr_t) rpipe->pipe_map.kva + rpipe->pipe_map.pos;
				error = uiomove(va, size, uio);
				pipeunlock(rpipe);
			}
			if (error)
				break;
			nread += size;
			rpipe->pipe_map.pos += size;
			rpipe->pipe_map.cnt -= size;
			if (rpipe->pipe_map.cnt == 0) {
				rpipe->pipe_state &= ~PIPE_DIRECTW;
				wakeup(rpipe);
			}
#endif
a392 216
#ifndef PIPE_NODIRECT
/*
 * Map the sending processes' buffer into kernel space and wire it.
 * This is similar to a physical write operation.
 */
int
pipe_build_write_buffer(wpipe, uio)
	struct pipe *wpipe;
	struct uio *uio;
{
	int size;
	int i;
	vaddr_t addr, endaddr, paddr;

	size = uio->uio_iov->iov_len;
	if (size > wpipe->pipe_buffer.size)
		size = wpipe->pipe_buffer.size;

	endaddr = round_page(uio->uio_iov->iov_base + size);
	for(i = 0, addr = trunc_page(uio->uio_iov->iov_base);
		addr < endaddr;
		addr += PAGE_SIZE, i+=1) {

		vm_page_t m;

		vm_fault_quick( (caddr_t) addr, VM_PROT_READ);
		paddr = pmap_kextract(addr);
		if (!paddr) {
			int j;
			for(j=0;j<i;j++)
				vm_page_unwire(wpipe->pipe_map.ms[j]);
			return EFAULT;
		}

		m = PHYS_TO_VM_PAGE(paddr);
		vm_page_wire(m);
		wpipe->pipe_map.ms[i] = m;
	}

/*
 * set up the control block
 */
	wpipe->pipe_map.npages = i;
	wpipe->pipe_map.pos = ((vaddr_t) uio->uio_iov->iov_base) & PAGE_MASK;
	wpipe->pipe_map.cnt = size;

/*
 * and map the buffer
 */
	if (wpipe->pipe_map.kva == 0) {
		/*
		 * We need to allocate space for an extra page because the
		 * address range might (will) span pages at times.
		 */
		wpipe->pipe_map.kva = kmem_alloc_pageable(kernel_map,
			wpipe->pipe_buffer.size + PAGE_SIZE);
		amountpipekva += wpipe->pipe_buffer.size + PAGE_SIZE;
	}
	pmap_qenter(wpipe->pipe_map.kva, wpipe->pipe_map.ms,
		wpipe->pipe_map.npages);

/*
 * and update the uio data
 */

	uio->uio_iov->iov_len -= size;
	uio->uio_iov->iov_base += size;
	if (uio->uio_iov->iov_len == 0)
		uio->uio_iov++;
	uio->uio_resid -= size;
	uio->uio_offset += size;
	return 0;
}

/*
 * unmap and unwire the process buffer
 */
void
pipe_destroy_write_buffer(wpipe)
struct pipe *wpipe;
{
	int i;
	if (wpipe->pipe_map.kva) {
		pmap_qremove(wpipe->pipe_map.kva, wpipe->pipe_map.npages);

		if (amountpipekva > MAXPIPEKVA) {
			vaddr_t kva = wpipe->pipe_map.kva;
			wpipe->pipe_map.kva = 0;
			kmem_free(kernel_map, kva,
				wpipe->pipe_buffer.size + PAGE_SIZE);
			amountpipekva -= wpipe->pipe_buffer.size + PAGE_SIZE;
		}
	}
	for (i=0;i<wpipe->pipe_map.npages;i++)
		vm_page_unwire(wpipe->pipe_map.ms[i]);
}

/*
 * In the case of a signal, the writing process might go away.  This
 * code copies the data into the circular buffer so that the source
 * pages can be freed without loss of data.
 */
void
pipe_clone_write_buffer(wpipe)
struct pipe *wpipe;
{
	int size;
	int pos;

	size = wpipe->pipe_map.cnt;
	pos = wpipe->pipe_map.pos;
	bcopy((caddr_t) wpipe->pipe_map.kva+pos,
			(caddr_t) wpipe->pipe_buffer.buffer,
			size);

	wpipe->pipe_buffer.in = size;
	wpipe->pipe_buffer.out = 0;
	wpipe->pipe_buffer.cnt = size;
	wpipe->pipe_state &= ~PIPE_DIRECTW;

	pipe_destroy_write_buffer(wpipe);
}

/*
 * This implements the pipe buffer write mechanism.  Note that only
 * a direct write OR a normal pipe write can be pending at any given time.
 * If there are any characters in the pipe buffer, the direct write will
 * be deferred until the receiving process grabs all of the bytes from
 * the pipe buffer.  Then the direct mapping write is set-up.
 */
int
pipe_direct_write(wpipe, uio)
	struct pipe *wpipe;
	struct uio *uio;
{
	int error;
retry:
	while (wpipe->pipe_state & PIPE_DIRECTW) {
		if ( wpipe->pipe_state & PIPE_WANTR) {
			wpipe->pipe_state &= ~PIPE_WANTR;
			wakeup(wpipe);
		}
		wpipe->pipe_state |= PIPE_WANTW;
		error = tsleep(wpipe,
				PRIBIO|PCATCH, "pipdww", 0);
		if (error)
			goto error1;
		if (wpipe->pipe_state & PIPE_EOF) {
			error = EPIPE;
			goto error1;
		}
	}
	wpipe->pipe_map.cnt = 0;	/* transfer not ready yet */
	if (wpipe->pipe_buffer.cnt > 0) {
		if ( wpipe->pipe_state & PIPE_WANTR) {
			wpipe->pipe_state &= ~PIPE_WANTR;
			wakeup(wpipe);
		}
			
		wpipe->pipe_state |= PIPE_WANTW;
		error = tsleep(wpipe,
				PRIBIO|PCATCH, "pipdwc", 0);
		if (error)
			goto error1;
		if (wpipe->pipe_state & PIPE_EOF) {
			error = EPIPE;
			goto error1;
		}
		goto retry;
	}

	wpipe->pipe_state |= PIPE_DIRECTW;

	error = pipe_build_write_buffer(wpipe, uio);
	if (error) {
		wpipe->pipe_state &= ~PIPE_DIRECTW;
		goto error1;
	}

	error = 0;
	while (!error && (wpipe->pipe_state & PIPE_DIRECTW)) {
		if (wpipe->pipe_state & PIPE_EOF) {
			pipelock(wpipe, 0);
			pipe_destroy_write_buffer(wpipe);
			pipeunlock(wpipe);
			pipeselwakeup(wpipe);
			error = EPIPE;
			goto error1;
		}
		if (wpipe->pipe_state & PIPE_WANTR) {
			wpipe->pipe_state &= ~PIPE_WANTR;
			wakeup(wpipe);
		}
		pipeselwakeup(wpipe);
		error = tsleep(wpipe, PRIBIO|PCATCH, "pipdwt", 0);
	}

	pipelock(wpipe,0);
	if (wpipe->pipe_state & PIPE_DIRECTW) {
		/*
		 * this bit of trickery substitutes a kernel buffer for
		 * the process that might be going away.
		 */
		pipe_clone_write_buffer(wpipe);
	} else {
		pipe_destroy_write_buffer(wpipe);
	}
	pipeunlock(wpipe);
	return error;

error1:
	wakeup(wpipe);
	return error;
}
#endif
	
d419 3
a421 4
		(nbigpipe < LIMITBIGPIPES) &&
		(wpipe->pipe_state & PIPE_DIRECTW) == 0 &&
		(wpipe->pipe_buffer.size <= PIPE_SIZE) &&
		(wpipe->pipe_buffer.cnt == 0)) {
a435 9
#ifndef PIPE_NODIRECT
		if (wpipe->pipe_map.kva) {
			amountpipekva -= wpipe->pipe_buffer.size + PAGE_SIZE;
			kmem_free(kernel_map,
				wpipe->pipe_map.kva,
				wpipe->pipe_buffer.size + PAGE_SIZE);
		}
#endif

a441 8

#ifndef PIPE_NODIRECT
		wpipe->pipe_map.cnt = 0;
		wpipe->pipe_map.kva = 0;
		wpipe->pipe_map.pos = 0;
		wpipe->pipe_map.npages = 0;
#endif

a457 37
#ifndef PIPE_NODIRECT
		/*
		 * If the transfer is large, we can gain performance if
		 * we do process-to-process copies directly.
		 * If the write is non-blocking, we don't use the
		 * direct write mechanism.
		 */
		if ((uio->uio_iov->iov_len >= PIPE_MINDIRECT) &&
		    (fp->f_flag & FNONBLOCK) == 0 &&
			(wpipe->pipe_map.kva || (amountpipekva < LIMITPIPEKVA)) &&
			(uio->uio_iov->iov_len >= PIPE_MINDIRECT)) {
			error = pipe_direct_write( wpipe, uio);
			if (error) {
				break;
			}
			continue;
		}
#endif

		/*
		 * Pipe buffered writes cannot be coincidental with
		 * direct writes.  We wait until the currently executing
		 * direct write is completed before we start filling the
		 * pipe buffer.
		 */
	retrywrite:
		while (wpipe->pipe_state & PIPE_DIRECTW) {
			if (wpipe->pipe_state & PIPE_WANTR) {
				wpipe->pipe_state &= ~PIPE_WANTR;
				wakeup(wpipe);
			}
			error = tsleep(wpipe,
					PRIBIO|PCATCH, "pipbww", 0);
			if (error)
				break;
		}

a481 8
				/*
				 * It is possible for a direct write to
				 * slip in on us... handle it here...
				 */
				if (wpipe->pipe_state & PIPE_DIRECTW) {
					pipeunlock(wpipe);
					goto retrywrite;
				}
d535 1
a535 1
		(wpipe->pipe_state & PIPE_WANT)) {
d553 2
a554 2
		(uio->uio_resid == 0) &&
		(error == EPIPE))
a577 3
#if defined(__FreeBSD__)
	int cmd;
#else
d579 1
a579 2
#endif
	register caddr_t data;
d582 1
a582 1
	register struct pipe *mpipe = (struct pipe *)fp->f_data;
d598 1
a598 6
#ifndef PIPE_NODIRECT
		if (mpipe->pipe_state & PIPE_DIRECTW)
			*(int *)data = mpipe->pipe_map.cnt;
		else
#endif
			*(int *)data = mpipe->pipe_buffer.cnt;
d619 1
a619 1
	register struct pipe *rpipe = (struct pipe *)fp->f_data;
d626 2
a627 3
		if ( (rpipe->pipe_state & PIPE_DIRECTW) ||
			(rpipe->pipe_buffer.cnt > 0) ||
			(rpipe->pipe_state & PIPE_EOF)) {
d636 2
a637 3
			(wpipe->pipe_state & PIPE_EOF) ||
			(((wpipe->pipe_state & PIPE_DIRECTW) == 0) &&
			 (wpipe->pipe_buffer.size - wpipe->pipe_buffer.cnt) >= PIPE_BUF)) {
d646 2
a647 2
			(wpipe == NULL) ||
			(wpipe->pipe_state & PIPE_EOF)) {
d660 2
a661 2
	register struct pipe *pipe;
	register struct stat *ub;
a741 8
#ifndef PIPE_NODIRECT
		if (cpipe->pipe_map.kva) {
			amountpipekva -= cpipe->pipe_buffer.size + PAGE_SIZE;
			kmem_free(kernel_map,
				cpipe->pipe_map.kva,
				cpipe->pipe_buffer.size + PAGE_SIZE);
		}
#endif
@


1.17
log
@vm_offset_t -> {v,p}addr_t ; vm_size_t -> {v,p}size_t
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.16 1999/07/13 15:17:50 provos Exp $	*/
d345 2
@


1.16
log
@introduce fdremove() to mark a file descriptor as unused. fdremove makes
sure that the fd_freefile hints stay in sync, otherwise free file
descriptors might not be overlooked by fdalloc(); ok millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.15 1999/06/08 16:05:22 deraadt Exp $	*/
d246 1
a246 1
		(vm_offset_t *) &cpipe->pipe_buffer.buffer, 
d251 1
a251 1
		(vm_offset_t *) &cpipe->pipe_buffer.buffer,
d512 1
a512 1
	vm_offset_t addr, endaddr, paddr;
d543 1
a543 1
	wpipe->pipe_map.pos = ((vm_offset_t) uio->uio_iov->iov_base) & PAGE_MASK;
d586 1
a586 1
			vm_offset_t kva = wpipe->pipe_map.kva;
d751 1
a751 1
				(vm_offset_t)wpipe->pipe_buffer.buffer,
d755 1
a755 1
				(vm_offset_t)wpipe->pipe_buffer.buffer,
d1131 1
a1131 1
				(vm_offset_t)cpipe->pipe_buffer.buffer,
d1135 1
a1135 1
				(vm_offset_t)cpipe->pipe_buffer.buffer,
@


1.15
log
@better fd leak prevention
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.14 1999/06/07 20:46:09 deraadt Exp $	*/
d204 1
a204 1
	fdp->fd_ofiles[retval[0]] = NULL;
@


1.14
log
@need seperate sys_pipe() versions, for pipeclose() or soclose() calls
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.13 1999/06/07 07:17:42 deraadt Exp $	*/
a152 28

int
sys_pipe(p, v, retval)
	struct proc *p;
	void *v;
	register_t *retval;
{
	register struct filedesc *fdp = p->p_fd;
	register struct sys_pipe_args /* {
		syscallarg(int *) fdp;
	} */ *uap = v;
	int error;

	if ((error = sys_opipe(p, v, retval)) == -1)
		return (error);
	
	error = copyout((caddr_t)retval, (caddr_t)SCARG(uap, fdp),
	    2 * sizeof (int));
	if (error) {
		pipeclose((struct pipe *)(fdp->fd_ofiles[retval[0]]->f_data));
		ffree(fdp->fd_ofiles[retval[0]]);
		fdp->fd_ofiles[retval[0]] = NULL;
		pipeclose((struct pipe *)(fdp->fd_ofiles[retval[1]]->f_data));
		ffree(fdp->fd_ofiles[retval[1]]);
		fdp->fd_ofiles[retval[1]] = NULL;
	}
	return (error);
}
@


1.13
log
@replacement pipe() system call; copies data into place inside kernel, so
that EFAULT return value is possible
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.12 1999/06/07 01:41:01 deraadt Exp $	*/
d153 28
@


1.12
log
@oops, premature commit
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.11 1999/06/07 01:38:44 deraadt Exp $	*/
d159 1
a159 1
sys_pipe(p, v, retval)
@


1.11
log
@store NULL in fd_ofiles
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.10 1999/02/26 05:12:18 art Exp $	*/
d159 1
a159 1
sys_opipe(p, v, retval)
@


1.10
log
@kmem allocation changes for uvm
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.9 1999/02/16 21:27:37 art Exp $	*/
d159 1
a159 1
sys_pipe(p, v, retval)
d204 1
a204 1
	fdp->fd_ofiles[retval[0]] = 0;
@


1.9
log
@Move defining of PIPE_NODIRECT to pipe.h and conditionalize more code with it.
This allows this code to compile on sparc.
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.8 1997/11/06 05:58:21 csapuntz Exp $	*/
d218 6
d257 1
d749 5
d757 1
d786 1
a786 1
	if( wpipe->pipe_buffer.buffer == NULL) {
d1129 5
d1137 1
@


1.8
log
@Updates for VFS Lite 2 + soft update.
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.7 1997/10/06 20:20:02 deraadt Exp $	*/
a90 9
 * Use this define if you want to disable *fancy* VM things.  Expect an
 * approx 30% decrease in transfer rate.  This could be useful for
 * NetBSD or OpenBSD.
 */
#if defined(__NetBSD__) || defined(__OpenBSD__)
#define PIPE_NODIRECT
#endif

/*
d975 1
d979 1
@


1.7
log
@back out vfs lite2 till after 2.2
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.5 1997/02/24 14:19:58 niklas Exp $	*/
d80 1
a80 1
#include <vm/lock.h>
@


1.6
log
@VFS Lite2 Changes
@
text
@d80 1
a80 1
#include <sys/lock.h>
@


1.5
log
@OpenBSD tags
@
text
@d1 1
a1 1
/*	$OpenBSD: sys_pipe.c,v 1.4 1996/10/12 14:34:42 niklas Exp $	*/
d80 1
a80 1
#include <vm/lock.h>
@


1.4
log
@Correct sys_pipe's 3rd arg type, alpha needs it
@
text
@d1 2
a19 2
 *
 * $Id: sys_pipe.c,v 1.3 1996/09/05 12:31:14 mickey Exp $
@


1.3
log
@compile!
@
text
@d19 1
a19 1
 * $Id: sys_pipe.c,v 1.2 1996/09/04 22:23:28 niklas Exp $
d172 1
d174 3
@


1.2
log
@Stylistic cleanup, like removing "static"s, and removing warnings
given by -Wall -Wstrict-prototypes -Wmissing-prototypes
@
text
@d19 1
a19 1
 * $Id: sys_pipe.c,v 1.1 1996/08/27 14:47:00 shawn Exp $
a75 1
#include <sys/pipe.h>
d87 2
@


1.1
log
@New fast pipe(2) from freebsd without fancy vm stuff.

The old pipes can be used with the "OLD_PIPE" config option.
@
text
@d19 1
a19 1
 * $Id: sys_pipe.c,v 1.20 1996/07/13 22:52:50 dyson Exp $
d72 3
d101 4
a104 6
static int pipe_read __P((struct file *fp, struct uio *uio, 
		struct ucred *cred));
static int pipe_write __P((struct file *fp, struct uio *uio, 
		struct ucred *cred));
static int pipe_close __P((struct file *fp, struct proc *p));
static int pipe_select __P((struct file *fp, int which, struct proc *p));
d106 3
a108 3
static int pipe_ioctl __P((struct file *fp, int cmd, caddr_t data, struct proc *p));
#else /* (__NetBSD__) || (__OpenBSD__) */
static int pipe_ioctl __P((struct file *fp, u_long cmd, caddr_t data, struct proc *p));
d144 6
a149 5
static void pipeclose __P((struct pipe *cpipe));
static void pipeinit __P((struct pipe *cpipe));
static __inline int pipelock __P((struct pipe *cpipe, int catch));
static __inline void pipeunlock __P((struct pipe *cpipe));
static __inline void pipeselwakeup __P((struct pipe *cpipe));
d151 4
a154 4
static int pipe_build_write_buffer __P((struct pipe *wpipe, struct uio *uio));
static void pipe_destroy_write_buffer __P((struct pipe *wpipe));
static int pipe_direct_write __P((struct pipe *wpipe, struct uio *uio));
static void pipe_clone_write_buffer __P((struct pipe *wpipe));
d156 1
a156 1
static void pipespace __P((struct pipe *cpipe));
d167 1
a167 1
sys_pipe(p, uap, retval)
d170 1
a170 3
	struct pipe_args /* {
		int	dummy;
	} */ *uap;
d218 1
a218 1
static void
d261 1
a261 1
static void
d311 3
a313 2
		if (error = tsleep( cpipe,
			catch?(PRIBIO|PCATCH):PRIBIO, "pipelk", 0)) {
a314 1
		}
d345 1
a345 1
static int
d363 2
a364 1
			int size = rpipe->pipe_buffer.size - rpipe->pipe_buffer.out;
d452 2
a453 1
			if (error = tsleep(rpipe, PRIBIO|PCATCH, "piperd", 0)) {
a454 1
			}
d502 1
a502 1
static int
d574 1
a574 1
static void
d599 1
a599 1
static void
d627 1
a627 1
static int
d713 1
a713 1
static int
d895 3
a897 1
			if (error = tsleep(wpipe, (PRIBIO+1)|PCATCH, "pipewr", 0)) {
a898 1
			}
d900 2
a901 2
			 * If read side wants to go away, we just issue a signal
			 * to ourselves.
d1066 1
a1066 1
static int
d1081 1
a1081 1
static void
d1103 1
a1103 1
		if (ppipe = cpipe->pipe_peer) {
@
