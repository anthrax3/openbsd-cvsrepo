head	1.56;
access;
symbols
	OPENBSD_6_2:1.56.0.6
	OPENBSD_6_2_BASE:1.56
	OPENBSD_6_1:1.56.0.4
	OPENBSD_6_1_BASE:1.56
	OPENBSD_6_0:1.55.0.2
	OPENBSD_6_0_BASE:1.55
	OPENBSD_5_9:1.54.0.2
	OPENBSD_5_9_BASE:1.54
	OPENBSD_5_8:1.54.0.4
	OPENBSD_5_8_BASE:1.54
	OPENBSD_5_7:1.53.0.2
	OPENBSD_5_7_BASE:1.53
	OPENBSD_5_6:1.51.0.8
	OPENBSD_5_6_BASE:1.51
	OPENBSD_5_5:1.51.0.6
	OPENBSD_5_5_BASE:1.51
	OPENBSD_5_4:1.51.0.2
	OPENBSD_5_4_BASE:1.51
	OPENBSD_5_3:1.50.0.8
	OPENBSD_5_3_BASE:1.50
	OPENBSD_5_2:1.50.0.6
	OPENBSD_5_2_BASE:1.50
	OPENBSD_5_1_BASE:1.50
	OPENBSD_5_1:1.50.0.4
	OPENBSD_5_0:1.50.0.2
	OPENBSD_5_0_BASE:1.50
	OPENBSD_4_9:1.49.0.2
	OPENBSD_4_9_BASE:1.49
	OPENBSD_4_8:1.46.0.2
	OPENBSD_4_8_BASE:1.46
	OPENBSD_4_7:1.45.0.2
	OPENBSD_4_7_BASE:1.45
	OPENBSD_4_6:1.44.0.8
	OPENBSD_4_6_BASE:1.44
	OPENBSD_4_5:1.44.0.4
	OPENBSD_4_5_BASE:1.44
	OPENBSD_4_4:1.44.0.2
	OPENBSD_4_4_BASE:1.44
	OPENBSD_4_3:1.43.0.4
	OPENBSD_4_3_BASE:1.43
	OPENBSD_4_2:1.43.0.2
	OPENBSD_4_2_BASE:1.43
	OPENBSD_4_1:1.42.0.2
	OPENBSD_4_1_BASE:1.42
	OPENBSD_4_0:1.41.0.2
	OPENBSD_4_0_BASE:1.41
	OPENBSD_3_9:1.37.0.2
	OPENBSD_3_9_BASE:1.37
	OPENBSD_3_8:1.32.0.2
	OPENBSD_3_8_BASE:1.32
	OPENBSD_3_7:1.29.0.2
	OPENBSD_3_7_BASE:1.29
	OPENBSD_3_6:1.28.0.2
	OPENBSD_3_6_BASE:1.28
	SMP_SYNC_A:1.25
	SMP_SYNC_B:1.25
	OPENBSD_3_5:1.25.0.4
	OPENBSD_3_5_BASE:1.25
	OPENBSD_3_4:1.25.0.2
	OPENBSD_3_4_BASE:1.25
	UBC_SYNC_A:1.23
	OPENBSD_3_3:1.23.0.6
	OPENBSD_3_3_BASE:1.23
	OPENBSD_3_2:1.23.0.4
	OPENBSD_3_2_BASE:1.23
	OPENBSD_3_1:1.23.0.2
	OPENBSD_3_1_BASE:1.23
	UBC_SYNC_B:1.23
	UBC:1.21.0.2
	UBC_BASE:1.21
	OPENBSD_3_0:1.19.0.2
	OPENBSD_3_0_BASE:1.19
	OPENBSD_2_9_BASE:1.18
	OPENBSD_2_9:1.18.0.2
	OPENBSD_2_8:1.12.0.4
	OPENBSD_2_8_BASE:1.12
	OPENBSD_2_7:1.12.0.2
	OPENBSD_2_7_BASE:1.12
	SMP:1.11.0.2
	SMP_BASE:1.11
	kame_19991208:1.10
	OPENBSD_2_6:1.5.0.4
	OPENBSD_2_6_BASE:1.5
	OPENBSD_2_5:1.5.0.2
	OPENBSD_2_5_BASE:1.5
	OPENBSD_2_4:1.4.0.2
	OPENBSD_2_4_BASE:1.4
	OPENBSD_2_3:1.3.0.2
	OPENBSD_2_3_BASE:1.3;
locks; strict;
comment	@ * @;


1.56
date	2017.02.14.10.31.15;	author mpi;	state Exp;
branches;
next	1.55;
commitid	PmGi4EGraGC0Z0ml;

1.55
date	2016.03.19.12.04.15;	author natano;	state Exp;
branches;
next	1.54;
commitid	gAjwyca5TfuoJAhn;

1.54
date	2015.03.14.03.38.51;	author jsg;	state Exp;
branches;
next	1.53;
commitid	p4LJxGKbi0BU2cG6;

1.53
date	2014.12.16.18.30.04;	author tedu;	state Exp;
branches;
next	1.52;
commitid	P6Av4XGqOi3rFasL;

1.52
date	2014.09.09.07.07.39;	author blambert;	state Exp;
branches;
next	1.51;
commitid	R0IvGgmM8zlXVXKS;

1.51
date	2013.07.02.01.04.23;	author guenther;	state Exp;
branches;
next	1.50;

1.50
date	2011.04.05.14.14.07;	author thib;	state Exp;
branches;
next	1.49;

1.49
date	2010.12.21.20.14.43;	author thib;	state Exp;
branches;
next	1.48;

1.48
date	2010.09.10.16.34.08;	author thib;	state Exp;
branches;
next	1.47;

1.47
date	2010.09.06.23.44.10;	author thib;	state Exp;
branches;
next	1.46;

1.46
date	2010.07.03.03.45.16;	author thib;	state Exp;
branches;
next	1.45;

1.45
date	2009.08.13.15.00.14;	author jasper;	state Exp;
branches;
next	1.44;

1.44
date	2008.05.08.17.45.45;	author thib;	state Exp;
branches;
next	1.43;

1.43
date	2007.06.01.23.47.56;	author deraadt;	state Exp;
branches;
next	1.42;

1.42
date	2006.11.18.10.19.59;	author jmc;	state Exp;
branches;
next	1.41;

1.41
date	2006.06.25.15.01.54;	author sturm;	state Exp;
branches;
next	1.40;

1.40
date	2006.06.14.20.01.50;	author sturm;	state Exp;
branches;
next	1.39;

1.39
date	2006.04.30.14.20.07;	author sturm;	state Exp;
branches;
next	1.38;

1.38
date	2006.04.19.11.55.55;	author pedro;	state Exp;
branches;
next	1.37;

1.37
date	2006.01.09.12.43.16;	author pedro;	state Exp;
branches;
next	1.36;

1.36
date	2005.11.30.10.35.07;	author pedro;	state Exp;
branches;
next	1.35;

1.35
date	2005.11.06.13.07.48;	author pedro;	state Exp;
branches;
next	1.34;

1.34
date	2005.10.19.16.50.46;	author pedro;	state Exp;
branches;
next	1.33;

1.33
date	2005.10.04.22.31.44;	author pedro;	state Exp;
branches;
next	1.32;

1.32
date	2005.05.31.11.35.33;	author art;	state Exp;
branches;
next	1.31;

1.31
date	2005.05.29.03.20.42;	author deraadt;	state Exp;
branches;
next	1.30;

1.30
date	2005.05.25.23.17.47;	author niklas;	state Exp;
branches;
next	1.29;

1.29
date	2004.10.29.11.51.49;	author pedro;	state Exp;
branches;
next	1.28;

1.28
date	2004.08.15.18.22.29;	author pedro;	state Exp;
branches;
next	1.27;

1.27
date	2004.08.03.13.34.48;	author art;	state Exp;
branches;
next	1.26;

1.26
date	2004.06.21.23.50.36;	author tholo;	state Exp;
branches;
next	1.25;

1.25
date	2003.09.01.18.06.03;	author henning;	state Exp;
branches;
next	1.24;

1.24
date	2003.06.02.23.28.07;	author millert;	state Exp;
branches;
next	1.23;

1.23
date	2002.03.14.01.27.06;	author millert;	state Exp;
branches;
next	1.22;

1.22
date	2001.12.19.08.58.06;	author art;	state Exp;
branches;
next	1.21;

1.21
date	2001.11.27.05.27.12;	author art;	state Exp;
branches
	1.21.2.1;
next	1.20;

1.20
date	2001.11.15.06.38.48;	author art;	state Exp;
branches;
next	1.19;

1.19
date	2001.06.22.14.14.11;	author deraadt;	state Exp;
branches;
next	1.18;

1.18
date	2001.03.16.15.51.58;	author art;	state Exp;
branches;
next	1.17;

1.17
date	2001.02.27.08.46.10;	author art;	state Exp;
branches;
next	1.16;

1.16
date	2001.02.24.23.50.00;	author csapuntz;	state Exp;
branches;
next	1.15;

1.15
date	2001.02.24.19.07.09;	author csapuntz;	state Exp;
branches;
next	1.14;

1.14
date	2001.02.23.16.05.53;	author csapuntz;	state Exp;
branches;
next	1.13;

1.13
date	2001.02.21.23.24.30;	author csapuntz;	state Exp;
branches;
next	1.12;

1.12
date	2000.03.23.15.57.33;	author art;	state Exp;
branches;
next	1.11;

1.11
date	2000.01.14.19.11.50;	author art;	state Exp;
branches
	1.11.2.1;
next	1.10;

1.10
date	99.12.05.07.19.28;	author art;	state Exp;
branches;
next	1.9;

1.9
date	99.12.05.06.56.35;	author art;	state Exp;
branches;
next	1.8;

1.8
date	99.12.05.06.29.30;	author art;	state Exp;
branches;
next	1.7;

1.7
date	99.12.05.06.12.38;	author art;	state Exp;
branches;
next	1.6;

1.6
date	99.12.05.05.17.38;	author art;	state Exp;
branches;
next	1.5;

1.5
date	98.11.12.04.36.32;	author csapuntz;	state Exp;
branches;
next	1.4;

1.4
date	98.08.06.19.34.27;	author csapuntz;	state Exp;
branches;
next	1.3;

1.3
date	98.03.14.19.32.59;	author millert;	state Exp;
branches;
next	1.2;

1.2
date	98.01.11.02.10.45;	author csapuntz;	state Exp;
branches;
next	1.1;

1.1
date	98.01.10.23.44.29;	author csapuntz;	state Exp;
branches;
next	;

1.11.2.1
date	2000.03.24.09.09.26;	author niklas;	state Exp;
branches;
next	1.11.2.2;

1.11.2.2
date	2001.05.14.22.32.46;	author niklas;	state Exp;
branches;
next	1.11.2.3;

1.11.2.3
date	2001.07.04.10.48.54;	author niklas;	state Exp;
branches;
next	1.11.2.4;

1.11.2.4
date	2001.12.05.01.02.39;	author niklas;	state Exp;
branches;
next	1.11.2.5;

1.11.2.5
date	2002.03.06.02.13.24;	author niklas;	state Exp;
branches;
next	1.11.2.6;

1.11.2.6
date	2002.03.28.11.43.04;	author niklas;	state Exp;
branches;
next	1.11.2.7;

1.11.2.7
date	2003.06.07.11.03.41;	author ho;	state Exp;
branches;
next	1.11.2.8;

1.11.2.8
date	2004.02.19.10.56.39;	author niklas;	state Exp;
branches;
next	;

1.21.2.1
date	2002.06.11.03.29.40;	author art;	state Exp;
branches;
next	1.21.2.2;

1.21.2.2
date	2003.05.21.04.18.24;	author tedu;	state Exp;
branches;
next	;


desc
@@


1.56
log
@Convert most of the manual checks for CPU hogging to sched_pause().

The distinction between preempt() and yield() stays as it is usueful
to know if a thread decided to yield by itself or if the kernel told
him to go away.

ok tedu@@, guenther@@
@
text
@/*       $OpenBSD: vfs_sync.c,v 1.55 2016/03/19 12:04:15 natano Exp $  */

/*
 *  Portions of this code are:
 *
 * Copyright (c) 1989, 1993
 *	The Regents of the University of California.  All rights reserved.
 * (c) UNIX System Laboratories, Inc.
 * All or some portions of this file are derived from material licensed
 * to the University of California by American Telephone and Telegraph
 * Co. or Unix System Laboratories, Inc. and are reproduced herein with
 * the permission of UNIX System Laboratories, Inc.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. Neither the name of the University nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 */

/*
 * Syncer daemon
 */

#include <sys/queue.h>
#include <sys/param.h>
#include <sys/systm.h>
#include <sys/proc.h>
#include <sys/mount.h>
#include <sys/vnode.h>
#include <sys/lock.h>
#include <sys/malloc.h>

#include <sys/kernel.h>
#include <sys/sched.h>

#ifdef FFS_SOFTUPDATES
int   softdep_process_worklist(struct mount *);
#endif

/*
 * The workitem queue.
 */
#define SYNCER_MAXDELAY	32		/* maximum sync delay time */
#define SYNCER_DEFAULT 30		/* default sync delay time */
int syncer_maxdelay = SYNCER_MAXDELAY;	/* maximum delay time */
int syncdelay = SYNCER_DEFAULT;		/* time to delay syncing vnodes */

int rushjob = 0;			/* number of slots to run ASAP */
int stat_rush_requests = 0;		/* number of rush requests */

int syncer_delayno = 0;
long syncer_mask;
LIST_HEAD(synclist, vnode);
static struct synclist *syncer_workitem_pending;

struct proc *syncerproc;

/*
 * The workitem queue.
 *
 * It is useful to delay writes of file data and filesystem metadata
 * for tens of seconds so that quickly created and deleted files need
 * not waste disk bandwidth being created and removed. To realize this,
 * we append vnodes to a "workitem" queue. When running with a soft
 * updates implementation, most pending metadata dependencies should
 * not wait for more than a few seconds. Thus, mounted block devices
 * are delayed only about half the time that file data is delayed.
 * Similarly, directory updates are more critical, so are only delayed
 * about a third the time that file data is delayed. Thus, there are
 * SYNCER_MAXDELAY queues that are processed round-robin at a rate of
 * one each second (driven off the filesystem syncer process). The
 * syncer_delayno variable indicates the next queue that is to be processed.
 * Items that need to be processed soon are placed in this queue:
 *
 *	syncer_workitem_pending[syncer_delayno]
 *
 * A delay of fifteen seconds is done by placing the request fifteen
 * entries later in the queue:
 *
 *	syncer_workitem_pending[(syncer_delayno + 15) & syncer_mask]
 *
 */

void
vn_initialize_syncerd(void)
{
	syncer_workitem_pending = hashinit(syncer_maxdelay, M_VNODE, M_WAITOK,
	    &syncer_mask);
	syncer_maxdelay = syncer_mask + 1;
}

/*
 * Add an item to the syncer work queue.
 */
void
vn_syncer_add_to_worklist(struct vnode *vp, int delay)
{
	int s, slot;

	if (delay > syncer_maxdelay - 2)
		delay = syncer_maxdelay - 2;
	slot = (syncer_delayno + delay) & syncer_mask;

	s = splbio();
	if (vp->v_bioflag & VBIOONSYNCLIST)
		LIST_REMOVE(vp, v_synclist);

	vp->v_bioflag |= VBIOONSYNCLIST;
	LIST_INSERT_HEAD(&syncer_workitem_pending[slot], vp, v_synclist);
	splx(s);
}

/*
 * System filesystem synchronizer daemon.
 */
void
sched_sync(struct proc *p)
{
	struct synclist *slp;
	struct vnode *vp;
	time_t starttime;
	int s;

	syncerproc = curproc;

	for (;;) {
		starttime = time_second;

		/*
		 * Push files whose dirty time has expired.
		 */
		s = splbio();
		slp = &syncer_workitem_pending[syncer_delayno];

		syncer_delayno += 1;
		if (syncer_delayno == syncer_maxdelay)
			syncer_delayno = 0;

		while ((vp = LIST_FIRST(slp)) != NULL) {
			if (vget(vp, LK_EXCLUSIVE | LK_NOWAIT, p)) {
				/*
				 * If we fail to get the lock, we move this
				 * vnode one second ahead in time.
				 * XXX - no good, but the best we can do.
				 */
				vn_syncer_add_to_worklist(vp, 1);
				continue;
			}
			splx(s);
			(void) VOP_FSYNC(vp, p->p_ucred, MNT_LAZY, p);
			vput(vp);
			s = splbio();
			if (LIST_FIRST(slp) == vp) {
				/*
				 * Note: disk vps can remain on the
				 * worklist too with no dirty blocks, but
				 * since sync_fsync() moves it to a different
				 * slot we are safe.
				 */
#ifdef DIAGNOSTIC
				if (LIST_FIRST(&vp->v_dirtyblkhd) == NULL &&
				    vp->v_type != VBLK) {
					vprint("fsync failed", vp);
					if (vp->v_mount != NULL)
						printf("mounted on: %s\n",
						    vp->v_mount->mnt_stat.f_mntonname);
					panic("sched_sync: fsync failed");
				}
#endif /* DIAGNOSTIC */
				/*
				 * Put us back on the worklist.  The worklist
				 * routine will remove us from our current
				 * position and then add us back in at a later
				 * position.
				 */
				vn_syncer_add_to_worklist(vp, syncdelay);
			}

			sched_pause(yield);
		}

		splx(s);

#ifdef FFS_SOFTUPDATES
		/*
		 * Do soft update processing.
		 */
		softdep_process_worklist(NULL);
#endif

		/*
		 * The variable rushjob allows the kernel to speed up the
		 * processing of the filesystem syncer process. A rushjob
		 * value of N tells the filesystem syncer to process the next
		 * N seconds worth of work on its queue ASAP. Currently rushjob
		 * is used by the soft update code to speed up the filesystem
		 * syncer process when the incore state is getting so far
		 * ahead of the disk that the kernel memory pool is being
		 * threatened with exhaustion.
		 */
		if (rushjob > 0) {
			rushjob -= 1;
			continue;
		}
		/*
		 * If it has taken us less than a second to process the
		 * current work, then wait. Otherwise start right over
		 * again. We can still lose time if any single round
		 * takes more than two seconds, but it does not really
		 * matter as we are just trying to generally pace the
		 * filesystem activity.
		 */
		if (time_second == starttime)
			tsleep(&lbolt, PPAUSE, "syncer", 0);
	}
}

/*
 * Request the syncer daemon to speed up its work.
 * We never push it to speed up more than half of its
 * normal turn time, otherwise it could take over the cpu.
 */
int
speedup_syncer(void)
{
	int s;

	SCHED_LOCK(s);
	if (syncerproc && syncerproc->p_wchan == &lbolt)
		setrunnable(syncerproc);
	SCHED_UNLOCK(s);
	if (rushjob < syncdelay / 2) {
		rushjob += 1;
		stat_rush_requests += 1;
		return 1;
	}
	return 0;
}

/* Routine to create and manage a filesystem syncer vnode. */
int   sync_fsync(void *);
int   sync_inactive(void *);
int   sync_print(void *);

struct vops sync_vops = {
	.vop_close	= nullop,
	.vop_fsync	= sync_fsync,
	.vop_inactive	= sync_inactive,
	.vop_reclaim	= nullop,
	.vop_lock	= vop_generic_lock,
	.vop_unlock	= vop_generic_unlock,
	.vop_islocked	= vop_generic_islocked,
	.vop_print	= sync_print
};

/*
 * Create a new filesystem syncer vnode for the specified mount point.
 */
int
vfs_allocate_syncvnode(struct mount *mp)
{
	struct vnode *vp;
	static long start, incr, next;
	int error;

	/* Allocate a new vnode */
	if ((error = getnewvnode(VT_VFS, mp, &sync_vops, &vp)) != 0) {
		mp->mnt_syncer = NULL;
		return (error);
	}
	vp->v_writecount = 1;
	vp->v_type = VNON;
	/*
	 * Place the vnode onto the syncer worklist. We attempt to
	 * scatter them about on the list so that they will go off
	 * at evenly distributed times even if all the filesystems
	 * are mounted at once.
	 */
	next += incr;
	if (next == 0 || next > syncer_maxdelay) {
		start /= 2;
		incr /= 2;
		if (start == 0) {
			start = syncer_maxdelay / 2;
			incr = syncer_maxdelay;
		}
		next = start;
	}
	vn_syncer_add_to_worklist(vp, next);
	mp->mnt_syncer = vp;
	return (0);
}

/*
 * Do a lazy sync of the filesystem.
 */
int
sync_fsync(void *v)
{
	struct vop_fsync_args *ap = v;
	struct vnode *syncvp = ap->a_vp;
	struct mount *mp = syncvp->v_mount;
	int asyncflag;

	/*
	 * We only need to do something if this is a lazy evaluation.
	 */
	if (ap->a_waitfor != MNT_LAZY)
		return (0);

	/*
	 * Move ourselves to the back of the sync list.
	 */
	vn_syncer_add_to_worklist(syncvp, syncdelay);

	/*
	 * Walk the list of vnodes pushing all that are dirty and
	 * not already on the sync list.
	 */
	if (vfs_busy(mp, VB_READ|VB_NOWAIT) == 0) {
		asyncflag = mp->mnt_flag & MNT_ASYNC;
		mp->mnt_flag &= ~MNT_ASYNC;
		VFS_SYNC(mp, MNT_LAZY, ap->a_cred, ap->a_p);
		if (asyncflag)
			mp->mnt_flag |= MNT_ASYNC;
		vfs_unbusy(mp);
	}

	return (0);
}

/*
 * The syncer vnode is no longer needed and is being decommissioned.
 */
int
sync_inactive(void *v)
{
	struct vop_inactive_args *ap = v;

	struct vnode *vp = ap->a_vp;
	int s;

	if (vp->v_usecount == 0) {
		VOP_UNLOCK(vp, ap->a_p);
		return (0);
	}

	vp->v_mount->mnt_syncer = NULL;

	s = splbio();

	LIST_REMOVE(vp, v_synclist);
	vp->v_bioflag &= ~VBIOONSYNCLIST;

	splx(s);

	vp->v_writecount = 0;
	vput(vp);

	return (0);
}

/*
 * Print out a syncer vnode.
 */
int
sync_print(void *v)
{
	printf("syncer vnode\n");

	return (0);
}
@


1.55
log
@Remove the unused flags argument from VOP_UNLOCK().

torture tested on amd64, i386 and macppc
ok beck mpi stefan
"the change looks right" deraadt
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.54 2015/03/14 03:38:51 jsg Exp $  */
d198 1
a198 1
			sched_pause();
@


1.54
log
@Remove some includes include-what-you-use claims don't
have any direct symbols used.  Tested for indirect use by compiling
amd64/i386/sparc64 kernels.

ok tedu@@ deraadt@@
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.53 2014/12/16 18:30:04 tedu Exp $  */
d363 1
a363 1
		VOP_UNLOCK(vp, 0, ap->a_p);
@


1.53
log
@primary change: move uvm_vnode out of vnode, keeping only a pointer.
objective: vnode.h doesn't include uvm_extern.h anymore.
followup changes: include uvm_extern.h or lock.h where necessary.
ok and help from deraadt
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.52 2014/09/09 07:07:39 blambert Exp $  */
a49 1
#include <sys/buf.h>
@


1.52
log
@Make the cleaner, syncer, pagedaemon, aiodone daemons all
yield() if the cpu is marked SHOULDYIELD.

ok miod@@ tedu@@ phessler@@
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.51 2013/07/02 01:04:23 guenther Exp $  */
d49 1
@


1.51
log
@Use time_t for storing time_t values, duh

ok deraadt@@
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.50 2011/04/05 14:14:07 thib Exp $  */
d197 2
@


1.50
log
@Every single vop_default is set to eopnotsupp, so retire it
and return EOPNOTSUPP directly from the VOP_* functions.

Filesystems should, at some point fill in every function
in the vop_default struct so we can get rid of the 'if'
statements in VOP_*.
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.49 2010/12/21 20:14:43 thib Exp $  */
d140 1
a140 1
	long starttime;
@


1.49
log
@Bring back the "End the VOP experiment." diff, naddy's issues where
unrelated, and his alpha is much happier now.

OK deraadt@@
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.48 2010/09/10 16:34:08 thib Exp $  */
a262 1
	.vop_default	= eopnotsupp,
@


1.48
log
@Backout the VOP diff until the issues naddy was seeing on alpha (gcc3)
have been resolved.
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.47 2010/09/06 23:44:10 thib Exp $  */
d257 1
a257 4
/*
 * Routine to create and manage a filesystem syncer vnode.
 */
#define sync_close nullop
a259 3
#define sync_reclaim nullop
#define sync_lock vop_generic_lock
#define sync_unlock vop_generic_unlock
a260 1
#define sync_islocked vop_generic_islocked
d262 10
a271 15
int (**sync_vnodeop_p)(void *);
struct vnodeopv_entry_desc sync_vnodeop_entries[] = {
      { &vop_default_desc, eopnotsupp },
      { &vop_close_desc, sync_close },
      { &vop_fsync_desc, sync_fsync },
      { &vop_inactive_desc, sync_inactive },
      { &vop_reclaim_desc, sync_reclaim },
      { &vop_lock_desc, sync_lock },
      { &vop_unlock_desc, sync_unlock },
      { &vop_print_desc, sync_print },
      { &vop_islocked_desc, sync_islocked },
      { (struct vnodeop_desc*)NULL, (int(*)(void *))NULL }
};
struct vnodeopv_desc sync_vnodeop_opv_desc = {
	&sync_vnodeop_p, sync_vnodeop_entries
d285 1
a285 1
	if ((error = getnewvnode(VT_VFS, mp, sync_vnodeop_p, &vp)) != 0) {
@


1.47
log
@End the VOP experiment. Instead of the ridicolusly complicated operation
vector setup that has questionable features (that have, as far as I can
tell never been used in practice, atleast not in OpenBSD), remove all
the gunk and favor a simple struct full of function pointers that get
set directly by each of the filesystems.

Removes gobs of ugly code and makes things simpler by a magnitude.

The only downside of this is that we loose the vnoperate feature so
the spec/fifo operations of the filesystems need to be kept in sync
with specfs and fifofs, this is no big deal as the API it self is pretty
static.

Many thanks to armani@@ who pulled an earlier version of this diff to
current after c2k10 and Gabriel Kihlman on tech@@ for testing.

Liked by many. "come on, find your balls" deraadt@@.
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.46 2010/07/03 03:45:16 thib Exp $  */
d257 4
a260 1
/* Routine to create and manage a filesystem syncer vnode. */
d263 3
d267 1
d269 15
a283 10
struct vops sync_vops = {
	.vop_default	= eopnotsupp,
	.vop_close	= nullop,
	.vop_fsync	= sync_fsync,
	.vop_inactive	= sync_inactive,
	.vop_reclaim	= nullop,
	.vop_lock	= vop_generic_lock,
	.vop_unlock	= vop_generic_unlock,
	.vop_islocked	= vop_generic_islocked,
	.vop_print	= sync_print
d297 1
a297 1
	if ((error = getnewvnode(VT_VFS, mp, &sync_vops, &vp)) != 0) {
@


1.46
log
@no need for syncdelay to be a time_t, make it it an int. unstatic variables
so I can twiddle them from ddb (not that I will mess with the hashmask, but
static burns).

ok tedu@@
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.45 2009/08/13 15:00:14 jasper Exp $  */
d257 1
a257 4
/*
 * Routine to create and manage a filesystem syncer vnode.
 */
#define sync_close nullop
a259 3
#define sync_reclaim nullop
#define sync_lock vop_generic_lock
#define sync_unlock vop_generic_unlock
a260 1
#define sync_islocked vop_generic_islocked
d262 10
a271 15
int (**sync_vnodeop_p)(void *);
struct vnodeopv_entry_desc sync_vnodeop_entries[] = {
      { &vop_default_desc, eopnotsupp },
      { &vop_close_desc, sync_close },
      { &vop_fsync_desc, sync_fsync },
      { &vop_inactive_desc, sync_inactive },
      { &vop_reclaim_desc, sync_reclaim },
      { &vop_lock_desc, sync_lock },
      { &vop_unlock_desc, sync_unlock },
      { &vop_print_desc, sync_print },
      { &vop_islocked_desc, sync_islocked },
      { (struct vnodeop_desc*)NULL, (int(*)(void *))NULL }
};
struct vnodeopv_desc sync_vnodeop_opv_desc = {
	&sync_vnodeop_p, sync_vnodeop_entries
d285 1
a285 1
	if ((error = getnewvnode(VT_VFS, mp, sync_vnodeop_p, &vp)) != 0) {
@


1.45
log
@- remove super-obvious comments from $fs_vnodeop_entries[]

prodded by and ok thib@@
agreed by art@@ and blambert@@
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.44 2008/05/08 17:45:45 thib Exp $  */
d65 1
a65 1
time_t syncdelay = SYNCER_DEFAULT;	/* time to delay syncing vnodes */
d70 2
a71 2
static int syncer_delayno = 0;
static long syncer_mask;
@


1.44
log
@retire vn_default_error() and replace all instances
with eopnotsupp() instead;

ok blambert@@
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.43 2007/06/01 23:47:56 deraadt Exp $  */
d272 8
a279 8
      { &vop_close_desc, sync_close },                /* close */
      { &vop_fsync_desc, sync_fsync },                /* fsync */
      { &vop_inactive_desc, sync_inactive },          /* inactive */
      { &vop_reclaim_desc, sync_reclaim },            /* reclaim */
      { &vop_lock_desc, sync_lock },                  /* lock */
      { &vop_unlock_desc, sync_unlock },              /* unlock */
      { &vop_print_desc, sync_print },                /* print */
      { &vop_islocked_desc, sync_islocked },          /* islocked */
@


1.43
log
@pedro ok'd this ~3500 line diff which removes the vop argument
"ap = v" comments in under 8 seconds, so it must be ok.  and it compiles
too.
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.42 2006/11/18 10:19:59 jmc Exp $  */
d271 1
a271 1
      { &vop_default_desc, vn_default_error },
@


1.42
log
@more fixes from bret lambert; ok pedro
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.41 2006/06/25 15:01:54 sturm Exp $  */
d330 1
a330 7
	struct vop_fsync_args /* {
		struct vnodeop_desc *a_desc;
		struct vnode *a_vp;
		struct ucred *a_cred;
		int a_waitfor;
		struct proc *a_p;
	} */ *ap = v;
d368 1
a368 5
	struct vop_inactive_args /* {
		struct vnodeop_desc *a_desc;
		struct vnode *a_vp;
		struct proc *a_p;
	} */ *ap = v;
@


1.41
log
@rename vfs_busy() flags VB_UMIGNORE/VB_UMWAIT to VB_NOWAIT/VB_WAIT

requested by and ok pedro
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.40 2006/06/14 20:01:50 sturm Exp $  */
d85 2
a86 2
 * not wait for more than a few seconds. Thus, mounted on block devices
 * are delayed only about a half the time that file data is delayed.
@


1.40
log
@move vfs_busy() to rwlocks and properly hide the locking api from vfs

ok tedu, pedro
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.39 2006/04/30 14:20:07 sturm Exp $  */
d356 1
a356 1
	if (vfs_busy(mp, VB_READ|VB_UMIGNORE) == 0) {
@


1.39
log
@remove the simplelock argument from vfs_busy() which is currently not
used and will never be used this way in VFS

requested by and ok pedro, ok krw, biorn
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.38 2006/04/19 11:55:55 pedro Exp $  */
d356 1
a356 1
	if (vfs_busy(mp, LK_NOWAIT) == 0) {
@


1.38
log
@Remove unused mount list simple_lock() goo
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.37 2006/01/09 12:43:16 pedro Exp $  */
d356 1
a356 1
	if (vfs_busy(mp, LK_NOWAIT, NULL) == 0) {
@


1.37
log
@Put vprint() under DIAGNOSTIC, as to save space in generated ramdisks.
Inspiration from miod@@, okay deraadt@@. Tested on i386, macppc and amd64.
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.36 2005/11/30 10:35:07 pedro Exp $  */
d356 1
a356 2
	simple_lock(&mountlist_slock);
	if (vfs_busy(mp, LK_NOWAIT, &mountlist_slock) == 0) {
d363 1
a363 2
	} else
		simple_unlock(&mountlist_slock);
@


1.36
log
@No need for vfs_busy() and vfs_unbusy() to take a process pointer
anymore. Testing by jolan@@, thanks.
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.35 2005/11/06 13:07:48 pedro Exp $  */
d179 1
d188 1
@


1.35
log
@Use ANSI-style function declarations, no binary change, okay jsg@@
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.34 2005/10/19 16:50:46 pedro Exp $  */
d355 1
a355 1
	if (vfs_busy(mp, LK_NOWAIT, &mountlist_slock, ap->a_p) == 0) {
d361 1
a361 1
		vfs_unbusy(mp, ap->a_p);
@


1.34
log
@Remove v_vnlock from struct vnode, okay krw@@ tedu@@
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.33 2005/10/04 22:31:44 pedro Exp $  */
d104 1
a104 2
vn_initialize_syncerd()

d115 1
a115 3
vn_syncer_add_to_worklist(vp, delay)
	struct vnode *vp;
	int delay;
a134 1

d136 1
a136 2
sched_sync(p)
	struct proc *p;
d239 1
a239 1
speedup_syncer()
d288 1
a288 2
vfs_allocate_syncvnode(mp)
	struct mount *mp;
d326 1
a326 2
sync_fsync(v)
	void *v;
d372 1
a372 2
sync_inactive(v)
	void *v;
d407 1
a407 3
sync_print(v)
	void *v;

@


1.33
log
@Make the syncer grab a reference for the vnode to avoid it from being
reclaimed while in this sensitive time frame. That is needed when we
don't have locks. Should fix the 'sched_sync: fsync failed' panic some
people were seeing.

Testing mostly by sturm@@ and krw@@, okay tedu@@ and deraadt@@.
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.32 2005/05/31 11:35:33 art Exp $  */
d419 1
a419 5
	struct vop_print_args /* {
		struct vnodeop_desc *a_desc;
		struct vnode *a_vp;
	} */ *ap = v;
	struct vnode *vp = ap->a_vp;
a420 4
	printf("syncer vnode");
	if (vp->v_vnlock != NULL)
		lockmgr_printinfo(vp->v_vnlock);
	printf("\n");
@


1.32
log
@Protect the run queues with SCHED_LOCK, not just spl (ot nothing at all in
one case fixed here).

miod@@ "appears to be harmless"
markus@@ ok
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.30 2005/05/25 23:17:47 niklas Exp $  */
d164 1
a164 1
			if (vn_lock(vp, LK_EXCLUSIVE | LK_NOWAIT, p) != 0) {
d175 1
a175 1
			VOP_UNLOCK(vp, 0, p);
@


1.31
log
@sched work by niklas and art backed out; causes panics
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.29 2004/10/29 11:51:49 pedro Exp $  */
d53 1
d248 1
a248 1
	s = splhigh();
d251 1
a251 1
	splx(s);
@


1.30
log
@This patch is mortly art's work and was done *a year* ago.  Art wants to thank
everyone for the prompt review and ok of this work ;-)  Yeah, that includes me
too, or maybe especially me.  I am sorry.

Change the sched_lock to a mutex. This fixes, among other things, the infamous
"telnet localhost &" problem.  The real bug in that case was that the sched_lock
which is by design a non-recursive lock, was recursively acquired, and not
enough releases made us hold the lock in the idle loop, blocking scheduling
on the other processors.  Some of the other processors would hold the biglock though,
which made it impossible for cpu 0 to enter the kernel...  A nice deadlock.
Let me just say debugging this for days just to realize that it was all fixed
in an old diff noone ever ok'd was somewhat of an anti-climax.

This diff also changes splsched to be correct for all our architectures.
@
text
@a52 1
#include <sys/sched.h>
d247 1
a247 1
	SCHED_LOCK(s);
d250 1
a250 1
	SCHED_UNLOCK(s);
@


1.29
log
@silly typo...
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.28 2004/08/15 18:22:29 pedro Exp $  */
d53 1
d248 1
a248 1
	s = splhigh();
d251 1
a251 1
	splx(s);
@


1.28
log
@protect code dealing with the vnode sync list with splbio(). fixes the
'fsync failed' panic on amd64. discussed with and ok'd by art@@, tedu@@
and deraadt@@. tested by many (thanks).
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.27 2004/08/03 13:34:48 art Exp $  */
d89 1
a89 1
 * one each second (driven off the filesystem syner process). The
@


1.27
log
@Print more diagnostics on fsync failure in sched_sync.
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.26 2004/06/21 23:50:36 tholo Exp $  */
d155 1
d157 1
d161 1
a161 1
		s = splbio();
d388 1
d394 1
d396 3
d401 3
d406 1
@


1.26
log
@First step towards more sane time handling in the kernel -- this changes
things such that code that only need a second-resolution uptime or wall
time, and used to get that from time.tv_secs or mono_time.tv_secs now get
this from separate time_t globals time_second and time_uptime.

ok art@@ niklas@@ nordin@@
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.25 2003/09/01 18:06:03 henning Exp $  */
d182 5
a186 1
				    vp->v_type != VBLK)
d188 1
@


1.25
log
@match syscallargs comments with reality
from Patrick Latifi <patrick.l@@hermes.usherb.ca>
ok jason@@ tedu@@
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.24 2003/06/02 23:28:07 millert Exp $  */
d150 1
a150 1
		starttime = time.tv_sec;
d225 1
a225 1
		if (time.tv_sec == starttime)
@


1.24
log
@Remove the advertising clause in the UCB license which Berkeley
rescinded 22 July 1999.  Proofed by myself and Theo.
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.23 2002/03/14 01:27:06 millert Exp $  */
d328 1
d375 1
d403 1
@


1.23
log
@First round of __P removal in sys
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.22 2001/12/19 08:58:06 art Exp $  */
d22 1
a22 5
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by the University of
 *	California, Berkeley and its contributors.
 * 4. Neither the name of the University nor the names of its contributors
@


1.22
log
@UBC was a disaster. It worked very good when it worked, but on some
machines or some configurations or in some phase of the moon (we actually
don't know when or why) files disappeared. Since we've not been able to
track down the problem in two weeks intense debugging and we need -current
to be stable, back out everything to a state it had before UBC.

We apologise for the inconvenience.
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.20 2001/11/15 06:38:48 art Exp $  */
d59 1
a59 1
int   softdep_process_worklist __P((struct mount *));
d260 2
a261 2
int   sync_fsync __P((void *));
int   sync_inactive __P((void *));
d265 1
a265 1
int   sync_print __P((void *));
d268 1
a268 1
int (**sync_vnodeop_p) __P((void *));
d279 1
a279 1
      { (struct vnodeop_desc*)NULL, (int(*) __P((void *)))NULL }
@


1.21
log
@Merge in the unified buffer cache code as found in NetBSD 2001/03/10. The
code is written mostly by Chuck Silvers <chuq@@chuq.com>/<chs@@netbsd.org>.

Tested for the past few weeks by many developers, should be in a pretty stable
state, but will require optimizations and additional cleanups.
@
text
@d179 9
a187 6
#ifdef DIAGNOSTIC
				if (!(vp->v_bioflag & VBIOONSYNCLIST)) {
					vprint("vnode", vp);
					panic("sched_fsync: on synclist, but no flag");
				}
#endif
@


1.21.2.1
log
@Sync UBC branch to -current
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.21 2001/11/27 05:27:12 art Exp $  */
d59 1
a59 1
int   softdep_process_worklist(struct mount *);
d257 2
a258 2
int   sync_fsync(void *);
int   sync_inactive(void *);
d262 1
a262 1
int   sync_print(void *);
d265 1
a265 1
int (**sync_vnodeop_p)(void *);
d276 1
a276 1
      { (struct vnodeop_desc*)NULL, (int(*)(void *))NULL }
@


1.21.2.2
log
@use genfs_nolock here
@
text
@d1 1
a1 1
/*       $OpenBSD$  */
d55 1
a57 2
#include <miscfs/genfs/genfs.h>

d260 2
a261 2
#define sync_lock	genfs_nolock
#define sync_unlock	genfs_nounlock
d263 1
a263 1
#define sync_islocked	genfs_noislocked
@


1.20
log
@Make sure that stuff on the syncer worklist has VBIOONSYNCLIST set
and stuff that isn't on the worklist doesn't have it set.
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.19 2001/06/22 14:14:11 deraadt Exp $  */
d179 6
a184 9
				/*
				 * Note: disk vps can remain on the
				 * worklist too with no dirty blocks, but
				 * since sync_fsync() moves it to a different
				 * slot we are safe.
				 */
				if (LIST_FIRST(&vp->v_dirtyblkhd) == NULL &&
				    vp->v_type != VBLK)
					panic("sched_sync: fsync failed");
@


1.19
log
@KNF
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.18 2001/03/16 15:51:58 art Exp $  */
d133 1
a134 1
	vp->v_bioflag |= VBIOONSYNCLIST;
d390 1
@


1.18
log
@No need to extern mountlist_slock here.
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.17 2001/02/27 08:46:10 art Exp $  */
d64 1
a64 1
 */ 
d72 1
a72 1
 
d82 1
a82 1
 * 
d142 1
a142 1
void 
d181 2
a182 2
				 * worklist too with no dirty blocks, but 
				 * since sync_fsync() moves it to a different 
d267 1
a267 1
 
d281 3
a283 2
struct vnodeopv_desc sync_vnodeop_opv_desc =
      { &sync_vnodeop_p, sync_vnodeop_entries };
d403 10
a412 10
      struct vop_print_args /* {
              struct vnode *a_vp;
      } */ *ap = v;
      struct vnode *vp = ap->a_vp;

      printf("syncer vnode");
      if (vp->v_vnlock != NULL)
              lockmgr_printinfo(vp->v_vnlock);
      printf("\n");
      return (0);
@


1.17
log
@Instead of doing VOP_ISLOCKED, vn_lock(..LK_RETRY..) we can do vn_lock(..LK_NOWAIT..).
Also, when we fail to get the lock on the vnode we want to sync, push
it ahead one second in time.
XXX - this could lead to some vnodes not being synced for a long time,
      but that is better than a panic.
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.16 2001/02/24 23:50:00 csapuntz Exp $  */
a76 2

extern struct simplelock mountlist_slock;
@


1.16
log
@

Move splbio's around so that they cover the data structures they need to
and don't cover the ones they don't
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.15 2001/02/24 19:07:09 csapuntz Exp $  */
d167 9
d177 2
a178 5
			if (VOP_ISLOCKED(vp) == 0) {
				vn_lock(vp, LK_EXCLUSIVE | LK_RETRY, p);
				(void) VOP_FSYNC(vp, p->p_ucred, MNT_LAZY, p);
				VOP_UNLOCK(vp, 0, p);
			}
@


1.15
log
@

Cleanup of vnode interface continues. Get rid of VHOLD/HOLDRELE.
Change VM/UVM to use buf_replacevnode to change the vnode associated
with a buffer.

Addition v_bioflag for flags written in interrupt handlers
(and read at splbio, though not strictly necessary)

Add vwaitforio and use it instead of a while loop of v_numoutput.

Fix race conditions when manipulation vnode free list
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.14 2001/02/23 16:05:53 csapuntz Exp $  */
d127 4
a131 1

a134 4
	if (delay > syncer_maxdelay - 2)
		delay = syncer_maxdelay - 2;
	slot = (syncer_delayno + delay) & syncer_mask;

a160 1
		s = splbio();
d165 1
a165 1
		splx(s);
d167 1
a191 1
			splx(s);
d193 2
@


1.14
log
@

Try to avoid sleeping in the syncer waiting for vnode locks.

From FreeBSD
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.13 2001/02/21 23:24:30 csapuntz Exp $  */
d129 1
a129 1
	if (vp->v_flag & VONSYNCLIST)
d137 1
a137 1
	vp->v_flag |= VONSYNCLIST;
@


1.13
log
@

Latest soft updates from FreeBSD/Kirk McKusick

Snapshot-related code has been commented out.
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.12 2000/03/23 15:57:33 art Exp $  */
d169 6
a174 3
			vn_lock(vp, LK_EXCLUSIVE | LK_RETRY, p);
			(void) VOP_FSYNC(vp, p->p_ucred, MNT_LAZY, p);
			VOP_UNLOCK(vp, 0, p);
d176 6
d186 4
a189 1
				 * Move ourselves to the back of the sync list.
d193 1
@


1.12
log
@No need for our own declaration of lbolt.
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.11 2000/01/14 19:11:50 art Exp $  */
d58 4
d74 1
a74 1
static long syncer_last;
d112 3
a114 10
	int i;

	syncer_last = SYNCER_MAXDELAY + 2;

	syncer_workitem_pending =
		malloc(syncer_last * sizeof(struct synclist), 
		       M_VNODE, M_WAITOK);

	for (i = 0; i < syncer_last; i++)
		LIST_INIT(&syncer_workitem_pending[i]);
d132 4
a135 3
	if (delay > syncer_maxdelay)
		delay = syncer_maxdelay;
	slot = (syncer_delayno + delay) % syncer_last;
d165 1
a165 1
		if (syncer_delayno >= syncer_last)
d183 1
d187 2
a188 2
		if (bioops.io_sync)
			(*bioops.io_sync)(NULL);
@


1.11
log
@Drop SYNCER_MAXDELAY to 32. The delay is never bigger than 30 anyway.
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.10 1999/12/05 07:19:28 art Exp $  */
a145 3


extern int lbolt;
@


1.11.2.1
log
@Sync with -current
@
text
@d1 1
a1 1
/*       $OpenBSD$  */
d146 3
@


1.11.2.2
log
@merge in approximately 2.9 into SMP branch
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.18 2001/03/16 15:51:58 art Exp $  */
a57 4
#ifdef FFS_SOFTUPDATES
int   softdep_process_worklist __P((struct mount *));
#endif

d70 1
a70 1
static long syncer_mask;
d74 2
d108 10
a117 3
	syncer_workitem_pending = hashinit(syncer_maxdelay, M_VNODE, M_WAITOK,
	    &syncer_mask);
	syncer_maxdelay = syncer_mask + 1;
d130 1
a130 3
	if (delay > syncer_maxdelay - 2)
		delay = syncer_maxdelay - 2;
	slot = (syncer_delayno + delay) & syncer_mask;
d132 1
a132 2
	s = splbio();
	if (vp->v_bioflag & VBIOONSYNCLIST)
d135 3
d139 1
a139 1
	vp->v_bioflag |= VBIOONSYNCLIST;
d164 1
d167 1
a167 1
		if (syncer_delayno == syncer_maxdelay)
d169 1
a169 1
		s = splbio();
d171 1
a171 10
			if (vn_lock(vp, LK_EXCLUSIVE | LK_NOWAIT, p) != 0) {
				/*
				 * If we fail to get the lock, we move this
				 * vnode one second ahead in time.
				 * XXX - no good, but the best we can do.
				 */
				vn_syncer_add_to_worklist(vp, 1);
				continue;
			}
			splx(s);
a173 1
			s = splbio();
a174 6
				/*
				 * Note: disk vps can remain on the
				 * worklist too with no dirty blocks, but 
				 * since sync_fsync() moves it to a different 
				 * slot we are safe.
				 */
d179 1
a179 4
				 * Put us back on the worklist.  The worklist
				 * routine will remove us from our current
				 * position and then add us back in at a later
				 * position.
a184 3
		splx(s);

#ifdef FFS_SOFTUPDATES
d188 2
a189 2
		softdep_process_worklist(NULL);
#endif
@


1.11.2.3
log
@Merge in -current from two days ago in the SMP branch.
As usual with merges, they do not indicate progress, so do not hold
your breath for working SMP, and do not mail me and ask about the
state of it.  It has not changed.  There is work ongoing, but very, very
slowly.  The commit is done in parts as to not lock up the tree in too
big chunks at a time.
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.11.2.2 2001/05/14 22:32:46 niklas Exp $  */
d64 1
a64 1
 */
d72 1
a72 1

d82 1
a82 1
 *
d142 1
a142 1
void
d181 2
a182 2
				 * worklist too with no dirty blocks, but
				 * since sync_fsync() moves it to a different
d267 1
a267 1

d281 2
a282 3
struct vnodeopv_desc sync_vnodeop_opv_desc = {
	&sync_vnodeop_p, sync_vnodeop_entries
};
d402 10
a411 10
	struct vop_print_args /* {
		struct vnode *a_vp;
	} */ *ap = v;
	struct vnode *vp = ap->a_vp;

	printf("syncer vnode");
	if (vp->v_vnlock != NULL)
		lockmgr_printinfo(vp->v_vnlock);
	printf("\n");
	return (0);
@


1.11.2.4
log
@Merge in -current
@
text
@d1 1
a1 1
/*       $OpenBSD$  */
d133 1
a134 1
	LIST_INSERT_HEAD(&syncer_workitem_pending[slot], vp, v_synclist);
d179 9
a187 6
#ifdef DIAGNOSTIC
				if (!(vp->v_bioflag & VBIOONSYNCLIST)) {
					vprint("vnode", vp);
					panic("sched_fsync: on synclist, but no flag");
				}
#endif
a389 1
	vp->v_bioflag &= ~VBIOONSYNCLIST;
@


1.11.2.5
log
@Merge in trunk
@
text
@d179 6
a184 9
				/*
				 * Note: disk vps can remain on the
				 * worklist too with no dirty blocks, but
				 * since sync_fsync() moves it to a different
				 * slot we are safe.
				 */
				if (LIST_FIRST(&vp->v_dirtyblkhd) == NULL &&
				    vp->v_type != VBLK)
					panic("sched_sync: fsync failed");
@


1.11.2.6
log
@Merge in -current from about a week ago
@
text
@d59 1
a59 1
int   softdep_process_worklist(struct mount *);
d260 2
a261 2
int   sync_fsync(void *);
int   sync_inactive(void *);
d265 1
a265 1
int   sync_print(void *);
d268 1
a268 1
int (**sync_vnodeop_p)(void *);
d279 1
a279 1
      { (struct vnodeop_desc*)NULL, (int(*)(void *))NULL }
@


1.11.2.7
log
@Sync SMP branch to -current
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.11.2.6 2002/03/28 11:43:04 niklas Exp $  */
d22 5
a26 1
 * 3. Neither the name of the University nor the names of its contributors
@


1.11.2.8
log
@Merge of current from two weeks agointo the SMP branch
@
text
@d1 1
a1 1
/*       $OpenBSD$  */
a327 1
		struct vnodeop_desc *a_desc;
a373 1
		struct vnodeop_desc *a_desc;
a400 1
		struct vnodeop_desc *a_desc;
@


1.10
log
@Add a new vnode flag "VONSYNCLIST" that indicates if the vnode is on the
syncers work list.
From NetBSD.
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.9 1999/12/05 06:56:35 art Exp $  */
d61 1
a61 1
#define SYNCER_MAXDELAY	60		/* maximum sync delay time */
@


1.9
log
@Add a new function "speedup_syncer()" that pushes the syncer to work harder.
Used by the new soft updates code.
@
text
@d1 1
a1 2
/*       $OpenBSD: vfs_sync.c,v 1.8 1999/12/05 06:29:30 art Exp $  */

d131 4
d139 1
a183 1
				LIST_REMOVE(vp, v_synclist);
a335 1
	LIST_REMOVE(syncvp, v_synclist);
@


1.8
log
@Unlock the vnode in inactive even when v_usecount == 0.
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.7 1999/12/05 06:12:38 art Exp $  */
d66 3
a68 1
int rushjob;				/* number of slots to run ASAP */
d77 2
d155 2
d218 21
@


1.7
log
@Release mountlist_slock if vfs_busy fails.
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.6 1999/12/05 05:17:38 art Exp $  */
d341 2
a342 1
	if (vp->v_usecount == 0)
d344 1
@


1.6
log
@Indentation fixes.
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.5 1998/11/12 04:36:32 csapuntz Exp $  */
d321 3
a323 1
	}
@


1.5
log
@

More soft updates fixes from Kirk McKusick.
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.4 1998/08/06 19:34:27 csapuntz Exp $  */
d246 1
a246 1
      struct mount *mp;
d248 30
a277 30
      struct vnode *vp;
      static long start, incr, next;
      int error;

      /* Allocate a new vnode */
      if ((error = getnewvnode(VT_VFS, mp, sync_vnodeop_p, &vp)) != 0) {
              mp->mnt_syncer = NULL;
              return (error);
      }
      vp->v_writecount = 1;
      vp->v_type = VNON;
      /*
       * Place the vnode onto the syncer worklist. We attempt to
       * scatter them about on the list so that they will go off
       * at evenly distributed times even if all the filesystems
       * are mounted at once.
       */
      next += incr;
      if (next == 0 || next > syncer_maxdelay) {
              start /= 2;
              incr /= 2;
              if (start == 0) {
                      start = syncer_maxdelay / 2;
                      incr = syncer_maxdelay;
              }
              next = start;
      }
      vn_syncer_add_to_worklist(vp, next);
      mp->mnt_syncer = vp;
      return (0);
d287 36
a322 37
      struct vop_fsync_args /* {
              struct vnode *a_vp;
              struct ucred *a_cred;
              int a_waitfor;
              struct proc *a_p;
      } */ *ap = v;

      struct vnode *syncvp = ap->a_vp;
      struct mount *mp = syncvp->v_mount;
      int asyncflag;

      /*
       * We only need to do something if this is a lazy evaluation.
       */
      if (ap->a_waitfor != MNT_LAZY)
              return (0);

      /*
       * Move ourselves to the back of the sync list.
       */
      LIST_REMOVE(syncvp, v_synclist);
      vn_syncer_add_to_worklist(syncvp, syncdelay);

      /*
       * Walk the list of vnodes pushing all that are dirty and
       * not already on the sync list.
       */
      simple_lock(&mountlist_slock);
      if (vfs_busy(mp, LK_NOWAIT, &mountlist_slock, ap->a_p) == 0) {
              asyncflag = mp->mnt_flag & MNT_ASYNC;
              mp->mnt_flag &= ~MNT_ASYNC;
              VFS_SYNC(mp, MNT_LAZY, ap->a_cred, ap->a_p);
              if (asyncflag)
                      mp->mnt_flag |= MNT_ASYNC;
              vfs_unbusy(mp, ap->a_p);
      }
      return (0);
a330 1
	
d332 14
a345 14
      struct vop_inactive_args /* {
               struct vnode *a_vp;
               struct proc *a_p;
      } */ *ap = v;

      struct vnode *vp = ap->a_vp;

      if (vp->v_usecount == 0)
              return (0);
      vp->v_mount->mnt_syncer = NULL;
      LIST_REMOVE(vp, v_synclist);
      vp->v_writecount = 0;
      vput(vp);
      return (0);
@


1.4
log
@

Rename vop_revoke, vn_bwrite, vop_noislocked, vop_nolock, vop_nounlock
to be vop_generic_revoke, vop_generic_bwrite, vop_generic_islocked,
vop_generic_lock and vop_generic_unlock.

Create vop_generic_abortop and propogate change to all file systems.

Fix PR/371.

Get rid of locking in NULLFS (should be mostly unnecessary now except for
forced unmounts).
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.3 1998/03/14 19:32:59 millert Exp $  */
d62 2
a63 1
#define SYNCER_MAXDELAY	32
d65 1
a65 1
time_t syncdelay = 30;			/* time to delay syncing vnodes */
d69 1
a69 1
static long syncer_mask;
d105 10
a114 3
	syncer_workitem_pending = hashinit(syncer_maxdelay, M_VNODE,
					   &syncer_mask);
	syncer_maxdelay = syncer_mask + 1;
d128 3
a130 3
	if (delay > syncer_maxdelay - 2)
		delay = syncer_maxdelay - 2;
	slot = (syncer_delayno + delay) & syncer_mask;
d160 1
a160 1
		if (syncer_delayno == syncer_maxdelay)
d168 2
a169 1
				if (LIST_FIRST(&vp->v_dirtyblkhd) == NULL)
@


1.3
log
@Changes necesary for new soft updates code.  Doesn't affect old soft updates
or kernels without soft updates...
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.2 1998/01/11 02:10:45 csapuntz Exp $  */
d211 2
a212 2
#define sync_lock vop_nolock
#define sync_unlock vop_nounlock
d214 1
a214 1
#define sync_islocked vop_noislocked
@


1.2
log
@Fix a couple spinlock references. More code motion in vfs_subr.c
@
text
@d1 1
a1 1
/*       $OpenBSD: vfs_sync.c,v 1.1 1998/01/10 23:44:29 csapuntz Exp $  */
d62 4
a65 3
#define SYNCER_MAXDELAY       32
int syncer_maxdelay = SYNCER_MAXDELAY;        /* maximum delay time */
time_t syncdelay = 30;                        /* time to delay syncing vnodes */
d176 14
@


1.1
log
@A couple more splbio()s in vfs_bio plus moving around a couple functions.
@
text
@d1 1
a1 1
/*       $OpenBSD:   $  */
d70 2
@

