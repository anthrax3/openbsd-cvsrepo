head	1.53;
access;
symbols
	OPENBSD_6_1:1.53.0.2
	OPENBSD_6_1_BASE:1.53
	OPENBSD_6_0:1.49.0.2
	OPENBSD_6_0_BASE:1.49
	OPENBSD_5_9:1.47.0.2
	OPENBSD_5_9_BASE:1.47
	OPENBSD_5_8:1.47.0.4
	OPENBSD_5_8_BASE:1.47
	OPENBSD_5_7:1.46.0.2
	OPENBSD_5_7_BASE:1.46
	OPENBSD_5_6:1.36.0.6
	OPENBSD_5_6_BASE:1.36
	OPENBSD_5_5:1.36.0.4
	OPENBSD_5_5_BASE:1.36
	OPENBSD_5_4:1.35.0.2
	OPENBSD_5_4_BASE:1.35
	OPENBSD_5_3:1.34.0.6
	OPENBSD_5_3_BASE:1.34
	OPENBSD_5_2:1.34.0.4
	OPENBSD_5_2_BASE:1.34
	OPENBSD_5_1_BASE:1.34
	OPENBSD_5_1:1.34.0.2
	OPENBSD_5_0:1.33.0.6
	OPENBSD_5_0_BASE:1.33
	OPENBSD_4_9:1.33.0.4
	OPENBSD_4_9_BASE:1.33
	OPENBSD_4_8:1.33.0.2
	OPENBSD_4_8_BASE:1.33
	OPENBSD_4_7:1.32.0.2
	OPENBSD_4_7_BASE:1.32
	OPENBSD_4_6:1.29.0.6
	OPENBSD_4_6_BASE:1.29
	OPENBSD_4_5:1.29.0.2
	OPENBSD_4_5_BASE:1.29
	OPENBSD_4_4:1.26.0.2
	OPENBSD_4_4_BASE:1.26
	OPENBSD_4_3:1.25.0.4
	OPENBSD_4_3_BASE:1.25
	OPENBSD_4_2:1.25.0.2
	OPENBSD_4_2_BASE:1.25
	OPENBSD_4_1:1.19.0.6
	OPENBSD_4_1_BASE:1.19
	OPENBSD_4_0:1.19.0.4
	OPENBSD_4_0_BASE:1.19
	OPENBSD_3_9:1.19.0.2
	OPENBSD_3_9_BASE:1.19
	OPENBSD_3_8:1.18.0.2
	OPENBSD_3_8_BASE:1.18
	OPENBSD_3_7:1.14.0.2
	OPENBSD_3_7_BASE:1.14
	OPENBSD_3_6:1.11.0.6
	OPENBSD_3_6_BASE:1.11
	SMP_SYNC_A:1.11
	SMP_SYNC_B:1.11
	OPENBSD_3_5:1.11.0.4
	OPENBSD_3_5_BASE:1.11
	OPENBSD_3_4:1.11.0.2
	OPENBSD_3_4_BASE:1.11
	UBC_SYNC_A:1.10
	OPENBSD_3_3:1.10.0.2
	OPENBSD_3_3_BASE:1.10
	OPENBSD_3_2:1.8.0.2
	OPENBSD_3_2_BASE:1.8
	OPENBSD_3_1:1.6.0.2
	OPENBSD_3_1_BASE:1.6
	UBC_SYNC_B:1.8
	UBC:1.5.0.4
	UBC_BASE:1.5
	OPENBSD_3_0:1.5.0.2
	OPENBSD_3_0_BASE:1.5
	OPENBSD_2_9_BASE:1.3
	OPENBSD_2_9:1.3.0.10
	OPENBSD_2_8:1.3.0.8
	OPENBSD_2_8_BASE:1.3
	OPENBSD_2_7:1.3.0.6
	OPENBSD_2_7_BASE:1.3
	SMP:1.3.0.4
	SMP_BASE:1.3
	kame_19991208:1.3
	OPENBSD_2_6:1.3.0.2
	OPENBSD_2_6_BASE:1.3
	OPENBSD_2_5:1.2.0.12
	OPENBSD_2_5_BASE:1.2
	OPENBSD_2_4:1.2.0.10
	OPENBSD_2_4_BASE:1.2
	OPENBSD_2_3:1.2.0.8
	OPENBSD_2_3_BASE:1.2
	OPENBSD_2_2:1.2.0.6
	OPENBSD_2_2_BASE:1.2
	OPENBSD_2_1:1.2.0.4
	OPENBSD_2_1_BASE:1.2
	OPENBSD_2_0:1.2.0.2
	OPENBSD_2_0_BASE:1.2
	netbsd_1_1:1.1.1.1;
locks; strict;
comment	@ * @;


1.53
date	2017.02.09.19.02.34;	author bluhm;	state Exp;
branches;
next	1.52;
commitid	cKjZqCihr2IUGYrO;

1.52
date	2016.09.16.03.21.16;	author dlg;	state Exp;
branches;
next	1.51;
commitid	qpxurnuozCzNjzBV;

1.51
date	2016.09.15.02.00.16;	author dlg;	state Exp;
branches;
next	1.50;
commitid	RlO92XR575sygHqm;

1.50
date	2016.08.25.00.01.13;	author dlg;	state Exp;
branches;
next	1.49;
commitid	qGDK47LQhxLxADuT;

1.49
date	2016.03.19.12.04.15;	author natano;	state Exp;
branches;
next	1.48;
commitid	gAjwyca5TfuoJAhn;

1.48
date	2016.03.07.18.43.59;	author naddy;	state Exp;
branches;
next	1.47;
commitid	Z6e4eqr6FuYFPnlL;

1.47
date	2015.03.14.03.38.51;	author jsg;	state Exp;
branches;
next	1.46;
commitid	p4LJxGKbi0BU2cG6;

1.46
date	2015.01.28.20.16.04;	author tedu;	state Exp;
branches;
next	1.45;
commitid	Pa9jTAHZjMbEfrIv;

1.45
date	2015.01.16.21.16.14;	author tedu;	state Exp;
branches;
next	1.44;
commitid	PZWa8mWfp1WSG5lM;

1.44
date	2015.01.16.17.05.49;	author tedu;	state Exp;
branches;
next	1.43;
commitid	9uNdWTVRd0shyYdM;

1.43
date	2015.01.12.20.00.11;	author tedu;	state Exp;
branches;
next	1.42;
commitid	CEgUrYCen3V9BM19;

1.42
date	2015.01.09.05.01.56;	author tedu;	state Exp;
branches;
next	1.41;
commitid	KWogeIYA2sxG3IjB;

1.41
date	2015.01.08.18.07.35;	author tedu;	state Exp;
branches;
next	1.40;
commitid	RsrS4R2NXHBc5D1Q;

1.40
date	2014.12.19.05.59.21;	author tedu;	state Exp;
branches;
next	1.39;
commitid	zdJTCwdpqRUwO1SL;

1.39
date	2014.12.16.18.30.04;	author tedu;	state Exp;
branches;
next	1.38;
commitid	P6Av4XGqOi3rFasL;

1.38
date	2014.12.10.02.44.47;	author tedu;	state Exp;
branches;
next	1.37;
commitid	tsoJBlEBSyYO22RG;

1.37
date	2014.09.13.16.06.37;	author doug;	state Exp;
branches;
next	1.36;
commitid	jdBY2kKXhfcoQitp;

1.36
date	2013.11.27.15.48.43;	author jsing;	state Exp;
branches;
next	1.35;

1.35
date	2013.03.27.01.56.50;	author tedu;	state Exp;
branches;
next	1.34;

1.34
date	2012.01.04.18.11.51;	author beck;	state Exp;
branches;
next	1.33;

1.33
date	2010.05.19.08.31.23;	author thib;	state Exp;
branches;
next	1.32;

1.32
date	2009.08.24.15.51.40;	author thib;	state Exp;
branches;
next	1.31;

1.31
date	2009.08.12.16.42.24;	author beck;	state Exp;
branches;
next	1.30;

1.30
date	2009.07.09.22.29.56;	author thib;	state Exp;
branches;
next	1.29;

1.29
date	2008.10.24.00.22.57;	author tedu;	state Exp;
branches;
next	1.28;

1.28
date	2008.10.23.23.54.02;	author tedu;	state Exp;
branches;
next	1.27;

1.27
date	2008.10.20.20.33.07;	author deraadt;	state Exp;
branches;
next	1.26;

1.26
date	2008.05.06.20.57.19;	author thib;	state Exp;
branches;
next	1.25;

1.25
date	2007.06.21.12.05.14;	author pedro;	state Exp;
branches;
next	1.24;

1.24
date	2007.05.30.04.27.42;	author beck;	state Exp;
branches;
next	1.23;

1.23
date	2007.05.29.17.33.27;	author beck;	state Exp;
branches;
next	1.22;

1.22
date	2007.05.29.05.28.53;	author beck;	state Exp;
branches;
next	1.21;

1.21
date	2007.04.19.09.25.33;	author pedro;	state Exp;
branches;
next	1.20;

1.20
date	2007.04.19.07.45.20;	author art;	state Exp;
branches;
next	1.19;

1.19
date	2006.01.21.00.00.55;	author pedro;	state Exp;
branches;
next	1.18;

1.18
date	2005.06.18.18.09.42;	author millert;	state Exp;
branches;
next	1.17;

1.17
date	2005.05.28.07.28.07;	author marius;	state Exp;
branches;
next	1.16;

1.16
date	2005.05.26.23.28.39;	author pedro;	state Exp;
branches;
next	1.15;

1.15
date	2005.05.26.22.40.53;	author marius;	state Exp;
branches;
next	1.14;

1.14
date	2005.03.04.11.43.37;	author pedro;	state Exp;
branches;
next	1.13;

1.13
date	2004.12.26.21.22.13;	author miod;	state Exp;
branches;
next	1.12;

1.12
date	2004.10.04.12.03.45;	author pedro;	state Exp;
branches;
next	1.11;

1.11
date	2003.06.02.23.28.07;	author millert;	state Exp;
branches;
next	1.10;

1.10
date	2003.02.25.09.48.33;	author tedu;	state Exp;
branches;
next	1.9;

1.9
date	2003.01.31.17.37.50;	author art;	state Exp;
branches;
next	1.8;

1.8
date	2002.07.03.21.19.08;	author miod;	state Exp;
branches;
next	1.7;

1.7
date	2002.07.02.04.23.25;	author ericj;	state Exp;
branches;
next	1.6;

1.6
date	2002.01.23.00.39.48;	author art;	state Exp;
branches;
next	1.5;

1.5
date	2001.05.02.05.55.13;	author fgsch;	state Exp;
branches
	1.5.4.1;
next	1.4;

1.4
date	2001.04.29.20.58.37;	author art;	state Exp;
branches;
next	1.3;

1.3
date	99.04.28.09.28.15;	author art;	state Exp;
branches
	1.3.4.1;
next	1.2;

1.2
date	96.03.03.17.20.23;	author niklas;	state Exp;
branches;
next	1.1;

1.1
date	95.10.18.08.52.47;	author deraadt;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	95.10.18.08.52.47;	author deraadt;	state Exp;
branches;
next	;

1.3.4.1
date	2001.07.04.10.48.48;	author niklas;	state Exp;
branches;
next	1.3.4.2;

1.3.4.2
date	2002.03.06.02.13.24;	author niklas;	state Exp;
branches;
next	1.3.4.3;

1.3.4.3
date	2003.03.28.00.41.27;	author niklas;	state Exp;
branches;
next	1.3.4.4;

1.3.4.4
date	2003.06.07.11.03.41;	author ho;	state Exp;
branches;
next	;

1.5.4.1
date	2002.01.31.22.55.41;	author niklas;	state Exp;
branches;
next	1.5.4.2;

1.5.4.2
date	2002.10.29.00.36.44;	author art;	state Exp;
branches;
next	1.5.4.3;

1.5.4.3
date	2003.05.19.22.31.57;	author tedu;	state Exp;
branches;
next	;


desc
@@


1.53
log
@Use TAILQ_FOREACH_SAFE in cache_purgevfs().  Fix whitespaces.
No binary change.
@
text
@/*	$OpenBSD: vfs_cache.c,v 1.52 2016/09/16 03:21:16 dlg Exp $	*/
/*	$NetBSD: vfs_cache.c,v 1.13 1996/02/04 02:18:09 christos Exp $	*/

/*
 * Copyright (c) 1989, 1993
 *	The Regents of the University of California.  All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. Neither the name of the University nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 *	@@(#)vfs_cache.c	8.3 (Berkeley) 8/22/94
 */

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/time.h>
#include <sys/mount.h>
#include <sys/vnode.h>
#include <sys/lock.h>
#include <sys/namei.h>
#include <sys/errno.h>
#include <sys/pool.h>

/*
 * TODO: namecache access should really be locked.
 */

/*
 * For simplicity (and economy of storage), names longer than
 * a maximum length of NAMECACHE_MAXLEN are not cached; they occur
 * infrequently in any case, and are almost never of interest.
 *
 * Upon reaching the last segment of a path, if the reference
 * is for DELETE, or NOCACHE is set (rewrite), and the
 * name is located in the cache, it will be dropped.
 */

/*
 * Structures associated with name caching.
 */
long	numcache;	/* total number of cache entries allocated */
long	numneg;		/* number of negative cache entries */

TAILQ_HEAD(, namecache) nclruhead;	/* Regular Entry LRU chain */
TAILQ_HEAD(, namecache) nclruneghead;	/* Negative Entry LRU chain */
struct	nchstats nchstats;		/* cache effectiveness statistics */

int doingcache = 1;			/* 1 => enable the cache */

struct pool nch_pool;

void cache_zap(struct namecache *);
u_long nextvnodeid;

static inline int
namecache_compare(const struct namecache *n1, const struct namecache *n2)
{
	if (n1->nc_nlen == n2->nc_nlen)
		return (memcmp(n1->nc_name, n2->nc_name, n1->nc_nlen));
	else
		return (n1->nc_nlen - n2->nc_nlen);
}

RBT_PROTOTYPE(namecache_rb_cache, namecache, n_rbcache, namecache_compare);
RBT_GENERATE(namecache_rb_cache, namecache, n_rbcache, namecache_compare);

void
cache_tree_init(struct namecache_rb_cache *tree)
{
	RBT_INIT(namecache_rb_cache, tree);
}

/*
 * blow away a namecache entry
 */
void
cache_zap(struct namecache *ncp)
{
	struct vnode *dvp = NULL;

	if (ncp->nc_vp != NULL) {
		TAILQ_REMOVE(&nclruhead, ncp, nc_lru);
		numcache--;
	} else {
		TAILQ_REMOVE(&nclruneghead, ncp, nc_neg);
		numneg--;
	}
	if (ncp->nc_dvp) {
		RBT_REMOVE(namecache_rb_cache, &ncp->nc_dvp->v_nc_tree, ncp);
		if (RBT_EMPTY(namecache_rb_cache, &ncp->nc_dvp->v_nc_tree))
			dvp = ncp->nc_dvp;
	}
	if (ncp->nc_vp && (ncp->nc_vpid == ncp->nc_vp->v_id)) {
		if (ncp->nc_vp != ncp->nc_dvp &&
		    ncp->nc_vp->v_type == VDIR &&
		    (ncp->nc_nlen > 2 ||
			(ncp->nc_nlen > 1 &&
			    ncp->nc_name[1] != '.') ||
			(ncp->nc_nlen > 0 &&
			    ncp->nc_name[0] != '.'))) {
			TAILQ_REMOVE(&ncp->nc_vp->v_cache_dst, ncp, nc_me);
		}
	}
	pool_put(&nch_pool, ncp);
	if (dvp)
		vdrop(dvp);
}

/*
 * Look for a name in the cache. We don't do this if the segment name is
 * long, simply so the cache can avoid holding long names (which would
 * either waste space, or add greatly to the complexity).
 * dvp points to the directory to search. The componentname cnp holds
 * the information on the entry being sought, such as its length
 * and its name. If the lookup succeeds, vpp is set to point to the vnode
 * and an error of 0 is returned. If the lookup determines the name does
 * not exist (negative caching) an error of ENOENT is returned. If the
 * lookup fails, an error of -1 is returned.
 */
int
cache_lookup(struct vnode *dvp, struct vnode **vpp,
    struct componentname *cnp)
{
	struct namecache *ncp;
	struct namecache n;
	struct vnode *vp;
	struct proc *p = curproc;
	u_long vpid;
	int error;

	*vpp = NULL;

	if (!doingcache) {
		cnp->cn_flags &= ~MAKEENTRY;
		return (-1);
	}
	if (cnp->cn_namelen > NAMECACHE_MAXLEN) {
		nchstats.ncs_long++;
		cnp->cn_flags &= ~MAKEENTRY;
		return (-1);
	}

	/* lookup in directory vnode's redblack tree */
	n.nc_nlen = cnp->cn_namelen;
	memcpy(n.nc_name, cnp->cn_nameptr, n.nc_nlen);
	ncp = RBT_FIND(namecache_rb_cache, &dvp->v_nc_tree, &n);

	if (ncp == NULL) {
		nchstats.ncs_miss++;
		return (-1);
	}
	if ((cnp->cn_flags & MAKEENTRY) == 0) {
		nchstats.ncs_badhits++;
		goto remove;
	} else if (ncp->nc_vp == NULL) {
		if (cnp->cn_nameiop != CREATE ||
		    (cnp->cn_flags & ISLASTCN) == 0) {
			nchstats.ncs_neghits++;
			/*
			 * Move this slot to end of the negative LRU chain,
			 */
			if (TAILQ_NEXT(ncp, nc_neg) != NULL) {
				TAILQ_REMOVE(&nclruneghead, ncp, nc_neg);
				TAILQ_INSERT_TAIL(&nclruneghead, ncp,
				    nc_neg);
			}
			return (ENOENT);
		} else {
			nchstats.ncs_badhits++;
			goto remove;
		}
	} else if (ncp->nc_vpid != ncp->nc_vp->v_id) {
		nchstats.ncs_falsehits++;
		goto remove;
	}

	/*
	 * Move this slot to end of the regular LRU chain.
	 */
	if (TAILQ_NEXT(ncp, nc_lru) != NULL) {
		TAILQ_REMOVE(&nclruhead, ncp, nc_lru);
		TAILQ_INSERT_TAIL(&nclruhead, ncp, nc_lru);
	}

	vp = ncp->nc_vp;
	vpid = vp->v_id;
	if (vp == dvp) {	/* lookup on "." */
		vref(dvp);
		error = 0;
	} else if (cnp->cn_flags & ISDOTDOT) {
		VOP_UNLOCK(dvp, p);
		cnp->cn_flags |= PDIRUNLOCK;
		error = vget(vp, LK_EXCLUSIVE, p);
		/*
		 * If the above vget() succeeded and both LOCKPARENT and
		 * ISLASTCN is set, lock the directory vnode as well.
		 */
		if (!error && (~cnp->cn_flags & (LOCKPARENT|ISLASTCN)) == 0) {
			if ((error = vn_lock(dvp, LK_EXCLUSIVE, p)) != 0) {
				vput(vp);
				return (error);
			}
			cnp->cn_flags &= ~PDIRUNLOCK;
		}
	} else {
		error = vget(vp, LK_EXCLUSIVE, p);
		/*
		 * If the above vget() failed or either of LOCKPARENT or
		 * ISLASTCN is set, unlock the directory vnode.
		 */
		if (error || (~cnp->cn_flags & (LOCKPARENT|ISLASTCN)) != 0) {
			VOP_UNLOCK(dvp, p);
			cnp->cn_flags |= PDIRUNLOCK;
		}
	}

	/*
	 * Check that the lock succeeded, and that the capability number did
	 * not change while we were waiting for the lock.
	 */
	if (error || vpid != vp->v_id) {
		if (!error) {
			vput(vp);
			nchstats.ncs_falsehits++;
		} else
			nchstats.ncs_badhits++;
		/*
		 * The parent needs to be locked when we return to VOP_LOOKUP().
		 * The `.' case here should be extremely rare (if it can happen
		 * at all), so we don't bother optimizing out the unlock/relock.
		 */
		if (vp == dvp || error ||
		    (~cnp->cn_flags & (LOCKPARENT|ISLASTCN)) != 0) {
			if ((error = vn_lock(dvp, LK_EXCLUSIVE, p)) != 0)
				return (error);
			cnp->cn_flags &= ~PDIRUNLOCK;
		}
		return (-1);
	}

	nchstats.ncs_goodhits++;
	*vpp = vp;
	return (0);

remove:
	/*
	 * Last component and we are renaming or deleting,
	 * the cache entry is invalid, or otherwise don't
	 * want cache entry to exist.
	 */
	cache_zap(ncp);
	return (-1);
}

/*
 * Scan cache looking for name of directory entry pointing at vp.
 *
 * Fill in dvpp.
 *
 * If bufp is non-NULL, also place the name in the buffer which starts
 * at bufp, immediately before *bpp, and move bpp backwards to point
 * at the start of it.  (Yes, this is a little baroque, but it's done
 * this way to cater to the whims of getcwd).
 *
 * Returns 0 on success, -1 on cache miss, positive errno on failure.
 *
 * TODO: should we return *dvpp locked?
 */

int
cache_revlookup(struct vnode *vp, struct vnode **dvpp, char **bpp, char *bufp)
{
	struct namecache *ncp;
	struct vnode *dvp = NULL;
	char *bp;

	if (!doingcache)
		goto out;
	TAILQ_FOREACH(ncp, &vp->v_cache_dst, nc_me) {
		dvp = ncp->nc_dvp;
		if (dvp && dvp != vp && ncp->nc_dvpid == dvp->v_id)
			goto found;
	}
	goto miss;
found:
#ifdef DIAGNOSTIC
	if (ncp->nc_nlen == 1 &&
	    ncp->nc_name[0] == '.')
		panic("cache_revlookup: found entry for .");
	if (ncp->nc_nlen == 2 &&
	    ncp->nc_name[0] == '.' &&
	    ncp->nc_name[1] == '.')
		panic("cache_revlookup: found entry for ..");
#endif
	nchstats.ncs_revhits++;

	if (bufp != NULL) {
		bp = *bpp;
		bp -= ncp->nc_nlen;
		if (bp <= bufp) {
			*dvpp = NULL;
			return (ERANGE);
		}
		memcpy(bp, ncp->nc_name, ncp->nc_nlen);
		*bpp = bp;
	}

	*dvpp = dvp;

	/*
	 * XXX: Should we vget() here to have more
	 * consistent semantics with cache_lookup()?
	 */
	return (0);

miss:
	nchstats.ncs_revmiss++;
out:
	*dvpp = NULL;
	return (-1);
}

/*
 * Add an entry to the cache
 */
void
cache_enter(struct vnode *dvp, struct vnode *vp, struct componentname *cnp)
{
	struct namecache *ncp, *lncp;

	if (!doingcache || cnp->cn_namelen > NAMECACHE_MAXLEN)
		return;

	/*
	 * allocate, or recycle (free and allocate) an ncp.
	 */
	if (numcache >= initialvnodes) {
		if ((ncp = TAILQ_FIRST(&nclruhead)) != NULL)
			cache_zap(ncp);
		else if ((ncp = TAILQ_FIRST(&nclruneghead)) != NULL)
			cache_zap(ncp);
		else
			panic("wtf? leak?");
	}
	ncp = pool_get(&nch_pool, PR_WAITOK|PR_ZERO);

	/* grab the vnode we just found */
	ncp->nc_vp = vp;
	if (vp)
		ncp->nc_vpid = vp->v_id;

	/* fill in cache info */
	ncp->nc_dvp = dvp;
	ncp->nc_dvpid = dvp->v_id;
	ncp->nc_nlen = cnp->cn_namelen;
	memcpy(ncp->nc_name, cnp->cn_nameptr, ncp->nc_nlen);
	if (RBT_EMPTY(namecache_rb_cache, &dvp->v_nc_tree)) {
		vhold(dvp);
	}
	if ((lncp = RBT_INSERT(namecache_rb_cache, &dvp->v_nc_tree, ncp))
	    != NULL) {
		/* someone has raced us and added a different entry
		 * for the same vnode (different ncp) - we don't need
		 * this entry, so free it and we are done.
		 */
		pool_put(&nch_pool, ncp);
		/* we know now dvp->v_nc_tree is not empty, no need
		 * to vdrop here
		 */
		goto done;
	}
	if (vp) {
		TAILQ_INSERT_TAIL(&nclruhead, ncp, nc_lru);
		numcache++;
		/* don't put . or .. in the reverse map */
		if (vp != dvp && vp->v_type == VDIR &&
		    (ncp->nc_nlen > 2 ||
			(ncp->nc_nlen > 1 &&
			    ncp->nc_name[1] != '.') ||
			(ncp->nc_nlen > 0 &&
			    ncp->nc_name[0] != '.')))
			TAILQ_INSERT_TAIL(&vp->v_cache_dst, ncp,
			    nc_me);
	} else {
		TAILQ_INSERT_TAIL(&nclruneghead, ncp, nc_neg);
		numneg++;
	}
	if (numneg  > initialvnodes) {
		if ((ncp = TAILQ_FIRST(&nclruneghead))
		    != NULL)
			cache_zap(ncp);
	}
done:
	return;
}


/*
 * Name cache initialization, from vfs_init() when we are booting
 */
void
nchinit(void)
{
	TAILQ_INIT(&nclruhead);
	TAILQ_INIT(&nclruneghead);
	pool_init(&nch_pool, sizeof(struct namecache), 0, IPL_NONE, PR_WAITOK,
	    "nchpl", NULL);
}

/*
 * Cache flush, a particular vnode; called when a vnode is renamed to
 * hide entries that would now be invalid
 */
void
cache_purge(struct vnode *vp)
{
	struct namecache *ncp;

	/* We should never have destinations cached for a non-VDIR vnode. */
	KASSERT(vp->v_type == VDIR || TAILQ_EMPTY(&vp->v_cache_dst));

	while ((ncp = TAILQ_FIRST(&vp->v_cache_dst)))
		cache_zap(ncp);
	while ((ncp = RBT_ROOT(namecache_rb_cache, &vp->v_nc_tree)))
		cache_zap(ncp);

	/* XXX this blows goats */
	vp->v_id = ++nextvnodeid;
	if (vp->v_id == 0)
		vp->v_id = ++nextvnodeid;
}

/*
 * Cache flush, a whole filesystem; called when filesys is umounted to
 * remove entries that would now be invalid
 */
void
cache_purgevfs(struct mount *mp)
{
	struct namecache *ncp, *nxtcp;

	/* whack the regular entries */
	TAILQ_FOREACH_SAFE(ncp, &nclruhead, nc_lru, nxtcp) {
		if (ncp->nc_dvp == NULL || ncp->nc_dvp->v_mount != mp)
			continue;
		/* free the resources we had */
		cache_zap(ncp);
	}
	/* whack the negative entries */
	TAILQ_FOREACH_SAFE(ncp, &nclruneghead, nc_neg, nxtcp) {
		if (ncp->nc_dvp == NULL || ncp->nc_dvp->v_mount != mp)
			continue;
		/* free the resources we had */
		cache_zap(ncp);
	}
}
@


1.52
log
@move the namecache_rb_tree from RB macros to RBT functions.

i had to shuffle the includes a bit. all the knowledge of the RB
tree is now inside vfs_cache.c, and all accesses are via cache_*
functions.
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.51 2016/09/15 02:00:16 dlg Exp $	*/
d138 1
a138 1
 * not exist (negative caching) an error of ENOENT is returned. If the 
d387 1
a387 1
	  	pool_put(&nch_pool, ncp);
d464 2
a465 3
	for (ncp = TAILQ_FIRST(&nclruhead); ncp != NULL; ncp = nxtcp) {
		nxtcp = TAILQ_NEXT(ncp, nc_lru);
		if (ncp->nc_dvp == NULL || ncp->nc_dvp->v_mount != mp) {
a466 1
		}
d471 2
a472 3
	for (ncp = TAILQ_FIRST(&nclruneghead); ncp != NULL; ncp = nxtcp) {
		nxtcp = TAILQ_NEXT(ncp, nc_neg);
		if (ncp->nc_dvp == NULL || ncp->nc_dvp->v_mount != mp) {
a473 1
		}
@


1.51
log
@all pools have their ipl set via pool_setipl, so fold it into pool_init.

the ioff argument to pool_init() is unused and has been for many
years, so this replaces it with an ipl argument. because the ipl
will be set on init we no longer need pool_setipl.

most of these changes have been done with coccinelle using the spatch
below. cocci sucks at formatting code though, so i fixed that by hand.

the manpage and subr_pool.c bits i did myself.

ok tedu@@ jmatthew@@

@@ipl@@
expression pp;
expression ipl;
expression s, a, o, f, m, p;
@@@@
-pool_init(pp, s, a, o, f, m, p);
-pool_setipl(pp, ipl);
+pool_init(pp, s, a, ipl, f, m, p);
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.50 2016/08/25 00:01:13 dlg Exp $	*/
d76 2
a77 2
static int
namecache_compare(struct namecache *n1, struct namecache *n2)
d85 8
a92 1
RB_GENERATE(namecache_rb_cache, namecache, n_rbcache, namecache_compare);
d110 2
a111 2
		RB_REMOVE(namecache_rb_cache, &ncp->nc_dvp->v_nc_tree, ncp);
		if (RB_EMPTY(&ncp->nc_dvp->v_nc_tree))
d167 1
a167 1
	ncp = RB_FIND(namecache_rb_cache, &dvp->v_nc_tree, &n);
d378 1
a378 1
	if (RB_EMPTY(&dvp->v_nc_tree)) {
d381 1
a381 1
	if ((lncp = RB_INSERT(namecache_rb_cache, &dvp->v_nc_tree, ncp))
d445 1
a445 1
	while ((ncp = RB_ROOT(&vp->v_nc_tree)))
@


1.50
log
@pool_setipl

ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.49 2016/03/19 12:04:15 natano Exp $	*/
d420 1
a420 1
	pool_init(&nch_pool, sizeof(struct namecache), 0, 0, PR_WAITOK,
a421 1
	pool_setipl(&nch_pool, IPL_NONE);
@


1.49
log
@Remove the unused flags argument from VOP_UNLOCK().

torture tested on amd64, i386 and macppc
ok beck mpi stefan
"the change looks right" deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.48 2016/03/07 18:43:59 naddy Exp $	*/
d422 1
@


1.48
log
@Sync no-argument function declaration and definition by adding (void).
ok mpi@@ millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.47 2015/03/14 03:38:51 jsg Exp $	*/
d205 1
a205 1
		VOP_UNLOCK(dvp, 0, p);
d226 1
a226 1
			VOP_UNLOCK(dvp, 0, p);
@


1.47
log
@Remove some includes include-what-you-use claims don't
have any direct symbols used.  Tested for indirect use by compiling
amd64/i386/sparc64 kernels.

ok tedu@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.46 2015/01/28 20:16:04 tedu Exp $	*/
d416 1
a416 1
nchinit()
@


1.46
log
@revert back to initial vnodes again so we can be sure nfs likes it
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.45 2015/01/16 21:16:14 tedu Exp $	*/
a42 1
#include <sys/malloc.h>
@


1.45
log
@increase namecache to maxvnodes again now that the n^2 loop is no more.
battle tested by krw
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.44 2015/01/16 17:05:49 tedu Exp $	*/
d352 1
a352 1
	if (numcache >= maxvnodes) {
@


1.44
log
@increasing the size of the namecache suddenly made the comment
"This makes the algorithm O(n^2), but do you think I care?"
a lot more meaningful, as discovered by krw.
fix the loop so it doesn't restart all the time, as it's not necessary.
(this was also tried years ago in rev 1.20 and reverted, but that change
also introduced pool_put before the namecache was ready to free things. we
have been freeing cache entries with pool_put for some time now, so that's
been made safe.)
ok deraadt krw
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.43 2015/01/12 20:00:11 tedu Exp $	*/
d352 1
a352 1
	if (numcache >= initialvnodes) {
@


1.43
log
@revert the namecache embiggening since it seems to cause hangs at reboot.
reported and revert tested by krw
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.42 2015/01/09 05:01:56 tedu Exp $	*/
a450 4
 *
 * The line "nxtcp = nchhead" near the end is to avoid potential problems
 * if the cache lru chain is modified while we are dumping the
 * inode.  This makes the algorithm O(n^2), but do you think I care?
d459 1
a460 1
			nxtcp = TAILQ_NEXT(ncp, nc_lru);
a464 2
		/* cause rescan of list, it may have altered */
		nxtcp = TAILQ_FIRST(&nclruhead);
d468 1
a469 1
			nxtcp = TAILQ_NEXT(ncp, nc_neg);
a473 2
		/* cause rescan of list, it may have altered */
		nxtcp = TAILQ_FIRST(&nclruneghead);
@


1.42
log
@rename desiredvnodes to initialvnodes. less of a lie. ok beck deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.41 2015/01/08 18:07:35 tedu Exp $	*/
d352 1
a352 1
	if (numcache >= maxvnodes) {
@


1.41
log
@increase namecache size to follow maxvnodes. seems better than desiredvnodes.
(accuracy of variable names, aside)
ok kettenis
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.40 2014/12/19 05:59:21 tedu Exp $	*/
d403 1
a403 1
	if (numneg  > desiredvnodes) {
@


1.40
log
@start retiring the nointr allocator. specify PR_WAITOK as a flag as a
marker for which pools are not interrupt safe. ok dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.39 2014/12/16 18:30:04 tedu Exp $	*/
d352 1
a352 1
	if (numcache >= desiredvnodes) {
@


1.39
log
@primary change: move uvm_vnode out of vnode, keeping only a pointer.
objective: vnode.h doesn't include uvm_extern.h anymore.
followup changes: include uvm_extern.h or lock.h where necessary.
ok and help from deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.38 2014/12/10 02:44:47 tedu Exp $	*/
d421 2
a422 2
	pool_init(&nch_pool, sizeof(struct namecache), 0, 0, 0, "nchpl",
	    &pool_allocator_nointr);
@


1.38
log
@convert bcopy to memcpy. ok millert
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.37 2014/09/13 16:06:37 doug Exp $	*/
d40 1
@


1.37
log
@Replace all queue *_END macro calls except CIRCLEQ_END with NULL.

CIRCLEQ_* is deprecated and not called in the tree.  The other queue types
have *_END macros which were added for symmetry with CIRCLEQ_END.  They are
defined as NULL.  There's no reason to keep the other *_END macro calls.

ok millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.36 2013/11/27 15:48:43 jsing Exp $	*/
d370 1
a370 1
	bcopy(cnp->cn_nameptr, ncp->nc_name, (unsigned)ncp->nc_nlen);
@


1.36
log
@Assert that we never have destinations cached for a non-VDIR vnode.

ok beck@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.35 2013/03/27 01:56:50 tedu Exp $	*/
d461 1
a461 2
	for (ncp = TAILQ_FIRST(&nclruhead); ncp != TAILQ_END(&nclruhead);
	    ncp = nxtcp) {
d472 1
a472 2
	for (ncp = TAILQ_FIRST(&nclruneghead); ncp != TAILQ_END(&nclruneghead);
	    ncp = nxtcp) {
@


1.35
log
@rename NCHNAMLEN to NAMECACHE_MAXLEN. easier to read, easier to type.
ok beck deraadt after a style issue noticed by kettenis
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.34 2012/01/04 18:11:51 beck Exp $	*/
d432 3
@


1.34
log
@
Fix use after free in cache_lookup() - found by Pedro

fix is to manipulate the name cache structures before
potentially sleeping on a vn_lock(). This avoids the race of
the ncp entry being recycled while we are asleep.

run in snaps and on ftp.openbsd.org for months

ok thib@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.33 2010/05/19 08:31:23 thib Exp $	*/
d51 1
a51 1
 * a maximum length of NCHNAMLEN are not cached; they occur
d151 1
a151 1
	if (cnp->cn_namelen > NCHNAMLEN) {
d345 1
a345 1
	if (!doingcache || cnp->cn_namelen > NCHNAMLEN)
@


1.33
log
@clean up a few things that where left to rot after bob's vfs cache work.
sync a few comments to reality (or remove them), remove the cn_hash member
from struct componentname, spacing.

ok beck@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.32 2009/08/24 15:51:40 thib Exp $	*/
d191 8
a255 7
	/*
	 * Move this slot to end of the regular LRU chain.
	 */
	if (TAILQ_NEXT(ncp, nc_lru) != NULL) {
		TAILQ_REMOVE(&nclruhead, ncp, nc_lru);
		TAILQ_INSERT_TAIL(&nclruhead, ncp, nc_lru);
	}
@


1.32
log
@garbage collect the nchash variable that used to store the
size of cache hashtable that has now been removed.
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.30 2009/07/09 22:29:56 thib Exp $	*/
a43 1
#include <sys/hash.h>
a49 8
 * Name caching works as follows:
 *
 * Names found by directory scans are retained in a cache
 * for future reference.  It is managed LRU, so frequently
 * used names will hang around.  Cache is indexed by hash value
 * obtained from (vp, name) where vp refers to the directory
 * containing name.
 *
d62 2
a63 2
long	numcache;			/* total number of cache entries allocated */
long	numneg;				/* number of negative cache entries */
d65 2
a66 2
TAILQ_HEAD(, namecache) nclruhead;		/* Regular Entry LRU chain */
TAILQ_HEAD(, namecache) nclruneghead;		/* Negative Entry LRU chain */
d127 6
a132 10
 *
 * Lookup is called with ni_dvp pointing to the directory to search,
 * ni_ptr pointing to the name of the entry being sought, ni_namelen
 * tells the length of the name, and ni_hash contains a hash of
 * the name. If the lookup succeeds, the vnode is returned in ni_vp
 * and a status of 0 is returned. If the locking fails for whatever
 * reason, the vnode is unlocked and the error is returned to caller.
 * If the lookup determines that the name does not exist (negative caching),
 * a status of ENOENT is returned. If the lookup fails, a status of -1
 * is returned.
@


1.31
log
@Namecache revamp.

This eliminates the large single namecache hash table, and implements
the name cache as a global lru of entires, and a redblack tree in each
vnode. It makes cache_purge actually purge the namecache entries associated
with a vnode when a vnode is recycled (very important for later on actually being
able to resize the vnode pool)

This commit does #if 0 out a bunch of procmap code that was
already broken before this change, but needs to be redone completely.

Tested by many, including in thib's nfs test setup.

ok oga@@,art@@,thib@@,miod@@
@
text
@a70 1
u_long	nchash;				/* size of hash table - 1 */
@


1.30
log
@Remove the VREF() macro and replaces all instances with a call to verf(),
which is exactly what the macro does.

Macro's that are nothing more then:
#define FUNCTION(arg) function(arg)
are almost always pointless and should go away.

OK blambert@@
Agreed by many.
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.27 2008/10/20 20:33:07 deraadt Exp $	*/
a70 1
LIST_HEAD(nchashhead, namecache) *nchashtbl;
d72 5
a76 2
long	numcache;			/* number of cache entries allocated */
TAILQ_HEAD(, namecache) nclruhead;		/* LRU chain */
d79 1
a79 2
LIST_HEAD(ncvhashhead, namecache) *ncvhashtbl;
u_long  ncvhash;                        /* size of hash table - 1 */
d81 4
a84 2
#define NCHASH(dvp, cnp) \
	hash32_buf(&(dvp)->v_id, sizeof((dvp)->v_id), (cnp)->cn_hash) & nchash
d86 8
a93 1
#define NCVHASH(vp) (vp)->v_id & ncvhash
d95 1
a95 1
int doingcache = 1;			/* 1 => enable the cache */
d97 7
a103 1
struct pool nch_pool;
d105 27
a131 1
u_long nextvnodeid;
d149 2
a150 1
cache_lookup(struct vnode *dvp, struct vnode **vpp, struct componentname *cnp)
d153 1
a153 1
	struct nchashhead *ncpp;
d171 5
a175 8
	ncpp = &nchashtbl[NCHASH(dvp, cnp)];
	LIST_FOREACH(ncp, ncpp, nc_hash) {
		if (ncp->nc_dvp == dvp &&
		    ncp->nc_dvpid == dvp->v_id &&
		    ncp->nc_nlen == cnp->cn_namelen &&
		    !memcmp(ncp->nc_name, cnp->cn_nameptr, (u_int)ncp->nc_nlen))
			break;
	}
d188 1
a188 2
			 * Move this slot to end of LRU chain,
			 * if not already there.
d190 4
a193 3
			if (TAILQ_NEXT(ncp, nc_lru) != NULL) {
				TAILQ_REMOVE(&nclruhead, ncp, nc_lru);
				TAILQ_INSERT_TAIL(&nclruhead, ncp, nc_lru);
d263 1
a263 1
	 * Move this slot to end of LRU chain, if not already there.
d278 1
a278 10
	TAILQ_REMOVE(&nclruhead, ncp, nc_lru);
	LIST_REMOVE(ncp, nc_hash);
	ncp->nc_hash.le_prev = NULL;

	if (ncp->nc_vhash.le_prev != NULL) {
		LIST_REMOVE(ncp, nc_vhash);
		ncp->nc_vhash.le_prev = NULL;
	}

	TAILQ_INSERT_HEAD(&nclruhead, ncp, nc_lru);
d301 1
a301 2
	struct vnode *dvp;
	struct ncvhashhead *nvcpp;
d306 7
a312 10

	nvcpp = &ncvhashtbl[NCVHASH(vp)];

	LIST_FOREACH(ncp, nvcpp, nc_vhash) {
		if (ncp->nc_vp == vp &&
		    ncp->nc_vpid == vp->v_id &&
		    (dvp = ncp->nc_dvp) != NULL &&
		    /* avoid pesky '.' entries.. */
		    dvp != vp && ncp->nc_dvpid == dvp->v_id) {

d314 7
a320 8
			if (ncp->nc_nlen == 1 &&
			    ncp->nc_name[0] == '.')
				panic("cache_revlookup: found entry for .");

			if (ncp->nc_nlen == 2 &&
			    ncp->nc_name[0] == '.' &&
			    ncp->nc_name[1] == '.')
				panic("cache_revlookup: found entry for ..");
d322 12
a333 1
			nchstats.ncs_revhits++;
d335 1
a335 10
			if (bufp != NULL) {
				bp = *bpp;
				bp -= ncp->nc_nlen;
				if (bp <= bufp) {
					*dvpp = NULL;
					return (ERANGE);
				}
				memcpy(bp, ncp->nc_name, ncp->nc_nlen);
				*bpp = bp;
			}
d337 5
a341 1
			*dvpp = dvp;
d343 1
a343 12
			/*
			 * XXX: Should we vget() here to have more
			 * consistent semantics with cache_lookup()?
			 *
			 * For MP safety it might be necessary to do
			 * this here, while also protecting hash
			 * tables themselves to provide some sort of
			 * sane inter locking.
			 */
			return (0);
		}
	}
d345 1
a345 2

 out:
d356 1
a356 3
	struct namecache *ncp;
	struct nchashhead *ncpp;
	struct ncvhashhead *nvcpp;
d362 1
a362 1
	 * Free the cache slot at head of lru chain.
d364 10
a373 15
	if (numcache < desiredvnodes) {
		ncp = pool_get(&nch_pool, PR_WAITOK|PR_ZERO);
		numcache++;
	} else if ((ncp = TAILQ_FIRST(&nclruhead)) != NULL) {
		TAILQ_REMOVE(&nclruhead, ncp, nc_lru);
		if (ncp->nc_hash.le_prev != NULL) {
			LIST_REMOVE(ncp, nc_hash);
			ncp->nc_hash.le_prev = NULL;
		}
		if (ncp->nc_vhash.le_prev != NULL) {
			LIST_REMOVE(ncp, nc_vhash);
			ncp->nc_vhash.le_prev = NULL;
		}
	} else
		return;
d378 1
d384 35
a418 18
	TAILQ_INSERT_TAIL(&nclruhead, ncp, nc_lru);
	ncpp = &nchashtbl[NCHASH(dvp, cnp)];
	LIST_INSERT_HEAD(ncpp, ncp, nc_hash);

	/*
	 * Create reverse-cache entries (used in getcwd) for
	 * directories.
	 */

	ncp->nc_vhash.le_prev = NULL;
	ncp->nc_vhash.le_next = NULL;

	if (vp && vp != dvp && vp->v_type == VDIR &&
	    (ncp->nc_nlen > 2 ||
		(ncp->nc_nlen > 1 && ncp->nc_name[1] != '.') ||
		(ncp->nc_nlen > 0 && ncp->nc_name[0] != '.'))) {
		nvcpp = &ncvhashtbl[NCVHASH(vp)];
		LIST_INSERT_HEAD(nvcpp, ncp, nc_vhash);
d420 2
d424 1
a430 1

d432 1
a432 2
	nchashtbl = hashinit(desiredvnodes, M_CACHE, M_WAITOK, &nchash);
	ncvhashtbl = hashinit(desiredvnodes/8, M_CACHE, M_WAITOK, &ncvhash);
a444 1
	struct nchashhead *ncpp;
d446 6
d453 2
a454 9
	if (nextvnodeid != 0)
		return;
	for (ncpp = &nchashtbl[nchash]; ncpp >= nchashtbl; ncpp--) {
		LIST_FOREACH(ncp, ncpp, nc_hash) {
			ncp->nc_vpid = 0;
			ncp->nc_dvpid = 0;
		}
	}
	vp->v_id = ++nextvnodeid;
d470 1
d478 10
a487 10
		ncp->nc_vp = NULL;
		ncp->nc_dvp = NULL;
		TAILQ_REMOVE(&nclruhead, ncp, nc_lru);
		if (ncp->nc_hash.le_prev != NULL) {
			LIST_REMOVE(ncp, nc_hash);
			ncp->nc_hash.le_prev = NULL;
		}
		if (ncp->nc_vhash.le_prev != NULL) {
			LIST_REMOVE(ncp, nc_vhash);
			ncp->nc_vhash.le_prev = NULL;
d489 2
d492 1
a492 2
		nxtcp = TAILQ_FIRST(&nclruhead);
		TAILQ_INSERT_HEAD(&nclruhead, ncp, nc_lru);
@


1.29
log
@another oops.
@
text
@d168 1
a168 1
		VREF(dvp);
@


1.28
log
@a better fix for the "uvm_km thread runs out of memory" problem.

add a new arg to the backend so it can tell pool to slow down.  when we get
this flag, yield *after* putting the page in the pool's free list.  whatever
we do, don't let the thread sleep.

this makes things better by still letting the thread run when a huge pf
request comes in, but without artificially increasing pressure on the backend
by eating pages without feeding them forward.

ok deraadt
@
text
@a164 3
	/* remove from lru now to prevent races */
	TAILQ_REMOVE(&nclruhead, ncp, nc_lru);

a180 2
				/* parent has permanent issues; recycle */
				TAILQ_INSERT_HEAD(&nclruhead, ncp, nc_lru);
a206 2
		/* cache entry is stale; recycle */
		TAILQ_INSERT_HEAD(&nclruhead, ncp, nc_lru);
d222 7
a228 2
	/* cache entry is valid; keep it */
	TAILQ_INSERT_TAIL(&nclruhead, ncp, nc_lru);
@


1.27
log
@The optimization done in 1.19 (and repaired in 1.20) results in
cache entries which are freed (and potentially reused), but which are
currently in use by another kernel thread which was sleeping in vput()
or vget().  This causes the crash in PR 5960, but potentially a
bunch of other side effects. figured out with pedro.
ok kettenis
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.19 2006/01/21 00:00:55 pedro Exp $	*/
d165 3
d184 2
d212 2
d229 2
a230 7
	/*
	 * Move this slot to end of LRU chain, if not already there.
	 */
	if (TAILQ_NEXT(ncp, nc_lru) != NULL) {
		TAILQ_REMOVE(&nclruhead, ncp, nc_lru);
		TAILQ_INSERT_TAIL(&nclruhead, ncp, nc_lru);
	}
@


1.26
log
@Add a PR_ZERO flag for pools, to compliment the M_ZERO
malloc flag, does the same thing.
use it in a few places.

OK tedu@@, "then go ahead. and don't forget the manpage (-:" miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.25 2007/06/21 12:05:14 pedro Exp $	*/
d247 1
a247 2
	pool_put(&nch_pool, ncp);
	numcache--;
d395 1
a395 1
nchinit(void)
d430 4
d439 1
a439 1
   
d442 2
a443 2
		nxtcp = TAILQ_NEXT(ncp, nc_lru);
		if (ncp->nc_dvp == NULL || ncp->nc_dvp->v_mount != mp)
d445 1
d458 3
a460 2
		pool_put(&nch_pool, ncp);
		numcache--;
@


1.25
log
@english, okay jmc@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.24 2007/05/30 04:27:42 beck Exp $	*/
d348 1
a348 2
		ncp = pool_get(&nch_pool, PR_WAITOK);
		bzero((char *)ncp, sizeof *ncp);
@


1.24
log
@back out vfs change - todd fries has seen afs issues, and I'm suspicious
this can cause other problems.
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.21 2007/04/19 09:25:33 pedro Exp $	*/
d92 3
a94 4
 * Look for a the name in the cache. We don't do this
 * if the segment name is long, simply so the cache can avoid
 * holding long names (which would either waste space, or
 * add greatly to the complexity).
@


1.23
log
@missing couple of #ifdef DIAGNOSTIC and style nits from art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.22 2007/05/29 05:28:53 beck Exp $	*/
a71 1
TAILQ_HEAD (, namecache) ncneq;
a73 1
long	numcachehv;			/* number of holding vnodes */
d132 1
d134 2
a135 8
		    !memcmp(ncp->nc_name, cnp->cn_nameptr, (u_int)ncp->nc_nlen)) {
#ifdef DIAGNOSTIC
			if (ncp->nc_dvpid != dvp->v_id)
				panic("ncp->nc_dvpid %x != dvp->v_id %x\n",
				ncp->nc_dvpid, dvp->v_id);
#endif
				break;
		}
d162 2
a163 4
#ifdef DIAGNOSTIC
		panic("ncp->vpid %x != ncp->nc_vp->v_id %x\n", ncp->nc_vpid,
			ncp->nc_vp->v_id);
#endif
a203 2
#ifdef DIAGNOSTIC
			panic("vpid %x != vp->vid %x\n", vpid, vp->v_id);
d205 1
a205 1
#endif
d239 11
a249 1
	cache_delete(ncp);
d283 1
d287 1
a288 3
			if (ncp->nc_vpid != vp->v_id)
				panic("ncp->nc_vpid %x != vp->v_id %x\n",
				ncp->nc_vpid, vp->v_id);
a340 1
	int hold = 0;
d348 16
a363 7
	while ((numcache >= desiredvnodes) &&
		((ncp = TAILQ_FIRST(&nclruhead)) != NULL)){
		cache_delete(ncp);
	}
	ncp = pool_get(&nch_pool, PR_WAITOK);
	bzero((char *)ncp, sizeof *ncp);
	numcache++;
a376 9
	/* record references to us in various vnodes... */
	if (LIST_EMPTY(&dvp->v_cache_src)) {
		hold = 1;
		numcachehv++;
	}
	LIST_INSERT_HEAD(&dvp->v_cache_src, ncp, nc_src);
	if (vp)
		TAILQ_INSERT_HEAD(&vp->v_cache_dst, ncp, nc_dst);

a391 2
	if (hold)
		vhold(dvp);
d400 1
a407 39
void
cache_delete (struct namecache *ncp)
{
	/*
	 * just make it go away...
	 */
	struct vnode *vp = NULL;
	/* 
	 * XXX abuse of the queue macro internals is endemic to this
	 * and needs fixing - for now this is inherited from earlier evil.
	 */
	if (ncp->nc_lru.tqe_prev != NULL) {
		TAILQ_REMOVE(&nclruhead, ncp, nc_lru);
		ncp->nc_lru.tqe_prev = NULL;
	}
	if (ncp->nc_hash.le_prev != NULL) { 
		LIST_REMOVE(ncp, nc_hash);
		ncp->nc_hash.le_prev = NULL;
	}
	if (ncp->nc_vhash.le_prev != NULL) {
		LIST_REMOVE(ncp, nc_vhash);
		ncp->nc_vhash.le_prev = NULL;
	}
	LIST_REMOVE(ncp, nc_src);
	if (LIST_EMPTY(&ncp->nc_dvp->v_cache_src)) {
		vp = ncp->nc_dvp;
		numcachehv--;
	}
	if (ncp->nc_vp)
		TAILQ_REMOVE(&ncp->nc_vp->v_cache_dst, ncp, nc_dst);
	ncp->nc_vp = NULL;
	ncp->nc_dvp = NULL;
	pool_put(&nch_pool, ncp);
	numcache--;
	if (vp) {
		vdrop(vp);
	}
}

a417 6
	while (!LIST_EMPTY(&vp->v_cache_src)) {
		cache_delete(LIST_FIRST(&vp->v_cache_src));
	}
	while (!TAILQ_EMPTY(&vp->v_cache_dst)) {
		cache_delete(TAILQ_FIRST(&vp->v_cache_dst));
	}
d445 13
a457 1
		cache_delete(ncp);
@


1.22
log
@
	Step one of some vnode improvements - change getnewvnode to
actually allocate "desiredvnodes" - add a vdrop to un-hold a vnode held
with vhold, and change the name cache to make use of vhold/vdrop, while
keeping track of which vnodes are referred to by which cache entries to
correctly hold/drop vnodes when the cache uses them.
ok thib@@, tedu@@, art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.21 2007/04/19 09:25:33 pedro Exp $	*/
a139 1
			else 
d169 1
d172 1
a172 2
		nchstats.ncs_falsehits++;
		goto remove;
d213 1
d216 1
a216 1
			nchstats.ncs_falsehits++;
d412 2
a413 1
void cache_delete (struct namecache *ncp)
@


1.21
log
@Fix freeing of namecache entries in cache_purgevfs(), okay miod@@ art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.20 2007/04/19 07:45:20 art Exp $	*/
d72 1
d75 1
a133 1
		    ncp->nc_dvpid == dvp->v_id &&
d135 9
a143 2
		    !memcmp(ncp->nc_name, cnp->cn_nameptr, (u_int)ncp->nc_nlen))
			break;
d170 2
d214 1
d250 1
a250 11
	TAILQ_REMOVE(&nclruhead, ncp, nc_lru);
	LIST_REMOVE(ncp, nc_hash);
	ncp->nc_hash.le_prev = NULL;

	if (ncp->nc_vhash.le_prev != NULL) {
		LIST_REMOVE(ncp, nc_vhash);
		ncp->nc_vhash.le_prev = NULL;
	}

	pool_put(&nch_pool, ncp);
	numcache--;
a283 1
		    ncp->nc_vpid == vp->v_id &&
a286 1

d288 3
d343 1
d351 7
a357 16
	if (numcache < desiredvnodes) {
		ncp = pool_get(&nch_pool, PR_WAITOK);
		bzero((char *)ncp, sizeof *ncp);
		numcache++;
	} else if ((ncp = TAILQ_FIRST(&nclruhead)) != NULL) {
		TAILQ_REMOVE(&nclruhead, ncp, nc_lru);
		if (ncp->nc_hash.le_prev != NULL) {
			LIST_REMOVE(ncp, nc_hash);
			ncp->nc_hash.le_prev = NULL;
		}
		if (ncp->nc_vhash.le_prev != NULL) {
			LIST_REMOVE(ncp, nc_vhash);
			ncp->nc_vhash.le_prev = NULL;
		}
	} else
		return;
d371 9
d395 2
a404 1

d412 38
d460 6
d493 1
a493 13
		ncp->nc_vp = NULL;
		ncp->nc_dvp = NULL;
		TAILQ_REMOVE(&nclruhead, ncp, nc_lru);
		if (ncp->nc_hash.le_prev != NULL) {
			LIST_REMOVE(ncp, nc_hash);
			ncp->nc_hash.le_prev = NULL;
		}
		if (ncp->nc_vhash.le_prev != NULL) {
			LIST_REMOVE(ncp, nc_vhash);
			ncp->nc_vhash.le_prev = NULL;
		}
		pool_put(&nch_pool, ncp);
		numcache--;
@


1.20
log
@After we bumped the maximal number of vnodes by quite a bit we became
painfully aware of what the comment:
   "This makes the algorithm O(n^2), but do you think I care?"
actually means. I started to care.

Fix up the cache_purgevfs algorithm to not be O(n^2) since it's not
preemptible anyway and while I'm here, make this code actually return
the cache entries to the pool instead of hogging them and implement a
marginally faster free list. This way we return memory to the system
when some parameters change.

miod@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.19 2006/01/21 00:00:55 pedro Exp $	*/
d437 6
a442 4
	struct namecache *ncp;

	TAILQ_FOREACH(ncp, &nclruhead, nc_lru) {
		if (ncp->nc_dvp == NULL || ncp->nc_dvp->v_mount != mp) {
a443 1
		}
@


1.19
log
@Make sure cache_revlookup() doesn't return invalid cache entries.
This function will be used in the future. Okay marius@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.18 2005/06/18 18:09:42 millert Exp $	*/
d248 2
a249 1
	TAILQ_INSERT_HEAD(&nclruhead, ncp, nc_lru);
d398 1
a398 1
nchinit()
a432 4
 *
 * The line "nxtcp = nchhead" near the end is to avoid potential problems
 * if the cache lru chain is modified while we are dumping the
 * inode.  This makes the algorithm O(n^2), but do you think I care?
d437 1
a437 1
	struct namecache *ncp, *nxtcp;
d439 1
a439 2
	for (ncp = TAILQ_FIRST(&nclruhead); ncp != TAILQ_END(&nclruhead);
	    ncp = nxtcp) {
a440 1
			nxtcp = TAILQ_NEXT(ncp, nc_lru);
d455 2
a456 3
		/* cause rescan of list, it may have altered */
		nxtcp = TAILQ_FIRST(&nclruhead);
		TAILQ_INSERT_HEAD(&nclruhead, ncp, nc_lru);
@


1.18
log
@Remove remaining whiteout tentacles; OK deraadt@@ miod@@ weingart@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.17 2005/05/28 07:28:07 marius Exp $	*/
d285 1
a285 1
		    dvp != vp) {
@


1.17
log
@fix one missed case for removing reverse name cache entries.

ok pedro@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.16 2005/05/26 23:28:39 pedro Exp $	*/
a144 4
		/*
		 * Restore the ISWHITEOUT flag saved earlier.
		 */
		cnp->cn_flags |= ncp->nc_vpid;
a366 7
	else {
		/*
		 * For negative hits, save the ISWHITEOUT flag so we can
		 * restore it later when the cache entry is used again.
		 */
		ncp->nc_vpid = cnp->cn_flags & ISWHITEOUT;
	}
@


1.16
log
@styling nits, ok marius@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.15 2005/05/26 22:40:53 marius Exp $	*/
d360 4
@


1.15
log
@add a reverse name mapping into the namecache.  (vnode->name)

this will help speedup getcwd (coming soon).

ok pedro@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.14 2005/03/04 11:43:37 pedro Exp $	*/
d81 1
a81 1
	hash32_buf(&(dvp)->v_id, sizeof((dvp)->v_id), (cnp)->cn_hash) &nchash
d357 1
a357 1
		if (ncp->nc_hash.le_prev != 0) {
d359 1
a359 1
			ncp->nc_hash.le_prev = 0;
d388 2
a389 2
	ncp->nc_vhash.le_prev = 0;
	ncp->nc_vhash.le_next = 0;
d459 1
a459 1
		if (ncp->nc_hash.le_prev != 0) {
d461 1
a461 1
			ncp->nc_hash.le_prev = 0;
d463 1
a463 1
		if (ncp->nc_vhash.le_prev != 0) {
d465 1
a465 1
			ncp->nc_vhash.le_prev = 0;
@


1.14
log
@Fix handling of names bigger than NCHNAMLEN in cache_enter(), okay tedu@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.13 2004/12/26 21:22:13 miod Exp $	*/
d47 4
d77 8
d108 1
a108 4
cache_lookup(dvp, vpp, cnp)
	struct vnode *dvp;
	struct vnode **vpp;
	struct componentname *cnp;
d129 1
a129 2
	ncpp = &nchashtbl[
	    hash32_buf(&dvp->v_id, sizeof(dvp->v_id), cnp->cn_hash) & nchash];
d137 1
a137 1
	if (ncp == 0) {
d246 1
a246 1
#if 0
d251 49
d301 31
a331 1
	TAILQ_INSERT_HEAD(&nclruhead, ncp, nc_lru);
d339 1
a339 4
cache_enter(dvp, vp, cnp)
	struct vnode *dvp;
	struct vnode *vp;
	struct componentname *cnp;
d341 3
a343 2
	register struct namecache *ncp;
	register struct nchashhead *ncpp;
d380 1
a380 2
	ncpp = &nchashtbl[
	    hash32_buf(&dvp->v_id, sizeof(dvp->v_id), cnp->cn_hash) & nchash];
d382 16
d409 1
d419 1
a419 2
cache_purge(vp)
	struct vnode *vp;
d445 1
a445 2
cache_purgevfs(mp)
	struct mount *mp;
d447 1
a447 1
	register struct namecache *ncp, *nxtcp;
d462 4
@


1.13
log
@Use list and queue macros where applicable to make the code easier to read;
no change in compiler assembly output.
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.12 2004/10/04 12:03:45 pedro Exp $	*/
d260 1
a260 5
#ifdef DIAGNOSTIC
	if (cnp->cn_namelen > NCHNAMLEN)
		panic("cache_enter: name too long");
#endif
	if (!doingcache)
d262 1
@


1.12
log
@cacheing -> caching
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.11 2003/06/02 23:28:07 millert Exp $	*/
d273 1
a273 1
	} else if ((ncp = nclruhead.tqh_first) != NULL) {
d331 1
a331 1
		for (ncp = ncpp->lh_first; ncp != 0; ncp = ncp->nc_hash.le_next) {
d353 2
a354 1
	for (ncp = nclruhead.tqh_first; ncp != 0; ncp = nxtcp) {
d356 1
a356 1
			nxtcp = ncp->nc_lru.tqe_next;
d368 1
a368 1
		nxtcp = nclruhead.tqh_first;
@


1.11
log
@Remove the advertising clause in the UCB license which Berkeley
rescinded 22 July 1999.  Proofed by myself and Theo.
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.10 2003/02/25 09:48:33 tedu Exp $	*/
d65 1
a65 1
 * Structures associated with name cacheing.
d91 1
a91 1
 * If the lookup determines that the name does not exist (negative cacheing),
@


1.10
log
@set *vpp to NULL on entry.  this provides a good example for other fs.

ok art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.9 2003/01/31 17:37:50 art Exp $	*/
d16 1
a16 5
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by the University of
 *	California, Berkeley and its contributors.
 * 4. Neither the name of the University nor the names of its contributors
@


1.9
log
@File system locking fixups, mostly from NetBSD:
- cache_lookup
        move common code from various fs's here
        always return with vnode and parent locked
        adjust return codes
- PDIRUNLOCK - new flag set if lookup couldn't lock parent vnode
- kernfs and procfs
        lock vnode in get_root
        don't unlock (again) in kernfs_freevp
        fix memory leak in procfs

From tedu@@stanford.edu
deraadt@@ and various other ok
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.8 2002/07/03 21:19:08 miod Exp $	*/
d112 2
a115 1
		*vpp = NULL;
a120 1
		*vpp = NULL;
a134 1
		*vpp = NULL;
a218 1
		*vpp = NULL;
a248 1
	*vpp = NULL;
@


1.8
log
@Change all variables definitions (int foo) in sys/sys/*.h to variable
declarations (extern int foo), and compensate in the appropriate locations.
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.7 2002/07/02 04:23:25 ericj Exp $	*/
d93 5
a97 3
 * and a status of -1 is returned. If the lookup determines that
 * the name does not exist (negative cacheing), a status of ENOENT
 * is returned. If the lookup fails, a status of zero is returned.
d105 6
a110 2
	register struct namecache *ncp;
	register struct nchashhead *ncpp;
d114 2
a115 1
		return (0);
d120 2
a121 1
		return (0);
d123 1
d126 1
a126 1
	for (ncp = ncpp->lh_first; ncp != 0; ncp = ncp->nc_hash.le_next) {
d130 1
a130 1
		    !bcmp(ncp->nc_name, cnp->cn_nameptr, (u_int)ncp->nc_nlen))
d135 2
a136 1
		return (0);
d140 1
d146 2
a147 1
		if (cnp->cn_nameiop != CREATE) {
d153 1
a153 1
			if (ncp->nc_lru.tqe_next != 0) {
d158 3
d164 23
d188 21
a208 1
		nchstats.ncs_goodhits++;
d210 3
a212 1
		 * move this slot to end of LRU chain, if not already there
d214 5
a218 3
		if (ncp->nc_lru.tqe_next != 0) {
			TAILQ_REMOVE(&nclruhead, ncp, nc_lru);
			TAILQ_INSERT_TAIL(&nclruhead, ncp, nc_lru);
d220 1
a220 1
		*vpp = ncp->nc_vp;
d224 12
d243 7
a249 1
	ncp->nc_hash.le_prev = 0;
d251 2
a252 1
	return (0);
@


1.7
log
@
use hash.h for nfs_hash as well as namei's hash
ok art@@ costa@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.6 2002/01/23 00:39:48 art Exp $	*/
d80 2
@


1.6
log
@Pool deals fairly well with physical memory shortage, but it doesn't deal
well (not at all) with shortages of the vm_map where the pages are mapped
(usually kmem_map).

Try to deal with it:
 - group all information the backend allocator for a pool in a separate
   struct. The pool will only have a pointer to that struct.
 - change the pool_init API to reflect that.
 - link all pools allocating from the same allocator on a linked list.
 - Since an allocator is responsible to wait for physical memory it will
   only fail (waitok) when it runs out of its backing vm_map, carefully
   drain pools using the same allocator so that va space is freed.
   (see comments in code for caveats and details).
 - change pool_reclaim to return if it actually succeeded to free some
   memory, use that information to make draining easier and more efficient.
 - get rid of PR_URGENT, noone uses it.
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.5 2001/05/02 05:55:13 fgsch Exp $	*/
d48 1
d113 2
a114 1
	ncpp = &nchashtbl[(cnp->cn_hash ^ dvp->v_id) & nchash];
d222 2
a223 1
	ncpp = &nchashtbl[(cnp->cn_hash ^ dvp->v_id) & nchash];
@


1.5
log
@Use correct M_CACHE type; art@@ ok.
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.4 2001/04/29 20:58:37 art Exp $	*/
d234 1
a234 1
		0, pool_page_alloc_nointr, pool_page_free_nointr, M_CACHE);
@


1.5.4.1
log
@Merge in -current, builds on i386, otherwise untested
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.6 2002/01/23 00:39:48 art Exp $	*/
d234 1
a234 1
	    &pool_allocator_nointr);
@


1.5.4.2
log
@sync to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.5.4.1 2002/01/31 22:55:41 niklas Exp $	*/
a47 1
#include <sys/hash.h>
a79 2
u_long nextvnodeid;

d112 1
a112 2
	ncpp = &nchashtbl[
	    hash32_buf(&dvp->v_id, sizeof(dvp->v_id), cnp->cn_hash) & nchash];
d220 1
a220 2
	ncpp = &nchashtbl[
	    hash32_buf(&dvp->v_id, sizeof(dvp->v_id), cnp->cn_hash) & nchash];
@


1.5.4.3
log
@sync
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d93 3
a95 5
 * and a status of 0 is returned. If the locking fails for whatever
 * reason, the vnode is unlocked and the error is returned to caller.
 * If the lookup determines that the name does not exist (negative cacheing),
 * a status of ENOENT is returned. If the lookup fails, a status of -1
 * is returned.
d103 2
a104 8
	struct namecache *ncp;
	struct nchashhead *ncpp;
	struct vnode *vp;
	struct proc *p = curproc;
	u_long vpid;
	int error;

	*vpp = NULL;
d108 1
a108 1
		return (-1);
d113 1
a113 1
		return (-1);
a114 1

d117 1
a117 1
	LIST_FOREACH(ncp, ncpp, nc_hash) {
d121 1
a121 1
		    !memcmp(ncp->nc_name, cnp->cn_nameptr, (u_int)ncp->nc_nlen))
d126 1
a126 1
		return (-1);
a129 1
		goto remove;
d135 1
a135 2
		if (cnp->cn_nameiop != CREATE ||
		    (cnp->cn_flags & ISLASTCN) == 0) {
d141 1
a141 1
			if (TAILQ_NEXT(ncp, nc_lru) != NULL) {
a145 3
		} else {
			nchstats.ncs_badhits++;
			goto remove;
a148 23
		goto remove;
	}

	vp = ncp->nc_vp;
	vpid = vp->v_id;
	if (vp == dvp) {	/* lookup on "." */
		VREF(dvp);
		error = 0;
	} else if (cnp->cn_flags & ISDOTDOT) {
		VOP_UNLOCK(dvp, 0, p);
		cnp->cn_flags |= PDIRUNLOCK;
		error = vget(vp, LK_EXCLUSIVE, p);
		/*
		 * If the above vget() succeeded and both LOCKPARENT and
		 * ISLASTCN is set, lock the directory vnode as well.
		 */
		if (!error && (~cnp->cn_flags & (LOCKPARENT|ISLASTCN)) == 0) {
			if ((error = vn_lock(dvp, LK_EXCLUSIVE, p)) != 0) {
				vput(vp);
				return (error);
			}
			cnp->cn_flags &= ~PDIRUNLOCK;
		}
d150 1
a150 1
		error = vget(vp, LK_EXCLUSIVE, p);
d152 1
a152 2
		 * If the above vget() failed or either of LOCKPARENT or
		 * ISLASTCN is set, unlock the directory vnode.
d154 3
a156 26
		if (error || (~cnp->cn_flags & (LOCKPARENT|ISLASTCN)) != 0) {
			VOP_UNLOCK(dvp, 0, p);
			cnp->cn_flags |= PDIRUNLOCK;
		}
	}

	/*
	 * Check that the lock succeeded, and that the capability number did
	 * not change while we were waiting for the lock.
	 */
	if (error || vpid != vp->v_id) {
		if (!error) {
			vput(vp);
			nchstats.ncs_falsehits++;
		} else
			nchstats.ncs_badhits++;
		/*
		 * The parent needs to be locked when we return to VOP_LOOKUP().
		 * The `.' case here should be extremely rare (if it can happen
		 * at all), so we don't bother optimizing out the unlock/relock.
		 */
		if (vp == dvp || error ||
		    (~cnp->cn_flags & (LOCKPARENT|ISLASTCN)) != 0) {
			if ((error = vn_lock(dvp, LK_EXCLUSIVE, p)) != 0)
				return (error);
			cnp->cn_flags &= ~PDIRUNLOCK;
d158 1
a161 12
	nchstats.ncs_goodhits++;
	/*
	 * Move this slot to end of LRU chain, if not already there.
	 */
	if (TAILQ_NEXT(ncp, nc_lru) != NULL) {
		TAILQ_REMOVE(&nclruhead, ncp, nc_lru);
		TAILQ_INSERT_TAIL(&nclruhead, ncp, nc_lru);
	}
	*vpp = vp;
	return (0);

remove:
d169 1
a169 7
	ncp->nc_hash.le_prev = NULL;
#if 0
	if (ncp->nc_vhash.le_prev != NULL) {
		LIST_REMOVE(ncp, nc_vhash);
		ncp->nc_vhash.le_prev = NULL;
	}
#endif
d171 1
a171 1
	return (-1);
@


1.4
log
@use pool for vfs cache.
(We should really put that info into the vnode).
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.3 1999/04/28 09:28:15 art Exp $	*/
d234 1
a234 1
		0, pool_page_alloc_nointr, pool_page_free_nointr, M_PROC);
@


1.3
log
@zap the newhashinit hack.
Add an extra flag to hashinit telling if it should wait in malloc.
update all calls to hashinit.
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.2 1996/03/03 17:20:23 niklas Exp $	*/
d47 1
d78 2
d192 1
a192 2
		ncp = (struct namecache *)
			malloc((u_long)sizeof *ncp, M_CACHE, M_WAITOK);
d233 2
@


1.3.4.1
log
@Merge in -current from two days ago in the SMP branch.
As usual with merges, they do not indicate progress, so do not hold
your breath for working SMP, and do not mail me and ask about the
state of it.  It has not changed.  There is work ongoing, but very, very
slowly.  The commit is done in parts as to not lock up the tree in too
big chunks at a time.
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.3 1999/04/28 09:28:15 art Exp $	*/
a46 1
#include <sys/pool.h>
a76 2
struct pool nch_pool;

d189 2
a190 1
		ncp = pool_get(&nch_pool, PR_WAITOK);
a230 2
	pool_init(&nch_pool, sizeof(struct namecache), 0, 0, 0, "nchpl",
		0, pool_page_alloc_nointr, pool_page_free_nointr, M_CACHE);
@


1.3.4.2
log
@Merge in trunk
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d234 1
a234 1
	    &pool_allocator_nointr);
@


1.3.4.3
log
@Sync the SMP branch with 3.3
@
text
@a47 1
#include <sys/hash.h>
a79 2
u_long nextvnodeid;

d90 3
a92 5
 * and a status of 0 is returned. If the locking fails for whatever
 * reason, the vnode is unlocked and the error is returned to caller.
 * If the lookup determines that the name does not exist (negative cacheing),
 * a status of ENOENT is returned. If the lookup fails, a status of -1
 * is returned.
d100 2
a101 8
	struct namecache *ncp;
	struct nchashhead *ncpp;
	struct vnode *vp;
	struct proc *p = curproc;
	u_long vpid;
	int error;

	*vpp = NULL;
d105 1
a105 1
		return (-1);
d110 1
a110 1
		return (-1);
d112 2
a113 4

	ncpp = &nchashtbl[
	    hash32_buf(&dvp->v_id, sizeof(dvp->v_id), cnp->cn_hash) & nchash];
	LIST_FOREACH(ncp, ncpp, nc_hash) {
d117 1
a117 1
		    !memcmp(ncp->nc_name, cnp->cn_nameptr, (u_int)ncp->nc_nlen))
d122 1
a122 1
		return (-1);
a125 1
		goto remove;
d131 1
a131 2
		if (cnp->cn_nameiop != CREATE ||
		    (cnp->cn_flags & ISLASTCN) == 0) {
d137 1
a137 1
			if (TAILQ_NEXT(ncp, nc_lru) != NULL) {
a141 3
		} else {
			nchstats.ncs_badhits++;
			goto remove;
a144 23
		goto remove;
	}

	vp = ncp->nc_vp;
	vpid = vp->v_id;
	if (vp == dvp) {	/* lookup on "." */
		VREF(dvp);
		error = 0;
	} else if (cnp->cn_flags & ISDOTDOT) {
		VOP_UNLOCK(dvp, 0, p);
		cnp->cn_flags |= PDIRUNLOCK;
		error = vget(vp, LK_EXCLUSIVE, p);
		/*
		 * If the above vget() succeeded and both LOCKPARENT and
		 * ISLASTCN is set, lock the directory vnode as well.
		 */
		if (!error && (~cnp->cn_flags & (LOCKPARENT|ISLASTCN)) == 0) {
			if ((error = vn_lock(dvp, LK_EXCLUSIVE, p)) != 0) {
				vput(vp);
				return (error);
			}
			cnp->cn_flags &= ~PDIRUNLOCK;
		}
d146 1
a146 1
		error = vget(vp, LK_EXCLUSIVE, p);
d148 1
a148 2
		 * If the above vget() failed or either of LOCKPARENT or
		 * ISLASTCN is set, unlock the directory vnode.
d150 3
a152 26
		if (error || (~cnp->cn_flags & (LOCKPARENT|ISLASTCN)) != 0) {
			VOP_UNLOCK(dvp, 0, p);
			cnp->cn_flags |= PDIRUNLOCK;
		}
	}

	/*
	 * Check that the lock succeeded, and that the capability number did
	 * not change while we were waiting for the lock.
	 */
	if (error || vpid != vp->v_id) {
		if (!error) {
			vput(vp);
			nchstats.ncs_falsehits++;
		} else
			nchstats.ncs_badhits++;
		/*
		 * The parent needs to be locked when we return to VOP_LOOKUP().
		 * The `.' case here should be extremely rare (if it can happen
		 * at all), so we don't bother optimizing out the unlock/relock.
		 */
		if (vp == dvp || error ||
		    (~cnp->cn_flags & (LOCKPARENT|ISLASTCN)) != 0) {
			if ((error = vn_lock(dvp, LK_EXCLUSIVE, p)) != 0)
				return (error);
			cnp->cn_flags &= ~PDIRUNLOCK;
d154 1
a157 12
	nchstats.ncs_goodhits++;
	/*
	 * Move this slot to end of LRU chain, if not already there.
	 */
	if (TAILQ_NEXT(ncp, nc_lru) != NULL) {
		TAILQ_REMOVE(&nclruhead, ncp, nc_lru);
		TAILQ_INSERT_TAIL(&nclruhead, ncp, nc_lru);
	}
	*vpp = vp;
	return (0);

remove:
d165 1
a165 7
	ncp->nc_hash.le_prev = NULL;
#if 0
	if (ncp->nc_vhash.le_prev != NULL) {
		LIST_REMOVE(ncp, nc_vhash);
		ncp->nc_vhash.le_prev = NULL;
	}
#endif
d167 1
a167 1
	return (-1);
d220 1
a220 2
	ncpp = &nchashtbl[
	    hash32_buf(&dvp->v_id, sizeof(dvp->v_id), cnp->cn_hash) & nchash];
@


1.3.4.4
log
@Sync SMP branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cache.c,v 1.3.4.3 2003/03/28 00:41:27 niklas Exp $	*/
d16 5
a20 1
 * 3. Neither the name of the University nor the names of its contributors
@


1.2
log
@From NetBSD: 960217 merge
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d230 1
a230 1
	nchashtbl = hashinit(desiredvnodes, M_CACHE, &nchash);
@


1.1
log
@Initial revision
@
text
@d1 2
a2 1
/*	$NetBSD: vfs_cache.c,v 1.12 1995/09/08 14:15:07 ws Exp $	*/
d170 1
d193 1
a193 1
	} else if (ncp = nclruhead.tqh_first) {
d225 1
d237 1
d264 1
@


1.1.1.1
log
@initial import of NetBSD tree
@
text
@@
