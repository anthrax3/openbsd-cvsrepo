head	1.46;
access;
symbols
	OPENBSD_5_9:1.45.0.2
	OPENBSD_5_9_BASE:1.45
	OPENBSD_5_8:1.44.0.4
	OPENBSD_5_8_BASE:1.44
	OPENBSD_5_7:1.43.0.2
	OPENBSD_5_7_BASE:1.43
	OPENBSD_5_6:1.42.0.4
	OPENBSD_5_6_BASE:1.42
	OPENBSD_5_5:1.40.0.4
	OPENBSD_5_5_BASE:1.40
	OPENBSD_5_4:1.39.0.2
	OPENBSD_5_4_BASE:1.39
	OPENBSD_5_3:1.38.0.8
	OPENBSD_5_3_BASE:1.38
	OPENBSD_5_2:1.38.0.6
	OPENBSD_5_2_BASE:1.38
	OPENBSD_5_1_BASE:1.38
	OPENBSD_5_1:1.38.0.4
	OPENBSD_5_0:1.38.0.2
	OPENBSD_5_0_BASE:1.38
	OPENBSD_4_9:1.37.0.16
	OPENBSD_4_9_BASE:1.37
	OPENBSD_4_8:1.37.0.14
	OPENBSD_4_8_BASE:1.37
	OPENBSD_4_7:1.37.0.10
	OPENBSD_4_7_BASE:1.37
	OPENBSD_4_6:1.37.0.12
	OPENBSD_4_6_BASE:1.37
	OPENBSD_4_5:1.37.0.8
	OPENBSD_4_5_BASE:1.37
	OPENBSD_4_4:1.37.0.6
	OPENBSD_4_4_BASE:1.37
	OPENBSD_4_3:1.37.0.4
	OPENBSD_4_3_BASE:1.37
	OPENBSD_4_2:1.37.0.2
	OPENBSD_4_2_BASE:1.37
	OPENBSD_4_1:1.36.0.2
	OPENBSD_4_1_BASE:1.36
	OPENBSD_4_0:1.34.0.4
	OPENBSD_4_0_BASE:1.34
	OPENBSD_3_9:1.34.0.2
	OPENBSD_3_9_BASE:1.34
	OPENBSD_3_8:1.33.0.4
	OPENBSD_3_8_BASE:1.33
	OPENBSD_3_7:1.33.0.2
	OPENBSD_3_7_BASE:1.33
	OPENBSD_3_6:1.32.0.2
	OPENBSD_3_6_BASE:1.32
	SMP_SYNC_A:1.32
	SMP_SYNC_B:1.32
	OPENBSD_3_5:1.31.0.4
	OPENBSD_3_5_BASE:1.31
	OPENBSD_3_4:1.31.0.2
	OPENBSD_3_4_BASE:1.31
	UBC_SYNC_A:1.30
	OPENBSD_3_3:1.30.0.2
	OPENBSD_3_3_BASE:1.30
	OPENBSD_3_2:1.29.0.2
	OPENBSD_3_2_BASE:1.29
	OPENBSD_3_1:1.27.0.2
	OPENBSD_3_1_BASE:1.27
	UBC_SYNC_B:1.29
	UBC:1.26.0.2
	UBC_BASE:1.26
	OPENBSD_3_0:1.25.0.2
	OPENBSD_3_0_BASE:1.25
	OPENBSD_2_9_BASE:1.22
	OPENBSD_2_9:1.22.0.2
	OPENBSD_2_8:1.17.0.2
	OPENBSD_2_8_BASE:1.17
	OPENBSD_2_7:1.16.0.8
	OPENBSD_2_7_BASE:1.16
	SMP:1.16.0.6
	SMP_BASE:1.16
	kame_19991208:1.16
	OPENBSD_2_6:1.16.0.4
	OPENBSD_2_6_BASE:1.16
	OPENBSD_2_5:1.16.0.2
	OPENBSD_2_5_BASE:1.16
	OPENBSD_2_4:1.15.0.2
	OPENBSD_2_4_BASE:1.15
	OPENBSD_2_3:1.13.0.2
	OPENBSD_2_3_BASE:1.13
	OPENBSD_2_2:1.10.0.2
	OPENBSD_2_2_BASE:1.10
	OPENBSD_2_1:1.7.0.2
	OPENBSD_2_1_BASE:1.7
	OPENBSD_2_0:1.5.0.2
	OPENBSD_2_0_BASE:1.5
	netbsd_1_1:1.1.1.1;
locks; strict;
comment	@ * @;


1.46
date	2016.03.25.18.53.41;	author zhuk;	state dead;
branches;
next	1.45;
commitid	W0qlJjPXXoeZUGDO;

1.45
date	2015.10.03.22.36.56;	author deraadt;	state Exp;
branches;
next	1.44;
commitid	9cn1QUMpVVJfgZ2G;

1.44
date	2015.03.14.03.38.51;	author jsg;	state Exp;
branches;
next	1.43;
commitid	p4LJxGKbi0BU2cG6;

1.43
date	2014.09.14.14.17.26;	author jsg;	state Exp;
branches;
next	1.42;
commitid	uzzBR7hz9ncd4O6G;

1.42
date	2014.07.12.18.43.32;	author tedu;	state Exp;
branches;
next	1.41;
commitid	QlVV51SZgNFxsXxC;

1.41
date	2014.07.08.17.19.25;	author deraadt;	state Exp;
branches;
next	1.40;
commitid	EF98ch02VpFassUi;

1.40
date	2013.10.01.20.22.12;	author sf;	state Exp;
branches;
next	1.39;

1.39
date	2013.06.11.16.42.16;	author deraadt;	state Exp;
branches;
next	1.38;

1.38
date	2011.07.04.04.30.41;	author tedu;	state Exp;
branches;
next	1.37;

1.37
date	2007.05.26.20.26.51;	author pedro;	state Exp;
branches;
next	1.36;

1.36
date	2006.10.16.11.27.53;	author pedro;	state Exp;
branches;
next	1.35;

1.35
date	2006.10.03.19.49.06;	author pedro;	state Exp;
branches;
next	1.34;

1.34
date	2005.11.08.15.43.44;	author pedro;	state Exp;
branches;
next	1.33;

1.33
date	2004.10.26.17.16.27;	author pedro;	state Exp;
branches;
next	1.32;

1.32
date	2004.04.13.00.15.28;	author tedu;	state Exp;
branches;
next	1.31;

1.31
date	2003.06.02.23.28.07;	author millert;	state Exp;
branches;
next	1.30;

1.30
date	2003.01.30.16.38.39;	author art;	state Exp;
branches;
next	1.29;

1.29
date	2002.06.14.21.34.59;	author todd;	state Exp;
branches;
next	1.28;

1.28
date	2002.05.24.08.39.15;	author art;	state Exp;
branches;
next	1.27;

1.27
date	2002.03.14.01.27.06;	author millert;	state Exp;
branches;
next	1.26;

1.26
date	2001.11.06.19.53.20;	author miod;	state Exp;
branches
	1.26.2.1;
next	1.25;

1.25
date	2001.06.22.14.14.10;	author deraadt;	state Exp;
branches;
next	1.24;

1.24
date	2001.05.28.00.23.02;	author gluk;	state Exp;
branches;
next	1.23;

1.23
date	2001.05.20.22.18.10;	author gluk;	state Exp;
branches;
next	1.22;

1.22
date	2001.03.21.10.11.22;	author art;	state Exp;
branches;
next	1.21;

1.21
date	2001.02.27.14.55.34;	author csapuntz;	state Exp;
branches;
next	1.20;

1.20
date	2001.02.23.14.52.50;	author csapuntz;	state Exp;
branches;
next	1.19;

1.19
date	2001.02.23.14.42.38;	author csapuntz;	state Exp;
branches;
next	1.18;

1.18
date	2001.02.21.23.24.30;	author csapuntz;	state Exp;
branches;
next	1.17;

1.17
date	2000.06.23.02.14.38;	author mickey;	state Exp;
branches;
next	1.16;

1.16
date	99.01.11.05.12.24;	author millert;	state Exp;
branches
	1.16.6.1;
next	1.15;

1.15
date	98.10.13.00.28.32;	author csapuntz;	state Exp;
branches;
next	1.14;

1.14
date	98.10.11.06.33.11;	author csapuntz;	state Exp;
branches;
next	1.13;

1.13
date	98.02.20.14.51.58;	author niklas;	state Exp;
branches;
next	1.12;

1.12
date	98.01.08.15.51.56;	author csapuntz;	state Exp;
branches;
next	1.11;

1.11
date	97.11.06.05.58.26;	author csapuntz;	state Exp;
branches;
next	1.10;

1.10
date	97.10.06.20.20.08;	author deraadt;	state Exp;
branches;
next	1.9;

1.9
date	97.10.06.15.12.36;	author csapuntz;	state Exp;
branches;
next	1.8;

1.8
date	97.09.27.06.56.18;	author niklas;	state Exp;
branches;
next	1.7;

1.7
date	97.02.01.00.09.31;	author niklas;	state Exp;
branches;
next	1.6;

1.6
date	97.01.10.23.18.40;	author niklas;	state Exp;
branches;
next	1.5;

1.5
date	96.06.11.03.25.13;	author tholo;	state Exp;
branches;
next	1.4;

1.4
date	96.05.02.13.12.33;	author deraadt;	state Exp;
branches;
next	1.3;

1.3
date	96.04.21.22.27.34;	author deraadt;	state Exp;
branches;
next	1.2;

1.2
date	96.03.03.17.20.25;	author niklas;	state Exp;
branches;
next	1.1;

1.1
date	95.10.18.08.52.47;	author deraadt;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	95.10.18.08.52.47;	author deraadt;	state Exp;
branches;
next	;

1.16.6.1
date	2001.05.14.22.32.45;	author niklas;	state Exp;
branches;
next	1.16.6.2;

1.16.6.2
date	2001.07.04.10.48.48;	author niklas;	state Exp;
branches;
next	1.16.6.3;

1.16.6.3
date	2001.11.13.23.04.23;	author niklas;	state Exp;
branches;
next	1.16.6.4;

1.16.6.4
date	2002.03.28.11.43.04;	author niklas;	state Exp;
branches;
next	1.16.6.5;

1.16.6.5
date	2003.03.28.00.41.27;	author niklas;	state Exp;
branches;
next	1.16.6.6;

1.16.6.6
date	2003.06.07.11.03.41;	author ho;	state Exp;
branches;
next	1.16.6.7;

1.16.6.7
date	2004.06.05.23.13.03;	author niklas;	state Exp;
branches;
next	;

1.26.2.1
date	2002.06.11.03.29.40;	author art;	state Exp;
branches;
next	1.26.2.2;

1.26.2.2
date	2002.10.29.00.36.44;	author art;	state Exp;
branches;
next	1.26.2.3;

1.26.2.3
date	2003.05.19.22.31.57;	author tedu;	state Exp;
branches;
next	;


desc
@@


1.46
log
@Free some more space in kernel - for network code, of course - by removal
of three unused FS-related functions.

okay mpi@@ and beck@@
@
text
@/*	$OpenBSD: vfs_cluster.c,v 1.45 2015/10/03 22:36:56 deraadt Exp $	*/
/*	$NetBSD: vfs_cluster.c,v 1.12 1996/04/22 01:39:05 christos Exp $	*/

/*
 * Copyright (c) 1993
 *	The Regents of the University of California.  All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. Neither the name of the University nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 *	@@(#)vfs_cluster.c	8.8 (Berkeley) 7/28/94
 */

#include <sys/param.h>
#include <sys/buf.h>
#include <sys/vnode.h>
#include <sys/mount.h>
#include <sys/malloc.h>
#include <sys/systm.h>

void cluster_wbuild(struct vnode *, struct buf *, long, daddr_t, int,
    daddr_t);
struct cluster_save *cluster_collectbufs(struct vnode *, struct cluster_info *,
    struct buf *, size_t *);

/*
 * Do clustered write for FFS.
 *
 * Three cases:
 *	1. Write is not sequential (write asynchronously)
 *	Write is sequential:
 *	2.	beginning of cluster - begin cluster
 *	3.	middle of a cluster - add to cluster
 *	4.	end of a cluster - asynchronously write cluster
 */
void
cluster_write(struct buf *bp, struct cluster_info *ci, u_quad_t filesize)
{
	struct vnode *vp;
	daddr_t lbn;
	int maxclen, cursize;

	vp = bp->b_vp;
	lbn = bp->b_lblkno;

	/* Initialize vnode to beginning of file. */
	if (lbn == 0)
		ci->ci_lasta = ci->ci_clen = ci->ci_cstart = ci->ci_lastw = 0;

	if (ci->ci_clen == 0 || lbn != ci->ci_lastw + 1 ||
	    (bp->b_blkno != ci->ci_lasta + btodb(bp->b_bcount))) {
		maxclen = MAXBSIZE / vp->v_mount->mnt_stat.f_iosize - 1;
		if (ci->ci_clen != 0) {
			/*
			 * Next block is not sequential.
			 *
			 * If we are not writing at end of file, the process
			 * seeked to another point in the file since its
			 * last write, or we have reached our maximum
			 * cluster size, then push the previous cluster.
			 * Otherwise try reallocating to make it sequential.
			 */
			cursize = ci->ci_lastw - ci->ci_cstart + 1;
			if (((u_quad_t)(lbn + 1)) * bp->b_bcount != filesize ||
			    lbn != ci->ci_lastw + 1 || ci->ci_clen <= cursize) {
				cluster_wbuild(vp, NULL, bp->b_bcount,
				    ci->ci_cstart, cursize, lbn);
			} else {
				struct buf **bpp, **endbp;
				struct cluster_save *buflist;
				size_t buflistsiz;

				buflist = cluster_collectbufs(vp, ci, bp, &buflistsiz);
				endbp = &buflist->bs_children
				    [buflist->bs_nchildren - 1];
				if (VOP_REALLOCBLKS(vp, buflist)) {
					/*
					 * Failed, push the previous cluster.
					 */
					for (bpp = buflist->bs_children;
					    bpp < endbp; bpp++)
						brelse(*bpp);
					free(buflist, M_VCLUSTER, buflistsiz);
					cluster_wbuild(vp, NULL, bp->b_bcount,
					    ci->ci_cstart, cursize, lbn);
				} else {
					/*
					 * Succeeded, keep building cluster.
					 */
					for (bpp = buflist->bs_children;
					    bpp <= endbp; bpp++)
						bdwrite(*bpp);
					free(buflist, M_VCLUSTER, buflistsiz);
					ci->ci_lastw = lbn;
					ci->ci_lasta = bp->b_blkno;
					return;
				}
			}
		}
		/*
		 * Consider beginning a cluster.
		 * If at end of file, make cluster as large as possible,
		 * otherwise find size of existing cluster.
		 */
		if ((u_quad_t)(lbn + 1) * (u_quad_t)bp->b_bcount != filesize &&
		    (VOP_BMAP(vp, lbn, NULL, &bp->b_blkno, &maxclen) ||
		    bp->b_blkno == -1)) {
			bawrite(bp);
			ci->ci_clen = 0;
			ci->ci_lasta = bp->b_blkno;
			ci->ci_cstart = lbn + 1;
			ci->ci_lastw = lbn;
			return;
		}
		ci->ci_clen = maxclen;
		if (maxclen == 0) {		/* I/O not contiguous */
			ci->ci_cstart = lbn + 1;
			bawrite(bp);
		} else {			/* Wait for rest of cluster */
			ci->ci_cstart = lbn;
			bdwrite(bp);
		}
	} else if (lbn == ci->ci_cstart + ci->ci_clen) {
		/*
		 * At end of cluster, write it out.
		 */
		cluster_wbuild(vp, bp, bp->b_bcount, ci->ci_cstart,
		    ci->ci_clen + 1, lbn);
		ci->ci_clen = 0;
		ci->ci_cstart = lbn + 1;
	} else
		/*
		 * In the middle of a cluster, so just delay the
		 * I/O for now.
		 */
		bdwrite(bp);
	ci->ci_lastw = lbn;
	ci->ci_lasta = bp->b_blkno;
}

/*
 * The last lbn argument is the current block on which I/O is being
 * performed.  Check to see that it doesn't fall in the middle of
 * the current block (if last_bp == NULL).
 */
void
cluster_wbuild(struct vnode *vp, struct buf *last_bp, long size,
    daddr_t start_lbn, int len, daddr_t lbn)
{
	struct buf *bp;

#ifdef DIAGNOSTIC
	if (size != vp->v_mount->mnt_stat.f_iosize)
		panic("cluster_wbuild: size %ld != filesize %u",
			size, vp->v_mount->mnt_stat.f_iosize);
#endif
redo:
	while ((!incore(vp, start_lbn) || start_lbn == lbn) && len) {
		++start_lbn;
		--len;
	}

	/* Get more memory for current buffer */
	if (len <= 1) {
		if (last_bp) {
			bawrite(last_bp);
		} else if (len) {
			bp = getblk(vp, start_lbn, size, 0, 0);
			/*
			 * The buffer could have already been flushed out of
			 * the cache. If that has happened, we'll get a new
			 * buffer here with random data, just drop it.
			 */
			if ((bp->b_flags & B_DELWRI) == 0)
				brelse(bp);
			else
				bawrite(bp);
		}
		return;
	}

	bp = getblk(vp, start_lbn, size, 0, 0);
	if (!(bp->b_flags & B_DELWRI)) {
		++start_lbn;
		--len;
		brelse(bp);
		goto redo;
	}

	++start_lbn;
	--len;
	bawrite(bp);
	goto redo;
}

/*
 * Collect together all the buffers in a cluster.
 * Plus add one additional buffer.
 */
struct cluster_save *
cluster_collectbufs(struct vnode *vp, struct cluster_info *ci,
    struct buf *last_bp, size_t *buflistsizp)
{
	struct cluster_save *buflist;
	size_t buflistsiz;
	daddr_t lbn;
	int i, len;

	len = ci->ci_lastw - ci->ci_cstart + 1;
	buflistsiz = sizeof(*buflist) + sizeof(struct buf *) * (len + 1);
	buflist = malloc(buflistsiz, M_VCLUSTER, M_WAITOK);
	buflist->bs_nchildren = 0;
	buflist->bs_children = (struct buf **)(buflist + 1);
	for (lbn = ci->ci_cstart, i = 0; i < len; lbn++, i++)
		(void)bread(vp, lbn, last_bp->b_bcount,
		    &buflist->bs_children[i]);
	buflist->bs_children[i] = last_bp;
	buflist->bs_nchildren = i + 1;
	*buflistsizp = buflistsiz;
	return (buflist);
}
@


1.45
log
@Track a size in the scary area of cluster_collectbufs, so that we know
what to free.
ok beck
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.44 2015/03/14 03:38:51 jsg Exp $	*/
@


1.44
log
@Remove some includes include-what-you-use claims don't
have any direct symbols used.  Tested for indirect use by compiling
amd64/i386/sparc64 kernels.

ok tedu@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.43 2014/09/14 14:17:26 jsg Exp $	*/
d45 1
a45 1
    struct buf *);
d92 1
d94 1
a94 1
				buflist = cluster_collectbufs(vp, ci, bp);
d104 1
a104 1
					free(buflist, M_VCLUSTER, 0);
d114 1
a114 1
					free(buflist, M_VCLUSTER, 0);
d223 1
a223 1
    struct buf *last_bp)
d226 1
d231 2
a232 2
	buflist = malloc(sizeof(struct buf *) * (len + 1) + sizeof(*buflist),
	    M_VCLUSTER, M_WAITOK);
d240 1
@


1.43
log
@remove uneeded proc.h includes
ok mpi@@ kspillner@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.42 2014/07/12 18:43:32 tedu Exp $	*/
a40 1
#include <sys/resourcevar.h>
@


1.42
log
@add a size argument to free. will be used soon, but for now default to 0.
after discussions with beck deraadt kettenis.
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.41 2014/07/08 17:19:25 deraadt Exp $	*/
a35 1
#include <sys/proc.h>
@


1.41
log
@decouple struct uvmexp into a new file, so that uvm_extern.h and sysctl.h
don't need to be married.
ok guenther miod beck jsing kettenis
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.40 2013/10/01 20:22:12 sf Exp $	*/
d105 1
a105 1
					free(buflist, M_VCLUSTER);
d115 1
a115 1
					free(buflist, M_VCLUSTER);
@


1.40
log
@Format string fixes: %hu/%hd for uint16_t, %u/%d/%x for uint32_t

- despite the name, ntohl returns uint32_t, not long
- also fix some %d into %u
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.39 2013/06/11 16:42:16 deraadt Exp $	*/
a42 2

#include <uvm/uvm_extern.h>
@


1.39
log
@final removal of daddr64_t.  daddr_t has been 64 bit for a long enough
test period; i think 3 years ago the last bugs fell out.
ok otto beck others
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.38 2011/07/04 04:30:41 tedu Exp $	*/
d178 1
a178 1
		panic("cluster_wbuild: size %ld != filesize %ld",
@


1.38
log
@bread does nothing with its ucred argument.  remove it.  ok matthew
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.37 2007/05/26 20:26:51 pedro Exp $	*/
d46 2
a47 2
void cluster_wbuild(struct vnode *, struct buf *, long, daddr64_t, int,
    daddr64_t);
d65 1
a65 1
	daddr64_t lbn;
d172 1
a172 1
    daddr64_t start_lbn, int len, daddr64_t lbn)
d229 1
a229 1
	daddr64_t lbn;
@


1.37
log
@Dynamic buffer cache. Initial diff from mickey@@, okay art@@ beck@@ toby@@
deraadt@@ dlg@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.36 2006/10/16 11:27:53 pedro Exp $	*/
d238 1
a238 1
		(void)bread(vp, lbn, last_bp->b_bcount, NOCRED,
@


1.36
log
@Use daddr64_t for logical blocks, okay krw@@ thib@@ mickey@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.35 2006/10/03 19:49:06 pedro Exp $	*/
a45 5
void cluster_callback(struct buf *);
struct buf *cluster_newbuf(struct vnode *, struct buf *, long, daddr64_t,
    daddr64_t, long, int);
struct buf *cluster_rbuild(struct vnode *, u_quad_t, struct buf *, daddr64_t,
    daddr64_t, long, int, long);
a50 393
#ifdef DIAGNOSTIC
/*
 * Set to 1 if reads of block zero should cause readahead to be done.
 * Set to 0 treats a read of block zero as a non-sequential read.
 *
 * Setting to one assumes that most reads of block zero of files are due to
 * sequential passes over the files (e.g. cat, sum) where additional blocks
 * will soon be needed.  Setting to zero assumes that the majority are
 * surgical strikes to get particular info (e.g. size, file) where readahead
 * blocks will not be used and, in fact, push out other potentially useful
 * blocks from the cache.  The former seems intuitive, but some quick tests
 * showed that the latter performed better from a system-wide point of view.
 */
int	doclusterraz = 0;
#define ISSEQREAD(ci, blk) \
	(((blk) != 0 || doclusterraz) && \
	 ((blk) == (ci)->ci_lastr + 1 || (blk) == (ci)->ci_lastr))
#else
#define ISSEQREAD(ci, blk) \
	((blk) != 0 && ((blk) == (ci)->ci_lastr + 1 || (blk) == (ci)->ci_lastr))
#endif

/*
 * This replaces bread.  If this is a bread at the beginning of a file and
 * lastr is 0, we assume this is the first read and we'll read up to two
 * blocks if they are sequential.  After that, we'll do regular read ahead
 * in clustered chunks.
 *
 * There are 4 or 5 cases depending on how you count:
 *	Desired block is in the cache:
 *	    1 Not sequential access (0 I/Os).
 *	    2 Access is sequential, do read-ahead (1 ASYNC).
 *	Desired block is not in cache:
 *	    3 Not sequential access (1 SYNC).
 *	    4 Sequential access, next block is contiguous (2 SYNC).
 *	    5 Sequential access, next block is not contiguous (1 SYNC, 1 ASYNC)
 *
 * There are potentially two buffers that require I/O.
 * 	bp is the block requested.
 *	rbp is the read-ahead block.
 *	If either is NULL, then you don't have to do the I/O.
 */
int
cluster_read(struct vnode *vp, struct cluster_info *ci, u_quad_t filesize,
    daddr64_t lblkno, long size, struct ucred *cred, struct buf **bpp)
{
	struct buf *bp, *rbp;
	daddr64_t blkno, ioblkno;
	long flags;
	int error, num_ra, alreadyincore;

#ifdef DIAGNOSTIC
	if (size == 0)
		panic("cluster_read: size = 0");
#endif

	error = 0;
	flags = B_READ;
	*bpp = bp = getblk(vp, lblkno, size, 0, 0);
	if (bp->b_flags & B_CACHE) {
		/*
		 * Desired block is in cache; do any readahead ASYNC.
		 * Case 1, 2.
		 */
		flags |= B_ASYNC;
		ioblkno = lblkno + (ci->ci_ralen ? ci->ci_ralen : 1);
		alreadyincore = incore(vp, ioblkno) != NULL;
		bp = NULL;
	} else {
		/* Block wasn't in cache, case 3, 4, 5. */
		bp->b_flags |= B_READ;
		ioblkno = lblkno;
		alreadyincore = 0;
		curproc->p_stats->p_ru.ru_inblock++;		/* XXX */
	}
	/*
	 * XXX
	 * Replace 1 with a window size based on some permutation of
	 * maxcontig and rot_delay.  This will let you figure out how
	 * many blocks you should read-ahead (case 2, 4, 5).
	 *
	 * If the access isn't sequential, reset the window to 1.
	 * Note that a read to the same block is considered sequential.
	 * This catches the case where the file is being read sequentially,
	 * but at smaller than the filesystem block size.
	 */
	rbp = NULL;
	if (!ISSEQREAD(ci, lblkno)) {
		ci->ci_ralen = 0;
		ci->ci_maxra = lblkno;
	} else if ((u_quad_t)(ioblkno + 1) * (u_quad_t)size <= filesize &&
		   !alreadyincore &&
		   !(error = VOP_BMAP(vp, ioblkno, NULL, &blkno, &num_ra)) &&
		   blkno != -1) {
		/*
		 * Reading sequentially, and the next block is not in the
		 * cache.  We are going to try reading ahead.
		 */
		if (num_ra) {
			/*
			 * If our desired readahead block had been read
			 * in a previous readahead but is no longer in
			 * core, then we may be reading ahead too far
			 * or are not using our readahead very rapidly.
			 * In this case we scale back the window.
			 */
			if (!alreadyincore && ioblkno <= ci->ci_maxra)
				ci->ci_ralen = max(ci->ci_ralen >> 1, 1);
			/*
			 * There are more sequential blocks than our current
			 * window allows, scale up.  Ideally we want to get
			 * in sync with the filesystem maxcontig value.
			 */
			else if (num_ra > ci->ci_ralen && lblkno != ci->ci_lastr)
				ci->ci_ralen = ci->ci_ralen ?
					min(num_ra, ci->ci_ralen << 1) : 1;

			if (num_ra > ci->ci_ralen)
				num_ra = ci->ci_ralen;
		}

		if (num_ra)				/* case 2, 4 */
			rbp = cluster_rbuild(vp, filesize,
			    bp, ioblkno, blkno, size, num_ra, flags);
		else if (ioblkno == lblkno) {
			bp->b_blkno = blkno;
			/* Case 5: check how many blocks to read ahead */
			++ioblkno;
			if ((u_quad_t)(ioblkno + 1) * (u_quad_t)size >
			    filesize ||
			    incore(vp, ioblkno) || (error = VOP_BMAP(vp,
			    ioblkno, NULL, &blkno, &num_ra)) || blkno == -1)
				goto skip_readahead;
			/*
			 * Adjust readahead as above.
			 * Don't check alreadyincore, we know it is 0 from
			 * the previous conditional.
			 */
			if (num_ra) {
				if (ioblkno <= ci->ci_maxra)
					ci->ci_ralen = max(ci->ci_ralen >> 1, 1);
				else if (num_ra > ci->ci_ralen &&
					 lblkno != ci->ci_lastr)
					ci->ci_ralen = ci->ci_ralen ?
						min(num_ra,ci->ci_ralen<<1) : 1;
				if (num_ra > ci->ci_ralen)
					num_ra = ci->ci_ralen;
			}
			flags |= B_ASYNC;
			if (num_ra)
				rbp = cluster_rbuild(vp, filesize,
				    NULL, ioblkno, blkno, size, num_ra, flags);
			else {
				rbp = getblk(vp, ioblkno, size, 0, 0);
				rbp->b_flags |= flags;
				rbp->b_blkno = blkno;
			}
		} else {
			/* case 2; read ahead single block */
			rbp = getblk(vp, ioblkno, size, 0, 0);
			rbp->b_flags |= flags;
			rbp->b_blkno = blkno;
		}

		if (rbp == bp)			/* case 4 */
			rbp = NULL;
		else if (rbp)			/* case 2, 5 */
			curproc->p_stats->p_ru.ru_inblock++;	/* XXX */
	}

	/* XXX Kirk, do we need to make sure the bp has creds? */
skip_readahead:
	if (bp) {
		if (bp->b_flags & (B_DONE | B_DELWRI))
			panic("cluster_read: DONE bp");
		else
			error = VOP_STRATEGY(bp);
	}

	if (rbp) {
		if (error || rbp->b_flags & (B_DONE | B_DELWRI)) {
			rbp->b_flags &= ~(B_ASYNC | B_READ);
			brelse(rbp);
		} else
			(void) VOP_STRATEGY(rbp);
	}

	/*
	 * Recalculate our maximum readahead
	 */
	if (rbp == NULL)
		rbp = bp;
	if (rbp)
		ci->ci_maxra = rbp->b_lblkno + (rbp->b_bcount / size) - 1;

	if (bp)
		return(biowait(bp));
	return(error);
}

/*
 * If blocks are contiguous on disk, use this to provide clustered
 * read ahead.  We will read as many blocks as possible sequentially
 * and then parcel them up into logical blocks in the buffer hash table.
 */
struct buf *
cluster_rbuild(struct vnode *vp, u_quad_t filesize, struct buf *bp,
    daddr64_t lbn, daddr64_t blkno, long size, int run, long flags)
{
	struct cluster_save *b_save;
	struct buf *tbp;
	daddr64_t bn;
	int i, inc;

#ifdef DIAGNOSTIC
	if (size != vp->v_mount->mnt_stat.f_iosize)
		panic("cluster_rbuild: size %ld != filesize %ld",
			size, vp->v_mount->mnt_stat.f_iosize);
#endif
	if ((u_quad_t)size * (u_quad_t)(lbn + run + 1) > filesize)
		--run;
	if (run == 0) {
		if (!bp) {
			bp = getblk(vp, lbn, size, 0, 0);
			bp->b_blkno = blkno;
			bp->b_flags |= flags;
		}
		return(bp);
	}

	bp = cluster_newbuf(vp, bp, flags, blkno, lbn, size, run + 1);
	if (bp->b_flags & (B_DONE | B_DELWRI))
		return (bp);

	b_save = malloc(sizeof(struct buf *) * run +
	    sizeof(struct cluster_save), M_VCLUSTER, M_WAITOK);
	b_save->bs_bufsize = b_save->bs_bcount = size;
	b_save->bs_nchildren = 0;
	b_save->bs_children = (struct buf **)(b_save + 1);
	b_save->bs_saveaddr = bp->b_saveaddr;
	bp->b_saveaddr = b_save;

	inc = btodb(size);
	for (bn = blkno + inc, i = 1; i <= run; ++i, bn += inc) {
		/*
		 * A component of the cluster is already in core,
		 * terminate the cluster early.
		 */
		if (incore(vp, lbn + i))
			break;
		tbp = getblk(vp, lbn + i, 0, 0, 0);

		/*
		 * getblk may return some memory in the buffer if there were
		 * no empty buffers to shed it to.  If there is currently
		 * memory in the buffer, we move it down size bytes to make
		 * room for the valid pages that cluster_callback will insert.
		 * We do this now so we don't have to do it at interrupt time
		 * in the callback routine.
		 */
		if (tbp->b_bufsize != 0) {
			caddr_t bdata = tbp->b_data;

			/*
			 * No room in the buffer to add another page,
			 * terminate the cluster early.
			 */
			if (tbp->b_bufsize + size > MAXBSIZE) {
#ifdef DIAGNOSTIC
				if (tbp->b_bufsize > MAXBSIZE)
					panic("cluster_rbuild: too much memory");
#endif
				/* This buffer is *not* valid.  */
				tbp->b_flags |= B_INVAL;
				brelse(tbp);
				break;
			}
			pagemove(bdata, bdata + tbp->b_bufsize, size);
		}
		tbp->b_blkno = bn;
		tbp->b_flags &= ~(B_DONE | B_ERROR);
		tbp->b_flags |= flags | B_READ | B_ASYNC;
		b_save->bs_children[b_save->bs_nchildren++] = tbp;
	}
	/*
	 * The cluster may have been terminated early, adjust the cluster
	 * buffer size accordingly.  If no cluster could be formed,
	 * deallocate the cluster save info.
	 */
	if (i <= run) {
		if (i == 1) {
			bp->b_saveaddr = b_save->bs_saveaddr;
			bp->b_flags &= ~B_CALL;
			bp->b_iodone = NULL;
			free(b_save, M_VCLUSTER);
		}
		allocbuf(bp, size * i);
	}
	return(bp);
}

/*
 * Either get a new buffer or grow the existing one.
 */
struct buf *
cluster_newbuf(struct vnode *vp, struct buf *bp, long flags, daddr64_t blkno,
    daddr64_t lblkno, long size, int run)
{
	if (!bp) {
		bp = getblk(vp, lblkno, size, 0, 0);
		if (bp->b_flags & (B_DONE | B_DELWRI)) {
			bp->b_blkno = blkno;
			return(bp);
		}
	}
	allocbuf(bp, run * size);
	bp->b_blkno = blkno;
	bp->b_iodone = cluster_callback;
	bp->b_flags |= flags | B_CALL;
	return(bp);
}

/*
 * Cleanup after a clustered read or write.
 * This is complicated by the fact that any of the buffers might have
 * extra memory (if there were no empty buffer headers at allocbuf time)
 * that we will need to shift around.
 */
void
cluster_callback(struct buf *bp)
{
	struct cluster_save *b_save;
	struct buf **bpp, *tbp;
	long bsize;
	caddr_t cp;
	int error = 0;

	splassert(IPL_BIO);

	/*
	 * Must propagate errors to all the components.
	 */
	if (bp->b_flags & B_ERROR)
		error = bp->b_error;

	b_save = (struct cluster_save *)(bp->b_saveaddr);
	bp->b_saveaddr = b_save->bs_saveaddr;

	bsize = b_save->bs_bufsize;
	cp = (char *)bp->b_data + bsize;
	/*
	 * Move memory from the large cluster buffer into the component
	 * buffers and mark IO as done on these.
	 */
	for (bpp = b_save->bs_children; b_save->bs_nchildren--; ++bpp) {
		tbp = *bpp;
		pagemove(cp, tbp->b_data, bsize);
		tbp->b_bufsize += bsize;
		tbp->b_bcount = bsize;
		if (error) {
			tbp->b_flags |= B_ERROR;
			tbp->b_error = error;
		}
		biodone(tbp);
		bp->b_bufsize -= bsize;
		cp += bsize;
	}
	/*
	 * If there was excess memory in the cluster buffer,
	 * slide it up adjacent to the remaining valid data.
	 */
	if (bp->b_bufsize != bsize) {
		if (bp->b_bufsize < bsize)
			panic("cluster_callback: too little memory");
		if (bp->b_bufsize < cp - (char *)bp->b_data)
			pagemove(cp, (char *)bp->b_data + bsize,
			    bp->b_bufsize - bsize);
		else
			pagemove((char *)bp->b_data + bp->b_bufsize,
			    (char *)bp->b_data + bsize,
			    cp - ((char *)bp->b_data + bsize));
	}
	bp->b_bcount = bsize;
	bp->b_iodone = NULL;
	free(b_save, M_VCLUSTER);
	if (bp->b_flags & B_ASYNC)
		brelse(bp);
	else {
		bp->b_flags &= ~B_WANTED;
		wakeup(bp);
	}
}

a165 1
 * This is an awful lot like cluster_rbuild...wish they could be combined.
d174 1
a174 4
	struct cluster_save *b_save;
	struct buf *bp, *tbp;
	caddr_t	cp;
	int i, s;
d214 1
a214 14
	/*
	 * Extra memory in the buffer, punt on this buffer.
	 * XXX we could handle this in most cases, but we would have to
	 * push the extra memory down to after our max possible cluster
	 * size and then potentially pull it back up if the cluster was
	 * terminated prematurely--too much hassle.
	 */
	if (bp->b_bcount != bp->b_bufsize) {
		++start_lbn;
		--len;
		bawrite(bp);
		goto redo;
	}

a215 78
	b_save = malloc(sizeof(struct buf *) * len +
	    sizeof(struct cluster_save), M_VCLUSTER, M_WAITOK);
	b_save->bs_bcount = bp->b_bcount;
	b_save->bs_bufsize = bp->b_bufsize;
	b_save->bs_nchildren = 0;
	b_save->bs_children = (struct buf **)(b_save + 1);
	b_save->bs_saveaddr = bp->b_saveaddr;
	bp->b_saveaddr = b_save;

	bp->b_flags |= B_CALL;
	bp->b_iodone = cluster_callback;
	cp = (char *)bp->b_data + size;
	for (++start_lbn, i = 0; i < len; ++i, ++start_lbn) {
		/*
		 * Block is not in core or the non-sequential block
		 * ending our cluster was part of the cluster (in which
		 * case we don't want to write it twice).
		 */
		if (!incore(vp, start_lbn) ||
		    (last_bp == NULL && start_lbn == lbn))
			break;

		/*
		 * Get the desired block buffer (unless it is the final
		 * sequential block whose buffer was passed in explicitly
		 * as last_bp).
		 */
		if (last_bp == NULL || start_lbn != lbn) {
			tbp = getblk(vp, start_lbn, size, 0, 0);
			if (!(tbp->b_flags & B_DELWRI)) {
				brelse(tbp);
				break;
			}
		} else
			tbp = last_bp;

		++b_save->bs_nchildren;

		if (tbp->b_blkno != (bp->b_blkno + btodb(bp->b_bufsize))) {
			printf("Clustered Block: %d addr %x bufsize: %ld\n",
			    bp->b_lblkno, bp->b_blkno, bp->b_bufsize);
			printf("Child Block: %d addr: %x\n", tbp->b_lblkno,
			    tbp->b_blkno);
			panic("Clustered write to wrong blocks");
		}

		/*
		 * We might as well AGE the buffer here; it's either empty, or
		 * contains data that we couldn't get rid of (but wanted to).
		 */
		tbp->b_flags &= ~(B_READ | B_DONE | B_ERROR);
		tbp->b_flags |= (B_ASYNC | B_AGE);
		s = splbio();
		buf_undirty(tbp);
		++tbp->b_vp->v_numoutput;
		splx(s);

		if (LIST_FIRST(&tbp->b_dep) != NULL)
			buf_start(tbp);

		/* Move memory from children to parent */
		pagemove(tbp->b_data, cp, size);
		bp->b_bcount += size;
		bp->b_bufsize += size;

		tbp->b_bufsize -= size;
		b_save->bs_children[i] = tbp;

		cp += size;
	}

	if (i == 0) {
		/* None to cluster */
		bp->b_saveaddr = b_save->bs_saveaddr;
		bp->b_flags &= ~B_CALL;
		bp->b_iodone = NULL;
		free(b_save, M_VCLUSTER);
	}
d217 1
a217 5
	if (i < len) {
		len -= i + 1;
		start_lbn += 1;
		goto redo;
	}
@


1.35
log
@Introduce daddr64_t and use it for physical block numbers
Okay weingart@@, "I'm game with putting my name on it" dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.34 2005/11/08 15:43:44 pedro Exp $	*/
d48 2
a49 2
    daddr_t, long, int);
struct buf *cluster_rbuild(struct vnode *, u_quad_t, struct buf *, daddr_t,
d51 2
a52 1
void cluster_wbuild(struct vnode *, struct buf *, long, daddr_t, int, daddr_t);
d100 1
a100 1
    daddr_t lblkno, long size, struct ucred *cred, struct buf **bpp)
d103 1
a103 2
	daddr64_t blkno;
	daddr_t ioblkno;
d263 1
a263 1
    daddr_t lbn, daddr64_t blkno, long size, int run, long flags)
d267 1
a267 1
	daddr_t bn;
d362 1
a362 1
    daddr_t lblkno, long size, int run)
d463 1
a463 1
	daddr_t lbn;
d571 1
a571 1
    daddr_t start_lbn, int len, daddr_t lbn)
d726 1
a726 1
	daddr_t	lbn;
@


1.34
log
@Use ANSI function declarations and deregister, no binary change
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.33 2004/10/26 17:16:27 pedro Exp $	*/
d46 8
a53 12
/*
 * Local declarations
 */
void	cluster_callback(struct buf *);
struct buf *cluster_newbuf(struct vnode *, struct buf *, long, daddr_t,
	    daddr_t, long, int);
struct buf *cluster_rbuild(struct vnode *, u_quad_t, struct buf *,
	    daddr_t, daddr_t, long, int, long);
void	    cluster_wbuild(struct vnode *, struct buf *, long,
	    daddr_t, int, daddr_t);
struct cluster_save *cluster_collectbufs(struct vnode *, 
	    struct cluster_info *, struct buf *);
d102 2
a103 1
	daddr_t blkno, ioblkno;
d263 1
a263 1
    daddr_t lbn, daddr_t blkno, long size, int run, long flags)
d361 1
a361 1
cluster_newbuf(struct vnode *vp, struct buf *bp, long flags, daddr_t blkno,
@


1.33
log
@styling
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.32 2004/04/13 00:15:28 tedu Exp $	*/
d4 1
a4 1
/*-
d102 2
a103 8
cluster_read(vp, ci, filesize, lblkno, size, cred, bpp)
	struct vnode *vp;
	struct cluster_info *ci;
	u_quad_t filesize;
	daddr_t lblkno;
	long size;
	struct ucred *cred;
	struct buf **bpp;
d265 2
a266 9
cluster_rbuild(vp, filesize, bp, lbn, blkno, size, run, flags)
	struct vnode *vp;
	u_quad_t filesize;
	struct buf *bp;
	daddr_t lbn;
	daddr_t blkno;
	long size;
	int run;
	long flags;
d364 2
a365 8
cluster_newbuf(vp, bp, flags, blkno, lblkno, size, run)
	struct vnode *vp;
	struct buf *bp;
	long flags;
	daddr_t blkno;
	daddr_t lblkno;
	long size;
	int run;
d388 1
a388 2
cluster_callback(bp)
	struct buf *bp;
d463 1
a463 4
cluster_write(bp, ci, filesize)
	struct buf *bp;
	struct cluster_info *ci;
	u_quad_t filesize;
a565 1

d573 2
a574 7
cluster_wbuild(vp, last_bp, size, start_lbn, len, lbn)
	struct vnode *vp;
	struct buf *last_bp;
	long size;
	daddr_t start_lbn;
	int len;
	daddr_t	lbn;
d725 2
a726 4
cluster_collectbufs(vp, ci, last_bp)
	struct vnode *vp;
	struct cluster_info *ci;
	struct buf *last_bp;
@


1.32
log
@useless caddr_t cast removal.  same md5s.
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.31 2003/06/02 23:28:07 millert Exp $	*/
d566 1
a566 1
		bawrite(bp);
d769 2
a770 2
		    (void)bread(vp, lbn, last_bp->b_bcount, NOCRED,
			&buflist->bs_children[i]);
@


1.31
log
@Remove the advertising clause in the UCB license which Berkeley
rescinded 22 July 1999.  Proofed by myself and Theo.
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.30 2003/01/30 16:38:39 art Exp $	*/
d312 1
a312 1
	bp->b_saveaddr = (caddr_t) b_save;
d333 1
a333 1
			caddr_t bdata = (char *)tbp->b_data;
d468 1
a468 1
		wakeup((caddr_t)bp);
d670 1
a670 1
	bp->b_saveaddr = (caddr_t) b_save;
@


1.30
log
@Stop using an LFS type for cluster mallocs, use an own type and
GC the LFS malloc types until LFS is resurrected.

from tedu@@stanford.edu
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.29 2002/06/14 21:34:59 todd Exp $	*/
d16 1
a16 5
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by the University of
 *	California, Berkeley and its contributors.
 * 4. Neither the name of the University nor the names of its contributors
@


1.29
log
@spelling; from Brian Poole <raj@@cerias.purdue.edu>
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.28 2002/05/24 08:39:15 art Exp $	*/
d311 1
a311 1
	    sizeof(struct cluster_save), M_SEGMENT, M_WAITOK);
d370 1
a370 1
			free(b_save, M_SEGMENT);
d467 1
a467 1
	free(b_save, M_SEGMENT);
d535 1
a535 1
					free(buflist, M_SEGMENT);
d545 1
a545 1
					free(buflist, M_SEGMENT);
d668 1
a668 1
	    sizeof(struct cluster_save), M_SEGMENT, M_WAITOK);
d743 1
a743 1
		free(b_save, M_SEGMENT);
d769 1
a769 1
	    M_SEGMENT, M_WAITOK);
@


1.28
log
@cluster_callback is a b_iodone handler. Since it calls functions
that assume splbio, splassert(IPL_BIO) in it.
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.27 2002/03/14 01:27:06 millert Exp $	*/
d691 1
a691 1
		 * sequential block whose buffer was passed in explictly
@


1.27
log
@First round of __P removal in sys
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.26 2001/11/06 19:53:20 miod Exp $	*/
d419 2
@


1.26
log
@Replace inclusion of <vm/foo.h> with the correct <uvm/bar.h> when necessary.
(Look ma, I might have broken the tree)
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.25 2001/06/22 14:14:10 deraadt Exp $	*/
d53 9
a61 9
void	cluster_callback __P((struct buf *));
struct buf *cluster_newbuf __P((struct vnode *, struct buf *, long, daddr_t,
	    daddr_t, long, int));
struct buf *cluster_rbuild __P((struct vnode *, u_quad_t, struct buf *,
	    daddr_t, daddr_t, long, int, long));
void	    cluster_wbuild __P((struct vnode *, struct buf *, long,
	    daddr_t, int, daddr_t));
struct cluster_save *cluster_collectbufs __P((struct vnode *, 
	    struct cluster_info *, struct buf *));
@


1.26.2.1
log
@Sync UBC branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.26 2001/11/06 19:53:20 miod Exp $	*/
d53 9
a61 9
void	cluster_callback(struct buf *);
struct buf *cluster_newbuf(struct vnode *, struct buf *, long, daddr_t,
	    daddr_t, long, int);
struct buf *cluster_rbuild(struct vnode *, u_quad_t, struct buf *,
	    daddr_t, daddr_t, long, int, long);
void	    cluster_wbuild(struct vnode *, struct buf *, long,
	    daddr_t, int, daddr_t);
struct cluster_save *cluster_collectbufs(struct vnode *, 
	    struct cluster_info *, struct buf *);
a418 2

	splassert(IPL_BIO);
@


1.26.2.2
log
@sync to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.26.2.1 2002/06/11 03:29:40 art Exp $	*/
d691 1
a691 1
		 * sequential block whose buffer was passed in explicitly
@


1.26.2.3
log
@sync
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d311 1
a311 1
	    sizeof(struct cluster_save), M_VCLUSTER, M_WAITOK);
d370 1
a370 1
			free(b_save, M_VCLUSTER);
d467 1
a467 1
	free(b_save, M_VCLUSTER);
d535 1
a535 1
					free(buflist, M_VCLUSTER);
d545 1
a545 1
					free(buflist, M_VCLUSTER);
d668 1
a668 1
	    sizeof(struct cluster_save), M_VCLUSTER, M_WAITOK);
d743 1
a743 1
		free(b_save, M_VCLUSTER);
d769 1
a769 1
	    M_VCLUSTER, M_WAITOK);
@


1.25
log
@KNF
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.24 2001/05/28 00:23:02 gluk Exp $	*/
d48 1
a48 1
#include <vm/vm.h>
@


1.24
log
@cluster_rbuild() have a race between incore and getblk. incore() returns
zero indicating that buffer is not in a cache, but getblk() going to sleep:
getblk->getnewbuf->tsleep. When getnewbuf() returns after a sleep, getblk()
may find B_DONE buffer in hash and return it. When io operation finishes
biodone() calls cluster_callback() which moves pages from one big cluster
buffer into several component buffers and calls biodone() for every component
buffer. Since there are a component buffer with B_DONE already set, biodone()
panices: "biodone already".

costa@@	ok.
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.23 2001/05/20 22:18:10 gluk Exp $	*/
d159 1
a159 1
	} else if ((u_quad_t)(ioblkno + 1) * (u_quad_t)size <= filesize && 
d197 2
a198 2
			if ((u_quad_t)(ioblkno + 1) * (u_quad_t)size 
			      > filesize ||
d200 1
a200 1
			     ioblkno, NULL, &blkno, &num_ra)) || blkno == -1)
d244 1
a244 1
		else 
d486 1
a486 1
        struct buf *bp;
d490 3
a492 3
        struct vnode *vp;
        daddr_t lbn;
        int maxclen, cursize;
d494 2
a495 2
        vp = bp->b_vp;
        lbn = bp->b_lblkno;
d501 1
a501 1
        if (ci->ci_clen == 0 || lbn != ci->ci_lastw + 1 ||
d531 1
a531 1
					     bpp < endbp; bpp++)
d541 1
a541 1
					     bpp <= endbp; bpp++)
d557 1
a557 1
		     bp->b_blkno == -1)) {
d565 2
a566 2
                ci->ci_clen = maxclen;
                if (maxclen == 0) {		/* I/O not contiguous */
d568 2
a569 2
                        bawrite(bp);
                } else {			/* Wait for rest of cluster */
d571 1
a571 1
                        bdwrite(bp);
@


1.23
log
@fix comments.
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.22 2001/03/21 10:11:22 art Exp $	*/
d356 1
@


1.22
log
@Fix a race which could cause us to write out data belonging
to some other buffer.
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.21 2001/02/27 14:55:34 csapuntz Exp $	*/
d97 1
a97 1
 *	    4 Sequential access, next block is contiguous (1 SYNC).
d420 1
a420 1
	 * Must propogate errors to all the components.
a701 1
		/* Move memory from children to parent */
d724 1
@


1.21
log
@

Move buf_undirty and tbp flags manipulation back before calling the
soft updates code
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.20 2001/02/23 14:52:50 csapuntz Exp $	*/
d628 9
a636 1
			bawrite(bp);
@


1.20
log
@

Change the B_DELWRI flag using buf_dirty and buf_undirty instead of
manually twiddling it. This allows the buffer cache to more easily
keep track of dirty buffers and decide when it is appropriate to speed
up the syncer.

Insipired by FreeBSD.
Look over by art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.19 2001/02/23 14:42:38 csapuntz Exp $	*/
d703 11
a721 11

		s = splbio();
		buf_undirty(bp);
		/*
		 * We might as well AGE the buffer here; it's either empty, or
		 * contains data that we couldn't get rid of (but wanted to).
		 */
		tbp->b_flags &= ~(B_READ | B_DONE | B_ERROR);
		tbp->b_flags |= (B_ASYNC | B_AGE);
		++tbp->b_vp->v_numoutput;
		splx(s);
@


1.19
log
@

Remove the clustering fields from the vnodes and place them in the
file system inode instead
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.18 2001/02/21 23:24:30 csapuntz Exp $	*/
a702 7
		/*
		 * We might as well AGE the buffer here; it's either empty, or
		 * contains data that we couldn't get rid of (but wanted to).
		 */
		tbp->b_flags &= ~(B_READ | B_DONE | B_ERROR | B_DELWRI);
		tbp->b_flags |= (B_ASYNC | B_AGE);

d713 7
a719 1
		reassignbuf(tbp, tbp->b_vp);		/* put on clean list */
@


1.18
log
@

Latest soft updates from FreeBSD/Kirk McKusick

Snapshot-related code has been commented out.
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.17 2000/06/23 02:14:38 mickey Exp $	*/
d53 1
d60 2
a61 1
struct cluster_save *cluster_collectbufs __P((struct vnode *, struct buf *));
d77 1
a77 1
#define ISSEQREAD(vp, blk) \
d79 1
a79 1
	 ((blk) == (vp)->v_lastr + 1 || (blk) == (vp)->v_lastr))
d81 2
a82 2
#define ISSEQREAD(vp, blk) \
	((blk) != 0 && ((blk) == (vp)->v_lastr + 1 || (blk) == (vp)->v_lastr))
d106 1
a106 1
cluster_read(vp, filesize, lblkno, size, cred, bpp)
d108 1
d134 1
a134 1
		ioblkno = lblkno + (vp->v_ralen ? vp->v_ralen : 1);
d156 3
a158 3
	if (!ISSEQREAD(vp, lblkno)) {
		vp->v_ralen = 0;
		vp->v_maxra = lblkno;
d175 2
a176 2
			if (!alreadyincore && ioblkno <= vp->v_maxra)
				vp->v_ralen = max(vp->v_ralen >> 1, 1);
d182 3
a184 3
			else if (num_ra > vp->v_ralen && lblkno != vp->v_lastr)
				vp->v_ralen = vp->v_ralen ?
					min(num_ra, vp->v_ralen << 1) : 1;
d186 2
a187 2
			if (num_ra > vp->v_ralen)
				num_ra = vp->v_ralen;
d208 8
a215 8
				if (ioblkno <= vp->v_maxra)
					vp->v_ralen = max(vp->v_ralen >> 1, 1);
				else if (num_ra > vp->v_ralen &&
					 lblkno != vp->v_lastr)
					vp->v_ralen = vp->v_ralen ?
						min(num_ra,vp->v_ralen<<1) : 1;
				if (num_ra > vp->v_ralen)
					num_ra = vp->v_ralen;
d262 1
a262 1
		vp->v_maxra = rbp->b_lblkno + (rbp->b_bcount / size) - 1;
d484 1
a484 1
cluster_write(bp, filesize)
d486 1
d498 1
a498 1
		vp->v_lasta = vp->v_clen = vp->v_cstart = vp->v_lastw = 0;
d500 2
a501 2
        if (vp->v_clen == 0 || lbn != vp->v_lastw + 1 ||
	    (bp->b_blkno != vp->v_lasta + btodb(bp->b_bcount))) {
d503 1
a503 1
		if (vp->v_clen != 0) {
d513 1
a513 1
			cursize = vp->v_lastw - vp->v_cstart + 1;
d515 1
a515 1
			    lbn != vp->v_lastw + 1 || vp->v_clen <= cursize) {
d517 1
a517 1
				    vp->v_cstart, cursize, lbn);
d522 1
a522 1
				buflist = cluster_collectbufs(vp, bp);
d534 1
a534 1
					    vp->v_cstart, cursize, lbn);
d543 2
a544 2
					vp->v_lastw = lbn;
					vp->v_lasta = bp->b_blkno;
d558 4
a561 4
			vp->v_clen = 0;
			vp->v_lasta = bp->b_blkno;
			vp->v_cstart = lbn + 1;
			vp->v_lastw = lbn;
d564 1
a564 1
                vp->v_clen = maxclen;
d566 1
a566 1
			vp->v_cstart = lbn + 1;
d569 1
a569 1
			vp->v_cstart = lbn;
d572 1
a572 1
	} else if (lbn == vp->v_cstart + vp->v_clen) {
d576 4
a579 4
		cluster_wbuild(vp, bp, bp->b_bcount, vp->v_cstart,
		    vp->v_clen + 1, lbn);
		vp->v_clen = 0;
		vp->v_cstart = lbn + 1;
d586 2
a587 2
	vp->v_lastw = lbn;
	vp->v_lasta = bp->b_blkno;
d748 1
a748 1
cluster_collectbufs(vp, last_bp)
d750 1
d757 1
a757 1
	len = vp->v_lastw - vp->v_cstart + 1;
d762 1
a762 1
	for (lbn = vp->v_cstart, i = 0; i < len; lbn++, i++)
@


1.17
log
@remove obsolete vtrace guts; art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.16 1999/01/11 05:12:24 millert Exp $	*/
d706 2
a707 2
		if (LIST_FIRST(&tbp->b_dep) != NULL && bioops.io_start)
			(*bioops.io_start)(tbp);
@


1.16
log
@panic prints a newline for you, don't do it in the panic string
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.15 1998/10/13 00:28:32 csapuntz Exp $	*/
a43 1
#include <sys/trace.h>
a129 1
		trace(TR_BREADHIT, pack(vp, size), lblkno);
a135 1
		trace(TR_BREADMISS, pack(vp, size), lblkno);
d232 1
a232 3
		else if (rbp) {			/* case 2, 5 */
			trace(TR_BREADMISSRA,
			    pack(vp, (num_ra + 1) * size), ioblkno);
a233 1
		}
@


1.16.6.1
log
@merge in approximately 2.9 into SMP branch
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.22 2001/03/21 10:11:22 art Exp $	*/
d44 1
a53 1
void	cluster_callback __P((struct buf *));
d60 1
a60 2
struct cluster_save *cluster_collectbufs __P((struct vnode *, 
	    struct cluster_info *, struct buf *));
d76 1
a76 1
#define ISSEQREAD(ci, blk) \
d78 1
a78 1
	 ((blk) == (ci)->ci_lastr + 1 || (blk) == (ci)->ci_lastr))
d80 2
a81 2
#define ISSEQREAD(ci, blk) \
	((blk) != 0 && ((blk) == (ci)->ci_lastr + 1 || (blk) == (ci)->ci_lastr))
d105 1
a105 1
cluster_read(vp, ci, filesize, lblkno, size, cred, bpp)
a106 1
	struct cluster_info *ci;
d131 1
d133 1
a133 1
		ioblkno = lblkno + (ci->ci_ralen ? ci->ci_ralen : 1);
d138 1
d156 3
a158 3
	if (!ISSEQREAD(ci, lblkno)) {
		ci->ci_ralen = 0;
		ci->ci_maxra = lblkno;
d175 2
a176 2
			if (!alreadyincore && ioblkno <= ci->ci_maxra)
				ci->ci_ralen = max(ci->ci_ralen >> 1, 1);
d182 3
a184 3
			else if (num_ra > ci->ci_ralen && lblkno != ci->ci_lastr)
				ci->ci_ralen = ci->ci_ralen ?
					min(num_ra, ci->ci_ralen << 1) : 1;
d186 2
a187 2
			if (num_ra > ci->ci_ralen)
				num_ra = ci->ci_ralen;
d208 8
a215 8
				if (ioblkno <= ci->ci_maxra)
					ci->ci_ralen = max(ci->ci_ralen >> 1, 1);
				else if (num_ra > ci->ci_ralen &&
					 lblkno != ci->ci_lastr)
					ci->ci_ralen = ci->ci_ralen ?
						min(num_ra,ci->ci_ralen<<1) : 1;
				if (num_ra > ci->ci_ralen)
					num_ra = ci->ci_ralen;
d235 3
a237 1
		else if (rbp)			/* case 2, 5 */
d239 1
d265 1
a265 1
		ci->ci_maxra = rbp->b_lblkno + (rbp->b_bcount / size) - 1;
d487 1
a487 1
cluster_write(bp, ci, filesize)
a488 1
	struct cluster_info *ci;
d500 1
a500 1
		ci->ci_lasta = ci->ci_clen = ci->ci_cstart = ci->ci_lastw = 0;
d502 2
a503 2
        if (ci->ci_clen == 0 || lbn != ci->ci_lastw + 1 ||
	    (bp->b_blkno != ci->ci_lasta + btodb(bp->b_bcount))) {
d505 1
a505 1
		if (ci->ci_clen != 0) {
d515 1
a515 1
			cursize = ci->ci_lastw - ci->ci_cstart + 1;
d517 1
a517 1
			    lbn != ci->ci_lastw + 1 || ci->ci_clen <= cursize) {
d519 1
a519 1
				    ci->ci_cstart, cursize, lbn);
d524 1
a524 1
				buflist = cluster_collectbufs(vp, ci, bp);
d536 1
a536 1
					    ci->ci_cstart, cursize, lbn);
d545 2
a546 2
					ci->ci_lastw = lbn;
					ci->ci_lasta = bp->b_blkno;
d560 4
a563 4
			ci->ci_clen = 0;
			ci->ci_lasta = bp->b_blkno;
			ci->ci_cstart = lbn + 1;
			ci->ci_lastw = lbn;
d566 1
a566 1
                ci->ci_clen = maxclen;
d568 1
a568 1
			ci->ci_cstart = lbn + 1;
d571 1
a571 1
			ci->ci_cstart = lbn;
d574 1
a574 1
	} else if (lbn == ci->ci_cstart + ci->ci_clen) {
d578 4
a581 4
		cluster_wbuild(vp, bp, bp->b_bcount, ci->ci_cstart,
		    ci->ci_clen + 1, lbn);
		ci->ci_clen = 0;
		ci->ci_cstart = lbn + 1;
d588 2
a589 2
	ci->ci_lastw = lbn;
	ci->ci_lasta = bp->b_blkno;
d630 1
a630 9
			/*
			 * The buffer could have already been flushed out of
			 * the cache. If that has happened, we'll get a new
			 * buffer here with random data, just drop it.
			 */
			if ((bp->b_flags & B_DELWRI) == 0)
				brelse(bp);
			else
				bawrite(bp);
d709 1
a709 1
		tbp->b_flags &= ~(B_READ | B_DONE | B_ERROR);
a710 4
		s = splbio();
		buf_undirty(tbp);
		++tbp->b_vp->v_numoutput;
		splx(s);
d712 2
a713 2
		if (LIST_FIRST(&tbp->b_dep) != NULL)
			buf_start(tbp);
d720 5
d750 1
a750 1
cluster_collectbufs(vp, ci, last_bp)
a751 1
	struct cluster_info *ci;
d758 1
a758 1
	len = ci->ci_lastw - ci->ci_cstart + 1;
d763 1
a763 1
	for (lbn = ci->ci_cstart, i = 0; i < len; lbn++, i++)
@


1.16.6.2
log
@Merge in -current from two days ago in the SMP branch.
As usual with merges, they do not indicate progress, so do not hold
your breath for working SMP, and do not mail me and ask about the
state of it.  It has not changed.  There is work ongoing, but very, very
slowly.  The commit is done in parts as to not lock up the tree in too
big chunks at a time.
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.16.6.1 2001/05/14 22:32:45 niklas Exp $	*/
d97 1
a97 1
 *	    4 Sequential access, next block is contiguous (2 SYNC).
d159 1
a159 1
	} else if ((u_quad_t)(ioblkno + 1) * (u_quad_t)size <= filesize &&
d197 2
a198 2
			if ((u_quad_t)(ioblkno + 1) * (u_quad_t)size >
			    filesize ||
d200 1
a200 1
			    ioblkno, NULL, &blkno, &num_ra)) || blkno == -1)
d244 1
a244 1
		else
a355 1
		tbp->b_flags &= ~(B_DONE | B_ERROR);
d420 1
a420 1
	 * Must propagate errors to all the components.
d485 1
a485 1
	struct buf *bp;
d489 3
a491 3
	struct vnode *vp;
	daddr_t lbn;
	int maxclen, cursize;
d493 2
a494 2
	vp = bp->b_vp;
	lbn = bp->b_lblkno;
d500 1
a500 1
	if (ci->ci_clen == 0 || lbn != ci->ci_lastw + 1 ||
d530 1
a530 1
					    bpp < endbp; bpp++)
d540 1
a540 1
					    bpp <= endbp; bpp++)
d556 1
a556 1
		    bp->b_blkno == -1)) {
d564 2
a565 2
		ci->ci_clen = maxclen;
		if (maxclen == 0) {		/* I/O not contiguous */
d567 2
a568 2
		bawrite(bp);
		} else {			/* Wait for rest of cluster */
d570 1
a570 1
			bdwrite(bp);
d702 1
a724 1
		/* Move memory from children to parent */
@


1.16.6.3
log
@merge in -current
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d48 1
a48 1
#include <uvm/uvm_extern.h>
@


1.16.6.4
log
@Merge in -current from about a week ago
@
text
@d53 9
a61 9
void	cluster_callback(struct buf *);
struct buf *cluster_newbuf(struct vnode *, struct buf *, long, daddr_t,
	    daddr_t, long, int);
struct buf *cluster_rbuild(struct vnode *, u_quad_t, struct buf *,
	    daddr_t, daddr_t, long, int, long);
void	    cluster_wbuild(struct vnode *, struct buf *, long,
	    daddr_t, int, daddr_t);
struct cluster_save *cluster_collectbufs(struct vnode *, 
	    struct cluster_info *, struct buf *);
@


1.16.6.5
log
@Sync the SMP branch with 3.3
@
text
@d311 1
a311 1
	    sizeof(struct cluster_save), M_VCLUSTER, M_WAITOK);
d370 1
a370 1
			free(b_save, M_VCLUSTER);
a419 2
	splassert(IPL_BIO);

d465 1
a465 1
	free(b_save, M_VCLUSTER);
d533 1
a533 1
					free(buflist, M_VCLUSTER);
d543 1
a543 1
					free(buflist, M_VCLUSTER);
d666 1
a666 1
	    sizeof(struct cluster_save), M_VCLUSTER, M_WAITOK);
d689 1
a689 1
		 * sequential block whose buffer was passed in explicitly
d741 1
a741 1
		free(b_save, M_VCLUSTER);
d767 1
a767 1
	    M_VCLUSTER, M_WAITOK);
@


1.16.6.6
log
@Sync SMP branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.16.6.5 2003/03/28 00:41:27 niklas Exp $	*/
d16 5
a20 1
 * 3. Neither the name of the University nor the names of its contributors
@


1.16.6.7
log
@Merge with the trunk
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d312 1
a312 1
	bp->b_saveaddr = b_save;
d333 1
a333 1
			caddr_t bdata = tbp->b_data;
d468 1
a468 1
		wakeup(bp);
d670 1
a670 1
	bp->b_saveaddr = b_save;
@


1.15
log
@

More fixes for huge (>2GB) files.
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.14 1998/10/11 06:33:11 csapuntz Exp $	*/
d295 1
a295 1
		panic("cluster_rbuild: size %ld != filesize %ld\n",
d615 1
a615 1
		panic("cluster_wbuild: size %ld != filesize %ld\n",
@


1.14
log
@

Fix from Kirk McKusick to make sure that clustering works correctly across
the 2GB file boundary.
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.13 1998/02/20 14:51:58 niklas Exp $	*/
d159 4
a162 3
	} else if ((ioblkno + 1) * size <= filesize && !alreadyincore &&
	    !(error = VOP_BMAP(vp, ioblkno, NULL, &blkno, &num_ra)) &&
	    blkno != -1) {
d197 2
a198 1
			if ((ioblkno + 1) * size > filesize ||
d298 1
a298 1
	if (size * (lbn + run + 1) > filesize)
d556 1
a556 1
		if ((lbn + 1) * bp->b_bcount != filesize &&
@


1.13
log
@Please GCC 2.8's harsher view of good style
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.12 1998/01/08 15:51:56 csapuntz Exp $	*/
d514 1
a514 1
			if ((lbn + 1) * bp->b_bcount != filesize ||
@


1.12
log
@Soft updates bug fix: Set the flags on the buffer describing our intentions
before we call bioops.io_start. However, don't move buffer memory to
parent until bioops.io_start has had a chance to do its thing (otherwise,
io_start will be very disappointed went it tries to read the buffer :)

Thanks to Todd T. Fries for finding this one!
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.11 1997/11/06 05:58:26 csapuntz Exp $	*/
d242 1
a242 1
	if (bp)
d247 1
d249 1
a249 1
	if (rbp)
d255 1
@


1.11
log
@Updates for VFS Lite 2 + soft update.
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.10 1997/10/06 20:20:08 deraadt Exp $	*/
d701 7
d716 1
a716 6
		tbp->b_flags &= ~(B_READ | B_DONE | B_ERROR | B_DELWRI);
		/*
		 * We might as well AGE the buffer here; it's either empty, or
		 * contains data that we couldn't get rid of (but wanted to).
		 */
		tbp->b_flags |= (B_ASYNC | B_AGE);
@


1.10
log
@back out vfs lite2 till after 2.2
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.8 1997/09/27 06:56:18 niklas Exp $	*/
a50 9
#ifdef DEBUG
#include <sys/sysctl.h>
int doreallocblks = 0;
struct ctldebug debug13 = { "doreallocblks", &doreallocblks };
#else
/* XXX for cluster_write */
#define doreallocblks 0
#endif

d512 1
a512 2
			if (!doreallocblks ||
			    (lbn + 1) * bp->b_bcount != filesize ||
d701 3
a708 2
		if (tbp->b_flags & B_DELWRI)
			TAILQ_REMOVE(&bdirties, tbp, b_synclist);
@


1.9
log
@VFS Lite2 Changes
@
text
@d51 9
d521 2
a522 1
			if ((lbn + 1) * bp->b_bcount != filesize ||
a710 3
		if (LIST_FIRST(&tbp->b_dep) != NULL && bioops.io_start)
			(*bioops.io_start)(tbp);

d716 2
@


1.8
log
@Cleaning up my tree.. that is why nits like this extra blank line
gets committed
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.7 1997/02/01 00:09:31 niklas Exp $	*/
a50 9
#ifdef DEBUG
#include <sys/sysctl.h>
int doreallocblks = 0;
struct ctldebug debug13 = { "doreallocblks", &doreallocblks };
#else
/* XXX for cluster_write */
#define doreallocblks 0
#endif

d512 1
a512 2
			if (!doreallocblks ||
			    (lbn + 1) * bp->b_bcount != filesize ||
d701 3
a708 2
		if (tbp->b_flags & B_DELWRI)
			TAILQ_REMOVE(&bdirties, tbp, b_synclist);
@


1.7
log
@Correct early termination case of read clustering which could cause
buffer cache poisoning when bufpages/nbuf is larger than 1.  Also correct
readahead amount calculation.  Optimize page moving when buffers have excess
pages.
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.6 1997/01/10 23:18:40 niklas Exp $	*/
d335 1
@


1.6
log
@Correct a panic condition hitting on machines with NBPG != ffs blocksize,
plus having a large bufpages value compared to nbuf.
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.5 1996/06/11 03:25:13 tholo Exp $	*/
d270 1
a270 1
		vp->v_maxra = rbp->b_lblkno + (rbp->b_bufsize / size) - 1;
d318 2
a319 2
	b_save = malloc(sizeof(struct buf *) * run + sizeof(struct cluster_save),
	    M_SEGMENT, M_WAITOK);
d355 2
d360 1
a360 15
			if (tbp->b_bufsize > size) {
				/*
				 * XXX if the source and destination regions
				 * overlap we have to copy backward to avoid
				 * clobbering any valid pages (i.e. pagemove
				 * implementations typically can't handle
				 * overlap).
				 */
				bdata += tbp->b_bufsize;
				while (bdata > (char *)tbp->b_data) {
					bdata -= CLBYTES;
					pagemove(bdata, bdata + size, CLBYTES);
				}
			} else 
				pagemove(bdata, bdata + size, tbp->b_bufsize);
d364 1
a364 2
		++b_save->bs_nchildren;
		b_save->bs_children[i - 1] = tbp;
d461 7
a467 1
		pagemove(cp, (char *)bp->b_data + bsize, bp->b_bufsize - bsize);
d663 2
a664 2
	b_save = malloc(sizeof(struct buf *) * len + sizeof(struct cluster_save),
	    M_SEGMENT, M_WAITOK);
@


1.5
log
@Kernel-implementation of update(8) my me
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.4 1996/05/02 13:12:33 deraadt Exp $	*/
d352 1
a352 1
				if (tbp->b_bufsize != MAXBSIZE)
@


1.4
log
@sync syscalls, no sys/cpu.h
@
text
@d1 1
a1 1
/*	$OpenBSD: vfs_cluster.c,v 1.3 1996/04/21 22:27:34 deraadt Exp $	*/
d722 2
@


1.3
log
@partial sync with netbsd 960418, more to come
@
text
@d1 2
a2 2
/*	$OpenBSD: vfs_cluster.c,v 1.2 1996/03/03 17:20:25 niklas Exp $	*/
/*	$NetBSD: vfs_cluster.c,v 1.11 1996/03/16 23:17:18 christos Exp $	*/
d48 2
a49 1
#include <sys/cpu.h>
a51 1
#include <vm/vm.h>
@


1.2
log
@From NetBSD: 960217 merge
@
text
@d1 2
a2 2
/*	$OpenBSD$	*/
/*	$NetBSD: vfs_cluster.c,v 1.10 1996/02/09 19:00:56 christos Exp $	*/
d300 1
a300 1
		panic("cluster_rbuild: size %d != filesize %d\n",
d627 1
a627 1
		panic("cluster_wbuild: size %d != filesize %d\n",
d710 1
a710 1
			printf("Clustered Block: %d addr %x bufsize: %d\n",
@


1.1
log
@Initial revision
@
text
@d1 2
a2 1
/*	$NetBSD: vfs_cluster.c,v 1.8 1995/07/24 21:19:50 cgd Exp $	*/
d46 1
d48 1
a48 1
#include <lib/libkern/libkern.h>
d113 1
d689 1
a689 1
		    last_bp == NULL && start_lbn == lbn)
@


1.1.1.1
log
@initial import of NetBSD tree
@
text
@@
