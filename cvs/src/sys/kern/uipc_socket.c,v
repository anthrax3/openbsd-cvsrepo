head	1.193;
access;
symbols
	OPENBSD_6_1:1.181.0.4
	OPENBSD_6_1_BASE:1.181
	OPENBSD_6_0:1.152.0.2
	OPENBSD_6_0_BASE:1.152
	OPENBSD_5_9:1.149.0.2
	OPENBSD_5_9_BASE:1.149
	OPENBSD_5_8:1.141.0.4
	OPENBSD_5_8_BASE:1.141
	OPENBSD_5_7:1.136.0.2
	OPENBSD_5_7_BASE:1.136
	OPENBSD_5_6:1.130.0.4
	OPENBSD_5_6_BASE:1.130
	OPENBSD_5_5:1.122.0.4
	OPENBSD_5_5_BASE:1.122
	OPENBSD_5_4:1.118.0.2
	OPENBSD_5_4_BASE:1.118
	OPENBSD_5_3:1.114.0.2
	OPENBSD_5_3_BASE:1.114
	OPENBSD_5_2:1.104.0.2
	OPENBSD_5_2_BASE:1.104
	OPENBSD_5_1_BASE:1.95
	OPENBSD_5_1:1.95.0.2
	OPENBSD_5_0:1.94.0.2
	OPENBSD_5_0_BASE:1.94
	OPENBSD_4_9:1.86.0.2
	OPENBSD_4_9_BASE:1.86
	OPENBSD_4_8:1.83.0.2
	OPENBSD_4_8_BASE:1.83
	OPENBSD_4_7:1.79.0.2
	OPENBSD_4_7_BASE:1.79
	OPENBSD_4_6:1.77.0.4
	OPENBSD_4_6_BASE:1.77
	OPENBSD_4_5:1.75.0.2
	OPENBSD_4_5_BASE:1.75
	OPENBSD_4_4:1.71.0.2
	OPENBSD_4_4_BASE:1.71
	OPENBSD_4_3:1.67.0.2
	OPENBSD_4_3_BASE:1.67
	OPENBSD_4_2:1.66.0.4
	OPENBSD_4_2_BASE:1.66
	OPENBSD_4_1:1.66.0.2
	OPENBSD_4_1_BASE:1.66
	OPENBSD_4_0:1.64.0.2
	OPENBSD_4_0_BASE:1.64
	OPENBSD_3_9:1.62.0.2
	OPENBSD_3_9_BASE:1.62
	OPENBSD_3_8:1.59.0.2
	OPENBSD_3_8_BASE:1.59
	OPENBSD_3_7:1.56.0.2
	OPENBSD_3_7_BASE:1.56
	OPENBSD_3_6:1.54.0.2
	OPENBSD_3_6_BASE:1.54
	SMP_SYNC_A:1.53
	SMP_SYNC_B:1.53
	OPENBSD_3_5:1.51.0.4
	OPENBSD_3_5_BASE:1.51
	OPENBSD_3_4:1.51.0.2
	OPENBSD_3_4_BASE:1.51
	UBC_SYNC_A:1.49
	OPENBSD_3_3:1.49.0.2
	OPENBSD_3_3_BASE:1.49
	OPENBSD_3_2:1.46.0.2
	OPENBSD_3_2_BASE:1.46
	OPENBSD_3_1:1.41.0.2
	OPENBSD_3_1_BASE:1.41
	UBC_SYNC_B:1.46
	UBC:1.39.0.2
	UBC_BASE:1.39
	OPENBSD_3_0:1.35.0.2
	OPENBSD_3_0_BASE:1.35
	OPENBSD_2_9_BASE:1.33
	OPENBSD_2_9:1.33.0.2
	OPENBSD_2_8:1.27.0.8
	OPENBSD_2_8_BASE:1.27
	OPENBSD_2_7:1.27.0.6
	OPENBSD_2_7_BASE:1.27
	SMP:1.27.0.4
	SMP_BASE:1.27
	kame_19991208:1.27
	OPENBSD_2_6:1.27.0.2
	OPENBSD_2_6_BASE:1.27
	OPENBSD_2_5:1.26.0.2
	OPENBSD_2_5_BASE:1.26
	OPENBSD_2_4:1.22.0.2
	OPENBSD_2_4_BASE:1.22
	OPENBSD_2_3:1.21.0.2
	OPENBSD_2_3_BASE:1.21
	OPENBSD_2_2:1.17.0.2
	OPENBSD_2_2_BASE:1.17
	OPENBSD_2_1:1.11.0.2
	OPENBSD_2_1_BASE:1.11
	OPENBSD_2_0:1.7.0.2
	OPENBSD_2_0_BASE:1.7
	netbsd_1_1:1.1.1.1;
locks; strict;
comment	@ * @;


1.193
date	2017.07.08.09.19.02;	author mpi;	state Exp;
branches;
next	1.192;
commitid	5bYsyVcQqSuIdi7J;

1.192
date	2017.07.04.12.58.32;	author mpi;	state Exp;
branches;
next	1.191;
commitid	SVn8rvXqimriZ7Tw;

1.191
date	2017.07.03.08.29.24;	author mpi;	state Exp;
branches;
next	1.190;
commitid	8LcdPSUEwjn8Ax7h;

1.190
date	2017.06.27.12.02.43;	author mpi;	state Exp;
branches;
next	1.189;
commitid	yfTuwTXinKA8ckkX;

1.189
date	2017.06.26.09.32.31;	author mpi;	state Exp;
branches;
next	1.188;
commitid	gZMpLuRopIsWa0cT;

1.188
date	2017.06.20.17.13.21;	author bluhm;	state Exp;
branches;
next	1.187;
commitid	0c19JRFM2etJCJpa;

1.187
date	2017.06.20.09.10.04;	author mpi;	state Exp;
branches;
next	1.186;
commitid	Y0CXGhDhWn7oJ3PO;

1.186
date	2017.05.31.08.55.10;	author markus;	state Exp;
branches;
next	1.185;
commitid	tU58o7vzg3WVm3T4;

1.185
date	2017.05.27.18.50.53;	author claudio;	state Exp;
branches;
next	1.184;
commitid	zgiH4da2QPzswD5J;

1.184
date	2017.05.15.13.00.10;	author mpi;	state Exp;
branches;
next	1.183;
commitid	vTtbspBIjhyCGLCR;

1.183
date	2017.05.15.12.26.00;	author mpi;	state Exp;
branches;
next	1.182;
commitid	WMZaI3vIHNC1J8ol;

1.182
date	2017.04.02.23.40.08;	author deraadt;	state Exp;
branches;
next	1.181;
commitid	hB2AVYbbbpiPCzTK;

1.181
date	2017.03.17.17.19.16;	author mpi;	state Exp;
branches;
next	1.180;
commitid	CxqvXOMqotM60GAI;

1.180
date	2017.03.13.20.18.21;	author claudio;	state Exp;
branches;
next	1.179;
commitid	ZsxSSZJSFxZH81LL;

1.179
date	2017.03.07.09.23.27;	author mpi;	state Exp;
branches;
next	1.178;
commitid	ilH9l7TRBZ95J9uu;

1.178
date	2017.03.03.09.41.20;	author mpi;	state Exp;
branches;
next	1.177;
commitid	KFfoA9Sc5ZswSFTf;

1.177
date	2017.02.14.09.46.21;	author mpi;	state Exp;
branches;
next	1.176;
commitid	4bln7omqWkS0RJo9;

1.176
date	2017.02.01.20.59.47;	author dhill;	state Exp;
branches;
next	1.175;
commitid	UBL7uwpXqTP4EWIu;

1.175
date	2017.01.27.20.31.42;	author bluhm;	state Exp;
branches;
next	1.174;
commitid	iyCOWv2EkHfmOzpr;

1.174
date	2017.01.26.00.08.50;	author bluhm;	state Exp;
branches;
next	1.173;
commitid	n62VJE6Fu4vdjg5P;

1.173
date	2017.01.25.16.45.50;	author bluhm;	state Exp;
branches;
next	1.172;
commitid	oqzcQwPmer4ABcpN;

1.172
date	2017.01.25.06.15.50;	author mpi;	state Exp;
branches;
next	1.171;
commitid	X7Hk1efefaYrWlw3;

1.171
date	2016.12.29.12.12.43;	author mpi;	state Exp;
branches;
next	1.170;
commitid	RhxGXGNe4WuNtTZs;

1.170
date	2016.12.20.21.15.36;	author mpi;	state Exp;
branches;
next	1.169;
commitid	FnVGQnLcvAzzyTgP;

1.169
date	2016.12.19.08.36.49;	author mpi;	state Exp;
branches;
next	1.168;
commitid	QqHqT2WhCBWqYgGJ;

1.168
date	2016.11.29.10.22.30;	author jsg;	state Exp;
branches;
next	1.167;
commitid	ZQetSMB5ilG2z10X;

1.167
date	2016.11.23.13.05.53;	author bluhm;	state Exp;
branches;
next	1.166;
commitid	tg1RJfUO6KCs0i7J;

1.166
date	2016.11.22.10.29.39;	author mpi;	state Exp;
branches;
next	1.165;
commitid	BKzUcumIIF7RIaBI;

1.165
date	2016.11.21.09.09.06;	author mpi;	state Exp;
branches;
next	1.164;
commitid	wuzpseLx3Ntn9R7b;

1.164
date	2016.11.14.08.45.30;	author mpi;	state Exp;
branches;
next	1.163;
commitid	qG6dX9YEkjnsp5mA;

1.163
date	2016.10.06.19.09.08;	author bluhm;	state Exp;
branches;
next	1.162;
commitid	IO8dsedjngxSg7J1;

1.162
date	2016.10.06.17.02.10;	author bluhm;	state Exp;
branches;
next	1.161;
commitid	RiiPM07FzrJt63iz;

1.161
date	2016.09.20.14.27.43;	author bluhm;	state Exp;
branches;
next	1.160;
commitid	88CTDRw0uPkfyaUQ;

1.160
date	2016.09.20.11.11.44;	author bluhm;	state Exp;
branches;
next	1.159;
commitid	lWclwIb8V7IBYfP5;

1.159
date	2016.09.15.02.00.16;	author dlg;	state Exp;
branches;
next	1.158;
commitid	RlO92XR575sygHqm;

1.158
date	2016.09.13.07.50.36;	author mpi;	state Exp;
branches;
next	1.157;
commitid	tdrLx5U0VuhVtKc5;

1.157
date	2016.09.03.14.09.58;	author bluhm;	state Exp;
branches;
next	1.156;
commitid	KXNS2XLtolyMs5Vv;

1.156
date	2016.09.03.11.13.36;	author yasuoka;	state Exp;
branches;
next	1.155;
commitid	ZaAsBjjQMVbtJUFm;

1.155
date	2016.08.25.14.13.19;	author bluhm;	state Exp;
branches;
next	1.154;
commitid	PnBATF8qpqSyZflF;

1.154
date	2016.08.25.13.59.16;	author bluhm;	state Exp;
branches;
next	1.153;
commitid	0V4U4HwpClmls4P7;

1.153
date	2016.08.22.10.23.42;	author claudio;	state Exp;
branches;
next	1.152;
commitid	TOC5sPGMe1yvsY7O;

1.152
date	2016.06.13.21.24.43;	author bluhm;	state Exp;
branches;
next	1.151;
commitid	t4rQrmZwTmcYiFNW;

1.151
date	2016.06.12.21.42.47;	author bluhm;	state Exp;
branches;
next	1.150;
commitid	EDFgMcy0RywJlW3Z;

1.150
date	2016.03.14.23.08.06;	author krw;	state Exp;
branches;
next	1.149;
commitid	kCz5QgxnxRMKOzNf;

1.149
date	2016.01.15.11.58.34;	author bluhm;	state Exp;
branches
	1.149.2.1;
next	1.148;
commitid	irpm9FJzAmTe7mkd;

1.148
date	2016.01.15.11.30.03;	author dlg;	state Exp;
branches;
next	1.147;
commitid	CNBr6krbLIbxKHAM;

1.147
date	2016.01.15.11.21.58;	author dlg;	state Exp;
branches;
next	1.146;
commitid	7LVjORDaEDODwOzR;

1.146
date	2016.01.13.21.39.39;	author bluhm;	state Exp;
branches;
next	1.145;
commitid	T7xTL2AZFdBEcamA;

1.145
date	2016.01.06.10.06.50;	author stefan;	state Exp;
branches;
next	1.144;
commitid	tXSZ0o5OdZ5vjZOy;

1.144
date	2015.12.05.10.11.53;	author tedu;	state Exp;
branches;
next	1.143;
commitid	Cl55DD2g2xm69E6W;

1.143
date	2015.10.30.19.47.40;	author bluhm;	state Exp;
branches;
next	1.142;
commitid	yzL4UuVOqvvNd4tp;

1.142
date	2015.08.24.14.28.25;	author bluhm;	state Exp;
branches;
next	1.141;
commitid	AwNJvJrfcvBWLcpx;

1.141
date	2015.07.08.07.21.50;	author mpi;	state Exp;
branches
	1.141.4.1;
next	1.140;
commitid	9ERVupAoYqW4Iok9;

1.140
date	2015.06.30.15.30.17;	author mpi;	state Exp;
branches;
next	1.139;
commitid	J4OPNuggl4DOKGzM;

1.139
date	2015.06.16.11.09.39;	author mpi;	state Exp;
branches;
next	1.138;
commitid	h7z8lokZ0dFyuWpg;

1.138
date	2015.05.06.08.52.17;	author mpi;	state Exp;
branches;
next	1.137;
commitid	8Nt1erARPXBfs0Oe;

1.137
date	2015.03.14.03.38.51;	author jsg;	state Exp;
branches;
next	1.136;
commitid	p4LJxGKbi0BU2cG6;

1.136
date	2015.02.10.21.56.10;	author miod;	state Exp;
branches;
next	1.135;
commitid	C5iGb36LQxjM60Q3;

1.135
date	2014.12.11.19.21.57;	author tedu;	state Exp;
branches;
next	1.134;
commitid	KtikWduHBwfG1emb;

1.134
date	2014.11.03.17.20.46;	author bluhm;	state Exp;
branches;
next	1.133;
commitid	Jo3b0hfgHpuqTRST;

1.133
date	2014.09.09.02.07.17;	author guenther;	state Exp;
branches;
next	1.132;
commitid	8mNtcvWyqXdDfneL;

1.132
date	2014.09.08.06.24.13;	author jsg;	state Exp;
branches;
next	1.131;
commitid	ZqXwxwmeo3l29NOg;

1.131
date	2014.08.31.01.42.36;	author guenther;	state Exp;
branches;
next	1.130;
commitid	zF5A8BuuSSyqaDyM;

1.130
date	2014.07.13.15.52.38;	author tedu;	state Exp;
branches;
next	1.129;
commitid	iyde0xIVfkKugN9I;

1.129
date	2014.07.09.15.43.33;	author tedu;	state Exp;
branches;
next	1.128;
commitid	yLyTcHToARzpOsQq;

1.128
date	2014.06.08.14.17.52;	author miod;	state Exp;
branches;
next	1.127;
commitid	OoDdbmqot8BB0Q5E;

1.127
date	2014.04.07.10.04.17;	author mpi;	state Exp;
branches;
next	1.126;

1.126
date	2014.03.30.21.54.48;	author guenther;	state Exp;
branches;
next	1.125;

1.125
date	2014.03.28.08.33.51;	author sthen;	state Exp;
branches;
next	1.124;

1.124
date	2014.03.27.13.27.28;	author mpi;	state Exp;
branches;
next	1.123;

1.123
date	2014.03.18.07.01.21;	author guenther;	state Exp;
branches;
next	1.122;

1.122
date	2014.01.21.23.57.56;	author guenther;	state Exp;
branches;
next	1.121;

1.121
date	2014.01.11.14.33.48;	author bluhm;	state Exp;
branches;
next	1.120;

1.120
date	2013.12.10.21.44.50;	author mikeb;	state Exp;
branches;
next	1.119;

1.119
date	2013.08.27.03.32.11;	author deraadt;	state Exp;
branches;
next	1.118;

1.118
date	2013.04.05.08.25.30;	author tedu;	state Exp;
branches;
next	1.117;

1.117
date	2013.04.04.18.13.43;	author bluhm;	state Exp;
branches;
next	1.116;

1.116
date	2013.03.27.15.41.04;	author bluhm;	state Exp;
branches;
next	1.115;

1.115
date	2013.03.19.20.07.14;	author bluhm;	state Exp;
branches;
next	1.114;

1.114
date	2013.02.16.14.34.52;	author bluhm;	state Exp;
branches;
next	1.113;

1.113
date	2013.01.17.16.30.10;	author bluhm;	state Exp;
branches;
next	1.112;

1.112
date	2013.01.15.21.48.32;	author bluhm;	state Exp;
branches;
next	1.111;

1.111
date	2013.01.15.11.12.57;	author bluhm;	state Exp;
branches;
next	1.110;

1.110
date	2012.12.31.13.46.49;	author bluhm;	state Exp;
branches;
next	1.109;

1.109
date	2012.10.05.01.30.28;	author yasuoka;	state Exp;
branches;
next	1.108;

1.108
date	2012.09.20.12.34.18;	author bluhm;	state Exp;
branches;
next	1.107;

1.107
date	2012.09.19.20.00.32;	author bluhm;	state Exp;
branches;
next	1.106;

1.106
date	2012.09.19.19.41.29;	author bluhm;	state Exp;
branches;
next	1.105;

1.105
date	2012.09.17.14.33.56;	author bluhm;	state Exp;
branches;
next	1.104;

1.104
date	2012.07.22.18.11.54;	author guenther;	state Exp;
branches;
next	1.103;

1.103
date	2012.07.10.11.42.53;	author guenther;	state Exp;
branches;
next	1.102;

1.102
date	2012.07.10.09.40.25;	author claudio;	state Exp;
branches;
next	1.101;

1.101
date	2012.07.07.18.48.19;	author bluhm;	state Exp;
branches;
next	1.100;

1.100
date	2012.04.24.16.35.08;	author deraadt;	state Exp;
branches;
next	1.99;

1.99
date	2012.04.22.05.43.14;	author guenther;	state Exp;
branches;
next	1.98;

1.98
date	2012.03.23.15.51.26;	author guenther;	state Exp;
branches;
next	1.97;

1.97
date	2012.03.17.10.16.41;	author dlg;	state Exp;
branches;
next	1.96;

1.96
date	2012.03.14.21.27.01;	author kettenis;	state Exp;
branches;
next	1.95;

1.95
date	2011.08.23.13.44.58;	author bluhm;	state Exp;
branches;
next	1.94;

1.94
date	2011.07.04.00.33.36;	author mikeb;	state Exp;
branches;
next	1.93;

1.93
date	2011.07.02.22.20.08;	author nicm;	state Exp;
branches;
next	1.92;

1.92
date	2011.05.02.13.48.38;	author mikeb;	state Exp;
branches;
next	1.91;

1.91
date	2011.04.19.22.33.08;	author bluhm;	state Exp;
branches;
next	1.90;

1.90
date	2011.04.04.21.08.26;	author claudio;	state Exp;
branches;
next	1.89;

1.89
date	2011.04.04.11.10.26;	author claudio;	state Exp;
branches;
next	1.88;

1.88
date	2011.03.14.01.06.20;	author bluhm;	state Exp;
branches;
next	1.87;

1.87
date	2011.03.12.18.31.41;	author bluhm;	state Exp;
branches;
next	1.86;

1.86
date	2011.02.28.16.29.42;	author bluhm;	state Exp;
branches;
next	1.85;

1.85
date	2011.01.07.17.50.42;	author bluhm;	state Exp;
branches;
next	1.84;

1.84
date	2010.09.24.02.59.45;	author claudio;	state Exp;
branches;
next	1.83;

1.83
date	2010.07.03.04.44.51;	author guenther;	state Exp;
branches;
next	1.82;

1.82
date	2010.07.02.19.57.15;	author tedu;	state Exp;
branches;
next	1.81;

1.81
date	2010.07.01.18.47.45;	author deraadt;	state Exp;
branches;
next	1.80;

1.80
date	2010.06.30.19.57.05;	author deraadt;	state Exp;
branches;
next	1.79;

1.79
date	2009.10.31.12.00.08;	author fgsch;	state Exp;
branches;
next	1.78;

1.78
date	2009.08.10.16.49.38;	author thib;	state Exp;
branches;
next	1.77;

1.77
date	2009.06.05.00.05.21;	author claudio;	state Exp;
branches;
next	1.76;

1.76
date	2009.03.15.19.40.41;	author miod;	state Exp;
branches;
next	1.75;

1.75
date	2009.02.22.07.47.22;	author otto;	state Exp;
branches;
next	1.74;

1.74
date	2009.01.13.13.36.12;	author blambert;	state Exp;
branches;
next	1.73;

1.73
date	2008.10.09.16.00.05;	author deraadt;	state Exp;
branches;
next	1.72;

1.72
date	2008.08.07.17.43.37;	author reyk;	state Exp;
branches;
next	1.71;

1.71
date	2008.06.14.10.55.21;	author mk;	state Exp;
branches;
next	1.70;

1.70
date	2008.05.23.15.51.12;	author thib;	state Exp;
branches;
next	1.69;

1.69
date	2008.05.09.02.52.15;	author markus;	state Exp;
branches;
next	1.68;

1.68
date	2008.05.02.06.49.32;	author ckuethe;	state Exp;
branches;
next	1.67;

1.67
date	2007.12.20.17.16.50;	author chl;	state Exp;
branches;
next	1.66;

1.66
date	2007.02.26.23.53.33;	author kurt;	state Exp;
branches;
next	1.65;

1.65
date	2007.02.14.00.53.48;	author jsg;	state Exp;
branches;
next	1.64;

1.64
date	2006.06.10.17.05.17;	author beck;	state Exp;
branches;
next	1.63;

1.63
date	2006.03.04.22.40.15;	author brad;	state Exp;
branches;
next	1.62;

1.62
date	2006.01.05.05.05.06;	author jsg;	state Exp;
branches;
next	1.61;

1.61
date	2005.09.16.16.44.43;	author deraadt;	state Exp;
branches;
next	1.60;

1.60
date	2005.09.10.19.13.32;	author deraadt;	state Exp;
branches;
next	1.59;

1.59
date	2005.08.11.18.20.10;	author millert;	state Exp;
branches;
next	1.58;

1.58
date	2005.05.27.17.16.13;	author dhartmei;	state Exp;
branches;
next	1.57;

1.57
date	2005.05.27.04.55.27;	author mcbride;	state Exp;
branches;
next	1.56;

1.56
date	2004.11.18.15.09.07;	author markus;	state Exp;
branches;
next	1.55;

1.55
date	2004.09.16.13.11.01;	author markus;	state Exp;
branches;
next	1.54;

1.54
date	2004.07.28.15.12.55;	author millert;	state Exp;
branches;
next	1.53;

1.53
date	2004.04.19.22.39.07;	author deraadt;	state Exp;
branches;
next	1.52;

1.52
date	2004.04.01.23.56.05;	author tedu;	state Exp;
branches;
next	1.51;

1.51
date	2003.07.21.22.44.50;	author tedu;	state Exp;
branches;
next	1.50;

1.50
date	2003.06.02.23.28.07;	author millert;	state Exp;
branches;
next	1.49;

1.49
date	2003.02.03.21.22.09;	author deraadt;	state Exp;
branches;
next	1.48;

1.48
date	2002.11.27.19.39.15;	author millert;	state Exp;
branches;
next	1.47;

1.47
date	2002.11.27.13.31.09;	author mickey;	state Exp;
branches;
next	1.46;

1.46
date	2002.08.08.19.18.12;	author provos;	state Exp;
branches;
next	1.45;

1.45
date	2002.08.08.18.26.37;	author todd;	state Exp;
branches;
next	1.44;

1.44
date	2002.08.08.17.07.32;	author provos;	state Exp;
branches;
next	1.43;

1.43
date	2002.06.11.05.07.43;	author art;	state Exp;
branches;
next	1.42;

1.42
date	2002.05.11.00.06.33;	author deraadt;	state Exp;
branches;
next	1.41;

1.41
date	2002.02.05.22.04.43;	author nordin;	state Exp;
branches;
next	1.40;

1.40
date	2002.01.23.00.39.48;	author art;	state Exp;
branches;
next	1.39;

1.39
date	2001.11.28.17.18.00;	author ericj;	state Exp;
branches
	1.39.2.1;
next	1.38;

1.38
date	2001.11.27.22.53.19;	author provos;	state Exp;
branches;
next	1.37;

1.37
date	2001.11.27.17.55.39;	author provos;	state Exp;
branches;
next	1.36;

1.36
date	2001.11.27.15.51.36;	author provos;	state Exp;
branches;
next	1.35;

1.35
date	2001.06.22.14.14.09;	author deraadt;	state Exp;
branches;
next	1.34;

1.34
date	2001.05.25.22.08.23;	author itojun;	state Exp;
branches;
next	1.33;

1.33
date	2001.03.06.19.42.43;	author provos;	state Exp;
branches;
next	1.32;

1.32
date	2001.03.06.17.06.23;	author provos;	state Exp;
branches;
next	1.31;

1.31
date	2001.03.01.20.54.34;	author provos;	state Exp;
branches;
next	1.30;

1.30
date	2001.02.07.12.20.42;	author itojun;	state Exp;
branches;
next	1.29;

1.29
date	2001.01.23.02.18.55;	author itojun;	state Exp;
branches;
next	1.28;

1.28
date	2000.11.16.20.02.19;	author provos;	state Exp;
branches;
next	1.27;

1.27
date	99.10.14.08.18.49;	author cmetz;	state Exp;
branches
	1.27.4.1;
next	1.26;

1.26
date	99.02.19.15.06.52;	author millert;	state Exp;
branches;
next	1.25;

1.25
date	99.02.18.22.56.58;	author deraadt;	state Exp;
branches;
next	1.24;

1.24
date	99.02.05.00.40.22;	author deraadt;	state Exp;
branches;
next	1.23;

1.23
date	99.01.21.03.27.42;	author millert;	state Exp;
branches;
next	1.22;

1.22
date	98.07.28.00.13.07;	author millert;	state Exp;
branches;
next	1.21;

1.21
date	98.02.14.10.55.09;	author deraadt;	state Exp;
branches;
next	1.20;

1.20
date	98.01.06.23.49.48;	author deraadt;	state Exp;
branches;
next	1.19;

1.19
date	97.11.15.19.57.51;	author deraadt;	state Exp;
branches;
next	1.18;

1.18
date	97.11.11.18.22.49;	author deraadt;	state Exp;
branches;
next	1.17;

1.17
date	97.08.31.20.42.24;	author deraadt;	state Exp;
branches;
next	1.16;

1.16
date	97.08.31.06.29.35;	author deraadt;	state Exp;
branches;
next	1.15;

1.15
date	97.06.29.18.14.35;	author deraadt;	state Exp;
branches;
next	1.14;

1.14
date	97.06.23.01.42.04;	author deraadt;	state Exp;
branches;
next	1.13;

1.13
date	97.06.23.00.22.03;	author deraadt;	state Exp;
branches;
next	1.12;

1.12
date	97.06.06.11.12.13;	author deraadt;	state Exp;
branches;
next	1.11;

1.11
date	97.02.28.04.03.45;	author angelos;	state Exp;
branches;
next	1.10;

1.10
date	97.02.28.03.20.38;	author angelos;	state Exp;
branches;
next	1.9;

1.9
date	97.02.28.02.56.50;	author angelos;	state Exp;
branches;
next	1.8;

1.8
date	96.12.16.14.30.17;	author deraadt;	state Exp;
branches;
next	1.7;

1.7
date	96.09.20.22.53.10;	author deraadt;	state Exp;
branches;
next	1.6;

1.6
date	96.08.24.04.56.36;	author deraadt;	state Exp;
branches;
next	1.5;

1.5
date	96.08.14.07.26.21;	author deraadt;	state Exp;
branches;
next	1.4;

1.4
date	96.08.05.01.00.53;	author deraadt;	state Exp;
branches;
next	1.3;

1.3
date	96.03.03.17.20.19;	author niklas;	state Exp;
branches;
next	1.2;

1.2
date	96.03.03.04.44.06;	author mickey;	state Exp;
branches;
next	1.1;

1.1
date	95.10.18.08.52.47;	author deraadt;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	95.10.18.08.52.47;	author deraadt;	state Exp;
branches;
next	;

1.27.4.1
date	2001.05.14.22.32.45;	author niklas;	state Exp;
branches;
next	1.27.4.2;

1.27.4.2
date	2001.07.04.10.48.45;	author niklas;	state Exp;
branches;
next	1.27.4.3;

1.27.4.3
date	2001.12.05.01.02.39;	author niklas;	state Exp;
branches;
next	1.27.4.4;

1.27.4.4
date	2002.03.06.02.13.23;	author niklas;	state Exp;
branches;
next	1.27.4.5;

1.27.4.5
date	2003.03.28.00.41.27;	author niklas;	state Exp;
branches;
next	1.27.4.6;

1.27.4.6
date	2003.06.07.11.03.40;	author ho;	state Exp;
branches;
next	1.27.4.7;

1.27.4.7
date	2004.02.19.10.56.38;	author niklas;	state Exp;
branches;
next	1.27.4.8;

1.27.4.8
date	2004.06.05.23.13.02;	author niklas;	state Exp;
branches;
next	;

1.39.2.1
date	2002.01.31.22.55.41;	author niklas;	state Exp;
branches;
next	1.39.2.2;

1.39.2.2
date	2002.06.11.03.29.40;	author art;	state Exp;
branches;
next	1.39.2.3;

1.39.2.3
date	2002.10.29.00.36.44;	author art;	state Exp;
branches;
next	1.39.2.4;

1.39.2.4
date	2003.05.19.22.31.57;	author tedu;	state Exp;
branches;
next	;

1.141.4.1
date	2016.07.21.14.31.29;	author tedu;	state Exp;
branches;
next	;
commitid	MLuylNuqysbESCPO;

1.149.2.1
date	2016.07.14.02.56.15;	author tedu;	state Exp;
branches;
next	;
commitid	0mSmzl4NTWthAxT7;


desc
@@


1.193
log
@Revert grabbing the socket lock in kqueue filters.

It is unsafe to sleep while iterating the list of pending events in
kqueue_scan().

Reported by abieber@@ and juanfra@@
@
text
@/*	$OpenBSD: uipc_socket.c,v 1.192 2017/07/04 12:58:32 mpi Exp $	*/
/*	$NetBSD: uipc_socket.c,v 1.21 1996/02/04 02:17:52 christos Exp $	*/

/*
 * Copyright (c) 1982, 1986, 1988, 1990, 1993
 *	The Regents of the University of California.  All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. Neither the name of the University nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 *	@@(#)uipc_socket.c	8.3 (Berkeley) 4/15/94
 */

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/proc.h>
#include <sys/file.h>
#include <sys/filedesc.h>
#include <sys/malloc.h>
#include <sys/mbuf.h>
#include <sys/domain.h>
#include <sys/kernel.h>
#include <sys/event.h>
#include <sys/protosw.h>
#include <sys/socket.h>
#include <sys/unpcb.h>
#include <sys/socketvar.h>
#include <sys/signalvar.h>
#include <net/if.h>
#include <sys/pool.h>

#ifdef DDB
#include <machine/db_machdep.h>
#endif

void	sbsync(struct sockbuf *, struct mbuf *);

int	sosplice(struct socket *, int, off_t, struct timeval *);
void	sounsplice(struct socket *, struct socket *, int);
void	soidle(void *);
void	sotask(void *);
int	somove(struct socket *, int);

void	filt_sordetach(struct knote *kn);
int	filt_soread(struct knote *kn, long hint);
void	filt_sowdetach(struct knote *kn);
int	filt_sowrite(struct knote *kn, long hint);
int	filt_solisten(struct knote *kn, long hint);

struct filterops solisten_filtops =
	{ 1, NULL, filt_sordetach, filt_solisten };
struct filterops soread_filtops =
	{ 1, NULL, filt_sordetach, filt_soread };
struct filterops sowrite_filtops =
	{ 1, NULL, filt_sowdetach, filt_sowrite };


#ifndef SOMINCONN
#define SOMINCONN 80
#endif /* SOMINCONN */

int	somaxconn = SOMAXCONN;
int	sominconn = SOMINCONN;

struct pool socket_pool;
#ifdef SOCKET_SPLICE
struct pool sosplice_pool;
struct taskq *sosplice_taskq;
#endif

void
soinit(void)
{
	pool_init(&socket_pool, sizeof(struct socket), 0, IPL_SOFTNET, 0,
	    "sockpl", NULL);
#ifdef SOCKET_SPLICE
	pool_init(&sosplice_pool, sizeof(struct sosplice), 0, IPL_SOFTNET, 0,
	    "sosppl", NULL);
#endif
}

/*
 * Socket operation routines.
 * These routines are called by the routines in
 * sys_socket.c or from a system process, and
 * implement the semantics of socket operations by
 * switching out to the protocol specific routines.
 */
int
socreate(int dom, struct socket **aso, int type, int proto)
{
	struct proc *p = curproc;		/* XXX */
	struct protosw *prp;
	struct socket *so;
	int error, s;

	if (proto)
		prp = pffindproto(dom, proto, type);
	else
		prp = pffindtype(dom, type);
	if (prp == NULL || prp->pr_attach == NULL)
		return (EPROTONOSUPPORT);
	if (prp->pr_type != type)
		return (EPROTOTYPE);
	so = pool_get(&socket_pool, PR_WAITOK | PR_ZERO);
	TAILQ_INIT(&so->so_q0);
	TAILQ_INIT(&so->so_q);
	so->so_type = type;
	if (suser(p, 0) == 0)
		so->so_state = SS_PRIV;
	so->so_ruid = p->p_ucred->cr_ruid;
	so->so_euid = p->p_ucred->cr_uid;
	so->so_rgid = p->p_ucred->cr_rgid;
	so->so_egid = p->p_ucred->cr_gid;
	so->so_cpid = p->p_p->ps_pid;
	so->so_proto = prp;

	s = solock(so);
	error = (*prp->pr_attach)(so, proto);
	if (error) {
		so->so_state |= SS_NOFDREF;
		sofree(so);
		sounlock(s);
		return (error);
	}
	sounlock(s);
	*aso = so;
	return (0);
}

int
sobind(struct socket *so, struct mbuf *nam, struct proc *p)
{
	int s, error;

	s = solock(so);
	error = (*so->so_proto->pr_usrreq)(so, PRU_BIND, NULL, nam, NULL, p);
	sounlock(s);
	return (error);
}

int
solisten(struct socket *so, int backlog)
{
	int s, error;

	if (so->so_state & (SS_ISCONNECTED|SS_ISCONNECTING|SS_ISDISCONNECTING))
		return (EOPNOTSUPP);
#ifdef SOCKET_SPLICE
	if (isspliced(so) || issplicedback(so))
		return (EOPNOTSUPP);
#endif /* SOCKET_SPLICE */
	s = solock(so);
	error = (*so->so_proto->pr_usrreq)(so, PRU_LISTEN, NULL, NULL, NULL,
	    curproc);
	if (error) {
		sounlock(s);
		return (error);
	}
	if (TAILQ_FIRST(&so->so_q) == NULL)
		so->so_options |= SO_ACCEPTCONN;
	if (backlog < 0 || backlog > somaxconn)
		backlog = somaxconn;
	if (backlog < sominconn)
		backlog = sominconn;
	so->so_qlimit = backlog;
	sounlock(s);
	return (0);
}

void
sofree(struct socket *so)
{
	soassertlocked(so);

	if (so->so_pcb || (so->so_state & SS_NOFDREF) == 0)
		return;
	if (so->so_head) {
		/*
		 * We must not decommission a socket that's on the accept(2)
		 * queue.  If we do, then accept(2) may hang after select(2)
		 * indicated that the listening socket was ready.
		 */
		if (!soqremque(so, 0))
			return;
	}
#ifdef SOCKET_SPLICE
	if (so->so_sp) {
		if (issplicedback(so))
			sounsplice(so->so_sp->ssp_soback, so,
			    so->so_sp->ssp_soback != so);
		if (isspliced(so))
			sounsplice(so, so->so_sp->ssp_socket, 0);
		pool_put(&sosplice_pool, so->so_sp);
		so->so_sp = NULL;
	}
#endif /* SOCKET_SPLICE */
	sbrelease(so, &so->so_snd);
	sorflush(so);
	pool_put(&socket_pool, so);
}

/*
 * Close a socket on last file table reference removal.
 * Initiate disconnect if connected.
 * Free socket when disconnect complete.
 */
int
soclose(struct socket *so)
{
	struct socket *so2;
	int s, error = 0;

	s = solock(so);
	if (so->so_options & SO_ACCEPTCONN) {
		while ((so2 = TAILQ_FIRST(&so->so_q0)) != NULL) {
			(void) soqremque(so2, 0);
			(void) soabort(so2);
		}
		while ((so2 = TAILQ_FIRST(&so->so_q)) != NULL) {
			(void) soqremque(so2, 1);
			(void) soabort(so2);
		}
	}
	if (so->so_pcb == 0)
		goto discard;
	if (so->so_state & SS_ISCONNECTED) {
		if ((so->so_state & SS_ISDISCONNECTING) == 0) {
			error = sodisconnect(so);
			if (error)
				goto drop;
		}
		if (so->so_options & SO_LINGER) {
			if ((so->so_state & SS_ISDISCONNECTING) &&
			    (so->so_state & SS_NBIO))
				goto drop;
			while (so->so_state & SS_ISCONNECTED) {
				error = sosleep(so, &so->so_timeo,
				    PSOCK | PCATCH, "netcls",
				    so->so_linger * hz);
				if (error)
					break;
			}
		}
	}
drop:
	if (so->so_pcb) {
		int error2 = (*so->so_proto->pr_usrreq)(so, PRU_DETACH, NULL,
		    NULL, NULL, curproc);
		if (error == 0)
			error = error2;
	}
discard:
	if (so->so_state & SS_NOFDREF)
		panic("soclose NOFDREF: so %p, so_type %d", so, so->so_type);
	so->so_state |= SS_NOFDREF;
	sofree(so);
	sounlock(s);
	return (error);
}

int
soabort(struct socket *so)
{
	soassertlocked(so);

	return (*so->so_proto->pr_usrreq)(so, PRU_ABORT, NULL, NULL, NULL,
	   curproc);
}

int
soaccept(struct socket *so, struct mbuf *nam)
{
	int error = 0;

	soassertlocked(so);

	if ((so->so_state & SS_NOFDREF) == 0)
		panic("soaccept !NOFDREF: so %p, so_type %d", so, so->so_type);
	so->so_state &= ~SS_NOFDREF;
	if ((so->so_state & SS_ISDISCONNECTED) == 0 ||
	    (so->so_proto->pr_flags & PR_ABRTACPTDIS) == 0)
		error = (*so->so_proto->pr_usrreq)(so, PRU_ACCEPT, NULL,
		    nam, NULL, curproc);
	else
		error = ECONNABORTED;
	return (error);
}

int
soconnect(struct socket *so, struct mbuf *nam)
{
	int s, error;

	if (so->so_options & SO_ACCEPTCONN)
		return (EOPNOTSUPP);
	s = solock(so);
	/*
	 * If protocol is connection-based, can only connect once.
	 * Otherwise, if connected, try to disconnect first.
	 * This allows user to disconnect by connecting to, e.g.,
	 * a null address.
	 */
	if (so->so_state & (SS_ISCONNECTED|SS_ISCONNECTING) &&
	    ((so->so_proto->pr_flags & PR_CONNREQUIRED) ||
	    (error = sodisconnect(so))))
		error = EISCONN;
	else
		error = (*so->so_proto->pr_usrreq)(so, PRU_CONNECT,
		    NULL, nam, NULL, curproc);
	sounlock(s);
	return (error);
}

int
soconnect2(struct socket *so1, struct socket *so2)
{
	int s, error;

	s = solock(so1);
	error = (*so1->so_proto->pr_usrreq)(so1, PRU_CONNECT2, NULL,
	    (struct mbuf *)so2, NULL, curproc);
	sounlock(s);
	return (error);
}

int
sodisconnect(struct socket *so)
{
	int error;

	soassertlocked(so);

	if ((so->so_state & SS_ISCONNECTED) == 0)
		return (ENOTCONN);
	if (so->so_state & SS_ISDISCONNECTING)
		return (EALREADY);
	error = (*so->so_proto->pr_usrreq)(so, PRU_DISCONNECT, NULL, NULL,
	    NULL, curproc);
	return (error);
}

int m_getuio(struct mbuf **, int, long, struct uio *);

#define	SBLOCKWAIT(f)	(((f) & MSG_DONTWAIT) ? M_NOWAIT : M_WAITOK)
/*
 * Send on a socket.
 * If send must go all at once and message is larger than
 * send buffering, then hard error.
 * Lock against other senders.
 * If must go all at once and not enough room now, then
 * inform user that this would block and do nothing.
 * Otherwise, if nonblocking, send as much as possible.
 * The data to be sent is described by "uio" if nonzero,
 * otherwise by the mbuf chain "top" (which must be null
 * if uio is not).  Data provided in mbuf chain must be small
 * enough to send all at once.
 *
 * Returns nonzero on error, timeout or signal; callers
 * must check for short counts if EINTR/ERESTART are returned.
 * Data and control buffers are freed on return.
 */
int
sosend(struct socket *so, struct mbuf *addr, struct uio *uio, struct mbuf *top,
    struct mbuf *control, int flags)
{
	long space, clen = 0;
	size_t resid;
	int error, s;
	int atomic = sosendallatonce(so) || top;

	if (uio)
		resid = uio->uio_resid;
	else
		resid = top->m_pkthdr.len;
	/* MSG_EOR on a SOCK_STREAM socket is invalid. */
	if (so->so_type == SOCK_STREAM && (flags & MSG_EOR)) {
		error = EINVAL;
		goto out;
	}
	if (uio && uio->uio_procp)
		uio->uio_procp->p_ru.ru_msgsnd++;
	if (control) {
		/*
		 * In theory clen should be unsigned (since control->m_len is).
		 * However, space must be signed, as it might be less than 0
		 * if we over-committed, and we must use a signed comparison
		 * of space and clen.
		 */
		clen = control->m_len;
		/* reserve extra space for AF_LOCAL's internalize */
		if (so->so_proto->pr_domain->dom_family == AF_LOCAL &&
		    clen >= CMSG_ALIGN(sizeof(struct cmsghdr)) &&
		    mtod(control, struct cmsghdr *)->cmsg_type == SCM_RIGHTS)
			clen = CMSG_SPACE(
			    (clen - CMSG_ALIGN(sizeof(struct cmsghdr))) *
			    (sizeof(struct fdpass) / sizeof(int)));
	}

#define	snderr(errno)	{ error = errno; goto release; }

	s = solock(so);
restart:
	if ((error = sblock(so, &so->so_snd, SBLOCKWAIT(flags))) != 0)
		goto out;
	so->so_state |= SS_ISSENDING;
	do {
		if (so->so_state & SS_CANTSENDMORE)
			snderr(EPIPE);
		if (so->so_error) {
			error = so->so_error;
			so->so_error = 0;
			snderr(error);
		}
		if ((so->so_state & SS_ISCONNECTED) == 0) {
			if (so->so_proto->pr_flags & PR_CONNREQUIRED) {
				if (!(resid == 0 && clen != 0))
					snderr(ENOTCONN);
			} else if (addr == 0)
				snderr(EDESTADDRREQ);
		}
		space = sbspace(so, &so->so_snd);
		if (flags & MSG_OOB)
			space += 1024;
		if ((atomic && resid > so->so_snd.sb_hiwat) ||
		    (so->so_proto->pr_domain->dom_family != AF_LOCAL &&
		    clen > so->so_snd.sb_hiwat))
			snderr(EMSGSIZE);
		if (space < clen ||
		    (space - clen < resid &&
		    (atomic || space < so->so_snd.sb_lowat))) {
			if ((so->so_state & SS_NBIO) || (flags & MSG_DONTWAIT))
				snderr(EWOULDBLOCK);
			sbunlock(&so->so_snd);
			error = sbwait(so, &so->so_snd);
			so->so_state &= ~SS_ISSENDING;
			if (error)
				goto out;
			goto restart;
		}
		space -= clen;
		do {
			if (uio == NULL) {
				/*
				 * Data is prepackaged in "top".
				 */
				resid = 0;
				if (flags & MSG_EOR)
					top->m_flags |= M_EOR;
			} else {
				sounlock(s);
				error = m_getuio(&top, atomic, space, uio);
				s = solock(so);
				if (error)
					goto release;
				space -= top->m_pkthdr.len;
				resid = uio->uio_resid;
				if (flags & MSG_EOR)
					top->m_flags |= M_EOR;
			}
			if (resid == 0)
				so->so_state &= ~SS_ISSENDING;
			if (top && so->so_options & SO_ZEROIZE)
				top->m_flags |= M_ZEROIZE;
			error = (*so->so_proto->pr_usrreq)(so,
			    (flags & MSG_OOB) ? PRU_SENDOOB : PRU_SEND,
			    top, addr, control, curproc);
			clen = 0;
			control = NULL;
			top = NULL;
			if (error)
				goto release;
		} while (resid && space > 0);
	} while (resid);

release:
	so->so_state &= ~SS_ISSENDING;
	sbunlock(&so->so_snd);
out:
	sounlock(s);
	m_freem(top);
	m_freem(control);
	return (error);
}

int
m_getuio(struct mbuf **mp, int atomic, long space, struct uio *uio)
{
	struct mbuf *m, *top = NULL;
	struct mbuf **nextp = &top;
	u_long len, mlen;
	size_t resid = uio->uio_resid;
	int error;

	do {
		if (top == NULL) {
			MGETHDR(m, M_WAIT, MT_DATA);
			mlen = MHLEN;
			m->m_pkthdr.len = 0;
			m->m_pkthdr.ph_ifidx = 0;
		} else {
			MGET(m, M_WAIT, MT_DATA);
			mlen = MLEN;
		}
		/* chain mbuf together */
		*nextp = m;
		nextp = &m->m_next;

		resid = ulmin(resid, space);
		if (resid >= MINCLSIZE) {
			MCLGETI(m, M_NOWAIT, NULL, ulmin(resid, MAXMCLBYTES));
			if ((m->m_flags & M_EXT) == 0)
				MCLGETI(m, M_NOWAIT, NULL, MCLBYTES);
			if ((m->m_flags & M_EXT) == 0)
				goto nopages;
			mlen = m->m_ext.ext_size;
			len = ulmin(mlen, resid);
			/*
			 * For datagram protocols, leave room
			 * for protocol headers in first mbuf.
			 */
			if (atomic && top == NULL && len < mlen - max_hdr)
				m->m_data += max_hdr;
		} else {
nopages:
			len = ulmin(mlen, resid);
			/*
			 * For datagram protocols, leave room
			 * for protocol headers in first mbuf.
			 */
			if (atomic && top == NULL && len < mlen - max_hdr)
				MH_ALIGN(m, len);
		}

		error = uiomove(mtod(m, caddr_t), len, uio);
		if (error) {
			m_freem(top);
			return (error);
		}

		/* adjust counters */
		resid = uio->uio_resid;
		space -= len;
		m->m_len = len;
		top->m_pkthdr.len += len;

		/* Is there more space and more data? */
	} while (space > 0 && resid > 0);

	*mp = top;
	return 0;
}

/*
 * Following replacement or removal of the first mbuf on the first
 * mbuf chain of a socket buffer, push necessary state changes back
 * into the socket buffer so that other consumers see the values
 * consistently.  'nextrecord' is the callers locally stored value of
 * the original value of sb->sb_mb->m_nextpkt which must be restored
 * when the lead mbuf changes.  NOTE: 'nextrecord' may be NULL.
 */
void
sbsync(struct sockbuf *sb, struct mbuf *nextrecord)
{

	/*
	 * First, update for the new value of nextrecord.  If necessary,
	 * make it the first record.
	 */
	if (sb->sb_mb != NULL)
		sb->sb_mb->m_nextpkt = nextrecord;
	else
		sb->sb_mb = nextrecord;

	/*
	 * Now update any dependent socket buffer fields to reflect
	 * the new state.  This is an inline of SB_EMPTY_FIXUP, with
	 * the addition of a second clause that takes care of the
	 * case where sb_mb has been updated, but remains the last
	 * record.
	 */
	if (sb->sb_mb == NULL) {
		sb->sb_mbtail = NULL;
		sb->sb_lastrecord = NULL;
	} else if (sb->sb_mb->m_nextpkt == NULL)
		sb->sb_lastrecord = sb->sb_mb;
}

/*
 * Implement receive operations on a socket.
 * We depend on the way that records are added to the sockbuf
 * by sbappend*.  In particular, each record (mbufs linked through m_next)
 * must begin with an address if the protocol so specifies,
 * followed by an optional mbuf or mbufs containing ancillary data,
 * and then zero or more mbufs of data.
 * In order to avoid blocking network for the entire time here, we release
 * the solock() while doing the actual copy to user space.
 * Although the sockbuf is locked, new data may still be appended,
 * and thus we must maintain consistency of the sockbuf during that time.
 *
 * The caller may receive the data as a single mbuf chain by supplying
 * an mbuf **mp0 for use in returning the chain.  The uio is then used
 * only for the count in uio_resid.
 */
int
soreceive(struct socket *so, struct mbuf **paddr, struct uio *uio,
    struct mbuf **mp0, struct mbuf **controlp, int *flagsp,
    socklen_t controllen)
{
	struct mbuf *m, **mp;
	struct mbuf *cm;
	u_long len, offset, moff;
	int flags, error, s, type, uio_error = 0;
	struct protosw *pr = so->so_proto;
	struct mbuf *nextrecord;
	size_t resid, orig_resid = uio->uio_resid;

	mp = mp0;
	if (paddr)
		*paddr = 0;
	if (controlp)
		*controlp = 0;
	if (flagsp)
		flags = *flagsp &~ MSG_EOR;
	else
		flags = 0;
	if (so->so_state & SS_NBIO)
		flags |= MSG_DONTWAIT;
	if (flags & MSG_OOB) {
		m = m_get(M_WAIT, MT_DATA);
		s = solock(so);
		error = (*pr->pr_usrreq)(so, PRU_RCVOOB, m,
		    (struct mbuf *)(long)(flags & MSG_PEEK), NULL, curproc);
		sounlock(s);
		if (error)
			goto bad;
		do {
			error = uiomove(mtod(m, caddr_t),
			    ulmin(uio->uio_resid, m->m_len), uio);
			m = m_free(m);
		} while (uio->uio_resid && error == 0 && m);
bad:
		m_freem(m);
		return (error);
	}
	if (mp)
		*mp = NULL;

restart:
	s = solock(so);
	if ((error = sblock(so, &so->so_rcv, SBLOCKWAIT(flags))) != 0) {
		sounlock(s);
		return (error);
	}

	m = so->so_rcv.sb_mb;
#ifdef SOCKET_SPLICE
	if (isspliced(so))
		m = NULL;
#endif /* SOCKET_SPLICE */
	/*
	 * If we have less data than requested, block awaiting more
	 * (subject to any timeout) if:
	 *   1. the current count is less than the low water mark,
	 *   2. MSG_WAITALL is set, and it is possible to do the entire
	 *	receive operation at once if we block (resid <= hiwat), or
	 *   3. MSG_DONTWAIT is not set.
	 * If MSG_WAITALL is set but resid is larger than the receive buffer,
	 * we have to do the receive in sections, and thus risk returning
	 * a short count if a timeout or signal occurs after we start.
	 */
	if (m == NULL || (((flags & MSG_DONTWAIT) == 0 &&
	    so->so_rcv.sb_cc < uio->uio_resid) &&
	    (so->so_rcv.sb_cc < so->so_rcv.sb_lowat ||
	    ((flags & MSG_WAITALL) && uio->uio_resid <= so->so_rcv.sb_hiwat)) &&
	    m->m_nextpkt == NULL && (pr->pr_flags & PR_ATOMIC) == 0)) {
#ifdef DIAGNOSTIC
		if (m == NULL && so->so_rcv.sb_cc)
#ifdef SOCKET_SPLICE
		    if (!isspliced(so))
#endif /* SOCKET_SPLICE */
			panic("receive 1: so %p, so_type %d, sb_cc %lu",
			    so, so->so_type, so->so_rcv.sb_cc);
#endif
		if (so->so_error) {
			if (m)
				goto dontblock;
			error = so->so_error;
			if ((flags & MSG_PEEK) == 0)
				so->so_error = 0;
			goto release;
		}
		if (so->so_state & SS_CANTRCVMORE) {
			if (m)
				goto dontblock;
			else if (so->so_rcv.sb_cc == 0)
				goto release;
		}
		for (; m; m = m->m_next)
			if (m->m_type == MT_OOBDATA  || (m->m_flags & M_EOR)) {
				m = so->so_rcv.sb_mb;
				goto dontblock;
			}
		if ((so->so_state & (SS_ISCONNECTED|SS_ISCONNECTING)) == 0 &&
		    (so->so_proto->pr_flags & PR_CONNREQUIRED)) {
			error = ENOTCONN;
			goto release;
		}
		if (uio->uio_resid == 0 && controlp == NULL)
			goto release;
		if ((so->so_state & SS_NBIO) || (flags & MSG_DONTWAIT)) {
			error = EWOULDBLOCK;
			goto release;
		}
		SBLASTRECORDCHK(&so->so_rcv, "soreceive sbwait 1");
		SBLASTMBUFCHK(&so->so_rcv, "soreceive sbwait 1");
		sbunlock(&so->so_rcv);
		error = sbwait(so, &so->so_rcv);
		sounlock(s);
		if (error)
			return (error);
		goto restart;
	}
dontblock:
	/*
	 * On entry here, m points to the first record of the socket buffer.
	 * From this point onward, we maintain 'nextrecord' as a cache of the
	 * pointer to the next record in the socket buffer.  We must keep the
	 * various socket buffer pointers and local stack versions of the
	 * pointers in sync, pushing out modifications before operations that
	 * may sleep, and re-reading them afterwards.
	 *
	 * Otherwise, we will race with the network stack appending new data
	 * or records onto the socket buffer by using inconsistent/stale
	 * versions of the field, possibly resulting in socket buffer
	 * corruption.
	 */
	if (uio->uio_procp)
		uio->uio_procp->p_ru.ru_msgrcv++;
	KASSERT(m == so->so_rcv.sb_mb);
	SBLASTRECORDCHK(&so->so_rcv, "soreceive 1");
	SBLASTMBUFCHK(&so->so_rcv, "soreceive 1");
	nextrecord = m->m_nextpkt;
	if (pr->pr_flags & PR_ADDR) {
#ifdef DIAGNOSTIC
		if (m->m_type != MT_SONAME)
			panic("receive 1a: so %p, so_type %d, m %p, m_type %d",
			    so, so->so_type, m, m->m_type);
#endif
		orig_resid = 0;
		if (flags & MSG_PEEK) {
			if (paddr)
				*paddr = m_copym(m, 0, m->m_len, M_NOWAIT);
			m = m->m_next;
		} else {
			sbfree(&so->so_rcv, m);
			if (paddr) {
				*paddr = m;
				so->so_rcv.sb_mb = m->m_next;
				m->m_next = 0;
				m = so->so_rcv.sb_mb;
			} else {
				so->so_rcv.sb_mb = m_free(m);
				m = so->so_rcv.sb_mb;
			}
			sbsync(&so->so_rcv, nextrecord);
		}
	}
	while (m && m->m_type == MT_CONTROL && error == 0) {
		if (flags & MSG_PEEK) {
			if (controlp)
				*controlp = m_copym(m, 0, m->m_len, M_NOWAIT);
			m = m->m_next;
		} else {
			sbfree(&so->so_rcv, m);
			so->so_rcv.sb_mb = m->m_next;
			m->m_nextpkt = m->m_next = NULL;
			cm = m;
			m = so->so_rcv.sb_mb;
			sbsync(&so->so_rcv, nextrecord);
			if (controlp) {
				if (pr->pr_domain->dom_externalize &&
				    mtod(cm, struct cmsghdr *)->cmsg_type ==
				    SCM_RIGHTS) {
					error =
					    (*pr->pr_domain->dom_externalize)
					    (cm, controllen, flags);
				}
				*controlp = cm;
			} else {
				/*
				 * Dispose of any SCM_RIGHTS message that went
				 * through the read path rather than recv.
				 */
				if (pr->pr_domain->dom_dispose &&
				    mtod(cm, struct cmsghdr *)->cmsg_type == SCM_RIGHTS)
					pr->pr_domain->dom_dispose(cm);
				m_free(cm);
			}
		}
		if (m != NULL)
			nextrecord = so->so_rcv.sb_mb->m_nextpkt;
		else
			nextrecord = so->so_rcv.sb_mb;
		if (controlp) {
			orig_resid = 0;
			controlp = &(*controlp)->m_next;
		}
	}

	/* If m is non-NULL, we have some data to read. */
	if (m) {
		type = m->m_type;
		if (type == MT_OOBDATA)
			flags |= MSG_OOB;
		if (m->m_flags & M_BCAST)
			flags |= MSG_BCAST;
		if (m->m_flags & M_MCAST)
			flags |= MSG_MCAST;
	}
	SBLASTRECORDCHK(&so->so_rcv, "soreceive 2");
	SBLASTMBUFCHK(&so->so_rcv, "soreceive 2");

	moff = 0;
	offset = 0;
	while (m && uio->uio_resid > 0 && error == 0) {
		if (m->m_type == MT_OOBDATA) {
			if (type != MT_OOBDATA)
				break;
		} else if (type == MT_OOBDATA)
			break;
#ifdef DIAGNOSTIC
		else if (m->m_type != MT_DATA && m->m_type != MT_HEADER)
			panic("receive 3: so %p, so_type %d, m %p, m_type %d",
			    so, so->so_type, m, m->m_type);
#endif
		so->so_state &= ~SS_RCVATMARK;
		len = uio->uio_resid;
		if (so->so_oobmark && len > so->so_oobmark - offset)
			len = so->so_oobmark - offset;
		if (len > m->m_len - moff)
			len = m->m_len - moff;
		/*
		 * If mp is set, just pass back the mbufs.
		 * Otherwise copy them out via the uio, then free.
		 * Sockbuf must be consistent here (points to current mbuf,
		 * it points to next record) when we drop priority;
		 * we must note any additions to the sockbuf when we
		 * block interrupts again.
		 */
		if (mp == NULL && uio_error == 0) {
			SBLASTRECORDCHK(&so->so_rcv, "soreceive uiomove");
			SBLASTMBUFCHK(&so->so_rcv, "soreceive uiomove");
			resid = uio->uio_resid;
			sounlock(s);
			uio_error = uiomove(mtod(m, caddr_t) + moff, len, uio);
			s = solock(so);
			if (uio_error)
				uio->uio_resid = resid - len;
		} else
			uio->uio_resid -= len;
		if (len == m->m_len - moff) {
			if (m->m_flags & M_EOR)
				flags |= MSG_EOR;
			if (flags & MSG_PEEK) {
				m = m->m_next;
				moff = 0;
			} else {
				nextrecord = m->m_nextpkt;
				sbfree(&so->so_rcv, m);
				if (mp) {
					*mp = m;
					mp = &m->m_next;
					so->so_rcv.sb_mb = m = m->m_next;
					*mp = NULL;
				} else {
					so->so_rcv.sb_mb = m_free(m);
					m = so->so_rcv.sb_mb;
				}
				/*
				 * If m != NULL, we also know that
				 * so->so_rcv.sb_mb != NULL.
				 */
				KASSERT(so->so_rcv.sb_mb == m);
				if (m) {
					m->m_nextpkt = nextrecord;
					if (nextrecord == NULL)
						so->so_rcv.sb_lastrecord = m;
				} else {
					so->so_rcv.sb_mb = nextrecord;
					SB_EMPTY_FIXUP(&so->so_rcv);
				}
				SBLASTRECORDCHK(&so->so_rcv, "soreceive 3");
				SBLASTMBUFCHK(&so->so_rcv, "soreceive 3");
			}
		} else {
			if (flags & MSG_PEEK)
				moff += len;
			else {
				if (mp)
					*mp = m_copym(m, 0, len, M_WAIT);
				m->m_data += len;
				m->m_len -= len;
				so->so_rcv.sb_cc -= len;
				so->so_rcv.sb_datacc -= len;
			}
		}
		if (so->so_oobmark) {
			if ((flags & MSG_PEEK) == 0) {
				so->so_oobmark -= len;
				if (so->so_oobmark == 0) {
					so->so_state |= SS_RCVATMARK;
					break;
				}
			} else {
				offset += len;
				if (offset == so->so_oobmark)
					break;
			}
		}
		if (flags & MSG_EOR)
			break;
		/*
		 * If the MSG_WAITALL flag is set (for non-atomic socket),
		 * we must not quit until "uio->uio_resid == 0" or an error
		 * termination.  If a signal/timeout occurs, return
		 * with a short count but without error.
		 * Keep sockbuf locked against other readers.
		 */
		while (flags & MSG_WAITALL && m == NULL && uio->uio_resid > 0 &&
		    !sosendallatonce(so) && !nextrecord) {
			if (so->so_error || so->so_state & SS_CANTRCVMORE)
				break;
			SBLASTRECORDCHK(&so->so_rcv, "soreceive sbwait 2");
			SBLASTMBUFCHK(&so->so_rcv, "soreceive sbwait 2");
			error = sbwait(so, &so->so_rcv);
			if (error) {
				sbunlock(&so->so_rcv);
				sounlock(s);
				return (0);
			}
			if ((m = so->so_rcv.sb_mb) != NULL)
				nextrecord = m->m_nextpkt;
		}
	}

	if (m && pr->pr_flags & PR_ATOMIC) {
		flags |= MSG_TRUNC;
		if ((flags & MSG_PEEK) == 0)
			(void) sbdroprecord(&so->so_rcv);
	}
	if ((flags & MSG_PEEK) == 0) {
		if (m == NULL) {
			/*
			 * First part is an inline SB_EMPTY_FIXUP().  Second
			 * part makes sure sb_lastrecord is up-to-date if
			 * there is still data in the socket buffer.
			 */
			so->so_rcv.sb_mb = nextrecord;
			if (so->so_rcv.sb_mb == NULL) {
				so->so_rcv.sb_mbtail = NULL;
				so->so_rcv.sb_lastrecord = NULL;
			} else if (nextrecord->m_nextpkt == NULL)
				so->so_rcv.sb_lastrecord = nextrecord;
		}
		SBLASTRECORDCHK(&so->so_rcv, "soreceive 4");
		SBLASTMBUFCHK(&so->so_rcv, "soreceive 4");
		if (pr->pr_flags & PR_WANTRCVD && so->so_pcb)
			(*pr->pr_usrreq)(so, PRU_RCVD, NULL,
			    (struct mbuf *)(long)flags, NULL, curproc);
	}
	if (orig_resid == uio->uio_resid && orig_resid &&
	    (flags & MSG_EOR) == 0 && (so->so_state & SS_CANTRCVMORE) == 0) {
		sbunlock(&so->so_rcv);
		sounlock(s);
		goto restart;
	}

	if (uio_error)
		error = uio_error;

	if (flagsp)
		*flagsp |= flags;
release:
	sbunlock(&so->so_rcv);
	sounlock(s);
	return (error);
}

int
soshutdown(struct socket *so, int how)
{
	struct protosw *pr = so->so_proto;
	int s, error = 0;

	s = solock(so);
	switch (how) {
	case SHUT_RD:
		sorflush(so);
		break;
	case SHUT_RDWR:
		sorflush(so);
		/* FALLTHROUGH */
	case SHUT_WR:
		error = (*pr->pr_usrreq)(so, PRU_SHUTDOWN, NULL, NULL, NULL,
		    curproc);
		break;
	default:
		error = EINVAL;
		break;
	}
	sounlock(s);

	return (error);
}

void
sorflush(struct socket *so)
{
	struct sockbuf *sb = &so->so_rcv;
	struct protosw *pr = so->so_proto;
	struct socket aso;

	sb->sb_flags |= SB_NOINTR;
	sblock(so, sb, M_WAITOK);
	socantrcvmore(so);
	sbunlock(sb);
	aso.so_proto = pr;
	aso.so_rcv = *sb;
	memset(sb, 0, sizeof (*sb));
	/* XXX - the memset stomps all over so_rcv */
	if (aso.so_rcv.sb_flags & SB_KNOTE) {
		sb->sb_sel.si_note = aso.so_rcv.sb_sel.si_note;
		sb->sb_flags = SB_KNOTE;
	}
	if (pr->pr_flags & PR_RIGHTS && pr->pr_domain->dom_dispose)
		(*pr->pr_domain->dom_dispose)(aso.so_rcv.sb_mb);
	sbrelease(&aso, &aso.so_rcv);
}

#ifdef SOCKET_SPLICE

#define so_splicelen	so_sp->ssp_len
#define so_splicemax	so_sp->ssp_max
#define so_idletv	so_sp->ssp_idletv
#define so_idleto	so_sp->ssp_idleto
#define so_splicetask	so_sp->ssp_task

int
sosplice(struct socket *so, int fd, off_t max, struct timeval *tv)
{
	struct file	*fp;
	struct socket	*sosp;
	int		 s, error = 0;

	if (sosplice_taskq == NULL)
		sosplice_taskq = taskq_create("sosplice", 1, IPL_SOFTNET, 0);
	if (sosplice_taskq == NULL)
		return (ENOMEM);

	if ((so->so_proto->pr_flags & PR_SPLICE) == 0)
		return (EPROTONOSUPPORT);
	if (so->so_options & SO_ACCEPTCONN)
		return (EOPNOTSUPP);
	if ((so->so_state & (SS_ISCONNECTED|SS_ISCONNECTING)) == 0 &&
	    (so->so_proto->pr_flags & PR_CONNREQUIRED))
		return (ENOTCONN);
	if (so->so_sp == NULL)
		so->so_sp = pool_get(&sosplice_pool, PR_WAITOK | PR_ZERO);

	/* If no fd is given, unsplice by removing existing link. */
	if (fd < 0) {
		s = solock(so);
		/* Lock receive buffer. */
		if ((error = sblock(so, &so->so_rcv,
		    (so->so_state & SS_NBIO) ? M_NOWAIT : M_WAITOK)) != 0) {
			sounlock(s);
			return (error);
		}
		if (so->so_sp->ssp_socket)
			sounsplice(so, so->so_sp->ssp_socket, 1);
		sbunlock(&so->so_rcv);
		sounlock(s);
		return (0);
	}

	if (max && max < 0)
		return (EINVAL);

	if (tv && (tv->tv_sec < 0 || tv->tv_usec < 0))
		return (EINVAL);

	/* Find sosp, the drain socket where data will be spliced into. */
	if ((error = getsock(curproc, fd, &fp)) != 0)
		return (error);
	sosp = fp->f_data;
	if (sosp->so_sp == NULL)
		sosp->so_sp = pool_get(&sosplice_pool, PR_WAITOK | PR_ZERO);

	s = solock(so);
	/* Lock both receive and send buffer. */
	if ((error = sblock(so, &so->so_rcv,
	    (so->so_state & SS_NBIO) ? M_NOWAIT : M_WAITOK)) != 0) {
		sounlock(s);
		FRELE(fp, curproc);
		return (error);
	}
	if ((error = sblock(so, &sosp->so_snd, M_WAITOK)) != 0) {
		sbunlock(&so->so_rcv);
		sounlock(s);
		FRELE(fp, curproc);
		return (error);
	}

	if (so->so_sp->ssp_socket || sosp->so_sp->ssp_soback) {
		error = EBUSY;
		goto release;
	}
	if (sosp->so_proto->pr_usrreq != so->so_proto->pr_usrreq) {
		error = EPROTONOSUPPORT;
		goto release;
	}
	if (sosp->so_options & SO_ACCEPTCONN) {
		error = EOPNOTSUPP;
		goto release;
	}
	if ((sosp->so_state & (SS_ISCONNECTED|SS_ISCONNECTING)) == 0) {
		error = ENOTCONN;
		goto release;
	}

	/* Splice so and sosp together. */
	so->so_sp->ssp_socket = sosp;
	sosp->so_sp->ssp_soback = so;
	so->so_splicelen = 0;
	so->so_splicemax = max;
	if (tv)
		so->so_idletv = *tv;
	else
		timerclear(&so->so_idletv);
	timeout_set_proc(&so->so_idleto, soidle, so);
	task_set(&so->so_splicetask, sotask, so);

	/*
	 * To prevent softnet interrupt from calling somove() while
	 * we sleep, the socket buffers are not marked as spliced yet.
	 */
	if (somove(so, M_WAIT)) {
		so->so_rcv.sb_flagsintr |= SB_SPLICE;
		sosp->so_snd.sb_flagsintr |= SB_SPLICE;
	}

 release:
	sbunlock(&sosp->so_snd);
	sbunlock(&so->so_rcv);
	sounlock(s);
	FRELE(fp, curproc);
	return (error);
}

void
sounsplice(struct socket *so, struct socket *sosp, int wakeup)
{
	soassertlocked(so);

	task_del(sosplice_taskq, &so->so_splicetask);
	timeout_del(&so->so_idleto);
	sosp->so_snd.sb_flagsintr &= ~SB_SPLICE;
	so->so_rcv.sb_flagsintr &= ~SB_SPLICE;
	so->so_sp->ssp_socket = sosp->so_sp->ssp_soback = NULL;
	if (wakeup && soreadable(so))
		sorwakeup(so);
}

void
soidle(void *arg)
{
	struct socket *so = arg;
	int s;

	s = solock(so);
	if (so->so_rcv.sb_flagsintr & SB_SPLICE) {
		so->so_error = ETIMEDOUT;
		sounsplice(so, so->so_sp->ssp_socket, 1);
	}
	sounlock(s);
}

void
sotask(void *arg)
{
	struct socket *so = arg;
	int s;

	s = solock(so);
	if (so->so_rcv.sb_flagsintr & SB_SPLICE) {
		/*
		 * We may not sleep here as sofree() and unsplice() may be
		 * called from softnet interrupt context.  This would remove
		 * the socket during somove().
		 */
		somove(so, M_DONTWAIT);
	}
	sounlock(s);

	/* Avoid user land starvation. */
	yield();
}

/*
 * Move data from receive buffer of spliced source socket to send
 * buffer of drain socket.  Try to move as much as possible in one
 * big chunk.  It is a TCP only implementation.
 * Return value 0 means splicing has been finished, 1 continue.
 */
int
somove(struct socket *so, int wait)
{
	struct socket	*sosp = so->so_sp->ssp_socket;
	struct mbuf	*m, **mp, *nextrecord;
	u_long		 len, off, oobmark;
	long		 space;
	int		 error = 0, maxreached = 0;
	short		 state;

	soassertlocked(so);

 nextpkt:
	if (so->so_error) {
		error = so->so_error;
		goto release;
	}
	if (sosp->so_state & SS_CANTSENDMORE) {
		error = EPIPE;
		goto release;
	}
	if (sosp->so_error && sosp->so_error != ETIMEDOUT &&
	    sosp->so_error != EFBIG && sosp->so_error != ELOOP) {
		error = sosp->so_error;
		goto release;
	}
	if ((sosp->so_state & SS_ISCONNECTED) == 0)
		goto release;

	/* Calculate how many bytes can be copied now. */
	len = so->so_rcv.sb_datacc;
	if (so->so_splicemax) {
		KASSERT(so->so_splicelen < so->so_splicemax);
		if (so->so_splicemax <= so->so_splicelen + len) {
			len = so->so_splicemax - so->so_splicelen;
			maxreached = 1;
		}
	}
	space = sbspace(sosp, &sosp->so_snd);
	if (so->so_oobmark && so->so_oobmark < len &&
	    so->so_oobmark < space + 1024)
		space += 1024;
	if (space <= 0) {
		maxreached = 0;
		goto release;
	}
	if (space < len) {
		maxreached = 0;
		if (space < sosp->so_snd.sb_lowat)
			goto release;
		len = space;
	}
	sosp->so_state |= SS_ISSENDING;

	SBLASTRECORDCHK(&so->so_rcv, "somove 1");
	SBLASTMBUFCHK(&so->so_rcv, "somove 1");
	m = so->so_rcv.sb_mb;
	if (m == NULL)
		goto release;
	nextrecord = m->m_nextpkt;

	/* Drop address and control information not used with splicing. */
	if (so->so_proto->pr_flags & PR_ADDR) {
#ifdef DIAGNOSTIC
		if (m->m_type != MT_SONAME)
			panic("somove soname: so %p, so_type %d, m %p, "
			    "m_type %d", so, so->so_type, m, m->m_type);
#endif
		m = m->m_next;
	}
	while (m && m->m_type == MT_CONTROL)
		m = m->m_next;
	if (m == NULL) {
		sbdroprecord(&so->so_rcv);
		if (so->so_proto->pr_flags & PR_WANTRCVD && so->so_pcb)
			(so->so_proto->pr_usrreq)(so, PRU_RCVD, NULL,
			    NULL, NULL, NULL);
		goto nextpkt;
	}

	/*
	 * By splicing sockets connected to localhost, userland might create a
	 * loop.  Dissolve splicing with error if loop is detected by counter.
	 */
	if ((m->m_flags & M_PKTHDR) && m->m_pkthdr.ph_loopcnt++ >= M_MAXLOOP) {
		error = ELOOP;
		goto release;
	}

	if (so->so_proto->pr_flags & PR_ATOMIC) {
		if ((m->m_flags & M_PKTHDR) == 0)
			panic("somove !PKTHDR: so %p, so_type %d, m %p, "
			    "m_type %d", so, so->so_type, m, m->m_type);
		if (sosp->so_snd.sb_hiwat < m->m_pkthdr.len) {
			error = EMSGSIZE;
			goto release;
		}
		if (len < m->m_pkthdr.len)
			goto release;
		if (m->m_pkthdr.len < len) {
			maxreached = 0;
			len = m->m_pkthdr.len;
		}
		/*
		 * Throw away the name mbuf after it has been assured
		 * that the whole first record can be processed.
		 */
		m = so->so_rcv.sb_mb;
		sbfree(&so->so_rcv, m);
		so->so_rcv.sb_mb = m_free(m);
		sbsync(&so->so_rcv, nextrecord);
	}
	/*
	 * Throw away the control mbufs after it has been assured
	 * that the whole first record can be processed.
	 */
	m = so->so_rcv.sb_mb;
	while (m && m->m_type == MT_CONTROL) {
		sbfree(&so->so_rcv, m);
		so->so_rcv.sb_mb = m_free(m);
		m = so->so_rcv.sb_mb;
		sbsync(&so->so_rcv, nextrecord);
	}

	SBLASTRECORDCHK(&so->so_rcv, "somove 2");
	SBLASTMBUFCHK(&so->so_rcv, "somove 2");

	/* Take at most len mbufs out of receive buffer. */
	for (off = 0, mp = &m; off <= len && *mp;
	    off += (*mp)->m_len, mp = &(*mp)->m_next) {
		u_long size = len - off;

#ifdef DIAGNOSTIC
		if ((*mp)->m_type != MT_DATA && (*mp)->m_type != MT_HEADER)
			panic("somove type: so %p, so_type %d, m %p, "
			    "m_type %d", so, so->so_type, *mp, (*mp)->m_type);
#endif
		if ((*mp)->m_len > size) {
			/*
			 * Move only a partial mbuf at maximum splice length or
			 * if the drain buffer is too small for this large mbuf.
			 */
			if (!maxreached && so->so_snd.sb_datacc > 0) {
				len -= size;
				break;
			}
			*mp = m_copym(so->so_rcv.sb_mb, 0, size, wait);
			if (*mp == NULL) {
				len -= size;
				break;
			}
			so->so_rcv.sb_mb->m_data += size;
			so->so_rcv.sb_mb->m_len -= size;
			so->so_rcv.sb_cc -= size;
			so->so_rcv.sb_datacc -= size;
		} else {
			*mp = so->so_rcv.sb_mb;
			sbfree(&so->so_rcv, *mp);
			so->so_rcv.sb_mb = (*mp)->m_next;
			sbsync(&so->so_rcv, nextrecord);
		}
	}
	*mp = NULL;

	SBLASTRECORDCHK(&so->so_rcv, "somove 3");
	SBLASTMBUFCHK(&so->so_rcv, "somove 3");
	SBCHECK(&so->so_rcv);
	if (m == NULL)
		goto release;
	m->m_nextpkt = NULL;
	if (m->m_flags & M_PKTHDR) {
		m_resethdr(m);
		m->m_pkthdr.len = len;
	}

	/* Send window update to source peer as receive buffer has changed. */
	if (so->so_proto->pr_flags & PR_WANTRCVD && so->so_pcb)
		(so->so_proto->pr_usrreq)(so, PRU_RCVD, NULL,
		    NULL, NULL, NULL);

	/* Receive buffer did shrink by len bytes, adjust oob. */
	state = so->so_state;
	so->so_state &= ~SS_RCVATMARK;
	oobmark = so->so_oobmark;
	so->so_oobmark = oobmark > len ? oobmark - len : 0;
	if (oobmark) {
		if (oobmark == len)
			so->so_state |= SS_RCVATMARK;
		if (oobmark >= len)
			oobmark = 0;
	}

	/*
	 * Handle oob data.  If any malloc fails, ignore error.
	 * TCP urgent data is not very reliable anyway.
	 */
	while (((state & SS_RCVATMARK) || oobmark) &&
	    (so->so_options & SO_OOBINLINE)) {
		struct mbuf *o = NULL;

		if (state & SS_RCVATMARK) {
			o = m_get(wait, MT_DATA);
			state &= ~SS_RCVATMARK;
		} else if (oobmark) {
			o = m_split(m, oobmark, wait);
			if (o) {
				error = (*sosp->so_proto->pr_usrreq)(sosp,
				    PRU_SEND, m, NULL, NULL, NULL);
				if (error) {
					if (sosp->so_state & SS_CANTSENDMORE)
						error = EPIPE;
					m_freem(o);
					goto release;
				}
				len -= oobmark;
				so->so_splicelen += oobmark;
				m = o;
				o = m_get(wait, MT_DATA);
			}
			oobmark = 0;
		}
		if (o) {
			o->m_len = 1;
			*mtod(o, caddr_t) = *mtod(m, caddr_t);
			error = (*sosp->so_proto->pr_usrreq)(sosp, PRU_SENDOOB,
			    o, NULL, NULL, NULL);
			if (error) {
				if (sosp->so_state & SS_CANTSENDMORE)
					error = EPIPE;
				m_freem(m);
				goto release;
			}
			len -= 1;
			so->so_splicelen += 1;
			if (oobmark) {
				oobmark -= 1;
				if (oobmark == 0)
					state |= SS_RCVATMARK;
			}
			m_adj(m, 1);
		}
	}

	/* Append all remaining data to drain socket. */
	if (so->so_rcv.sb_cc == 0 || maxreached)
		sosp->so_state &= ~SS_ISSENDING;
	error = (*sosp->so_proto->pr_usrreq)(sosp, PRU_SEND, m, NULL, NULL,
	    NULL);
	if (error) {
		if (sosp->so_state & SS_CANTSENDMORE)
			error = EPIPE;
		goto release;
	}
	so->so_splicelen += len;

	/* Move several packets if possible. */
	if (!maxreached && nextrecord)
		goto nextpkt;

 release:
	sosp->so_state &= ~SS_ISSENDING;
	if (!error && maxreached && so->so_splicemax == so->so_splicelen)
		error = EFBIG;
	if (error)
		so->so_error = error;
	if (((so->so_state & SS_CANTRCVMORE) && so->so_rcv.sb_cc == 0) ||
	    (sosp->so_state & SS_CANTSENDMORE) || maxreached || error) {
		sounsplice(so, sosp, 1);
		return (0);
	}
	if (timerisset(&so->so_idletv))
		timeout_add_tv(&so->so_idleto, &so->so_idletv);
	return (1);
}

#endif /* SOCKET_SPLICE */

void
sorwakeup(struct socket *so)
{
	soassertlocked(so);

#ifdef SOCKET_SPLICE
	if (so->so_rcv.sb_flagsintr & SB_SPLICE) {
		/*
		 * TCP has a sendbuffer that can handle multiple packets
		 * at once.  So queue the stream a bit to accumulate data.
		 * The sosplice thread will call somove() later and send
		 * the packets calling tcp_output() only once.
		 * In the UDP case, send out the packets immediately.
		 * Using a thread would make things slower.
		 */
		if (so->so_proto->pr_flags & PR_WANTRCVD)
			task_add(sosplice_taskq, &so->so_splicetask);
		else
			somove(so, M_DONTWAIT);
	}
	if (isspliced(so))
		return;
#endif
	sowakeup(so, &so->so_rcv);
	if (so->so_upcall)
		(*(so->so_upcall))(so, so->so_upcallarg, M_DONTWAIT);
}

void
sowwakeup(struct socket *so)
{
	soassertlocked(so);

#ifdef SOCKET_SPLICE
	if (so->so_snd.sb_flagsintr & SB_SPLICE)
		task_add(sosplice_taskq, &so->so_sp->ssp_soback->so_splicetask);
#endif
	sowakeup(so, &so->so_snd);
}

int
sosetopt(struct socket *so, int level, int optname, struct mbuf *m0)
{
	int s, error = 0;
	struct mbuf *m = m0;

	if (level != SOL_SOCKET) {
		if (so->so_proto && so->so_proto->pr_ctloutput) {
			s = solock(so);
			error = (*so->so_proto->pr_ctloutput)(PRCO_SETOPT, so,
			    level, optname, m0);
			sounlock(s);
			return (error);
		}
		error = ENOPROTOOPT;
	} else {
		switch (optname) {
		case SO_BINDANY:
			if ((error = suser(curproc, 0)) != 0)	/* XXX */
				goto bad;
			break;
		}

		switch (optname) {

		case SO_LINGER:
			if (m == NULL || m->m_len != sizeof (struct linger) ||
			    mtod(m, struct linger *)->l_linger < 0 ||
			    mtod(m, struct linger *)->l_linger > SHRT_MAX) {
				error = EINVAL;
				goto bad;
			}
			so->so_linger = mtod(m, struct linger *)->l_linger;
			/* FALLTHROUGH */

		case SO_BINDANY:
		case SO_DEBUG:
		case SO_KEEPALIVE:
		case SO_USELOOPBACK:
		case SO_BROADCAST:
		case SO_REUSEADDR:
		case SO_REUSEPORT:
		case SO_OOBINLINE:
		case SO_TIMESTAMP:
		case SO_ZEROIZE:
			if (m == NULL || m->m_len < sizeof (int)) {
				error = EINVAL;
				goto bad;
			}
			if (*mtod(m, int *))
				so->so_options |= optname;
			else
				so->so_options &= ~optname;
			break;

		case SO_DONTROUTE:
			if (m == NULL || m->m_len < sizeof (int)) {
				error = EINVAL;
				goto bad;
			}
			if (*mtod(m, int *))
				error = EOPNOTSUPP;
			break;

		case SO_SNDBUF:
		case SO_RCVBUF:
		case SO_SNDLOWAT:
		case SO_RCVLOWAT:
		    {
			u_long cnt;

			if (m == NULL || m->m_len < sizeof (int)) {
				error = EINVAL;
				goto bad;
			}
			cnt = *mtod(m, int *);
			if ((long)cnt <= 0)
				cnt = 1;
			switch (optname) {

			case SO_SNDBUF:
				if (so->so_state & SS_CANTSENDMORE) {
					error = EINVAL;
					goto bad;
				}
				s = solock(so);
				if (sbcheckreserve(cnt, so->so_snd.sb_wat) ||
				    sbreserve(so, &so->so_snd, cnt)) {
				    	sounlock(s);
					error = ENOBUFS;
					goto bad;
				}
				sounlock(s);
				so->so_snd.sb_wat = cnt;
				break;

			case SO_RCVBUF:
				if (so->so_state & SS_CANTRCVMORE) {
					error = EINVAL;
					goto bad;
				}
				s = solock(so);
				if (sbcheckreserve(cnt, so->so_rcv.sb_wat) ||
				    sbreserve(so, &so->so_rcv, cnt)) {
					sounlock(s);
					error = ENOBUFS;
					goto bad;
				}
				sounlock(s);
				so->so_rcv.sb_wat = cnt;
				break;

			case SO_SNDLOWAT:
				so->so_snd.sb_lowat =
				    (cnt > so->so_snd.sb_hiwat) ?
				    so->so_snd.sb_hiwat : cnt;
				break;
			case SO_RCVLOWAT:
				so->so_rcv.sb_lowat =
				    (cnt > so->so_rcv.sb_hiwat) ?
				    so->so_rcv.sb_hiwat : cnt;
				break;
			}
			break;
		    }

		case SO_SNDTIMEO:
		case SO_RCVTIMEO:
		    {
			struct timeval tv;
			int val;

			if (m == NULL || m->m_len < sizeof (tv)) {
				error = EINVAL;
				goto bad;
			}
			memcpy(&tv, mtod(m, struct timeval *), sizeof tv);
			val = tvtohz(&tv);
			if (val > USHRT_MAX) {
				error = EDOM;
				goto bad;
			}

			switch (optname) {

			case SO_SNDTIMEO:
				so->so_snd.sb_timeo = val;
				break;
			case SO_RCVTIMEO:
				so->so_rcv.sb_timeo = val;
				break;
			}
			break;
		    }

		case SO_RTABLE:
			if (so->so_proto && so->so_proto->pr_domain &&
			    so->so_proto->pr_domain->dom_protosw &&
			    so->so_proto->pr_ctloutput) {
				struct domain *dom = so->so_proto->pr_domain;

				level = dom->dom_protosw->pr_protocol;
				s = solock(so);
				error = (*so->so_proto->pr_ctloutput)
				    (PRCO_SETOPT, so, level, optname, m0);
				sounlock(s);
				return (error);
			}
			error = ENOPROTOOPT;
			break;

#ifdef SOCKET_SPLICE
		case SO_SPLICE:
			if (m == NULL) {
				error = sosplice(so, -1, 0, NULL);
			} else if (m->m_len < sizeof(int)) {
				error = EINVAL;
				goto bad;
			} else if (m->m_len < sizeof(struct splice)) {
				error = sosplice(so, *mtod(m, int *), 0, NULL);
			} else {
				error = sosplice(so,
				    mtod(m, struct splice *)->sp_fd,
				    mtod(m, struct splice *)->sp_max,
				   &mtod(m, struct splice *)->sp_idle);
			}
			break;
#endif /* SOCKET_SPLICE */

		default:
			error = ENOPROTOOPT;
			break;
		}
		if (error == 0 && so->so_proto && so->so_proto->pr_ctloutput) {
			s = solock(so);
			(*so->so_proto->pr_ctloutput)(PRCO_SETOPT, so,
			    level, optname, m0);
			sounlock(s);
			m = NULL;	/* freed by protocol */
		}
	}
bad:
	if (m)
		(void) m_free(m);
	return (error);
}

int
sogetopt(struct socket *so, int level, int optname, struct mbuf **mp)
{
	int s, error = 0;
	struct mbuf *m;

	if (level != SOL_SOCKET) {
		if (so->so_proto && so->so_proto->pr_ctloutput) {
			m = m_get(M_WAIT, MT_SOOPTS);
			m->m_len = 0;

			s = solock(so);
			error = (*so->so_proto->pr_ctloutput)(PRCO_GETOPT, so,
			    level, optname, m);
			sounlock(s);
			if (error) {
				m_free(m);
				return (error);
			}
			*mp = m;
			return (0);
		} else
			return (ENOPROTOOPT);
	} else {
		m = m_get(M_WAIT, MT_SOOPTS);
		m->m_len = sizeof (int);

		switch (optname) {

		case SO_LINGER:
			m->m_len = sizeof (struct linger);
			mtod(m, struct linger *)->l_onoff =
				so->so_options & SO_LINGER;
			mtod(m, struct linger *)->l_linger = so->so_linger;
			break;

		case SO_BINDANY:
		case SO_USELOOPBACK:
		case SO_DEBUG:
		case SO_KEEPALIVE:
		case SO_REUSEADDR:
		case SO_REUSEPORT:
		case SO_BROADCAST:
		case SO_OOBINLINE:
		case SO_TIMESTAMP:
		case SO_ZEROIZE:
			*mtod(m, int *) = so->so_options & optname;
			break;

		case SO_DONTROUTE:
			*mtod(m, int *) = 0;
			break;

		case SO_TYPE:
			*mtod(m, int *) = so->so_type;
			break;

		case SO_ERROR:
			*mtod(m, int *) = so->so_error;
			so->so_error = 0;
			break;

		case SO_SNDBUF:
			*mtod(m, int *) = so->so_snd.sb_hiwat;
			break;

		case SO_RCVBUF:
			*mtod(m, int *) = so->so_rcv.sb_hiwat;
			break;

		case SO_SNDLOWAT:
			*mtod(m, int *) = so->so_snd.sb_lowat;
			break;

		case SO_RCVLOWAT:
			*mtod(m, int *) = so->so_rcv.sb_lowat;
			break;

		case SO_SNDTIMEO:
		case SO_RCVTIMEO:
		    {
			struct timeval tv;
			int val = (optname == SO_SNDTIMEO ?
			    so->so_snd.sb_timeo : so->so_rcv.sb_timeo);

			m->m_len = sizeof(struct timeval);
			memset(&tv, 0, sizeof(tv));
			tv.tv_sec = val / hz;
			tv.tv_usec = (val % hz) * tick;
			memcpy(mtod(m, struct timeval *), &tv, sizeof tv);
			break;
		    }

		case SO_RTABLE:
			if (so->so_proto && so->so_proto->pr_domain &&
			    so->so_proto->pr_domain->dom_protosw &&
			    so->so_proto->pr_ctloutput) {
				struct domain *dom = so->so_proto->pr_domain;

				level = dom->dom_protosw->pr_protocol;
				s = solock(so);
				error = (*so->so_proto->pr_ctloutput)
				    (PRCO_GETOPT, so, level, optname, m);
				sounlock(s);
				if (error) {
					(void)m_free(m);
					return (error);
				}
				break;
			}
			(void)m_free(m);
			return (ENOPROTOOPT);

#ifdef SOCKET_SPLICE
		case SO_SPLICE:
		    {
			off_t len;
			int s;

			s = solock(so);
			m->m_len = sizeof(off_t);
			len = so->so_sp ? so->so_sp->ssp_len : 0;
			memcpy(mtod(m, off_t *), &len, sizeof(off_t));
			sounlock(s);
			break;
		    }
#endif /* SOCKET_SPLICE */

		case SO_PEERCRED:
			if (so->so_proto->pr_protocol == AF_UNIX) {
				struct unpcb *unp = sotounpcb(so);

				if (unp->unp_flags & UNP_FEIDS) {
					m->m_len = sizeof(unp->unp_connid);
					memcpy(mtod(m, caddr_t),
					    &(unp->unp_connid), m->m_len);
					break;
				}
				(void)m_free(m);
				return (ENOTCONN);
			}
			(void)m_free(m);
			return (EOPNOTSUPP);

		default:
			(void)m_free(m);
			return (ENOPROTOOPT);
		}
		*mp = m;
		return (0);
	}
}

void
sohasoutofband(struct socket *so)
{
	csignal(so->so_pgid, SIGURG, so->so_siguid, so->so_sigeuid);
	selwakeup(&so->so_rcv.sb_sel);
}

int
soo_kqfilter(struct file *fp, struct knote *kn)
{
	struct socket *so = kn->kn_fp->f_data;
	struct sockbuf *sb;

	KERNEL_ASSERT_LOCKED();

	switch (kn->kn_filter) {
	case EVFILT_READ:
		if (so->so_options & SO_ACCEPTCONN)
			kn->kn_fop = &solisten_filtops;
		else
			kn->kn_fop = &soread_filtops;
		sb = &so->so_rcv;
		break;
	case EVFILT_WRITE:
		kn->kn_fop = &sowrite_filtops;
		sb = &so->so_snd;
		break;
	default:
		return (EINVAL);
	}

	SLIST_INSERT_HEAD(&sb->sb_sel.si_note, kn, kn_selnext);
	sb->sb_flags |= SB_KNOTE;

	return (0);
}

void
filt_sordetach(struct knote *kn)
{
	struct socket *so = kn->kn_fp->f_data;

	KERNEL_ASSERT_LOCKED();

	SLIST_REMOVE(&so->so_rcv.sb_sel.si_note, kn, knote, kn_selnext);
	if (SLIST_EMPTY(&so->so_rcv.sb_sel.si_note))
		so->so_rcv.sb_flags &= ~SB_KNOTE;
}

int
filt_soread(struct knote *kn, long hint)
{
	struct socket *so = kn->kn_fp->f_data;

	kn->kn_data = so->so_rcv.sb_cc;
#ifdef SOCKET_SPLICE
	if (isspliced(so))
		return (0);
#endif /* SOCKET_SPLICE */
	if (so->so_state & SS_CANTRCVMORE) {
		kn->kn_flags |= EV_EOF;
		kn->kn_fflags = so->so_error;
		return (1);
	}
	if (so->so_error)	/* temporary udp error */
		return (1);
	if (kn->kn_sfflags & NOTE_LOWAT)
		return (kn->kn_data >= kn->kn_sdata);
	return (kn->kn_data >= so->so_rcv.sb_lowat);
}

void
filt_sowdetach(struct knote *kn)
{
	struct socket *so = kn->kn_fp->f_data;

	KERNEL_ASSERT_LOCKED();

	SLIST_REMOVE(&so->so_snd.sb_sel.si_note, kn, knote, kn_selnext);
	if (SLIST_EMPTY(&so->so_snd.sb_sel.si_note))
		so->so_snd.sb_flags &= ~SB_KNOTE;
}

int
filt_sowrite(struct knote *kn, long hint)
{
	struct socket *so = kn->kn_fp->f_data;
	int rv;

	kn->kn_data = sbspace(so, &so->so_snd);
	if (so->so_state & SS_CANTSENDMORE) {
		kn->kn_flags |= EV_EOF;
		kn->kn_fflags = so->so_error;
		rv = 1;
	} else if (so->so_error) {	/* temporary udp error */
		rv = 1;
	} else if (((so->so_state & SS_ISCONNECTED) == 0) &&
	    (so->so_proto->pr_flags & PR_CONNREQUIRED)) {
		rv = 0;
	} else if (kn->kn_sfflags & NOTE_LOWAT) {
		rv = (kn->kn_data >= kn->kn_sdata);
	} else {
		rv = (kn->kn_data >= so->so_snd.sb_lowat);
	}

	return (rv);
}

int
filt_solisten(struct knote *kn, long hint)
{
	struct socket *so = kn->kn_fp->f_data;

	kn->kn_data = so->so_qlen;

	return (kn->kn_data != 0);
}

#ifdef DDB
void
sobuf_print(struct sockbuf *,
    int (*)(const char *, ...) __attribute__((__format__(__kprintf__,1,2))));

void
sobuf_print(struct sockbuf *sb,
    int (*pr)(const char *, ...) __attribute__((__format__(__kprintf__,1,2))))
{
	(*pr)("\tsb_cc: %lu\n", sb->sb_cc);
	(*pr)("\tsb_datacc: %lu\n", sb->sb_datacc);
	(*pr)("\tsb_hiwat: %lu\n", sb->sb_hiwat);
	(*pr)("\tsb_wat: %lu\n", sb->sb_wat);
	(*pr)("\tsb_mbcnt: %lu\n", sb->sb_mbcnt);
	(*pr)("\tsb_mbmax: %lu\n", sb->sb_mbmax);
	(*pr)("\tsb_lowat: %ld\n", sb->sb_lowat);
	(*pr)("\tsb_mb: %p\n", sb->sb_mb);
	(*pr)("\tsb_mbtail: %p\n", sb->sb_mbtail);
	(*pr)("\tsb_lastrecord: %p\n", sb->sb_lastrecord);
	(*pr)("\tsb_sel: ...\n");
	(*pr)("\tsb_flagsintr: %d\n", sb->sb_flagsintr);
	(*pr)("\tsb_flags: %i\n", sb->sb_flags);
	(*pr)("\tsb_timeo: %i\n", sb->sb_timeo);
}

void
so_print(void *v,
    int (*pr)(const char *, ...) __attribute__((__format__(__kprintf__,1,2))))
{
	struct socket *so = v;

	(*pr)("socket %p\n", so);
	(*pr)("so_type: %i\n", so->so_type);
	(*pr)("so_options: 0x%04x\n", so->so_options); /* %b */
	(*pr)("so_linger: %i\n", so->so_linger);
	(*pr)("so_state: 0x%04x\n", so->so_state);
	(*pr)("so_pcb: %p\n", so->so_pcb);
	(*pr)("so_proto: %p\n", so->so_proto);

	(*pr)("so_head: %p\n", so->so_head);
	(*pr)("so_onq: %p\n", so->so_onq);
	(*pr)("so_q0: @@%p first: %p\n", &so->so_q0, TAILQ_FIRST(&so->so_q0));
	(*pr)("so_q: @@%p first: %p\n", &so->so_q, TAILQ_FIRST(&so->so_q));
	(*pr)("so_eq: next: %p\n", TAILQ_NEXT(so, so_qe));
	(*pr)("so_q0len: %i\n", so->so_q0len);
	(*pr)("so_qlen: %i\n", so->so_qlen);
	(*pr)("so_qlimit: %i\n", so->so_qlimit);
	(*pr)("so_timeo: %i\n", so->so_timeo);
	(*pr)("so_pgid: %i\n", so->so_pgid);
	(*pr)("so_siguid: %i\n", so->so_siguid);
	(*pr)("so_sigeuid: %i\n", so->so_sigeuid);
	(*pr)("so_obmark: %lu\n", so->so_oobmark);

	(*pr)("so_sp: %p\n", so->so_sp);
	if (so->so_sp != NULL) {
		(*pr)("\tssp_socket: %p\n", so->so_sp->ssp_socket);
		(*pr)("\tssp_soback: %p\n", so->so_sp->ssp_soback);
		(*pr)("\tssp_len: %lld\n",
		    (unsigned long long)so->so_sp->ssp_len);
		(*pr)("\tssp_max: %lld\n",
		    (unsigned long long)so->so_sp->ssp_max);
		(*pr)("\tssp_idletv: %lld %ld\n", so->so_sp->ssp_idletv.tv_sec,
		    so->so_sp->ssp_idletv.tv_usec);
		(*pr)("\tssp_idleto: %spending (@@%i)\n",
		    timeout_pending(&so->so_sp->ssp_idleto) ? "" : "not ",
		    so->so_sp->ssp_idleto.to_time);
	}

	(*pr)("so_rcv:\n");
	sobuf_print(&so->so_rcv, pr);
	(*pr)("so_snd:\n");
	sobuf_print(&so->so_snd, pr);

	(*pr)("so_upcall: %p so_upcallarg: %p\n",
	    so->so_upcall, so->so_upcallarg);

	(*pr)("so_euid: %d so_ruid: %d\n", so->so_euid, so->so_ruid);
	(*pr)("so_egid: %d so_rgid: %d\n", so->so_egid, so->so_rgid);
	(*pr)("so_cpid: %d\n", so->so_cpid);
}
#endif

@


1.192
log
@Always hold the socket lock when calling sblock().

Implicitely protects `so_state' with the socket lock in sosend().

ok visa@@, bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.191 2017/07/03 08:29:24 mpi Exp $	*/
d2001 1
a2001 1
	int s, rv;
a2002 2
	if (!(hint & NOTE_SUBMIT))
		s = solock(so);
a2017 2
	if (!(hint & NOTE_SUBMIT))
		sounlock(s);
a2025 1
	int s;
a2026 2
	if (!(hint & NOTE_SUBMIT))
		s = solock(so);
a2027 2
	if (!(hint & NOTE_SUBMIT))
		sounlock(s);
@


1.191
log
@Protect `so_state', `so_error' and `so_qlen' with the socket lock in
kqueue filters.

ok millert@@, bluhm@@, visa@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.190 2017/06/27 12:02:43 mpi Exp $	*/
d421 1
a421 1
#define	snderr(errno)	{ error = errno; sounlock(s); goto release; }
d423 1
d425 1
a425 1
	if ((error = sblock(&so->so_snd, SBLOCKWAIT(flags), NULL)) != 0)
a428 1
		s = solock(so);
a457 1
			sounlock(s);
a461 1
		sounlock(s);
d472 3
a474 2
				error = m_getuio(&top, atomic,
				    space, uio);
a481 1
			s = solock(so);
a488 1
			sounlock(s);
d501 1
d671 3
a673 1
	if ((error = sblock(&so->so_rcv, SBLOCKWAIT(flags), NULL)) != 0)
d675 1
a675 1
	s = solock(so);
a1042 1
	sa_family_t af = pr->pr_domain->dom_family;
d1046 1
a1046 3
	sblock(sb, M_WAITOK,
	    (af != PF_LOCAL && af != PF_ROUTE && af != PF_KEY) ?
	    &netlock : NULL);
d1094 1
d1096 3
a1098 2
		if ((error = sblock(&so->so_rcv,
		    (so->so_state & SS_NBIO) ? M_NOWAIT : M_WAITOK, NULL)) != 0)
d1100 1
a1100 1
		s = solock(so);
d1103 1
a1104 1
		sbunlock(&so->so_rcv);
d1121 1
d1123 3
a1125 2
	if ((error = sblock(&so->so_rcv,
	    (so->so_state & SS_NBIO) ? M_NOWAIT : M_WAITOK, NULL)) != 0) {
d1129 1
a1129 1
	if ((error = sblock(&sosp->so_snd, M_WAITOK, NULL)) != 0) {
d1131 1
a1134 1
	s = solock(so);
a1174 1
	sounlock(s);
d1177 1
@


1.190
log
@Add missing solock()/sounlock() dances around sbreserve().

While here document an abuse of parent socket's lock.

Problem reported by krw@@, analysis and ok bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.189 2017/06/26 09:32:31 mpi Exp $	*/
d2000 1
a2000 1
	int s;
a2004 2
	if (!(hint & NOTE_SUBMIT))
		sounlock(s);
d2008 10
a2017 1
		return (1);
d2019 4
a2022 8
	if (so->so_error)	/* temporary udp error */
		return (1);
	if (((so->so_state & SS_ISCONNECTED) == 0) &&
	    (so->so_proto->pr_flags & PR_CONNREQUIRED))
		return (0);
	if (kn->kn_sfflags & NOTE_LOWAT)
		return (kn->kn_data >= kn->kn_sdata);
	return (kn->kn_data >= so->so_snd.sb_lowat);
d2029 1
d2031 2
d2034 4
a2037 1
	return (so->so_qlen != 0);
@


1.189
log
@Assert that the corresponding socket is locked when manipulating socket
buffers.

This is one step towards unlocking TCP input path.  Note that all the
functions asserting for the socket lock are not necessarilly MP-safe.
All the fields of 'struct socket' aren't protected.

Introduce a new kernel-only kqueue hint, NOTE_SUBMIT, to be able to
tell when a filter needs to lock the underlying data structures.  Logic
and name taken from NetBSD.

Tested by Hrvoje Popovski.

ok claudio@@, bluhm@@, mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.188 2017/06/20 17:13:21 bluhm Exp $	*/
d1638 1
d1641 1
d1645 1
d1654 1
d1657 1
d1661 1
@


1.188
log
@In ddb print socket bit field so_state in hex to match SS_ defines.
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.187 2017/06/20 09:10:04 mpi Exp $	*/
d219 1
a219 1
	sbrelease(&so->so_snd);
d443 1
a443 1
		space = sbspace(&so->so_snd);
d1044 1
a1044 1
	struct sockbuf asb;
d1052 2
a1053 1
	asb = *sb;
d1056 2
a1057 2
	if (asb.sb_flags & SB_KNOTE) {
		sb->sb_sel.si_note = asb.sb_sel.si_note;
d1061 2
a1062 2
		(*pr->pr_domain->dom_dispose)(asb.sb_mb);
	sbrelease(&asb);
d1274 1
a1274 1
	space = sbspace(&sosp->so_snd);
d1639 1
a1639 1
				    sbreserve(&so->so_snd, cnt)) {
d1652 1
a1652 1
				    sbreserve(&so->so_rcv, cnt)) {
d1994 1
d1996 5
a2000 1
	kn->kn_data = sbspace(&so->so_snd);
@


1.187
log
@Convert sodidle() to timeout_set_proc(9), it needs a process context
to grab the rwlock.

Problem reported by Rivo Nurges.

ok bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.186 2017/05/31 08:55:10 markus Exp $	*/
d2054 1
a2054 1
	(*pr)("so_state: %i\n", so->so_state);
@


1.186
log
@new socketoption SO_ZEROIZE: zero out all mbufs sent over socket
ok deraadt bluhm
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.184 2017/05/15 13:00:10 mpi Exp $	*/
d1160 1
a1160 1
	timeout_set(&so->so_idleto, soidle, so);
@


1.185
log
@Push the NET_LOCK down into PF_KEY so that it can be treated like PF_ROUTE.
Only pfkeyv2_send() needs the NET_LOCK() so grab it at the start and release
at the end.  This should allow to push the locks down in other places.
OK mpi@@, bluhm@@
@
text
@d486 2
d1596 1
d1798 1
@


1.184
log
@so_splicelen needs to be protected by the socket lock.  We are now
safe since we're always holding the KERNEL_LOCK() but we want to move
away from that.

Suggested by and ok bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.183 2017/05/15 12:26:00 mpi Exp $	*/
d1046 2
a1047 1
	    (af != PF_LOCAL && af != PF_ROUTE) ? &netlock : NULL);
@


1.183
log
@Enable the NET_LOCK(), take 3.

Recursions are still marked as XXXSMP.

ok deraadt@@, bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.182 2017/04/02 23:40:08 deraadt Exp $	*/
d1865 1
a1865 1
			int s = splsoftnet();
d1867 1
d1871 1
a1871 1
			splx(s);
@


1.182
log
@Less convoluted code in soshutdown()
ok guenther
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.181 2017/03/17 17:19:16 mpi Exp $	*/
d1041 1
d1045 2
a1046 1
	sblock(sb, M_WAITOK, NULL);
@


1.181
log
@Revert the NET_LOCK() and bring back pf's contention lock for release.

For the moment the NET_LOCK() is always taken by threads running under
KERNEL_LOCK().  That means it doesn't buy us anything except a possible
deadlock that we did not spot.  So make sure this doesn't happen, we'll
have plenty of time in the next release cycle to stress test it.

ok visa@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.180 2017/03/13 20:18:21 claudio Exp $	*/
d1018 2
a1021 2
		if (how == SHUT_RD)
			break;
@


1.180
log
@Move PRU_ATTACH out of the pr_usrreq functions into pr_attach.
Attach is quite a different thing to the other PRU functions and
this should make locking a bit simpler. This also removes the ugly
hack on how proto was passed to the attach function.
OK bluhm@@ and mpi@@ on a previous version
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.179 2017/03/07 09:23:27 mpi Exp $	*/
a1040 1
	sa_family_t af = pr->pr_domain->dom_family;
d1044 1
a1044 2
	sblock(sb, M_WAITOK,
	    (af != PF_LOCAL && af != PF_ROUTE) ? &netlock : NULL);
@


1.179
log
@Do not grab the NET_LOCK() for routing sockets operations.

The only function that need the lock is rtm_output() as it messes with
the routing table.  So grab the lock there since it is safe to sleep
in a process context.

ok bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.178 2017/03/03 09:41:20 mpi Exp $	*/
d122 1
a122 1
	if (prp == NULL || prp->pr_usrreq == 0)
d138 1
d140 1
a140 2
	error = (*prp->pr_usrreq)(so, PRU_ATTACH, NULL,
	    (struct mbuf *)(long)proto, NULL, p);
@


1.178
log
@Prevent a recursion in the socket layer.

Always defere soreceive() to an nfsd(8) process instead of doing it in
the 'softnet' thread.  Avoiding this recursion ensure that we do not
introduce a new sleeping point by releasing and grabbing the netlock.

Tested by many, committing now in order to find possible performance
regression.
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.177 2017/02/14 09:46:21 mpi Exp $	*/
d1041 1
d1046 1
a1046 1
	    (pr->pr_domain->dom_family != PF_LOCAL) ? &netlock : NULL);
@


1.177
log
@Wrap the NET_LOCK() into a per-socket solock() that does nothing for
unix domain sockets.

This should prevent the multiple deadlock related to unix domain sockets.

Inputs from millert@@ and bluhm@@, ok bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.176 2017/02/01 20:59:47 dhill Exp $	*/
d1532 1
a1532 3
	if (so->so_upcall) {
		/* XXXSMP breaks atomicity */
		rw_exit_write(&netlock);
a1533 2
		rw_enter_write(&netlock);
	}
@


1.176
log
@In sogetopt, preallocate an mbuf to avoid using sleeping mallocs with
the netlock held.  This also changes the prototypes of the *ctloutput
functions to take an mbuf instead of an mbuf pointer.

help, guidance from bluhm@@ and mpi@@
ok bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.175 2017/01/27 20:31:42 bluhm Exp $	*/
d138 1
a138 1
	NET_LOCK(s);
d144 1
a144 1
		NET_UNLOCK(s);
d147 1
a147 1
	NET_UNLOCK(s);
d157 1
a157 1
	NET_LOCK(s);
d159 1
a159 1
	NET_UNLOCK(s);
d174 1
a174 1
	NET_LOCK(s);
d178 1
a178 1
		NET_UNLOCK(s);
d188 1
a188 1
	NET_UNLOCK(s);
d195 1
a195 1
	NET_ASSERT_LOCKED();
d235 1
a235 1
	NET_LOCK(s);
d259 1
a259 1
				error = rwsleep(&so->so_timeo, &netlock,
d279 1
a279 1
	NET_UNLOCK(s);
d286 1
a286 1
	NET_ASSERT_LOCKED();
d297 1
a297 1
	NET_ASSERT_LOCKED();
d318 1
a318 1
	NET_LOCK(s);
d332 1
a332 1
	NET_UNLOCK(s);
d341 1
a341 1
	NET_LOCK(s);
d344 1
a344 1
	NET_UNLOCK(s);
d353 1
a353 1
	NET_ASSERT_LOCKED();
d421 1
a421 1
#define	snderr(errno)	{ error = errno; NET_UNLOCK(s); goto release; }
d428 1
a428 1
		NET_LOCK(s);
d456 1
a456 1
			error = sbwait(&so->so_snd);
d458 1
a458 1
			NET_UNLOCK(s);
d463 1
a463 1
		NET_UNLOCK(s);
d483 1
a483 1
			NET_LOCK(s);
d489 1
a489 1
			NET_UNLOCK(s);
d618 1
a618 1
 * the NET_LOCK() while doing the actual copy to user space.
d652 1
a652 1
		NET_LOCK(s);
d655 1
a655 1
		NET_UNLOCK(s);
d673 1
a673 1
	NET_LOCK(s);
d737 2
a738 2
		error = sbwait(&so->so_rcv);
		NET_UNLOCK(s);
a803 1
					NET_UNLOCK(s);
a806 1
					NET_LOCK(s);
d874 1
a874 1
			NET_UNLOCK(s);
d876 1
a876 1
			NET_LOCK(s);
d955 1
a955 1
			error = sbwait(&so->so_rcv);
d958 1
a958 1
				NET_UNLOCK(s);
d994 1
a994 1
		NET_UNLOCK(s);
d1005 1
a1005 1
	NET_UNLOCK(s);
d1015 1
a1015 1
	NET_LOCK(s);
d1031 1
a1031 1
	NET_UNLOCK(s);
d1044 2
a1045 1
	(void) sblock(sb, M_WAITOK, &netlock);
d1096 1
a1096 1
		NET_LOCK(s);
d1099 1
a1099 1
		NET_UNLOCK(s);
d1128 1
a1128 1
	NET_LOCK(s);
d1169 1
a1169 1
	NET_UNLOCK(s);
d1179 1
a1179 1
	NET_ASSERT_LOCKED();
d1196 1
a1196 1
	NET_LOCK(s);
d1201 1
a1201 1
	NET_UNLOCK(s);
d1210 1
a1210 1
	NET_LOCK(s);
d1219 1
a1219 1
	NET_UNLOCK(s);
d1241 1
a1241 1
	NET_ASSERT_LOCKED();
d1511 1
a1511 1
	NET_ASSERT_LOCKED();
d1543 1
a1543 1
	NET_ASSERT_LOCKED();
d1560 1
a1560 1
			NET_LOCK(s);
d1563 1
a1563 1
			NET_UNLOCK(s);
d1707 1
a1707 1
				NET_LOCK(s);
d1710 1
a1710 1
				NET_UNLOCK(s);
d1739 1
a1739 1
			NET_LOCK(s);
d1742 1
a1742 1
			NET_UNLOCK(s);
d1763 1
a1763 1
			NET_LOCK(s);
d1766 1
a1766 1
			NET_UNLOCK(s);
d1851 1
a1851 1
				NET_LOCK(s);
d1854 1
a1854 1
				NET_UNLOCK(s);
@


1.175
log
@In sosend() the size of the control message for file descriptor
passing is checked.  As the data type has changed in unp_internalize(),
the calculation has to be adapted in sosend().
Found by relayd regress test on i386.
OK millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.174 2017/01/26 00:08:50 bluhm Exp $	*/
d1563 1
a1563 1
			    level, optname, &m0);
d1710 1
a1710 1
				    (PRCO_SETOPT, so, level, optname, &m0);
d1742 1
a1742 1
			    level, optname, &m0);
d1761 3
d1766 1
a1766 1
			    level, optname, mp);
d1768 6
a1773 1
			return (error);
a1845 1
			(void)m_free(m);
d1854 1
a1854 1
				    (PRCO_GETOPT, so, level, optname, mp);
d1856 5
a1860 1
				return (error);
d1862 1
a1863 1
			break;
a1893 1
			break;
@


1.174
log
@Do not hold the netlock while pool_get() may sleep.  It is not
necessary to lock code that initializes a new socket structure
before it has been linked to any global list.
OK mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.173 2017/01/25 16:45:50 bluhm Exp $	*/
d418 1
a418 1
			    (sizeof(struct file *) / sizeof(int)));
@


1.173
log
@As NET_LOCK() is a read/write lock, it can sleep in sotask().  So
the TASKQ_CANTSLEEP flag is no longer valid for the splicing thread.
OK mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.172 2017/01/25 06:15:50 mpi Exp $	*/
a125 1
	NET_LOCK(s);
d138 1
@


1.172
log
@Enable the NET_LOCK(), take 2.

Recursions are currently known and marked a XXXSMP.

Please report any assert to bugs@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.171 2016/12/29 12:12:43 mpi Exp $	*/
d1077 1
a1077 2
		sosplice_taskq = taskq_create("sosplice", 1, IPL_SOFTNET,
		    TASKQ_CANTSLEEP);
@


1.171
log
@Change NET_LOCK()/NET_UNLOCK() to be simple wrappers around
splsoftnet()/splx() until the known issues are fixed.

In other words, stop using a rwlock since it creates a deadlock when
chrome is used.

Issue reported by Dimitris Papastamos and kettenis@@

ok visa@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.170 2016/12/20 21:15:36 mpi Exp $	*/
d259 1
a259 1
				error = tsleep(&so->so_timeo,
d617 2
a618 2
 * In order to avoid blocking network for the entire time here, we splx()
 * and release NET_LOCK() while doing the actual copy to user space.
d803 7
a809 3
				    SCM_RIGHTS)
				   error = (*pr->pr_domain->dom_externalize)(cm,
				       controllen, flags);
d1046 1
a1046 1
	(void) sblock(sb, M_WAITOK, NULL);
d1535 2
d1538 1
@


1.170
log
@Grab the NET_LOCK() in so{s,g}etopt(), pffasttimo() and pfslowtimo().

ok rzalamena@@, bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.169 2016/12/19 08:36:49 mpi Exp $	*/
d259 1
a259 1
				error = rwsleep(&so->so_timeo, &netlock,
d618 1
a618 1
 * and release ``netlock'' while doing the actual copy to user space.
d1042 1
a1042 1
	(void) sblock(sb, M_WAITOK, &netlock);
a1530 2
		/* XXXSMP breaks atomicity */
		rw_exit_write(&netlock);
a1531 1
		rw_enter_write(&netlock);
@


1.169
log
@Introduce the NET_LOCK() a rwlock used to serialize accesses to the parts
of the network stack that are not yet ready to be executed in parallel or
where new sleeping points are not possible.

This first pass replace all the entry points leading to ip_output(). This
is done to not introduce new sleeping points when trying to acquire ART's
write lock, needed when a new L2 entry is created via the RT_RESOLVE.

Inputs from and ok bluhm@@, ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.168 2016/11/29 10:22:30 jsg Exp $	*/
d1558 1
a1558 1
			s = splsoftnet();
d1561 1
a1561 1
			splx(s);
d1705 1
a1705 1
				s = splsoftnet();
d1708 1
a1708 1
				splx(s);
d1737 1
a1737 1
			s = splsoftnet();
d1740 1
a1740 1
			splx(s);
d1758 1
a1758 1
			s = splsoftnet();
d1761 1
a1761 1
			splx(s);
d1842 1
a1842 1
				s = splsoftnet();
d1845 1
a1845 1
				splx(s);
@


1.168
log
@m_free() and m_freem() test for NULL.  Simplify callers which had their own
NULL tests.

ok mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.167 2016/11/23 13:05:53 bluhm Exp $	*/
d126 1
a126 1
	s = splsoftnet();
d144 1
a144 1
		splx(s);
d147 1
a147 1
	splx(s);
d157 1
a157 1
	s = splsoftnet();
d159 1
a159 1
	splx(s);
d174 1
a174 1
	s = splsoftnet();
d178 1
a178 1
		splx(s);
d188 1
a188 1
	splx(s);
d195 1
a195 1
	splsoftassert(IPL_SOFTNET);
d235 1
a235 1
	s = splsoftnet();
d259 1
a259 1
				error = tsleep(&so->so_timeo,
d279 1
a279 1
	splx(s);
d286 1
a286 1
	splsoftassert(IPL_SOFTNET);
d297 1
a297 1
	splsoftassert(IPL_SOFTNET);
d318 1
a318 1
	s = splsoftnet();
d332 1
a332 1
	splx(s);
d341 1
a341 1
	s = splsoftnet();
d344 1
a344 1
	splx(s);
d353 1
a353 1
	splsoftassert(IPL_SOFTNET);
d421 1
a421 1
#define	snderr(errno)	{ error = errno; splx(s); goto release; }
d424 1
a424 1
	if ((error = sblock(&so->so_snd, SBLOCKWAIT(flags))) != 0)
d428 1
a428 1
		s = splsoftnet();
d434 1
a434 2
			splx(s);
			goto release;
d458 1
a458 1
			splx(s);
d463 1
a463 1
		splx(s);
d483 1
a483 1
			s = splsoftnet();		/* XXX */
d489 1
a489 1
			splx(s);
d617 2
a618 2
 * In order to avoid blocking network interrupts for the entire time here,
 * we splx() while doing the actual copy to user space.
d652 1
a652 1
		s = splsoftnet();
d655 1
a655 1
		splx(s);
d671 1
a671 1
	if ((error = sblock(&so->so_rcv, SBLOCKWAIT(flags))) != 0)
d673 1
a673 1
	s = splsoftnet();
d738 1
a738 1
		splx(s);
d872 1
a872 1
			splx(s);
d874 1
a874 1
			s = splsoftnet();
d956 1
a956 1
				splx(s);
d992 1
a992 1
		splx(s);
d1003 1
a1003 1
	splx(s);
d1013 1
a1013 1
	s = splsoftnet();
d1029 2
a1030 1
	splx(s);
d1042 1
a1042 1
	(void) sblock(sb, M_WAITOK);
d1092 1
a1092 1
		    (so->so_state & SS_NBIO) ? M_NOWAIT : M_WAITOK)) != 0)
d1094 1
a1094 1
		s = splsoftnet();
d1097 1
a1097 1
		splx(s);
d1117 1
a1117 1
	    (so->so_state & SS_NBIO) ? M_NOWAIT : M_WAITOK)) != 0) {
d1121 1
a1121 1
	if ((error = sblock(&sosp->so_snd, M_WAITOK)) != 0) {
d1126 1
a1126 1
	s = splsoftnet();
d1167 1
a1167 1
	splx(s);
d1177 1
a1177 1
	splsoftassert(IPL_SOFTNET);
d1194 1
a1194 1
	s = splsoftnet();
d1199 1
a1199 1
	splx(s);
d1208 1
a1208 1
	s = splsoftnet();
d1217 1
a1217 1
	splx(s);
d1239 1
a1239 1
	splsoftassert(IPL_SOFTNET);
d1509 1
a1509 1
	splsoftassert(IPL_SOFTNET);
d1530 3
a1532 1
	if (so->so_upcall)
d1534 2
d1541 1
a1541 1
	splsoftassert(IPL_SOFTNET);
@


1.167
log
@Some socket splicing tests on loopback hang with large mbufs and
reduced buffer size.  If the send buffer size is less than the size
of a single mbuf, it will never fit.  So if the send buffer is
empty, split the large mbuf and move only a part.
OK claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.166 2016/11/22 10:29:39 mpi Exp $	*/
d503 2
a504 4
	if (top)
		m_freem(top);
	if (control)
		m_freem(control);
d665 1
a665 2
		if (m)
			m_freem(m);
@


1.166
log
@Enforce that pr_ctloutput is called at IPL_SOFTNET.

This will allow us to keep locking simple as soon as we trade
splsoftnet() for a rwlock.

ok bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.165 2016/11/21 09:09:06 mpi Exp $	*/
d1370 10
a1379 2
			if (!maxreached || (*mp = m_copym(
			    so->so_rcv.sb_mb, 0, size, wait)) == NULL) {
@


1.165
log
@Enforce that pr_usrreq functions are called at IPL_SOFTNET.

This will allow us to keep locking simple as soon as we trade
splsoftnet() for a rwlock.

ok bluhm@@, claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.164 2016/11/14 08:45:30 mpi Exp $	*/
d1544 1
a1544 1
	int error = 0;
d1548 7
a1554 3
		if (so->so_proto && so->so_proto->pr_ctloutput)
			return ((*so->so_proto->pr_ctloutput)
				  (PRCO_SETOPT, so, level, optname, &m0));
d1696 5
a1700 2
				return ((*so->so_proto->pr_ctloutput)
				    (PRCO_SETOPT, so, level, optname, &m0));
d1728 4
a1731 2
			(void) ((*so->so_proto->pr_ctloutput)
				  (PRCO_SETOPT, so, level, optname, &m0));
d1744 1
d1749 5
a1753 2
			return ((*so->so_proto->pr_ctloutput)
				  (PRCO_GETOPT, so, level, optname, mp));
d1833 5
a1837 2
				return ((*so->so_proto->pr_ctloutput)
				    (PRCO_GETOPT, so, level, optname, mp));
@


1.164
log
@Remove splnet() from socket kqueue code.

splnet() was necessary when link state changes were executed from
hardware interrupt handlers, nowdays all the changes are serialized
by the KERNEL_LOCK() so assert that it is held instead.

ok mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.163 2016/10/06 19:09:08 bluhm Exp $	*/
d655 1
d658 1
@


1.163
log
@Remove redundant comments that say a function must be called at
splsoftnet() if the function does a splsoftassert(IPL_SOFTNET)
anyway.
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.162 2016/10/06 17:02:10 bluhm Exp $	*/
a1039 1
	int s;
a1043 1
	s = splnet();
a1052 1
	splx(s);
d1876 2
a1877 1
	int s;
a1894 1
	s = splnet();
d1897 1
a1897 1
	splx(s);
d1905 2
a1906 1
	int s = splnet();
a1910 1
	splx(s);
d1939 2
a1940 1
	int s = splnet();
a1944 1
	splx(s);
@


1.162
log
@Separate splsoftnet() from variable initialization.
From mpi@@'s netlock diff; OK mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.161 2016/09/20 14:27:43 bluhm Exp $	*/
a191 4
/*
 *  Must be called at splsoftnet()
 */

a282 3
/*
 * Must be called at splsoftnet.
 */
@


1.161
log
@Protect soshutdown() with splsoftnet() to define one layer where
we enter networking code.  Fixes an splassert() found by David Hill.
OK mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.160 2016/09/20 11:11:44 bluhm Exp $	*/
d155 1
a155 2
	int s = splsoftnet();
	int error;
d157 1
d237 1
a237 2
	int s = splsoftnet();		/* conservative */
	int error = 0;
d239 1
d321 1
a321 2
	int s;
	int error;
d346 1
a346 2
	int s = splsoftnet();
	int error;
d348 1
@


1.160
log
@Add some spl softnet assertions that will help us to find the right
places for the upcoming network lock.  This might trigger some
asserts, but we have to find the missing code paths.
OK mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.159 2016/09/15 02:00:16 dlg Exp $	*/
d1021 1
d1023 1
d1029 1
a1029 1
			return (0);
d1032 1
a1032 1
		return (*pr->pr_usrreq)(so, PRU_SHUTDOWN, NULL, NULL, NULL,
d1034 1
d1036 2
a1037 1
		return (EINVAL);
d1039 2
@


1.159
log
@all pools have their ipl set via pool_setipl, so fold it into pool_init.

the ioff argument to pool_init() is unused and has been for many
years, so this replaces it with an ipl argument. because the ipl
will be set on init we no longer need pool_setipl.

most of these changes have been done with coccinelle using the spatch
below. cocci sucks at formatting code though, so i fixed that by hand.

the manpage and subr_pool.c bits i did myself.

ok tedu@@ jmatthew@@

@@ipl@@
expression pp;
expression ipl;
expression s, a, o, f, m, p;
@@@@
-pool_init(pp, s, a, o, f, m, p);
-pool_setipl(pp, ipl);
+pool_init(pp, s, a, ipl, f, m, p);
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.158 2016/09/13 07:50:36 mpi Exp $	*/
a358 1
	int s = splsoftnet();
d361 6
a366 8
	if ((so->so_state & SS_ISCONNECTED) == 0) {
		error = ENOTCONN;
		goto bad;
	}
	if (so->so_state & SS_ISDISCONNECTING) {
		error = EALREADY;
		goto bad;
	}
a368 2
bad:
	splx(s);
d1507 2
d1535 2
@


1.158
log
@Do not raise splsoftnet() recursively in soaccept().

This is not an issue right now, but it will become one when an non
recursive lock will be used.

ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.157 2016/09/03 14:09:58 bluhm Exp $	*/
d95 2
a96 2
	pool_init(&socket_pool, sizeof(struct socket), 0, 0, 0, "sockpl", NULL);
	pool_setipl(&socket_pool, IPL_SOFTNET);
d98 2
a99 3
	pool_init(&sosplice_pool, sizeof(struct sosplice), 0, 0, 0, "sosppl",
	    NULL);
	pool_setipl(&sosplice_pool, IPL_SOFTNET);
@


1.157
log
@If sosend() cannot allocate a large cluster, try a small one as
fallback.
OK claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.156 2016/09/03 11:13:36 yasuoka Exp $	*/
a302 1
	int s = splsoftnet();
d305 2
a315 1
	splx(s);
@


1.156
log
@Return immediately when m_getuio() fails by invalid uio parameter.

ok mikeb bluhm claudio
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.155 2016/08/25 14:13:19 bluhm Exp $	*/
d550 2
@


1.155
log
@Spliced TCP sockets become faster when the output part is running
as its own task thread.  This is inspired by userland copy where a
process also has to go through the scheduler.  This gives the socket
buffer a chance to be filled up and tcp_output() is called less
often and with bigger chunks.
When two kernel tasks share all the workload, the current scheduler
implementation will hang userland processes on single cpu machines.
As a workaround put a yield() into the splicing thread after each
task execution.  This reduces the number of calls of tcp_output()
even more.
OK tedu@@ mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.154 2016/08/25 13:59:16 bluhm Exp $	*/
d491 2
@


1.154
log
@Completely revert the M_WAIT change on the cluster allocation and
bring back the behaviour of rev 1.72.  Although allocating small
mbufs when allocating an mbuf cluster fails seems suboptimal, this
should not be changed as a side effect when introducing m_getuio().
OK claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.153 2016/08/22 10:23:42 claudio Exp $	*/
d62 1
d89 1
d1071 1
d1080 6
d1163 1
d1187 1
d1210 21
a1503 5
#undef so_splicelen
#undef so_splicemax
#undef so_idletv
#undef so_idleto

d1510 14
a1523 2
	if (so->so_rcv.sb_flagsintr & SB_SPLICE)
		(void) somove(so, M_DONTWAIT);
d1537 1
a1537 1
		(void) somove(so->so_sp->ssp_soback, M_DONTWAIT);
@


1.153
log
@Refactor the uio to mbuf code out of sosend and start to make use of
MCLGETI and large mbuf clusters. This should speed up local connections
a fair bit. OK dlg@@ and bluhm@@ (after reverting the M_WAIT change on the
cluster allocation)
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.152 2016/06/13 21:24:43 bluhm Exp $	*/
d545 3
a547 8
			mlen = ulmin(resid, MAXMCLBYTES);
			MCLGETI(m, M_NOWAIT, NULL, mlen);

			if ((m->m_flags & M_EXT) == 0) {
				/* should not happen */
				m_freem(top);
				return (ENOBUFS);
			}
d557 1
@


1.152
log
@On localhost a user program may create a socket splicing loop.
After writing data into this loop, it was spinning forever causing
a kernel hang.  Detect the loop by counting how often the same mbuf
is spliced.  If that happens 128 times, assume that there is a loop
and abort the splicing with ELOOP.
Bug found by tedu@@;  OK tedu@@ millert@@ benno@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.151 2016/06/12 21:42:47 bluhm Exp $	*/
d376 2
a399 2
	struct mbuf **mp;
	struct mbuf *m;
a400 1
	u_long len, mlen;
a476 1
		mp = &top;
d486 4
a489 33
			} else do {
				if (top == 0) {
					MGETHDR(m, M_WAIT, MT_DATA);
					mlen = MHLEN;
					m->m_pkthdr.len = 0;
					m->m_pkthdr.ph_ifidx = 0;
				} else {
					MGET(m, M_WAIT, MT_DATA);
					mlen = MLEN;
				}
				if (resid >= MINCLSIZE && space >= MCLBYTES) {
					MCLGET(m, M_NOWAIT);
					if ((m->m_flags & M_EXT) == 0)
						goto nopages;
					if (atomic && top == 0) {
						len = ulmin(MCLBYTES - max_hdr,
						    resid);
						m->m_data += max_hdr;
					} else
						len = ulmin(MCLBYTES, resid);
					space -= len;
				} else {
nopages:
					len = ulmin(ulmin(mlen, resid), space);
					space -= len;
					/*
					 * For datagram protocols, leave room
					 * for protocol headers in first mbuf.
					 */
					if (atomic && top == 0 && len < mlen)
						MH_ALIGN(m, len);
				}
				error = uiomove(mtod(m, caddr_t), len, uio);
d491 3
a493 12
				m->m_len = len;
				*mp = m;
				top->m_pkthdr.len += len;
				if (error)
					goto release;
				mp = &m->m_next;
				if (resid == 0) {
					if (flags & MSG_EOR)
						top->m_flags |= M_EOR;
					break;
				}
			} while (space > 0 && atomic);
d502 2
a503 3
			control = 0;
			top = 0;
			mp = &top;
d518 70
@


1.151
log
@Fix format string in ddb show socket.
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.150 2016/03/14 23:08:06 krw Exp $	*/
d1202 1
a1202 1
	    sosp->so_error != EFBIG) {
d1258 9
@


1.150
log
@Change a bunch of (<blah> *)0 to NULL.

ok beck@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.149 2016/01/15 11:58:34 bluhm Exp $	*/
d1968 1
a1968 1
		(*pr)("\tssp_idletv: %lld %ldn", so->so_sp->ssp_idletv.tv_sec,
@


1.149
log
@Improve the socket panic messages further.  claudio@@ wants to see
the socket type and dlg@@ is interested in the pointers for ddb show
socket.
OK deraadt@@ dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.148 2016/01/15 11:30:03 dlg Exp $	*/
d1256 1
a1256 1
			    (struct mbuf *)0L, NULL, NULL);
@


1.149.2.1
log
@backport splice loop fix:
On localhost a user program may create a socket splicing loop.
After writing data into this loop, it was spinning forever causing
a kernel hang.  Detect the loop by counting how often the same mbuf
is spliced.  If that happens 128 times, assume that there is a loop
and abort the splicing with ELOOP.
Bug found by tedu@@;  OK tedu@@ millert@@ benno@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.149 2016/01/15 11:58:34 bluhm Exp $	*/
d1202 1
a1202 1
	    sosp->so_error != EFBIG && sosp->so_error != ELOOP) {
a1257 9
	}

	/*
	 * By splicing sockets connected to localhost, userland might create a
	 * loop.  Dissolve splicing with error if loop is detected by counter.
	 */
	if ((m->m_flags & M_PKTHDR) && m->m_pkthdr.ph_loopcnt++ >= M_MAXLOOP) {
		error = ELOOP;
		goto release;
@


1.148
log
@print TAILQ_NEXT(so, so_qe) too
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.147 2016/01/15 11:21:58 dlg Exp $	*/
d279 1
a279 1
		panic("soclose: NOFDREF");
d305 1
a305 1
		panic("soaccept: !NOFDREF");
d686 2
a687 1
			panic("receive 1, sb_cc %lu", so->so_rcv.sb_cc);
d751 2
a752 1
			panic("receive 1a, m_type %d", m->m_type);
d836 2
a837 1
			panic("receive 3, m_type %d", m->m_type);
d1245 2
a1246 1
			panic("somove soname, m_type %d", m->m_type);
d1262 2
a1263 1
			panic("somove !pkthdr");
d1305 2
a1306 1
			panic("somove type, m_type %d", (*mp)->m_type);
@


1.147
log
@add a "show socket" command to ddb

should help inspecting socket issues in the future.

enthusiasm from mpi@@ bluhm@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.146 2016/01/13 21:39:39 bluhm Exp $	*/
d1944 1
@


1.146
log
@To make bug hunting easier, print more information in the soreceive()
and somove() panic messages.
OK phessler@@ benno@@ deraadt@@ mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.145 2016/01/06 10:06:50 stefan Exp $	*/
d53 4
d1900 82
@


1.145
log
@Prevent integer overflows in sosend() and soreceive() by converting
min()+uiomovei() to ulmin()+uiomove() and re-arranging space computations
in sosend(). The soreceive() part was also reported by Martin Natano.

ok bluhm@@ and also discussed with tedu@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.144 2015/12/05 10:11:53 tedu Exp $	*/
d682 1
a682 1
			panic("receive 1");
d746 1
a746 1
			panic("receive 1a");
d830 1
a830 1
			panic("receive 3");
d1238 1
a1238 1
			panic("somove soname");
d1254 1
a1254 1
			panic("somove pkthdr");
d1296 1
a1296 1
			panic("somove type");
@


1.144
log
@remove stale lint annotations
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.143 2015/10/30 19:47:40 bluhm Exp $	*/
d396 3
a398 2
	long space, len, mlen, clen = 0;
	quad_t resid;
d406 2
a407 10
	/*
	 * In theory resid should be unsigned (since uio->uio_resid is).
	 * However, space must be signed, as it might be less than 0
	 * if we over-committed, and we must use a signed comparison
	 * of space and resid.  On the other hand, a negative resid
	 * causes us to loop sending 0-length segments to the protocol.
	 * MSG_EOR on a SOCK_STREAM socket is also invalid.
	 */
	if (resid < 0 ||
	    (so->so_type == SOCK_STREAM && (flags & MSG_EOR))) {
d414 6
d460 3
a462 2
		if (space < resid + clen &&
		    (atomic || space < so->so_snd.sb_lowat || space < clen)) {
d499 1
a499 1
						len = lmin(MCLBYTES - max_hdr,
d503 1
a503 1
						len = lmin(MCLBYTES, resid);
d507 1
a507 1
					len = lmin(lmin(mlen, resid), space);
d516 1
a516 2
				error = uiomovei(mtod(m, caddr_t), (int)len,
				    uio);
d524 1
a524 1
				if (resid <= 0) {
d531 1
a531 1
			if (resid <= 0)
d615 2
a616 1
	int flags, len, error, s, offset;
d619 1
a619 4
	int moff, type = 0;
	size_t orig_resid = uio->uio_resid;
	int uio_error = 0;
	int resid;
d639 2
a640 2
			error = uiomovei(mtod(m, caddr_t),
			    (int) min(uio->uio_resid, m->m_len), uio);
d851 1
a851 1
			uio_error = uiomovei(mtod(m, caddr_t) + moff, len, uio);
@


1.143
log
@Let m_resethdr() clear the whole mbuf packet header, not only the
pf part.  This allows to reuse this function in socket splicing.
Reset the mbuf flags that are related to the packet header, but
preserve the data flags.
pair(4) tested by reyk@@; sosplice(9) tested by bluhm@@; OK mikeb@@ reyk@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.142 2015/08/24 14:28:25 bluhm Exp $	*/
a104 1
/*ARGSUSED*/
a1835 1
/*ARGSUSED*/
a1869 1
/*ARGSUSED*/
a1890 1
/*ARGSUSED*/
@


1.142
log
@Items from pool sosplice_pool are get in process context and put
in soft interrupt.  So the pool needs an IPL_SOFTNET protection.
This fixes a panic: mtx_enter: locking against myself.
While there, call pool_setipl() also for socket_pool.  Although
this pool uses explicit spl protection around pool_get() and
pool_put(), it is better to specify the IPL it is operating on.
OK mpi@@ mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.141 2015/07/08 07:21:50 mpi Exp $	*/
d1328 1
a1328 2
		m_tag_delete_chain(m);
		memset(&m->m_pkthdr, 0, sizeof(m->m_pkthdr));
a1329 1
		m->m_pkthdr.pf.prio = IFQ_DEFPRIO;
@


1.141
log
@MFREE(9) is dead, long live m_freem(9)!

ok bluhm@@, claudio@@, dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.140 2015/06/30 15:30:17 mpi Exp $	*/
a88 1

d90 1
d94 1
@


1.141.4.1
log
@I forgot to commit the 5.8 version of the splice fix.
Reminded by Florian Riehm
backport splice loop fix:
On localhost a user program may create a socket splicing loop.
After writing data into this loop, it was spinning forever causing
a kernel hang.  Detect the loop by counting how often the same mbuf
is spliced.  If that happens 128 times, assume that there is a loop
and abort the splicing with ELOOP.
Bug found by tedu@@;  OK tedu@@ millert@@ benno@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.141 2015/07/08 07:21:50 mpi Exp $	*/
d1198 1
a1198 1
	    sosp->so_error != EFBIG && sosp->so_error != ELOOP) {
a1254 9
	/*
	 * By splicing sockets connected to localhost, userland might create a
	 * loop.  Dissolve splicing with error if loop is detected by counter.
	 */
	if ((m->m_flags & M_PKTHDR) && m->m_pkthdr.ph_loopcnt++ >= M_MAXLOOP) {
		error = ELOOP;
		goto release;
	}

a1326 1
		u_int8_t loopcnt = m->m_pkthdr.ph_loopcnt;
a1330 1
		m->m_pkthdr.ph_loopcnt = loopcnt;
@


1.140
log
@Get rid of the undocumented & temporary* m_copy() macro added for
compatibility with 4.3BSD in September 1989.

*Pick your own definition for "temporary".

ok bluhm@@, claudio@@, dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.139 2015/06/16 11:09:39 mpi Exp $	*/
d764 1
a764 1
				MFREE(m, so->so_rcv.sb_mb);
d875 1
a875 1
					MFREE(m, so->so_rcv.sb_mb);
d1274 1
a1274 1
		MFREE(m, so->so_rcv.sb_mb);
d1284 1
a1284 1
		MFREE(m, so->so_rcv.sb_mb);
@


1.139
log
@Store a unique ID, an interface index, rather than a pointer to the
receiving interface in the packet header of every mbuf.

The interface pointer should now be retrieved when necessary with
if_get().  If a NULL pointer is returned by if_get(), the interface
has probably been destroy/removed and the mbuf should be freed.

Such mechanism will simplify garbage collection of mbufs and limit
problems with dangling ifp pointers.

Tested by jmatthew@@ and krw@@, discussed with many.

ok mikeb@@, bluhm@@, dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.138 2015/05/06 08:52:17 mpi Exp $	*/
d754 1
a754 1
				*paddr = m_copy(m, 0, m->m_len);
d773 1
a773 1
				*controlp = m_copy(m, 0, m->m_len);
@


1.138
log
@Pass a thread pointer instead of its file descriptor table to getsock(9).

Diff from Vitaliy Makkoveev.

Manpage tweak and ok millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.137 2015/03/14 03:38:51 jsg Exp $	*/
d489 1
a489 1
					m->m_pkthdr.rcvif = (struct ifnet *)0;
@


1.137
log
@Remove some includes include-what-you-use claims don't
have any direct symbols used.  Tested for indirect use by compiling
amd64/i386/sparc64 kernels.

ok tedu@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.136 2015/02/10 21:56:10 miod Exp $	*/
d1079 1
a1079 1
	if ((error = getsock(curproc->p_fd, fd, &fp)) != 0)
@


1.136
log
@First step towards making uiomove() take a size_t size argument:
- rename uiomove() to uiomovei() and update all its users.
- introduce uiomove(), which is similar to uiomovei() but with a size_t.
- rewrite uiomovei() as an uiomove() wrapper.
ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.135 2014/12/11 19:21:57 tedu Exp $	*/
a49 1
#include <sys/resourcevar.h>
@


1.135
log
@convert bcopy to memcpy/memmove. ok krw
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.134 2014/11/03 17:20:46 bluhm Exp $	*/
d517 1
a517 1
				error = uiomove(mtod(m, caddr_t), (int)len,
d643 1
a643 1
			error = uiomove(mtod(m, caddr_t),
d855 1
a855 1
			uio_error = uiomove(mtod(m, caddr_t) + moff, len, uio);
@


1.134
log
@Put the socket splicing fields into a seperate struct sosplice that
gets only allocated when needed.  This way struct socket shrinks
from 472 to 392 bytes on amd64.  When splicing gets active, another
88 bytes are allocated for struct sosplice.
OK dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.133 2014/09/09 02:07:17 guenther Exp $	*/
d1770 2
a1771 2
					bcopy(&(unp->unp_connid),
					    mtod(m, caddr_t), m->m_len);
@


1.133
log
@Delete the SS_ISCONFIRMING flag that supported delayed connection
confirmation: it was only used for netiso, which was deleted a *decade* ago

ok mpi@@ claudio@@  ports scan by sthen@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.132 2014/09/08 06:24:13 jsg Exp $	*/
d83 3
d92 4
d167 1
a167 1
	if (so->so_splice || so->so_spliceback)
d209 9
a217 4
	if (so->so_spliceback)
		sounsplice(so->so_spliceback, so, so->so_spliceback != so);
	if (so->so_splice)
		sounsplice(so, so->so_splice, 0);
d662 1
a662 1
	if (so->so_splice)
d684 1
a684 1
		    if (so->so_splice == NULL)
d1036 6
d1056 2
d1066 2
a1067 2
		if (so->so_splice)
			sounsplice(so, so->so_splice, 1);
d1083 2
d1099 1
a1099 1
	if (so->so_splice || sosp->so_spliceback) {
d1117 2
a1118 2
	so->so_splice = sosp;
	sosp->so_spliceback = so;
d1152 1
a1152 1
	so->so_splice = sosp->so_spliceback = NULL;
d1164 1
a1164 1
	if (so->so_splice) {
d1166 1
a1166 1
		sounsplice(so, so->so_splice, 1);
d1180 1
a1180 1
	struct socket	*sosp = so->so_splice;
d1433 6
d1447 1
a1447 1
	if (so->so_splice)
d1460 1
a1460 1
		(void) somove(so->so_spliceback, M_DONTWAIT);
d1753 1
d1757 2
a1758 2
			memcpy(mtod(m, off_t *), &so->so_splicelen,
			    sizeof(off_t));
d1847 1
a1847 1
	if (so->so_splice)
@


1.132
log
@remove uneeded route.h includes
ok miod@@ mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.131 2014/08/31 01:42:36 guenther Exp $	*/
d438 1
a438 2
				if ((so->so_state & SS_ISCONFIRMING) == 0 &&
				    !(resid == 0 && clen != 0))
a641 2
	if (so->so_state & SS_ISCONFIRMING && uio->uio_resid)
		(*pr->pr_usrreq)(so, PRU_RCVD, NULL, NULL, NULL, curproc);
a1062 4

	if (so->so_state & SS_ISCONFIRMING)
		(*so->so_proto->pr_usrreq)(so, PRU_RCVD, NULL, NULL, NULL,
		    curproc);
@


1.131
log
@Add additional kernel interfaces for setting close-on-exec on fds
when creating them: pipe2(), dup3(), accept4(), MSG_CMSG_CLOEXEC,
SOCK_CLOEXEC.  Includes SOCK_NONBLOCK support.

ok matthew@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.130 2014/07/13 15:52:38 tedu Exp $	*/
a51 1
#include <net/route.h>
@


1.130
log
@bzero -> memset. for the speeds.
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.129 2014/07/09 15:43:33 tedu Exp $	*/
d780 1
a780 1
				       controllen);
@


1.129
log
@spelling
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.128 2014/06/08 14:17:52 miod Exp $	*/
d1015 2
a1016 2
	bzero(sb, sizeof (*sb));
	/* XXX - the bzero stomps all over so_rcv */
d1315 1
a1315 1
		bzero(&m->m_pkthdr, sizeof(m->m_pkthdr));
@


1.128
log
@Use memcpy to copy the sogetopt() SO_SPLICE off_t value, for it may not be
correctly aligned. Similar in spirit to 1.119.
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.127 2014/04/07 10:04:17 mpi Exp $	*/
d1016 1
a1016 1
	/* XXX - the bzero stumps all over so_rcv */
@


1.127
log
@Retire kernel support for SO_DONTROUTE, this time without breaking
localhost connections.

The plan is to always use the routing table for addresses and routes
resolutions, so there is no future for an option that wants to bypass
it.  This option has never been implemented for IPv6 anyway, so let's
just remove the IPv4 bits that you weren't aware of.

Tested a least by lteo@@, guenther@@ and chrisz@@, ok mikeb@@, benno@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.126 2014/03/30 21:54:48 guenther Exp $	*/
d1736 2
a1737 1
			*mtod(m, off_t *) = so->so_splicelen;
@


1.126
log
@Eliminates struct pcred by moving the real and saved ugids into
struct ucred; struct process then directly links to the ucred

Based on a discussion at c2k10 or so before noting that FreeBSD and
NetBSD did this too.

ok matthew@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.125 2014/03/28 08:33:51 sthen Exp $	*/
d388 1
a388 1
	int error, s, dontroute;
a407 3
	dontroute =
	    (flags & MSG_DONTROUTE) && (so->so_options & SO_DONTROUTE) == 0 &&
	    (so->so_proto->pr_flags & PR_ATOMIC);
a521 2
			if (dontroute)
				so->so_options |= SO_DONTROUTE;
a528 2
			if (dontroute)
				so->so_options &= ~SO_DONTROUTE;
a1478 1
		case SO_DONTROUTE:
d1495 9
a1661 1
		case SO_DONTROUTE:
d1670 4
@


1.125
log
@revert "Retire kernel support for SO_DONTROUTE" diff, which does bad things
for localhost connections. discussed with deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.123 2014/03/18 07:01:21 guenther Exp $	*/
d123 1
a123 1
	so->so_ruid = p->p_cred->p_ruid;
d125 1
a125 1
	so->so_rgid = p->p_cred->p_rgid;
@


1.124
log
@Retire kernel support for SO_DONTROUTE, since the plan is to always
use the routing table there's no future for an option that wants to
bypass it.  This option has never been implemented for IPv6 anyway,
so let's just remove the IPv4 bits that you weren't aware of.

Tested by florian@@, man pages inputs from jmc@@, ok benno@@
@
text
@d388 1
a388 1
	int error, s;
d408 3
d525 2
d534 2
d1486 1
a1502 9
		case SO_DONTROUTE:
			if (m == NULL || m->m_len < sizeof (int)) {
				error = EINVAL;
				goto bad;
			}
			if (*mtod(m, int *))
				error = EOPNOTSUPP;
			break;

d1661 1
a1669 4
			break;

		case SO_DONTROUTE:
			*mtod(m, int *) = 0;
@


1.123
log
@When creating a unix socket, save the PID for pf's log(user), even when
not in the original thread.

ok matthew@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.122 2014/01/21 23:57:56 guenther Exp $	*/
d388 1
a388 1
	int error, s, dontroute;
a407 3
	dontroute =
	    (flags & MSG_DONTROUTE) && (so->so_options & SO_DONTROUTE) == 0 &&
	    (so->so_proto->pr_flags & PR_ATOMIC);
a521 2
			if (dontroute)
				so->so_options |= SO_DONTROUTE;
a528 2
			if (dontroute)
				so->so_options &= ~SO_DONTROUTE;
a1478 1
		case SO_DONTROUTE:
d1495 9
a1661 1
		case SO_DONTROUTE:
d1670 4
@


1.122
log
@Don't leak kernel stack in timeval padding in getsockopt(SO_{SND,RCV}TIMEO)

ok mikeb@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.121 2014/01/11 14:33:48 bluhm Exp $	*/
d127 1
a127 1
	so->so_cpid = p->p_pid;
@


1.121
log
@When I created UDP socket splicing, I added the goto nextpkt loop
to splice multiple UDP packets in the m_nextpkt list.  Some profiling
with TCP splicing showed that checking so_rcv.sb_mb is wrong.  It
causes several useless runs through the loop.  Better check for
nextrecord which contains the original m_nextpkt value of the mbuf.
OK mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.120 2013/12/10 21:44:50 mikeb Exp $	*/
d1705 1
@


1.120
log
@dead assignment;  from david hill, ok claudio
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.119 2013/08/27 03:32:11 deraadt Exp $	*/
d1408 1
a1408 1
	if (!maxreached && so->so_rcv.sb_mb)
@


1.119
log
@Manipulate timevals seperately, not inside a mbuf.  Alignment constraints
miod ran into.
ok miod matthew
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.118 2013/04/05 08:25:30 tedu Exp $	*/
a491 1
					mlen = MCLBYTES;
d493 2
a494 1
						len = lmin(MCLBYTES - max_hdr, resid);
@


1.118
log
@remove some obsolete casts
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.117 2013/04/04 18:13:43 bluhm Exp $	*/
d1562 1
a1562 1
			struct timeval *tv;
d1565 1
a1565 1
			if (m == NULL || m->m_len < sizeof (*tv)) {
d1569 2
a1570 2
			tv = mtod(m, struct timeval *);
			val = tvtohz(tv);
d1700 1
d1705 3
a1707 3
			mtod(m, struct timeval *)->tv_sec = val / hz;
			mtod(m, struct timeval *)->tv_usec =
			    (val % hz) * tick;
@


1.117
log
@Do not allow the listen(2) syscall for an already connected socket.
This would create a weird set of states in TCP.  FreeBSD has the
same check.
Issue found by and OK guenther@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.116 2013/03/27 15:41:04 bluhm Exp $	*/
d854 1
a854 3
			uio_error =
				uiomove(mtod(m, caddr_t) + moff, (int)len,
					uio);
d1330 1
a1330 1
		    (struct mbuf *)0L, NULL, NULL);
d1742 2
a1743 3
					bcopy((caddr_t)(&(unp->unp_connid)),
					    mtod(m, caddr_t),
					    m->m_len);
d1772 1
a1772 1
	struct socket *so = (struct socket *)kn->kn_fp->f_data;
d1802 1
a1802 1
	struct socket *so = (struct socket *)kn->kn_fp->f_data;
d1815 1
a1815 1
	struct socket *so = (struct socket *)kn->kn_fp->f_data;
d1837 1
a1837 1
	struct socket *so = (struct socket *)kn->kn_fp->f_data;
d1850 1
a1850 1
	struct socket *so = (struct socket *)kn->kn_fp->f_data;
d1872 1
a1872 1
	struct socket *so = (struct socket *)kn->kn_fp->f_data;
@


1.116
log
@Move soidle() into the big #ifdef SOCKET_SPLICE block to have it
all in one place.  Saves one additional #ifdef, no functional change.
OK mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.115 2013/03/19 20:07:14 bluhm Exp $	*/
d158 2
@


1.115
log
@After a socket splicing timeout is fired, a network interrupt can
unsplice() the sockets before soidle() goes to splsoftnet.  In this
case, unsplice() was called twice.  So check wether splicing still
exists within the splsoftnet protection.
Uvm fault in sounsplice() reported by keith at scott-land dot net.
OK claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.114 2013/02/16 14:34:52 bluhm Exp $	*/
d59 1
a60 1
void	soidle(void *);
d1150 14
a1450 16

#ifdef SOCKET_SPLICE
void
soidle(void *arg)
{
	struct socket *so = arg;
	int s;

	s = splsoftnet();
	if (so->so_splice) {
		so->so_error = ETIMEDOUT;
		sounsplice(so, so->so_splice, 1);
	}
	splx(s);
}
#endif /* SOCKET_SPLICE */
@


1.114
log
@Fix a bug in udp socket splicing in case a packet gets diverted and
spliced and routed to loopback.  The content of the pf header in
the mbuf was keeping the divert information on its way.  Reinitialize
the whole packet header of the mbuf and remove the mbuf tags when
the packet gets spliced.
OK claudio@@ markus@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.113 2013/01/17 16:30:10 bluhm Exp $	*/
d1446 4
a1449 2
	so->so_error = ETIMEDOUT;
	sounsplice(so, so->so_splice, 1);
@


1.113
log
@Expand the socket splicing functionality from TCP to UDP.  Merge
the code relevant for UDP from sosend() and soreceive() into somove().
That allows the kernel to directly transfer the UDP data from one
socket to another.
OK claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.112 2013/01/15 21:48:32 bluhm Exp $	*/
d51 1
d1306 6
@


1.112
log
@Pass an EFBIG error to user land when the maximum splicing length
has been reached.  This creates a read event on the spliced source
socket that can be noticed with select(2).  So the kernel passes
control to the relay process immediately.  This could be used to
log the end of an http request within a persistent connection.
deraadt@@ reyk@@ mikeb@@ like the idea
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.111 2013/01/15 11:12:57 bluhm Exp $	*/
d1045 2
a1046 1
	if ((so->so_state & (SS_ISCONNECTED|SS_ISCONNECTING)) == 0)
d1074 4
d1167 1
d1185 1
a1185 3
	len = so->so_rcv.sb_cc;
	if (len == 0)
		goto release;
d1209 2
a1210 1
	/* Take at most len mbufs out of receive buffer. */
d1212 2
d1215 58
a1272 1
	for (off = 0, mp = &m; off < len;
d1276 4
d1299 2
a1300 3
	SBLASTRECORDCHK(&so->so_rcv, "somove");
	SBLASTMBUFCHK(&so->so_rcv, "somove");
	KASSERT(so->so_rcv.sb_mb == so->so_rcv.sb_lastrecord);
a1301 2

	/* m might be NULL if the loop did break during the first iteration. */
d1304 1
d1385 4
@


1.111
log
@Changing the socket buffer flags sb_flags was not interrupt safe
as |= and &= are non-atomic operations.  To avoid additional locks,
put the flags that have to be accessed from interrupt into a separate
sb_flagsintr 32 bit integer field.  sb_flagsintr is protected by
splsoftnet.
Input from miod@@ deraadt@@; OK deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.110 2012/12/31 13:46:49 bluhm Exp $	*/
d1170 2
a1171 1
	if (sosp->so_error && sosp->so_error != ETIMEDOUT) {
d1322 2
@


1.110
log
@Put the #ifdef SOCKBUF_DEBUG around sbcheck() into a SBCHECK macro.
That is consistent to the SBLASTRECORDCHK and SBLASTMBUFCHK macros.
OK markus@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.109 2012/10/05 01:30:28 yasuoka Exp $	*/
d1119 2
a1120 2
		so->so_rcv.sb_flags |= SB_SPLICE;
		sosp->so_snd.sb_flags |= SB_SPLICE;
d1137 2
a1138 2
	sosp->so_snd.sb_flags &= ~SB_SPLICE;
	so->so_rcv.sb_flags &= ~SB_SPLICE;
d1338 1
a1338 1
	if (so->so_rcv.sb_flags & SB_SPLICE)
d1352 1
a1352 1
	if (so->so_snd.sb_flags & SB_SPLICE)
@


1.109
log
@add send(2) MSG_DONTWAIT support which enables us to choose nonblocking
or blocking for each send(2) call.

diff from UMEZAWA Takeshi
ok bluhm
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.108 2012/09/20 12:34:18 bluhm Exp $	*/
d1233 1
a1233 3
#ifdef SOCKBUF_DEBUG
	sbcheck(&so->so_rcv);
#endif
@


1.108
log
@In somove() free the mbufs when necessary instead of freeing them
in the release path.  Especially accessing m in a KDASSERT() could
go wrong.
OK claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.107 2012/09/19 20:00:32 bluhm Exp $	*/
d454 1
a454 1
			if (so->so_state & SS_NBIO)
@


1.107
log
@When a socket is spliced, it may not wakeup the userland for reading.
There was a small race in sorwakeup() where that could happen if
we slept before the SB_SPLICE flag was set.
ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.106 2012/09/19 19:41:29 bluhm Exp $	*/
d1154 1
a1154 1
	struct mbuf	*m = NULL, **mp, *nextrecord;
a1231 1
	KDASSERT(m->m_nextpkt == NULL);
d1237 6
a1242 2
	/* Send window update to source peer if receive buffer has changed. */
	if (m && so->so_proto->pr_flags & PR_WANTRCVD && so->so_pcb)
d1262 1
a1262 1
	while (m && ((state & SS_RCVATMARK) || oobmark) &&
a1273 1
				m = o;
d1277 1
d1282 1
d1295 1
d1310 8
a1317 12
	if (m) {
		if (so->so_rcv.sb_cc == 0 || maxreached)
			sosp->so_state &= ~SS_ISSENDING;
		error = (*sosp->so_proto->pr_usrreq)(sosp, PRU_SEND, m, NULL,
		    NULL, NULL);
		m = NULL;
		if (error) {
			if (sosp->so_state & SS_CANTSENDMORE)
				error = EPIPE;
			goto release;
		}
		so->so_splicelen += len;
d1319 1
a1321 2
	if (m)
		m_freem(m);
@


1.106
log
@In somove() make the call to pr_usrreq(PRU_RCVD) under the same
conditions as in soreceive().  My goal is to make socket splicing
less protocol dependent.
ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.105 2012/09/17 14:33:56 bluhm Exp $	*/
d1340 1
a1340 1
	if (so->so_rcv.sb_flags & SB_SPLICE) {
d1342 1
a1343 1
	}
@


1.105
log
@Fix indent white spaces.
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.104 2012/07/22 18:11:54 guenther Exp $	*/
d1239 1
a1239 1
	if (m)
@


1.104
log
@unp_dispose() walks not just the mbuf chain (m_next) but also the packet
chain (m_nextpkt), so the mbuf passed to it must be disconnected completely
from the socket buffer's chains.

Problem noticed by yasuoka@@; tweak from krw@@, ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.103 2012/07/10 11:42:53 guenther Exp $	*/
d574 12
a585 12
        /*
         * Now update any dependent socket buffer fields to reflect
         * the new state.  This is an inline of SB_EMPTY_FIXUP, with
         * the addition of a second clause that takes care of the
         * case where sb_mb has been updated, but remains the last
         * record.
         */
        if (sb->sb_mb == NULL) {
                sb->sb_mbtail = NULL;
                sb->sb_lastrecord = NULL;
        } else if (sb->sb_mb->m_nextpkt == NULL)
                sb->sb_lastrecord = sb->sb_mb;
@


1.103
log
@For setsockopt(SO_{SND,RCV}TIMEO), convert the timeval to ticks using
tvtohz() so that the rounding is correct and we don't time out a tick early

ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.102 2012/07/10 09:40:25 claudio Exp $	*/
d775 1
a775 1
			m->m_next = 0;
@


1.102
log
@Try to cleanup the macro magic because of socket spliceing. Since struct
socket is no longer affected by option SOCKET_SPLICE we can simplyfy the
code. OK bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.101 2012/07/07 18:48:19 bluhm Exp $	*/
d1485 1
a1485 1
			u_short val;
d1492 2
a1493 1
			if (tv->tv_sec > (USHRT_MAX - tv->tv_usec / tick) / hz) {
a1496 3
			val = tv->tv_sec * hz + tv->tv_usec / tick;
			if (val == 0 && tv->tv_usec != 0)
				val = 1;
@


1.101
log
@Fix two races in socket splicing.  When somove() gets called from
sosplice() to move the data already there, it might sleep in
m_copym().
Another process must not unsplice during that sleep, so also lock
the receive buffer when sosplice is called with fd -1.
The same sleep can allow network interrupts to modify the socket
buffer.  So use sbsync() to write back modifications within the
loop instead of fixing the socket buffer after the loop.
OK claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.100 2012/04/24 16:35:08 deraadt Exp $	*/
d1271 1
a1271 1
				m = NULL;
a1272 1
					m_freem(o);
a1278 1
				m = o;
d1334 1
d1339 1
d1344 4
a1347 1
	_sorwakeup(so);
d1353 1
d1356 2
a1357 1
	_sowwakeup(so);
d1360 1
@


1.100
log
@In sosend() for AF_UNIX control message sending, correctly calculate
the size (internalized ones can be larger on some architectures) for
fitting into the socket.  Avoid getting confused by sb_hiwat as well.
This fixes a variety of issues where sendmsg() would fail to deliver
a fd set or fail to wait; even leading to file leakage.
Worked on this with claudio for about a week...
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.99 2012/04/22 05:43:14 guenther Exp $	*/
d1050 4
d1058 1
d1154 1
a1154 1
	struct mbuf	*m = NULL, **mp;
d1206 1
d1225 1
a1228 2
	SB_EMPTY_FIXUP(&so->so_rcv);
	so->so_rcv.sb_lastrecord = so->so_rcv.sb_mb;
@


1.99
log
@Add struct proc * argument to FRELE() and FILE_SET_MATURE() in
anticipation of further changes to closef().  No binary change.

ok krw@@ miod@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.98 2012/03/23 15:51:26 guenther Exp $	*/
d410 1
a410 1
	if (control)
d412 9
d449 2
a450 1
		    clen > so->so_snd.sb_hiwat)
@


1.98
log
@Make rusage totals, itimers, and profile settings per-process instead
of per-rthread.  Handling of per-thread tick and runtime counters
inspired by how FreeBSD does it.

ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.97 2012/03/17 10:16:41 dlg Exp $	*/
d1061 1
a1061 1
		FRELE(fp);
d1066 1
a1066 1
		FRELE(fp);
d1112 1
a1112 1
	FRELE(fp);
@


1.97
log
@remove IP_JUMBO, SO_JUMBO, and RTF_JUMBO.

no objection from mcbride@@ krw@@ markus@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.96 2012/03/14 21:27:01 kettenis Exp $	*/
d409 1
a409 1
		uio->uio_procp->p_stats->p_ru.ru_msgsnd++;
d728 1
a728 1
		uio->uio_procp->p_stats->p_ru.ru_msgrcv++;
@


1.96
log
@Close a race that would corrupt a sockbuf because the code that externalizes
an SCM_RIGHTS message may sleep.  Bits and pieces from NetBSD with some
simplifications by yours truly.

Fixes the "receive 1" panic seen by many.

ok guenther@@, claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.95 2011/08/23 13:44:58 bluhm Exp $	*/
a1392 1
		case SO_JUMBO:
a1570 1
		case SO_JUMBO:
@


1.95
log
@iPrevent that a socket splicing timeout error in one direction is
also added to the other direction.
ok mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.94 2011/07/04 00:33:36 mikeb Exp $	*/
d54 2
d544 35
d600 1
d716 10
a725 2
	 * While we process the initial mbufs containing address and control
	 * info, we save a copy of m->m_nextpkt into nextrecord.
d754 1
d764 5
d771 1
a771 1
				    mtod(m, struct cmsghdr *)->cmsg_type ==
d773 1
a773 1
				   error = (*pr->pr_domain->dom_externalize)(m,
d775 1
a775 4
				*controlp = m;
				so->so_rcv.sb_mb = m->m_next;
				m->m_next = 0;
				m = so->so_rcv.sb_mb;
d782 3
a784 4
				    mtod(m, struct cmsghdr *)->cmsg_type == SCM_RIGHTS)
					pr->pr_domain->dom_dispose(m);
				MFREE(m, so->so_rcv.sb_mb);
				m = so->so_rcv.sb_mb;
d787 4
d797 1
a797 6
	/*
	 * If m is non-NULL, we have some data to read.  From now on,
	 * make sure to keep sb_lastrecord consistent when working on
	 * the last packet on the chain (nextrecord == NULL) and we
	 * change m->m_nextpkt.
	 */
a798 12
		if ((flags & MSG_PEEK) == 0) {
			m->m_nextpkt = nextrecord;
			/*
			 * If nextrecord == NULL (this is a single chain),
			 * then sb_lastrecord may not be valid here if m
			 * was changed earlier.
			 */
			if (nextrecord == NULL) {
				KASSERT(so->so_rcv.sb_mb == m);
				so->so_rcv.sb_lastrecord = m;
			}
		}
a805 6
	} else {
		if ((flags & MSG_PEEK) == 0) {
			KASSERT(so->so_rcv.sb_mb == m);
			so->so_rcv.sb_mb = nextrecord;
			SB_EMPTY_FIXUP(&so->so_rcv);
		}
@


1.94
log
@Implement an idle timeout for the socket splicing.  A new `sp_idle'
field of the `splice' structure can be used to specify a period of
inactivity after which splicing will be dissolved.  ETIMEDOUT error
retrieved with a SO_ERROR indicates the idle timeout expiration.
With comments from and OK bluhm.
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.93 2011/07/02 22:20:08 nicm Exp $	*/
d1126 1
a1126 1
	if (sosp->so_error) {
@


1.93
log
@kqueue attach functions should return an errno or 0, not a plain 1. Fix
the obvious cases to return EINVAL and ENXIO.

ok tedu deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.92 2011/05/02 13:48:38 mikeb Exp $	*/
d54 1
a54 1
int	sosplice(struct socket *, int, off_t);
d57 1
d996 1
a996 1
sosplice(struct socket *so, int fd, off_t max)
d1021 3
d1064 5
d1092 1
d1288 2
d1310 12
d1479 1
a1479 1
				error = sosplice(so, -1, 0);
d1484 1
a1484 1
				error = sosplice(so, *mtod(m, int *), 0);
d1488 2
a1489 1
				    mtod(m, struct splice *)->sp_max);
@


1.92
log
@recognize SO_RTABLE socket option at the SOL_SOCKET level;
discussed with and ok claudio
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.91 2011/04/19 22:33:08 bluhm Exp $	*/
d1641 1
a1641 1
		return (1);
@


1.91
log
@Put splice cleanup code into a common function sounsplice().
ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.90 2011/04/04 21:08:26 claudio Exp $	*/
d1439 13
d1560 14
@


1.90
log
@Plug mbuf leaks in SO_PEERCRED by not double allocating mbufs into
the same variable. Leak found with dlg's magic mbuf leakage finder.
OK henning@@, deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.89 2011/04/04 11:10:26 claudio Exp $	*/
d55 1
d57 4
a60 3
void 	filt_sordetach(struct knote *kn);
int 	filt_soread(struct knote *kn, long hint);
void 	filt_sowdetach(struct knote *kn);
d197 4
a200 13
	if (so->so_spliceback) {
		so->so_snd.sb_flags &= ~SB_SPLICE;
		so->so_spliceback->so_rcv.sb_flags &= ~SB_SPLICE;
		so->so_spliceback->so_splice = NULL;
		if (soreadable(so->so_spliceback))
			sorwakeup(so->so_spliceback);
	}
	if (so->so_splice) {
		so->so_splice->so_snd.sb_flags &= ~SB_SPLICE;
		so->so_rcv.sb_flags &= ~SB_SPLICE;
		so->so_splice->so_spliceback = NULL;
	}
	so->so_spliceback = so->so_splice = NULL;
d1011 2
a1012 8
		if (so->so_splice) {
			so->so_splice->so_snd.sb_flags &= ~SB_SPLICE;
			so->so_rcv.sb_flags &= ~SB_SPLICE;
			so->so_splice->so_spliceback = NULL;
			so->so_splice = NULL;
			if (soreadable(so))
				sorwakeup(so);
		}
d1078 12
d1275 1
a1275 5
		sosp->so_snd.sb_flags &= ~SB_SPLICE;
		so->so_rcv.sb_flags &= ~SB_SPLICE;
		so->so_splice = sosp->so_spliceback = NULL;
		if (soreadable(so))
			sorwakeup(so);
@


1.89
log
@If the socket was half closed then don't let userland change the
socketbuffer size of the closed side since on half close the high
watermark was set to 0.
OK blambert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.88 2011/03/14 01:06:20 bluhm Exp $	*/
a1569 1
					*mp = m = m_get(M_WAIT, MT_SOOPTS);
d1573 8
a1580 5
					    (unsigned)m->m_len);
				} else
					return (ENOTCONN);
			} else
				return (EOPNOTSUPP);
@


1.88
log
@When a process reads from a spliced socket that already got an
end-of-file but still has data in the receive buffer, soreceive()
should block until all data has been moved.
To make kqueue work with socket splicing, it has to report spliced
sockets as non-readable.
ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.87 2011/03/12 18:31:41 bluhm Exp $	*/
d1374 4
d1387 4
d1400 2
a1401 1
				so->so_snd.sb_lowat = (cnt > so->so_snd.sb_hiwat) ?
d1405 2
a1406 1
				so->so_rcv.sb_lowat = (cnt > so->so_rcv.sb_hiwat) ?
@


1.87
log
@There existed a race when a process was trying to read from a spliced
socket.  soreceive() releases splsoftnet for uiomove().  In that
moment, somove() could pull the mbuf from the receive buffer.  After
that, soreceive removed the mbuf again.  The corrupted length
accounting resulted in a panic.
The fix is to block read calls in soreceive() until splicing has
been finished.
just commit deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.86 2011/02/28 16:29:42 bluhm Exp $	*/
d653 1
a653 1
			else
d1636 4
@


1.86
log
@When the maximum splice length has been reached, send out the data
immediately by unsetting the SS_ISSENDING flag.  This prevents a
possible 5 seconds delay in socket splicing.
ok markus@@; commit it deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.85 2011/01/07 17:50:42 bluhm Exp $	*/
d615 4
d637 3
@


1.85
log
@Add socket option SO_SPLICE to splice together two TCP sockets.
The data received on the source socket will automatically be sent
on the drain socket.  This allows to write relay daemons with zero
data copy.
ok markus@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.84 2010/09/24 02:59:45 claudio Exp $	*/
d1248 1
a1248 1
		if (so->so_rcv.sb_cc == 0)
@


1.84
log
@TCP send and recv buffer scaling.
Send buffer is scaled by not accounting unacknowledged on the wire
data against the buffer limit. Receive buffer scaling is done similar
to FreeBSD -- measure the delay * bandwith product and base the
buffer on that. The problem is that our RTT measurment is coarse
so it overshoots on low delay links. This does not matter that much
since the recvbuffer is almost always empty.
Add a back pressure mechanism to control the amount of memory
assigned to socketbuffers that kicks in when 80% of the cluster
pool is used.
Increases the download speed from 300kB/s to 4.4MB/s on ftp.eu.openbsd.org.

Based on work by markus@@ and djm@@.

OK dlg@@, henning@@, put it in deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.83 2010/07/03 04:44:51 guenther Exp $	*/
d39 1
d54 2
d150 1
a150 1
	int s = splsoftnet(), error;
d152 5
d194 15
d993 305
d1427 17
d1535 12
@


1.83
log
@Fix the naming of interfaces and variables for rdomains and rtables
and make it possible to bind sockets (including listening sockets!)
to rtables and not just rdomains.  This changes the name of the
system calls, socket option, and ioctl.  After building with this
you should remove the files /usr/share/man/cat2/[gs]etrdomain.0.

Since this removes the existing [gs]etrdomain() system calls, the
libc major is bumped.

Written by claudio@@, criticized^Wcritiqued by me
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.82 2010/07/02 19:57:15 tedu Exp $	*/
d1039 1
a1039 1
				if (sbcheckreserve(cnt, so->so_snd.sb_hiwat) ||
d1044 1
d1048 1
a1048 1
				if (sbcheckreserve(cnt, so->so_rcv.sb_hiwat) ||
d1053 1
@


1.82
log
@remove support for compat_sunos (and m68k4k).  ok deraadt guenther
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.81 2010/07/01 18:47:45 deraadt Exp $	*/
a983 1
		case SO_RDOMAIN:
@


1.81
log
@SO_PEERCRED should return ENOTCONN when the sockets are not connected
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.80 2010/06/30 19:57:05 deraadt Exp $	*/
a127 7
#ifdef COMPAT_SUNOS
	{
		extern struct emul emul_sunos;
		if (p->p_emul == &emul_sunos && type == SOCK_DGRAM)
			so->so_options |= SO_BROADCAST;
	}
#endif
@


1.80
log
@Add getsockopt SOL_SOCKET SO_PEERCRED support. This behaves similar to
getpeereid(2), but also supplies the remote pid.  This is supplied in
a 'struct sockpeercred' (unlike Linux -- they showed how little they
know about real unix by calling theirs 'struct ucred').
ok guenther ajacoutot
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.79 2009/10/31 12:00:08 fgsch Exp $	*/
d1208 1
a1208 1
					return (EINVAL);
@


1.79
log
@Use suser when possible. Suggested by miod@@.
miod@@ deraadt@@ ok.
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.78 2009/08/10 16:49:38 thib Exp $	*/
d46 1
d1196 16
@


1.78
log
@Don't use char arrays for sleep wchans and reuse them.
just use strings and make things unique.

ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.76 2009/03/15 19:40:41 miod Exp $	*/
d111 1
a111 1
	if (p->p_ucred->cr_uid == 0)
@


1.77
log
@Initial support for routing domains. This allows to bind interfaces to
alternate routing table and separate them from other interfaces in distinct
routing tables. The same network can now be used in any doamin at the same
time without causing conflicts.
This diff is mostly mechanical and adds the necessary rdomain checks accross
net and netinet. L2 and IPv4 are mostly covered still missing pf and IPv6.
input and tested by jsg@@, phessler@@ and reyk@@. "put it in" deraadt@@
@
text
@d233 1
a233 1
				    PSOCK | PCATCH, netcls,
@


1.76
log
@Introduce splsoftassert(), similar to splassert() but for soft interrupt
levels. This will allow for platforms where soft interrupt levels do not
map to real hardware interrupt levels to have soft ipl values overlapping
hard ipl values without breaking spl asserts.
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.75 2009/02/22 07:47:22 otto Exp $	*/
d49 1
d990 1
@


1.75
log
@fix PR 6082: do not create more fd's than will fit in the message on
the receiving side when passing fd's. ok deraadt@@ kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.74 2009/01/13 13:36:12 blambert Exp $	*/
d178 1
a178 1
	splassert(IPL_SOFTNET);
d261 1
a261 1
	splassert(IPL_SOFTNET);
@


1.74
log
@Change sbreserve() to return 0 on success, 1 on failure, as god intended.
This sort of breaking with traditional and expected behavior annoys me.

"yes!" henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.73 2008/10/09 16:00:05 deraadt Exp $	*/
d547 2
a548 1
    struct mbuf **mp0, struct mbuf **controlp, int *flagsp)
d702 2
a703 1
				   error = (*pr->pr_domain->dom_externalize)(m);
@


1.73
log
@Change sb_timeo to unsigned, so that even if some calculation (ie. n * HZ)
becomes a very large number it will not wrap the short into a negative
number and screw up timeouts.  It will simply become a max of 65535.  Since
this happens when HZ is cranked to a high number, this will still only take
n seconds, or less.  Safer than crashing.
Prompted by PR 5511
ok guenther
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.72 2008/08/07 17:43:37 reyk Exp $	*/
d1043 1
a1043 1
				    sbreserve(&so->so_snd, cnt) == 0) {
d1051 1
a1051 1
				    sbreserve(&so->so_rcv, cnt) == 0) {
@


1.72
log
@don't wait for a free mbuf cluster in sosend() and enter the existing
error handler that was never used before.  this fixes a bug that a
userland process might hang if the system ran out of mbuf clusters or
even other unexpected behaviour in the network drivers.

this bug is very old - it is also found in rev 1.1/stevens v2/44lite2/...

discussed with many
ok markus@@ thib@@ dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.71 2008/06/14 10:55:21 mk Exp $	*/
d1073 1
a1073 1
			short val;
d1080 1
a1080 1
			if (tv->tv_sec > (SHRT_MAX - tv->tv_usec / tick) / hz) {
@


1.71
log
@A bunch of pool_get() + bzero() -> pool_get(..., .. | PR_ZERO)
conversions that should shave a few bytes off the kernel.

ok henning, krw, jsing, oga, miod, and thib (``even though i usually prefer
FOO|BAR''; thanks for looking.
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.70 2008/05/23 15:51:12 thib Exp $	*/
d462 1
a462 1
					MCLGET(m, M_WAIT);
@


1.70
log
@Deal with the situation when TCP nfs mounts timeout and processes
get hung in nfs_reconnect() because they do not have the proper
privilages to bind to a socket, by adding a struct proc * argument
to sobind() (and the *_usrreq() routines, and finally in{6}_pcbbind)
and do the sobind() with proc0 in nfs_connect.

OK markus@@, blambert@@.
"go ahead" deraadt@@.

Fixes an issue reported by bernd@@ (Tested by bernd@@).
Fixes PR5135 too.
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.69 2008/05/09 02:52:15 markus Exp $	*/
d106 1
a106 2
	so = pool_get(&socket_pool, PR_WAITOK);
	bzero(so, sizeof(*so));
@


1.69
log
@Add SO_BINDANY socket option from BSD/OS.

The option allows a socket to be bound to addresses which are not
local to the machine.  In order to receive packets for these addresses
SO_BINDANY needs to be combined with matching outgoing pf(4) divert
rules, see pf.conf(5).

ok beck@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.68 2008/05/02 06:49:32 ckuethe Exp $	*/
d120 1
a120 1
	    (struct mbuf *)(long)proto, NULL);
d140 1
a140 1
sobind(struct socket *so, struct mbuf *nam)
d145 1
a145 1
	error = (*so->so_proto->pr_usrreq)(so, PRU_BIND, NULL, nam, NULL);
d155 2
a156 1
	error = (*so->so_proto->pr_usrreq)(so, PRU_LISTEN, NULL, NULL, NULL);
d243 1
a243 1
							NULL, NULL);
d264 2
a265 1
	return (*so->so_proto->pr_usrreq)(so, PRU_ABORT, NULL, NULL, NULL);
d280 1
a280 1
		    nam, NULL);
d308 1
a308 1
						   NULL, nam, NULL);
d320 1
a320 1
					    (struct mbuf *)so2, NULL);
d340 1
a340 1
					   NULL);
d506 1
a506 1
			    top, addr, control);
d573 1
a573 1
		    (struct mbuf *)(long)(flags & MSG_PEEK), NULL);
d589 1
a589 1
		(*pr->pr_usrreq)(so, PRU_RCVD, NULL, NULL, NULL);
d908 1
a908 1
					 (struct mbuf *)(long)flags, NULL);
d941 2
a942 1
		return (*pr->pr_usrreq)(so, PRU_SHUTDOWN, NULL, NULL, NULL);
@


1.68
log
@Make the SO_TIMESTAMP sockopt work. When set, this allows the user to
get a timestamp of when the datagram was accepted (by udp(4), for
example) rather than having to take a timestamp with gettimeofday(2)
when recv(2) returns - possibly several hundreds of microseconds later.
May be of use to those interested in precision network timing schemes
or QoS for media applications. Tested on alpha, amd64, i386 and sparc64.
manpage suggestions from jmc, ok deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.67 2007/12/20 17:16:50 chl Exp $	*/
d984 7
d1002 1
d1138 1
@


1.67
log
@Remove an obsolete nfs kludge, spotted by Frank Denis (many thanks), also there in NetBSD and FreeBSD trees.

Tested by thib@@ who found that it shaved 18min wall clock time of coping a 20G file.

Been in snaps for some time

"looks ok" markus@@ "makes sense" blambert@@ ok claudio@@ thib@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.66 2007/02/26 23:53:33 kurt Exp $	*/
d1004 1
d1139 1
@


1.66
log
@exclude control data from the number of bytes returned by FIONREAD ioctl()
by adding a sb_datacc count to sockbuf that counts data excluding
MT_CONTROL and MT_SONAME mbuf types.  w/help from deraadt@@.
okay deraadt@@ claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.65 2007/02/14 00:53:48 jsg Exp $	*/
d427 1
a427 1
		if (space < resid + clen && uio &&
@


1.65
log
@Consistently spell FALLTHROUGH to appease lint.
ok kettenis@@ cloder@@ tom@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.64 2006/06/10 17:05:17 beck Exp $	*/
d841 1
@


1.64
log
@allow SO_SNDBUF and SO_RECVBUF setsockopts on existing sockets to succeed
for any value that is not an increase in size when we are under mbuf pressure,
rather than only succeeding when setting the value to the 4k minimum.
ok markus@@, henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.63 2006/03/04 22:40:15 brad Exp $	*/
d992 1
a992 1
			/* fall thru... */
@


1.63
log
@With the exception of two other small uncommited diffs this moves
the remainder of the network stack from splimp to splnet.

ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.62 2006/01/05 05:05:06 jsg Exp $	*/
a1018 2
			extern u_long unpst_recvspace;
			extern u_long unpst_sendspace;
d1030 1
a1030 1
				if (sbcheckreserve(cnt, unpst_sendspace) ||
d1038 1
a1038 1
				if (sbcheckreserve(cnt, unpst_recvspace) ||
@


1.62
log
@ansi/deregister
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.61 2005/09/16 16:44:43 deraadt Exp $	*/
d954 1
a954 1
	s = splimp();
@


1.61
log
@backout until we find a socket state for init
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.60 2005/09/10 19:13:32 deraadt Exp $	*/
d90 1
a90 5
socreate(dom, aso, type, proto)
	int dom;
	struct socket **aso;
	register int type;
	int proto;
d140 1
a140 3
sobind(so, nam)
	struct socket *so;
	struct mbuf *nam;
d151 1
a151 3
solisten(so, backlog)
	register struct socket *so;
	int backlog;
d202 1
a202 2
soclose(so)
	register struct socket *so;
d267 1
a267 3
soaccept(so, nam)
	register struct socket *so;
	struct mbuf *nam;
d286 1
a286 3
soconnect(so, nam)
	register struct socket *so;
	struct mbuf *nam;
d312 1
a312 3
soconnect2(so1, so2)
	register struct socket *so1;
	struct socket *so2;
d324 1
a324 2
sodisconnect(so)
	register struct socket *so;
d363 2
a364 7
sosend(so, addr, uio, top, control, flags)
	register struct socket *so;
	struct mbuf *addr;
	struct uio *uio;
	struct mbuf *top;
	struct mbuf *control;
	int flags;
d545 2
a546 7
soreceive(so, paddr, uio, mp0, controlp, flagsp)
	register struct socket *so;
	struct mbuf **paddr;
	struct uio *uio;
	struct mbuf **mp0;
	struct mbuf **controlp;
	int *flagsp;
d548 2
a549 2
	register struct mbuf *m, **mp;
	register int flags, len, error, s, offset;
d926 1
a926 3
soshutdown(so, how)
	register struct socket *so;
	register int how;
d928 1
a928 1
	register struct protosw *pr = so->so_proto;
d945 1
a945 2
sorflush(so)
	register struct socket *so;
d947 3
a949 3
	register struct sockbuf *sb = &so->so_rcv;
	register struct protosw *pr = so->so_proto;
	register int s;
d971 1
a971 4
sosetopt(so, level, optname, m0)
	register struct socket *so;
	int level, optname;
	struct mbuf *m0;
d974 1
a974 1
	register struct mbuf *m = m0;
d1107 1
a1107 4
sogetopt(so, level, optname, mp)
	register struct socket *so;
	int level, optname;
	struct mbuf **mp;
d1109 1
a1109 1
	register struct mbuf *m;
d1190 1
a1190 2
sohasoutofband(so)
	register struct socket *so;
@


1.60
log
@upon shutdown(), if socket is unconnected return ENOTCONN; ok millert
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.59 2005/08/11 18:20:10 millert Exp $	*/
a957 2
	if ((so->so_state & SS_ISCONNECTED) == 0)
		return (ENOTCONN);
@


1.59
log
@Use SHUT_* values directly in soshutdown() instead of converting
to FREAD/FWRITE.  OK deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.58 2005/05/27 17:16:13 dhartmei Exp $	*/
d958 2
@


1.58
log
@add a field to struct socket that stores the pid of the process that
created the socket, and populate it. ok bob@@, henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.57 2005/05/27 04:55:27 mcbride Exp $	*/
d958 3
a960 4
	how++;
	if (how & ~(FREAD|FWRITE))
		return (EINVAL);
	if (how & FREAD)
d962 4
a965 1
	if (how & FWRITE)
d967 3
a969 1
	return (0);
@


1.57
log
@Experimental support for opportunitic use of jumbograms where only some hosts
on the local network support them.

This adds a new socket option, SO_JUMBO, and a new route flag,
RTF_JUMBO. If _both_ the socket option is set and the route for the host
has RTF_JUMBO set, ip_output will fragment the packet to the largest
possible size for the link, ignoring the card's MTU.

The semantics of this feature will be evolving rapidly; talk to us
if you intend to use it.

ok deraadt@@ marius@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.56 2004/11/18 15:09:07 markus Exp $	*/
d121 1
@


1.56
log
@enable receive() accounting and use uio_procp for send() accounting, too
ok deraadt, jared, djm
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.55 2004/09/16 13:11:01 markus Exp $	*/
d1029 1
d1168 1
@


1.55
log
@add hint for lower layer that a sosend() is in progress (SS_ISSENDING)
inspired by a posting from David Borman and similar changes in net/freebsd
ok mcbride
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.54 2004/07/28 15:12:55 millert Exp $	*/
a385 1
	struct proc *p = curproc;		/* XXX */
d413 2
a414 1
	p->p_stats->p_ru.ru_msgsnd++;
a684 1
#ifdef notyet /* XXXX */
a686 1
#endif
@


1.54
log
@Call dom_dispose() for any SCM_RIGHTS message that went through the
read path rather than recv.  Previously, if an fd was passed via
sendmsg() but was consumed by the receiver via read() the ref count
was incremented and never decremented and so the ref count would
never reach zero even when there was no long any processes holding
the file open (this was especially bad for locked fds).
OK markus@@ and art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.53 2004/04/19 22:39:07 deraadt Exp $	*/
d422 1
d453 1
d520 2
d538 1
@


1.53
log
@also use sbcheckreserve() for setsockopt of SO_SNDBUF and SO_RCVBUF
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.52 2004/04/01 23:56:05 tedu Exp $	*/
d728 7
@


1.52
log
@use NULL for ptrs.  parts from Joris Vink
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.51 2003/07/21 22:44:50 tedu Exp $	*/
d1035 2
d1048 7
d1056 2
a1057 3
				if (sbreserve(optname == SO_SNDBUF ?
				    &so->so_snd : &so->so_rcv,
				    cnt) == 0) {
@


1.51
log
@remove caddr_t casts.  it's just silly to cast something when the function
takes a void *.  convert uiomove to take a void * as well.  ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.50 2003/06/02 23:28:07 millert Exp $	*/
d105 1
a105 1
	if (prp == 0 || prp->pr_usrreq == 0)
d605 1
a605 1
		*mp = (struct mbuf *)0;
d626 1
a626 1
	if (m == 0 || (((flags & MSG_DONTWAIT) == 0 &&
d630 1
a630 1
	    m->m_nextpkt == 0 && (pr->pr_flags & PR_ATOMIC) == 0)) {
d632 1
a632 1
		if (m == 0 && so->so_rcv.sb_cc)
d800 1
a800 1
		if (mp == 0 && uio_error == 0) {
d826 1
a826 1
					*mp = (struct mbuf *)0;
d880 1
a880 1
		while (flags & MSG_WAITALL && m == 0 && uio->uio_resid > 0 &&
d903 1
a903 1
		if (m == 0) {
@


1.50
log
@Remove the advertising clause in the UCB license which Berkeley
rescinded 22 July 1999.  Proofed by myself and Theo.
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.49 2003/02/03 21:22:09 deraadt Exp $	*/
d111 1
a111 1
	bzero((caddr_t)so, sizeof(*so));
d239 1
a239 1
				error = tsleep((caddr_t)&so->so_timeo,
d972 1
a972 1
	bzero((caddr_t)sb, sizeof (*sb));
@


1.49
log
@knf
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.48 2002/11/27 19:39:15 millert Exp $	*/
d16 1
a16 5
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by the University of
 *	California, Berkeley and its contributors.
 * 4. Neither the name of the University nor the names of its contributors
@


1.48
log
@Avoid possible wraparound when checking timeout size; mickey@@ OK
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.47 2002/11/27 13:31:09 mickey Exp $	*/
d465 8
a472 8
		    if (uio == NULL) {
			/*
			 * Data is prepackaged in "top".
			 */
			resid = 0;
			if (flags & MSG_EOR)
				top->m_flags |= M_EOR;
		    } else do {
@


1.47
log
@fix an underflow in socket timeout calculations.
(see http://www.freebsd.org/cgi/query-pr.cgi?pr=kern/32827).
itojun@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.46 2002/08/08 19:18:12 provos Exp $	*/
d1082 1
a1082 1
			if (tv->tv_sec * hz + tv->tv_usec / tick > SHRT_MAX) {
@


1.46
log
@redo socketbuf speedup.
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.44 2002/08/08 17:07:32 provos Exp $	*/
d1087 2
@


1.45
log
@backout the tree break. ok pb@@, art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.43 2002/06/11 05:07:43 art Exp $	*/
d669 2
d679 5
d688 3
d741 7
d749 1
a749 1
		if ((flags & MSG_PEEK) == 0)
d751 10
d768 6
d775 3
d805 2
d835 6
a840 1
				if (m)
d842 8
d888 2
d907 6
a912 1
		if (m == 0)
d914 8
@


1.44
log
@socket buf speedup from thorpej@@netbsd, okay art@@ ericj@@:

Make insertion of data into socket buffers O(C):
* Keep pointers to the first and last mbufs of the last record in the
  socket buffer.
* Use the sb_lastrecord pointer in the sbappend*() family of functions
  to avoid traversing the packet chain to find the last record.
* Add a new sbappend_stream() function for stream protocols which
  guarantee that there will never be more than one record in the
  socket buffer.  This function uses the sb_mbtail pointer to perform
  the data insertion.  Make TCP use sbappend_stream(). On a profiling
run, this makes sbappend of a TCP transmission using
a 1M socket buffer go from 50% of the time to .02% of the time. Thanks
to Bill Sommerfeld and YAMAMOTO Takashi for their debugging
assistance!
@
text
@a668 2
		SBLASTRECORDCHK(&so->so_rcv, "soreceive sbwait 1");
		SBLASTMBUFCHK(&so->so_rcv, "soreceive sbwait 1");
a676 5
	/*
	 * On entry here, m points to the first record of the socket buffer.
	 * While we process the initial mbufs containing address and control
	 * info, we save a copy of m->m_nextpkt into nextrecord.
	 */
a680 3
	KASSERT(m == so->so_rcv.sb_mb);
	SBLASTRECORDCHK(&so->so_rcv, "soreceive 1");
	SBLASTMBUFCHK(&so->so_rcv, "soreceive 1");
a730 7

	/*
	 * If m is non-NULL, we have some data to read.  From now on,
	 * make sure to keep sb_lastrecord consistent when working on
	 * the last packet on the chain (nextrecord == NULL) and we
	 * change m->m_nextpkt.
	 */
d732 1
a732 1
		if ((flags & MSG_PEEK) == 0) {
a733 10
			/*
			 * If nextrecord == NULL (this is a single chain),
			 * then sb_lastrecord may not be valid here if m
			 * was changed earlier.
			 */
			if (nextrecord == NULL) {
				KASSERT(so->so_rcv.sb_mb == m);
				so->so_rcv.sb_lastrecord = m;
			}
		}
a740 6
	} else {
		if ((flags & MSG_PEEK) == 0) {
			KASSERT(so->so_rcv.sb_mb == m);
			so->so_rcv.sb_mb = nextrecord;
			SB_EMPTY_FIXUP(&so->so_rcv);
		}
a741 3
	SBLASTRECORDCHK(&so->so_rcv, "soreceive 2");
	SBLASTMBUFCHK(&so->so_rcv, "soreceive 2");

a768 2
			SBLASTRECORDCHK(&so->so_rcv, "soreceive uiomove");
			SBLASTMBUFCHK(&so->so_rcv, "soreceive uiomove");
d797 1
a797 6
				/*
				 * If m != NULL, we also know that
				 * so->so_rcv.sb_mb != NULL.
				 */
				KASSERT(so->so_rcv.sb_mb == m);
				if (m) {
a798 8
					if (nextrecord == NULL)
						so->so_rcv.sb_lastrecord = m;
				} else {
					so->so_rcv.sb_mb = nextrecord;
					SB_EMPTY_FIXUP(&so->so_rcv);
				}
				SBLASTRECORDCHK(&so->so_rcv, "soreceive 3");
				SBLASTMBUFCHK(&so->so_rcv, "soreceive 3");
a836 2
			SBLASTRECORDCHK(&so->so_rcv, "soreceive sbwait 2");
			SBLASTMBUFCHK(&so->so_rcv, "soreceive sbwait 2");
d854 1
a854 6
		if (m == 0) {
			/*
			 * First part is an inline SB_EMPTY_FIXUP().  Second
			 * part makes sure sb_lastrecord is up-to-date if
			 * there is still data in the socket buffer.
			 */
a855 8
			if (so->so_rcv.sb_mb == NULL) {
				so->so_rcv.sb_mbtail = NULL;
				so->so_rcv.sb_lastrecord = NULL;
			} else if (nextrecord->m_nextpkt == NULL)
				so->so_rcv.sb_lastrecord = nextrecord;
		}
		SBLASTRECORDCHK(&so->so_rcv, "soreceive 4");
		SBLASTMBUFCHK(&so->so_rcv, "soreceive 4");
@


1.43
log
@splassert where necessary
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.42 2002/05/11 00:06:33 deraadt Exp $	*/
d669 2
d679 5
d688 3
d741 7
d749 1
a749 1
		if ((flags & MSG_PEEK) == 0)
d751 10
d768 6
d775 3
d805 2
d835 6
a840 1
				if (m)
d842 8
d888 2
d907 6
a912 1
		if (m == 0)
d914 8
@


1.42
log
@track egid/rgid on bound/connected sockets too (pf will use this)
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.41 2002/02/05 22:04:43 nordin Exp $	*/
d187 1
a187 2
sofree(so)
	register struct socket *so;
d189 1
d268 1
a268 1
 * Must be called at splsoftnet...
d271 1
a271 2
soabort(so)
	struct socket *so;
d273 1
@


1.41
log
@Do range check on SO_LINGER, closes pr#2375. art@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.40 2002/01/23 00:39:48 art Exp $	*/
d123 2
@


1.40
log
@Pool deals fairly well with physical memory shortage, but it doesn't deal
well (not at all) with shortages of the vm_map where the pages are mapped
(usually kmem_map).

Try to deal with it:
 - group all information the backend allocator for a pool in a separate
   struct. The pool will only have a pointer to that struct.
 - change the pool_init API to reflect that.
 - link all pools allocating from the same allocator on a linked list.
 - Since an allocator is responsible to wait for physical memory it will
   only fail (waitok) when it runs out of its backing vm_map, carefully
   drain pools using the same allocator so that va space is freed.
   (see comments in code for caveats and details).
 - change pool_reclaim to return if it actually succeeded to free some
   memory, use that information to make draining easier and more efficient.
 - get rid of PR_URGENT, noone uses it.
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.39 2001/11/28 17:18:00 ericj Exp $	*/
d938 3
a940 1
			if (m == NULL || m->m_len != sizeof (struct linger)) {
@


1.39
log
@
avoid possible infinite loop in sosend() on 64bit systems. - from netbsd
art@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.38 2001/11/27 22:53:19 provos Exp $	*/
d82 1
a82 2
	pool_init(&socket_pool, sizeof(struct socket), 0, 0, 0,
	    "sockpl", 0, NULL, NULL, M_SOCKET);
@


1.39.2.1
log
@Merge in -current, builds on i386, otherwise untested
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.40 2002/01/23 00:39:48 art Exp $	*/
d82 2
a83 1
	pool_init(&socket_pool, sizeof(struct socket), 0, 0, 0, "sockpl", NULL);
@


1.39.2.2
log
@Sync UBC branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.39.2.1 2002/01/31 22:55:41 niklas Exp $	*/
a122 2
	so->so_rgid = p->p_cred->p_rgid;
	so->so_egid = p->p_ucred->cr_gid;
d938 1
a938 3
			if (m == NULL || m->m_len != sizeof (struct linger) ||
			    mtod(m, struct linger *)->l_linger < 0 ||
			    mtod(m, struct linger *)->l_linger > SHRT_MAX) {
@


1.39.2.3
log
@sync to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.39.2.2 2002/06/11 03:29:40 art Exp $	*/
d187 2
a188 1
sofree(struct socket *so)
a189 1
	splassert(IPL_SOFTNET);
d268 1
a268 1
 * Must be called at splsoftnet.
d271 2
a272 1
soabort(struct socket *so)
a273 1
	splassert(IPL_SOFTNET);
a668 2
		SBLASTRECORDCHK(&so->so_rcv, "soreceive sbwait 1");
		SBLASTMBUFCHK(&so->so_rcv, "soreceive sbwait 1");
a676 5
	/*
	 * On entry here, m points to the first record of the socket buffer.
	 * While we process the initial mbufs containing address and control
	 * info, we save a copy of m->m_nextpkt into nextrecord.
	 */
a680 3
	KASSERT(m == so->so_rcv.sb_mb);
	SBLASTRECORDCHK(&so->so_rcv, "soreceive 1");
	SBLASTMBUFCHK(&so->so_rcv, "soreceive 1");
a730 7

	/*
	 * If m is non-NULL, we have some data to read.  From now on,
	 * make sure to keep sb_lastrecord consistent when working on
	 * the last packet on the chain (nextrecord == NULL) and we
	 * change m->m_nextpkt.
	 */
d732 1
a732 1
		if ((flags & MSG_PEEK) == 0) {
a733 10
			/*
			 * If nextrecord == NULL (this is a single chain),
			 * then sb_lastrecord may not be valid here if m
			 * was changed earlier.
			 */
			if (nextrecord == NULL) {
				KASSERT(so->so_rcv.sb_mb == m);
				so->so_rcv.sb_lastrecord = m;
			}
		}
a740 6
	} else {
		if ((flags & MSG_PEEK) == 0) {
			KASSERT(so->so_rcv.sb_mb == m);
			so->so_rcv.sb_mb = nextrecord;
			SB_EMPTY_FIXUP(&so->so_rcv);
		}
a741 3
	SBLASTRECORDCHK(&so->so_rcv, "soreceive 2");
	SBLASTMBUFCHK(&so->so_rcv, "soreceive 2");

a768 2
			SBLASTRECORDCHK(&so->so_rcv, "soreceive uiomove");
			SBLASTMBUFCHK(&so->so_rcv, "soreceive uiomove");
d797 1
a797 6
				/*
				 * If m != NULL, we also know that
				 * so->so_rcv.sb_mb != NULL.
				 */
				KASSERT(so->so_rcv.sb_mb == m);
				if (m) {
a798 8
					if (nextrecord == NULL)
						so->so_rcv.sb_lastrecord = m;
				} else {
					so->so_rcv.sb_mb = nextrecord;
					SB_EMPTY_FIXUP(&so->so_rcv);
				}
				SBLASTRECORDCHK(&so->so_rcv, "soreceive 3");
				SBLASTMBUFCHK(&so->so_rcv, "soreceive 3");
a836 2
			SBLASTRECORDCHK(&so->so_rcv, "soreceive sbwait 2");
			SBLASTMBUFCHK(&so->so_rcv, "soreceive sbwait 2");
d854 1
a854 6
		if (m == 0) {
			/*
			 * First part is an inline SB_EMPTY_FIXUP().  Second
			 * part makes sure sb_lastrecord is up-to-date if
			 * there is still data in the socket buffer.
			 */
a855 8
			if (so->so_rcv.sb_mb == NULL) {
				so->so_rcv.sb_mbtail = NULL;
				so->so_rcv.sb_lastrecord = NULL;
			} else if (nextrecord->m_nextpkt == NULL)
				so->so_rcv.sb_lastrecord = nextrecord;
		}
		SBLASTRECORDCHK(&so->so_rcv, "soreceive 4");
		SBLASTMBUFCHK(&so->so_rcv, "soreceive 4");
@


1.39.2.4
log
@sync
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d465 8
a472 8
			if (uio == NULL) {
				/*
				 * Data is prepackaged in "top".
				 */
				resid = 0;
				if (flags & MSG_EOR)
					top->m_flags |= M_EOR;
			} else do {
d1082 1
a1082 1
			if (tv->tv_sec > (SHRT_MAX - tv->tv_usec / tick) / hz) {
a1086 2
			if (val == 0 && tv->tv_usec != 0)
				val = 1;
@


1.38
log
@change socket allocation to pool allocator; from netbsd; okay niklas@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.37 2001/11/27 17:55:39 provos Exp $	*/
d391 4
a394 4
	register struct mbuf *m;
	register long space, len;
	register quad_t resid;
	int clen = 0, error, s, dontroute, mlen;
a485 3
#ifdef	MAPPED_MBUFS
					len = min(MCLBYTES, resid);
#else
d487 1
a487 1
						len = min(MCLBYTES - max_hdr, resid);
d490 1
a490 2
						len = min(MCLBYTES, resid);
#endif
d494 1
a494 1
					len = min(min(mlen, resid), space);
@


1.37
log
@fix an error in sosend() that could make a transient error permant.
verified with both netbsd and freebsd.

from netbsd:
Tue Jun  8 02:39:57 1999 UTC by thorpej

In sosend(), if so_error is set, clear it before returning the error to
the process (i.e. pre-Reno behavior).  The 4.4BSD behavior (introduced
in Reno) caused transient errors to stick incorrectly.

This is from PR #7640 (Havard Eidnes), cross-checked w/ FreeBSD, where
Bill Fenner committed the same fix (as described in a comment in the
Vat sources, by Van Jacobsen).
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.36 2001/11/27 15:51:36 provos Exp $	*/
d53 1
d76 10
d102 3
a104 3
	register struct protosw *prp;
	register struct socket *so;
	register int error;
d114 2
a115 1
	MALLOC(so, struct socket *, sizeof(*so), M_SOCKET, M_WAIT);
d130 1
d140 1
d181 4
d203 1
a203 1
	FREE(so, M_SOCKET);
@


1.36
log
@change socket connection queues to use TAILQ_

from NetBSD:
Wed Jan  7 23:47:08 1998 UTC by thorpej

Make insertion and removal of sockets from the partial and incoming
connections queues O(C) rather than O(N).
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.35 2001/06/22 14:14:09 deraadt Exp $	*/
d411 6
a416 2
		if (so->so_error)
			snderr(so->so_error);
@


1.35
log
@KNF
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.34 2001/05/25 22:08:23 itojun Exp $	*/
d105 2
d156 1
a156 1
	if (so->so_q == 0)
d202 1
a202 1
		while ((so2 = so->so_q0) != NULL) {
d206 1
a206 1
		while ((so2 = so->so_q) != NULL) {
@


1.34
log
@recover old acecept(2) behavior (no ECONNABORTED) for unix domain socket.
it is to be friendly with postfix daemon-to-daemon communication
(not 100% sure if which behavior is correct, specwise).  patch similar to netbsd.
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.33 2001/03/06 19:42:43 provos Exp $	*/
d60 1
a60 1
struct filterops solisten_filtops = 
d64 1
a64 1
struct filterops sowrite_filtops = 
d111 2
a112 3
	error =
	    (*prp->pr_usrreq)(so, PRU_ATTACH, NULL, (struct mbuf *)(long)proto,
			      NULL);
d448 14
a461 14
			if (top == 0) {
				MGETHDR(m, M_WAIT, MT_DATA);
				mlen = MHLEN;
				m->m_pkthdr.len = 0;
				m->m_pkthdr.rcvif = (struct ifnet *)0;
			} else {
				MGET(m, M_WAIT, MT_DATA);
				mlen = MLEN;
			}
			if (resid >= MINCLSIZE && space >= MCLBYTES) {
				MCLGET(m, M_WAIT);
				if ((m->m_flags & M_EXT) == 0)
					goto nopages;
				mlen = MCLBYTES;
d463 1
a463 1
				len = min(MCLBYTES, resid);
d465 5
a469 5
				if (atomic && top == 0) {
					len = min(MCLBYTES - max_hdr, resid);
					m->m_data += max_hdr;
				} else
					len = min(MCLBYTES, resid);
d471 2
a472 2
				space -= len;
			} else {
d474 37
a510 14
				len = min(min(mlen, resid), space);
				space -= len;
				/*
				 * For datagram protocols, leave room
				 * for protocol headers in first mbuf.
				 */
				if (atomic && top == 0 && len < mlen)
					MH_ALIGN(m, len);
			}
			error = uiomove(mtod(m, caddr_t), (int)len, uio);
			resid = uio->uio_resid;
			m->m_len = len;
			*mp = m;
			top->m_pkthdr.len += len;
a512 22
			mp = &m->m_next;
			if (resid <= 0) {
				if (flags & MSG_EOR)
					top->m_flags |= M_EOR;
				break;
			}
		    } while (space > 0 && atomic);
		    if (dontroute)
			    so->so_options |= SO_DONTROUTE;
		    s = splsoftnet();				/* XXX */
		    error = (*so->so_proto->pr_usrreq)(so, (flags & MSG_OOB) ?
							PRU_SENDOOB : PRU_SEND,
						       top, addr, control);
		    splx(s);
		    if (dontroute)
			    so->so_options &= ~SO_DONTROUTE;
		    clen = 0;
		    control = 0;
		    top = 0;
		    mp = &top;
		    if (error)
			goto release;
d848 1
a848 1
		
d1094 1
a1094 1
			     so->so_snd.sb_timeo : so->so_rcv.sb_timeo);
d1170 1
a1170 1
		kn->kn_flags |= EV_EOF; 
d1201 1
a1201 1
		kn->kn_flags |= EV_EOF; 
@


1.33
log
@different fix, we still need to deliver EV_EOF; from jlemon@@freebsd.org
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.32 2001/03/06 17:06:23 provos Exp $	*/
d269 2
a270 1
	if ((so->so_state & SS_ISDISCONNECTED) == 0)
@


1.32
log
@fix a kqueue related panic triggered by shutdown, okay art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.31 2001/03/01 20:54:34 provos Exp $	*/
a885 3
	/* XXX - the bzero stumps all over so_rcv, rm knotes while possible */
	if (sb->sb_flags & SB_KNOTE)
		knote_remove(curproc, &sb->sb_sel.si_note);
d889 5
@


1.31
log
@port kqueue changes from freebsd, plus all required openbsd glue.
okay deraadt@@, millert@@
from jlemon@@freebsd.org:
extend kqueue down to the device layer, backwards compatible approach
suggested by peter@@freebsd.org
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.30 2001/02/07 12:20:42 itojun Exp $	*/
d886 3
@


1.30
log
@return ECONNABORTED, if the socket (tcp connection for example)
is disconnected by RST right before accept(2).  fixes NetBSD PR 10698/12027.
checked with SUSv2, XNET 5.2, and Stevens (unix network programming
vol 1 2nd ed) section 5.11.
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.29 2001/01/23 02:18:55 itojun Exp $	*/
a53 1
int 	filt_sorattach(struct knote *kn);
a55 1
int 	filt_sowattach(struct knote *kn);
d61 5
a65 1
	{ 1, filt_sorattach, filt_sordetach, filt_solisten };
a66 4
struct filterops so_rwfiltops[] = {
	{ 1, filt_sorattach, filt_sordetach, filt_soread },
	{ 1, filt_sowattach, filt_sowdetach, filt_sowrite },
};
d1115 1
a1115 1
filt_sorattach(struct knote *kn)
d1118 18
a1135 1
	int s = splnet();
d1137 3
a1139 4
	if (so->so_options & SO_ACCEPTCONN)
		kn->kn_fop = &solisten_filtops;
	SLIST_INSERT_HEAD(&so->so_rcv.sb_sel.si_note, kn, kn_selnext);
	so->so_rcv.sb_flags |= SB_KNOTE;
d1165 1
d1170 2
a1174 12
int
filt_sowattach(struct knote *kn)
{
	struct socket *so = (struct socket *)kn->kn_fp->f_data;
	int s = splnet();

	SLIST_INSERT_HEAD(&so->so_snd.sb_sel.si_note, kn, kn_selnext);
	so->so_snd.sb_flags |= SB_KNOTE;
	splx(s);
	return (0);
}

d1196 1
d1204 2
@


1.29
log
@when the peer is disconnected before accept(2) is issued,
do not return junk data in mbuf (= sockaddr on accept(2)'s 2nd arg).
set the length to zero.

behavior checked with bsdi and freebsd.
partial solution to NetBSD PR 12027 and 10698 (need more investigation).
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.28 2000/11/16 20:02:19 provos Exp $	*/
d275 1
a275 1
		nam->m_len = 0;
@


1.28
log
@support kernel event queues, from FreeBSD by Jonathan Lemon,
okay art@@, millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.27 1999/10/14 08:18:49 cmetz Exp $	*/
d274 2
@


1.27
log
@Fix for PR 871.

This fix is taken from BSD/OS (the file in question being BSD licensed).

It continues to remove a datagram from a socket receive buffer even if there is
an error on the copy-out, so as to leave the buffer in a reasonable state.
Before, the kernel would stop in mid-receive if the copy-out failed, and the
buffer's structural requirements would be violated (since the start of a
datagram must be an address iff ).

Note that if the user provides any invalid addresses as arguments to a
recvmsg(), the datagram at the front of the buffer will be discarded. The more
correct behavior would be not to remove this datagram if the arguments are
invalid. Implementing this behavior requires a lot of significant changes, and
socket receives are a critical path.

Also included are two simple and fairly obvious fixes from the same source.
If non-blocking I/O is set, it makes sure the receieve is non-blocking. It also
fixes a slightly over-aggressive optimization.
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.26 1999/02/19 15:06:52 millert Exp $	*/
d47 1
d54 16
d1112 95
@


1.27.4.1
log
@merge in approximately 2.9 into SMP branch
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.33 2001/03/06 19:42:43 provos Exp $	*/
a46 1
#include <sys/event.h>
a52 14
void 	filt_sordetach(struct knote *kn);
int 	filt_soread(struct knote *kn, long hint);
void 	filt_sowdetach(struct knote *kn);
int	filt_sowrite(struct knote *kn, long hint);
int	filt_solisten(struct knote *kn, long hint);

struct filterops solisten_filtops = 
	{ 1, NULL, filt_sordetach, filt_solisten };
struct filterops soread_filtops =
	{ 1, NULL, filt_sordetach, filt_soread };
struct filterops sowrite_filtops = 
	{ 1, NULL, filt_sowdetach, filt_sowrite };


a256 2
	else
		error = ECONNABORTED;
a871 5
	/* XXX - the bzero stumps all over so_rcv */
	if (asb.sb_flags & SB_KNOTE) {
		sb->sb_sel.si_note = asb.sb_sel.si_note;
		sb->sb_flags = SB_KNOTE;
	}
a1094 105
}

int
soo_kqfilter(struct file *fp, struct knote *kn)
{
	struct socket *so = (struct socket *)kn->kn_fp->f_data;
	struct sockbuf *sb;
	int s;

	switch (kn->kn_filter) {
	case EVFILT_READ:
		if (so->so_options & SO_ACCEPTCONN)
			kn->kn_fop = &solisten_filtops;
		else
			kn->kn_fop = &soread_filtops;
		sb = &so->so_rcv;
		break;
	case EVFILT_WRITE:
		kn->kn_fop = &sowrite_filtops;
		sb = &so->so_snd;
		break;
	default:
		return (1);
	}

	s = splnet();
	SLIST_INSERT_HEAD(&sb->sb_sel.si_note, kn, kn_selnext);
	sb->sb_flags |= SB_KNOTE;
	splx(s);
	return (0);
}

void
filt_sordetach(struct knote *kn)
{
	struct socket *so = (struct socket *)kn->kn_fp->f_data;
	int s = splnet();

	SLIST_REMOVE(&so->so_rcv.sb_sel.si_note, kn, knote, kn_selnext);
	if (SLIST_EMPTY(&so->so_rcv.sb_sel.si_note))
		so->so_rcv.sb_flags &= ~SB_KNOTE;
	splx(s);
}

/*ARGSUSED*/
int
filt_soread(struct knote *kn, long hint)
{
	struct socket *so = (struct socket *)kn->kn_fp->f_data;

	kn->kn_data = so->so_rcv.sb_cc;
	if (so->so_state & SS_CANTRCVMORE) {
		kn->kn_flags |= EV_EOF; 
		kn->kn_fflags = so->so_error;
		return (1);
	}
	if (so->so_error)	/* temporary udp error */
		return (1);
	if (kn->kn_sfflags & NOTE_LOWAT)
		return (kn->kn_data >= kn->kn_sdata);
	return (kn->kn_data >= so->so_rcv.sb_lowat);
}

void
filt_sowdetach(struct knote *kn)
{
	struct socket *so = (struct socket *)kn->kn_fp->f_data;
	int s = splnet();

	SLIST_REMOVE(&so->so_snd.sb_sel.si_note, kn, knote, kn_selnext);
	if (SLIST_EMPTY(&so->so_snd.sb_sel.si_note))
		so->so_snd.sb_flags &= ~SB_KNOTE;
	splx(s);
}

/*ARGSUSED*/
int
filt_sowrite(struct knote *kn, long hint)
{
	struct socket *so = (struct socket *)kn->kn_fp->f_data;

	kn->kn_data = sbspace(&so->so_snd);
	if (so->so_state & SS_CANTSENDMORE) {
		kn->kn_flags |= EV_EOF; 
		kn->kn_fflags = so->so_error;
		return (1);
	}
	if (so->so_error)	/* temporary udp error */
		return (1);
	if (((so->so_state & SS_ISCONNECTED) == 0) &&
	    (so->so_proto->pr_flags & PR_CONNREQUIRED))
		return (0);
	if (kn->kn_sfflags & NOTE_LOWAT)
		return (kn->kn_data >= kn->kn_sdata);
	return (kn->kn_data >= so->so_snd.sb_lowat);
}

/*ARGSUSED*/
int
filt_solisten(struct knote *kn, long hint)
{
	struct socket *so = (struct socket *)kn->kn_fp->f_data;

	kn->kn_data = so->so_qlen;
	return (so->so_qlen != 0);
@


1.27.4.2
log
@Merge in -current from two days ago in the SMP branch.
As usual with merges, they do not indicate progress, so do not hold
your breath for working SMP, and do not mail me and ask about the
state of it.  It has not changed.  There is work ongoing, but very, very
slowly.  The commit is done in parts as to not lock up the tree in too
big chunks at a time.
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.27.4.1 2001/05/14 22:32:45 niklas Exp $	*/
d60 1
a60 1
struct filterops solisten_filtops =
d64 1
a64 1
struct filterops sowrite_filtops =
d111 3
a113 2
	error = (*prp->pr_usrreq)(so, PRU_ATTACH, NULL,
	    (struct mbuf *)(long)proto, NULL);
d269 1
a269 2
	if ((so->so_state & SS_ISDISCONNECTED) == 0 ||
	    (so->so_proto->pr_flags & PR_ABRTACPTDIS) == 0)
d448 14
a461 14
				if (top == 0) {
					MGETHDR(m, M_WAIT, MT_DATA);
					mlen = MHLEN;
					m->m_pkthdr.len = 0;
					m->m_pkthdr.rcvif = (struct ifnet *)0;
				} else {
					MGET(m, M_WAIT, MT_DATA);
					mlen = MLEN;
				}
				if (resid >= MINCLSIZE && space >= MCLBYTES) {
					MCLGET(m, M_WAIT);
					if ((m->m_flags & M_EXT) == 0)
						goto nopages;
					mlen = MCLBYTES;
d463 6
a469 6
#else
					if (atomic && top == 0) {
						len = min(MCLBYTES - max_hdr, resid);
						m->m_data += max_hdr;
					} else
						len = min(MCLBYTES, resid);
d471 2
a472 2
					space -= len;
				} else {
d474 14
a487 37
					len = min(min(mlen, resid), space);
					space -= len;
					/*
					 * For datagram protocols, leave room
					 * for protocol headers in first mbuf.
					 */
					if (atomic && top == 0 && len < mlen)
						MH_ALIGN(m, len);
				}
				error = uiomove(mtod(m, caddr_t), (int)len,
				    uio);
				resid = uio->uio_resid;
				m->m_len = len;
				*mp = m;
				top->m_pkthdr.len += len;
				if (error)
					goto release;
				mp = &m->m_next;
				if (resid <= 0) {
					if (flags & MSG_EOR)
						top->m_flags |= M_EOR;
					break;
				}
			} while (space > 0 && atomic);
			if (dontroute)
				so->so_options |= SO_DONTROUTE;
			s = splsoftnet();		/* XXX */
			error = (*so->so_proto->pr_usrreq)(so,
			    (flags & MSG_OOB) ? PRU_SENDOOB : PRU_SEND,
			    top, addr, control);
			splx(s);
			if (dontroute)
				so->so_options &= ~SO_DONTROUTE;
			clen = 0;
			control = 0;
			top = 0;
			mp = &top;
d490 22
d847 1
a847 1

d1093 1
a1093 1
			    so->so_snd.sb_timeo : so->so_rcv.sb_timeo);
d1169 1
a1169 1
		kn->kn_flags |= EV_EOF;
d1200 1
a1200 1
		kn->kn_flags |= EV_EOF;
@


1.27.4.3
log
@Merge in -current
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
a52 1
#include <sys/pool.h>
a74 10
struct pool socket_pool;

void
soinit(void)
{

	pool_init(&socket_pool, sizeof(struct socket), 0, 0, 0,
	    "sockpl", 0, NULL, NULL, M_SOCKET);
}

d91 3
a93 3
	struct protosw *prp;
	struct socket *so;
	int error, s;
d103 1
a103 2
	s = splsoftnet();
	so = pool_get(&socket_pool, PR_WAITOK);
a104 2
	TAILQ_INIT(&so->so_q0);
	TAILQ_INIT(&so->so_q);
a115 1
		splx(s);
a124 1
	splx(s);
d154 1
a154 1
	if (TAILQ_FIRST(&so->so_q) == NULL)
a164 4
/*
 *  Must be called at splsoftnet()
 */

d183 1
a183 1
	pool_put(&socket_pool, so);
d200 1
a200 1
		while ((so2 = TAILQ_FIRST(&so->so_q0)) != NULL) {
d204 1
a204 1
		while ((so2 = TAILQ_FIRST(&so->so_q)) != NULL) {
d371 4
a374 4
	struct mbuf *m;
	long space, len, mlen, clen = 0;
	quad_t resid;
	int error, s, dontroute;
d409 2
a410 6
		if (so->so_error) {
			error = so->so_error;
			so->so_error = 0;
			splx(s);
			goto release;
		}
d462 3
d466 1
a466 1
						len = lmin(MCLBYTES - max_hdr, resid);
d469 2
a470 1
						len = lmin(MCLBYTES, resid);
d474 1
a474 1
					len = lmin(lmin(mlen, resid), space);
@


1.27.4.4
log
@Merge in trunk
@
text
@d82 2
a83 1
	pool_init(&socket_pool, sizeof(struct socket), 0, 0, 0, "sockpl", NULL);
d939 1
a939 3
			if (m == NULL || m->m_len != sizeof (struct linger) ||
			    mtod(m, struct linger *)->l_linger < 0 ||
			    mtod(m, struct linger *)->l_linger > SHRT_MAX) {
@


1.27.4.5
log
@Sync the SMP branch with 3.3
@
text
@a122 2
	so->so_rgid = p->p_cred->p_rgid;
	so->so_egid = p->p_ucred->cr_gid;
d185 2
a186 1
sofree(struct socket *so)
a187 1
	splassert(IPL_SOFTNET);
d266 1
a266 1
 * Must be called at splsoftnet.
d269 2
a270 1
soabort(struct socket *so)
a271 1
	splassert(IPL_SOFTNET);
d463 8
a470 8
			if (uio == NULL) {
				/*
				 * Data is prepackaged in "top".
				 */
				resid = 0;
				if (flags & MSG_EOR)
					top->m_flags |= M_EOR;
			} else do {
a666 2
		SBLASTRECORDCHK(&so->so_rcv, "soreceive sbwait 1");
		SBLASTMBUFCHK(&so->so_rcv, "soreceive sbwait 1");
a674 5
	/*
	 * On entry here, m points to the first record of the socket buffer.
	 * While we process the initial mbufs containing address and control
	 * info, we save a copy of m->m_nextpkt into nextrecord.
	 */
a678 3
	KASSERT(m == so->so_rcv.sb_mb);
	SBLASTRECORDCHK(&so->so_rcv, "soreceive 1");
	SBLASTMBUFCHK(&so->so_rcv, "soreceive 1");
a728 7

	/*
	 * If m is non-NULL, we have some data to read.  From now on,
	 * make sure to keep sb_lastrecord consistent when working on
	 * the last packet on the chain (nextrecord == NULL) and we
	 * change m->m_nextpkt.
	 */
d730 1
a730 1
		if ((flags & MSG_PEEK) == 0) {
a731 10
			/*
			 * If nextrecord == NULL (this is a single chain),
			 * then sb_lastrecord may not be valid here if m
			 * was changed earlier.
			 */
			if (nextrecord == NULL) {
				KASSERT(so->so_rcv.sb_mb == m);
				so->so_rcv.sb_lastrecord = m;
			}
		}
a738 6
	} else {
		if ((flags & MSG_PEEK) == 0) {
			KASSERT(so->so_rcv.sb_mb == m);
			so->so_rcv.sb_mb = nextrecord;
			SB_EMPTY_FIXUP(&so->so_rcv);
		}
a739 3
	SBLASTRECORDCHK(&so->so_rcv, "soreceive 2");
	SBLASTMBUFCHK(&so->so_rcv, "soreceive 2");

a766 2
			SBLASTRECORDCHK(&so->so_rcv, "soreceive uiomove");
			SBLASTMBUFCHK(&so->so_rcv, "soreceive uiomove");
d795 1
a795 6
				/*
				 * If m != NULL, we also know that
				 * so->so_rcv.sb_mb != NULL.
				 */
				KASSERT(so->so_rcv.sb_mb == m);
				if (m) {
a796 8
					if (nextrecord == NULL)
						so->so_rcv.sb_lastrecord = m;
				} else {
					so->so_rcv.sb_mb = nextrecord;
					SB_EMPTY_FIXUP(&so->so_rcv);
				}
				SBLASTRECORDCHK(&so->so_rcv, "soreceive 3");
				SBLASTMBUFCHK(&so->so_rcv, "soreceive 3");
a834 2
			SBLASTRECORDCHK(&so->so_rcv, "soreceive sbwait 2");
			SBLASTMBUFCHK(&so->so_rcv, "soreceive sbwait 2");
d852 1
a852 6
		if (m == 0) {
			/*
			 * First part is an inline SB_EMPTY_FIXUP().  Second
			 * part makes sure sb_lastrecord is up-to-date if
			 * there is still data in the socket buffer.
			 */
a853 8
			if (so->so_rcv.sb_mb == NULL) {
				so->so_rcv.sb_mbtail = NULL;
				so->so_rcv.sb_lastrecord = NULL;
			} else if (nextrecord->m_nextpkt == NULL)
				so->so_rcv.sb_lastrecord = nextrecord;
		}
		SBLASTRECORDCHK(&so->so_rcv, "soreceive 4");
		SBLASTMBUFCHK(&so->so_rcv, "soreceive 4");
d1014 1
a1014 1
			if (tv->tv_sec > (SHRT_MAX - tv->tv_usec / tick) / hz) {
a1018 2
			if (val == 0 && tv->tv_usec != 0)
				val = 1;
@


1.27.4.6
log
@Sync SMP branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.27.4.5 2003/03/28 00:41:27 niklas Exp $	*/
d16 5
a20 1
 * 3. Neither the name of the University nor the names of its contributors
@


1.27.4.7
log
@Merge of current from two weeks agointo the SMP branch
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d111 1
a111 1
	bzero(so, sizeof(*so));
d239 1
a239 1
				error = tsleep(&so->so_timeo,
d972 1
a972 1
	bzero(sb, sizeof (*sb));
@


1.27.4.8
log
@Merge with the trunk
@
text
@d105 1
a105 1
	if (prp == NULL || prp->pr_usrreq == 0)
d605 1
a605 1
		*mp = NULL;
d626 1
a626 1
	if (m == NULL || (((flags & MSG_DONTWAIT) == 0 &&
d630 1
a630 1
	    m->m_nextpkt == NULL && (pr->pr_flags & PR_ATOMIC) == 0)) {
d632 1
a632 1
		if (m == NULL && so->so_rcv.sb_cc)
d800 1
a800 1
		if (mp == NULL && uio_error == 0) {
d826 1
a826 1
					*mp = NULL;
d880 1
a880 1
		while (flags & MSG_WAITALL && m == NULL && uio->uio_resid > 0 &&
d903 1
a903 1
		if (m == NULL) {
a1034 2
			extern u_long unpst_recvspace;
			extern u_long unpst_sendspace;
a1045 7
				if (sbcheckreserve(cnt, unpst_sendspace) ||
				    sbreserve(&so->so_snd, cnt) == 0) {
					error = ENOBUFS;
					goto bad;
				}
				break;

d1047 3
a1049 2
				if (sbcheckreserve(cnt, unpst_recvspace) ||
				    sbreserve(&so->so_rcv, cnt) == 0) {
@


1.26
log
@fixed patch for accept/select race; mycroft@@netbsd.org
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.24 1999/02/05 00:40:22 deraadt Exp $	*/
d539 2
d551 2
d624 1
a624 1
		if (uio->uio_resid == 0)
d729 2
a730 1
		if (mp == 0) {
d732 3
a734 1
			error = uiomove(mtod(m, caddr_t) + moff, (int)len, uio);
d736 2
a737 2
			if (error)
				goto release;
d827 3
@


1.25
log
@undo select/accept patch, which causes full listen queues apparently
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.22 1998/07/28 00:13:07 millert Exp $	*/
d159 7
a165 3
		if (!soqremque(so, 0) && !soqremque(so, 1))
			panic("sofree dq");
		so->so_head = 0;
d181 1
d186 8
a193 4
		while (so->so_q0)
			(void) soabort(so->so_q0);
		while (so->so_q)
			(void) soabort(so->so_q);
d249 1
a249 1
	int error;
d254 3
a256 1
	error = (*so->so_proto->pr_usrreq)(so, PRU_ACCEPT, NULL, nam, NULL);
@


1.24
log
@support MSG_BCAST and MSG_MCAST
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.23 1999/01/21 03:27:42 millert Exp $	*/
d156 1
a156 6
	/*
	 * We must not decommission a socket that's on the accept(2) queue.
	 * If we do, then accept(2) may hang even after select(2) indicated
	 * that the listening socket was ready.
	 */
	if (so->so_pcb || so->so_head || (so->so_state & SS_NOFDREF) == 0)
d158 5
a176 1
	struct socket *so2;
d181 4
a184 8
		while ((so2 = so->so_q0) != NULL) {
			(void) soqremque(so2, 0);
			(void) soabort(so2);
		}
		while ((so2 = so->so_q) != NULL) {
			(void) soqremque(so2, 1);
			(void) soabort(so2);
		}
d240 1
a240 1
	int error = 0;
d245 1
a245 3
	if ((so->so_state & SS_ISDISCONNECTED) == 0)
		error = (*so->so_proto->pr_usrreq)(so, PRU_ACCEPT, NULL,
		    nam, NULL);
@


1.23
log
@Fixes select(2)/accept(2) race condition which permits DoS; mycroft@@netbsd.org
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.22 1998/07/28 00:13:07 millert Exp $	*/
d548 1
a548 2
					(struct mbuf *)(long)(flags & MSG_PEEK),
					NULL);
d690 4
@


1.22
log
@Return EINVAL when msg_iovlen or iovcnt <= 0; Make uio_resid unsigned (size_t) and don't return EINVAL if it is < 0 in sys_{read,write}.  Remove check for uio_resid < 0 uiomove() now that uio_resid is unsigned and brack remaining panics with #ifdef DIAGNOSTIC.  vn_rdwr() must now take a size_t * as its 9th argument so change that and clean up uses of vn_rdwr().  Fixes 549 + more
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.21 1998/02/14 10:55:09 deraadt Exp $	*/
d156 6
a161 1
	if (so->so_pcb || (so->so_state & SS_NOFDREF) == 0)
a162 5
	if (so->so_head) {
		if (!soqremque(so, 0) && !soqremque(so, 1))
			panic("sofree dq");
		so->so_head = 0;
	}
d177 1
d182 8
a189 4
		while (so->so_q0)
			(void) soabort(so->so_q0);
		while (so->so_q)
			(void) soabort(so->so_q);
d245 1
a245 1
	int error;
d250 3
a252 1
	error = (*so->so_proto->pr_usrreq)(so, PRU_ACCEPT, NULL, nam, NULL);
@


1.21
log
@add seperate so_euid & so_ruid to struct socket, so that identd is still fast.. Sigh. I will change this again later
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.20 1998/01/06 23:49:48 deraadt Exp $	*/
d344 2
a345 1
	register long space, len, resid;
d354 1
a354 1
	 * In theory resid should be unsigned.
d527 1
a527 1
	int orig_resid = uio->uio_resid;
@


1.20
log
@so_linger is in seconds
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.19 1997/11/15 19:57:51 deraadt Exp $	*/
d93 2
a94 1
	so->so_uid = p->p_ucred->cr_uid;
@


1.19
log
@for shutdown(2), if "how" is not 0-2, return EINVAL
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.18 1997/11/11 18:22:49 deraadt Exp $	*/
d199 2
a200 2
					       PSOCK | PCATCH, netcls,
					       so->so_linger);
@


1.18
log
@MSG_EOR on SOCK_STREAM is invalid; wollman
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.17 1997/08/31 20:42:24 deraadt Exp $	*/
d821 2
@


1.17
log
@for non-tty TIOCSPGRP/F_SETOWN/FIOSETOWN pgid setting calls, store uid
and euid as well, then deliver them using new csignal() interface
which ensures that pgid setting process is permitted to signal the
pgid process(es). Thanks to newsham@@aloha.net for extensive help and
discussion.
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.15 1997/06/29 18:14:35 deraadt Exp $	*/
d357 1
d359 2
a360 1
	if (resid < 0) {
@


1.16
log
@mbuf leak repair; mycroft@@netbsd
@
text
@d1063 1
a1063 6
	struct proc *p;

	if (so->so_pgid < 0)
		gsignal(-so->so_pgid, SIGURG);
	else if (so->so_pgid > 0 && (p = pfind(so->so_pgid)) != 0)
		psignal(p, SIGURG);
@


1.15
log
@constrain lowwater >= highwater
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.14 1997/06/23 01:42:04 deraadt Exp $	*/
d358 4
a361 2
	if (resid < 0)
		return (EINVAL);
@


1.14
log
@oops
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.13 1997/06/23 00:22:03 deraadt Exp $	*/
d916 2
a917 1
				so->so_snd.sb_lowat = (long)cnt;
d920 2
a921 1
				so->so_rcv.sb_lowat = (long)cnt;
@


1.13
log
@for SO_SND*/SO_RCV*, clip low-end of parameter to 1
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.12 1997/06/06 11:12:13 deraadt Exp $	*/
d900 1
a900 1
			bufsize = *mtod(m, int *);
@


1.12
log
@SO_SNDTIMEO tv_usec calc error; stevens, vol2, p548
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.11 1997/02/28 04:03:45 angelos Exp $	*/
d893 3
d900 3
d909 1
a909 1
				    (u_long) *mtod(m, int *)) == 0) {
d916 1
a916 1
				so->so_snd.sb_lowat = *mtod(m, int *);
d919 1
a919 1
				so->so_rcv.sb_lowat = *mtod(m, int *);
d923 1
@


1.11
log
@Moved IPsec socket state to the PCB.
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.10 1997/02/28 03:20:38 angelos Exp $	*/
d1035 1
a1035 1
			    (val % hz) / tick;
@


1.10
log
@New variables for system-wide security default levels.
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.9 1997/02/28 02:56:50 angelos Exp $	*/
a56 4
extern u_char ipsec_auth_default_level;
extern u_char ipsec_esp_trans_default_level;
extern u_char ipsec_esp_network_default_level;

a94 3
	so->so_seclevel[SL_AUTH] = ipsec_auth_default_level;
	so->so_seclevel[SL_ESP_TRANS] = ipsec_esp_trans_default_level;
	so->so_seclevel[SL_ESP_NETWORK] = ipsec_esp_network_default_level;
a161 3
#ifdef IPSEC
	/* XXX Free TDBs/routing entries if necessary */
#endif
@


1.9
log
@IPsec socket API additions.
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.8 1996/12/16 14:30:17 deraadt Exp $	*/
d56 5
d99 3
a101 3
	so->so_seclevel[SL_AUTH] = IPSEC_AUTH_LEVEL_DEFAULT;
	so->so_seclevel[SL_ESP_TRANS] = IPSEC_ESP_TRANS_LEVEL_DEFAULT;
	so->so_seclevel[SL_ESP_NETWORK] = IPSEC_ESP_NETWORK_LEVEL_DEFAULT;
@


1.8
log
@uiomove not checked for failure; wpaul@@skynet.ctr.columbia.edu
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.7 1996/09/20 22:53:10 deraadt Exp $	*/
d94 3
d164 3
@


1.7
log
@`solve' the syn bomb problem as well as currently known; add sysctl's for
SOMAXCONN (kern.somaxconn), SOMINCONN (kern.sominconn), and TCPTV_KEEP_INIT
(net.inet.tcp.keepinittime). when this is not enough (ie. overfull), start
doing tail drop, but slightly prefer the same port.
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.6 1996/08/24 04:56:36 deraadt Exp $	*/
d708 2
@


1.6
log
@change to so_uid, also fix a missing credential found by dm
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.5 1996/08/14 07:26:21 deraadt Exp $	*/
d53 6
d140 5
a144 3
	if (backlog < 0)
		backlog = 0;
	so->so_qlimit = min(backlog, SOMAXCONN);
@


1.5
log
@incorrect size calculation in mbuf copying, netbsd pr#2692; fix from explorer@@flame.org
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.4 1996/08/05 01:00:53 deraadt Exp $	*/
d86 1
a86 1
	so->so_ucred = crdup(p->p_ucred);
a154 2
	if (so->so_ucred)
		crfree(so->so_ucred);
@


1.4
log
@struct socket gets so_ucred; permit only same uid or root to do port takeover.
@
text
@d1 1
a1 1
/*	$OpenBSD: uipc_socket.c,v 1.3 1996/03/03 17:20:19 niklas Exp $	*/
d430 1
a430 1
				space -= MCLBYTES;
@


1.3
log
@From NetBSD: 960217 merge
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d86 1
d155 2
@


1.2
log
@from NetBSD: so it compiles now again ;)
@
text
@d1 2
a2 1
/*	$NetBSD: uipc_socket.c,v 1.20 1995/08/12 23:59:11 mycroft Exp $	*/
d50 1
d88 2
a89 2
	    (*prp->pr_usrreq)(so, PRU_ATTACH, (struct mbuf *)0,
		(struct mbuf *)(long)proto, (struct mbuf *)0);
d114 1
a114 3
	error =
	    (*so->so_proto->pr_usrreq)(so, PRU_BIND,
		(struct mbuf *)0, nam, (struct mbuf *)0);
d126 1
a126 3
	error =
	    (*so->so_proto->pr_usrreq)(so, PRU_LISTEN,
		(struct mbuf *)0, (struct mbuf *)0, (struct mbuf *)0);
d187 5
a191 3
			while (so->so_state & SS_ISCONNECTED)
				if (error = tsleep((caddr_t)&so->so_timeo,
				    PSOCK | PCATCH, netcls, so->so_linger))
d193 1
d198 2
a199 3
		int error2 =
		    (*so->so_proto->pr_usrreq)(so, PRU_DETACH,
			(struct mbuf *)0, (struct mbuf *)0, (struct mbuf *)0);
d220 1
a220 3
	return (
	    (*so->so_proto->pr_usrreq)(so, PRU_ABORT,
		(struct mbuf *)0, (struct mbuf *)0, (struct mbuf *)0));
d234 1
a234 2
	error = (*so->so_proto->pr_usrreq)(so, PRU_ACCEPT,
	    (struct mbuf *)0, nam, (struct mbuf *)0);
d262 1
a262 1
		    (struct mbuf *)0, nam, (struct mbuf *)0);
d275 2
a276 2
	error = (*so1->so_proto->pr_usrreq)(so1, PRU_CONNECT2,
	    (struct mbuf *)0, (struct mbuf *)so2, (struct mbuf *)0);
d296 2
a297 2
	error = (*so->so_proto->pr_usrreq)(so, PRU_DISCONNECT,
	    (struct mbuf *)0, (struct mbuf *)0, (struct mbuf *)0);
d359 1
a359 1
	if (error = sblock(&so->so_snd, SBLOCKWAIT(flags)))
d378 1
a378 1
		if (atomic && resid > so->so_snd.sb_hiwat ||
d456 3
a458 3
		    error = (*so->so_proto->pr_usrreq)(so,
			(flags & MSG_OOB) ? PRU_SENDOOB : PRU_SEND,
			top, addr, control);
d510 1
a510 1
	int moff, type;
d525 2
a526 1
		    (struct mbuf *)(long)(flags & MSG_PEEK), (struct mbuf *)0);
d542 1
a542 2
		(*pr->pr_usrreq)(so, PRU_RCVD, (struct mbuf *)0,
		    (struct mbuf *)0, (struct mbuf *)0);
d545 1
a545 1
	if (error = sblock(&so->so_rcv, SBLOCKWAIT(flags)))
d561 1
a561 1
	if (m == 0 || ((flags & MSG_DONTWAIT) == 0 &&
d565 1
a565 1
	    m->m_nextpkt == 0 && (pr->pr_flags & PR_ATOMIC) == 0) {
d765 1
a765 1
			if (m = so->so_rcv.sb_mb)
d779 2
a780 3
			(*pr->pr_usrreq)(so, PRU_RCVD, (struct mbuf *)0,
			    (struct mbuf *)(long)flags, (struct mbuf *)0,
			    (struct mbuf *)0);
d808 1
a808 2
		return ((*pr->pr_usrreq)(so, PRU_SHUTDOWN,
		    (struct mbuf *)0, (struct mbuf *)0, (struct mbuf *)0));
@


1.1
log
@Initial revision
@
text
@d142 1
a142 1
int
@


1.1.1.1
log
@initial import of NetBSD tree
@
text
@@
