head	1.128;
access;
symbols
	OPENBSD_6_0:1.128.0.6
	OPENBSD_6_0_BASE:1.128
	OPENBSD_5_9:1.128.0.2
	OPENBSD_5_9_BASE:1.128
	OPENBSD_5_8:1.128.0.4
	OPENBSD_5_8_BASE:1.128
	OPENBSD_5_7:1.127.0.2
	OPENBSD_5_7_BASE:1.127
	OPENBSD_5_6:1.114.0.4
	OPENBSD_5_6_BASE:1.114
	OPENBSD_5_5:1.104.0.4
	OPENBSD_5_5_BASE:1.104
	OPENBSD_5_4:1.102.0.2
	OPENBSD_5_4_BASE:1.102
	OPENBSD_5_3:1.94.0.2
	OPENBSD_5_3_BASE:1.94
	OPENBSD_5_2:1.92.0.2
	OPENBSD_5_2_BASE:1.92
	OPENBSD_5_1_BASE:1.90
	OPENBSD_5_1:1.90.0.2
	OPENBSD_5_0:1.89.0.2
	OPENBSD_5_0_BASE:1.89
	OPENBSD_4_9:1.86.0.2
	OPENBSD_4_9_BASE:1.86
	OPENBSD_4_8:1.84.0.2
	OPENBSD_4_8_BASE:1.84
	OPENBSD_4_7:1.81.0.2
	OPENBSD_4_7_BASE:1.81
	OPENBSD_4_6:1.79.0.6
	OPENBSD_4_6_BASE:1.79
	OPENBSD_4_5:1.79.0.2
	OPENBSD_4_5_BASE:1.79
	OPENBSD_4_4:1.74.0.4
	OPENBSD_4_4_BASE:1.74
	OPENBSD_4_3:1.74.0.2
	OPENBSD_4_3_BASE:1.74
	OPENBSD_4_2:1.70.0.2
	OPENBSD_4_2_BASE:1.70
	OPENBSD_4_1:1.66.0.2
	OPENBSD_4_1_BASE:1.66
	OPENBSD_4_0:1.62.0.4
	OPENBSD_4_0_BASE:1.62
	OPENBSD_3_9:1.62.0.2
	OPENBSD_3_9_BASE:1.62
	OPENBSD_3_8:1.59.0.4
	OPENBSD_3_8_BASE:1.59
	OPENBSD_3_7:1.59.0.2
	OPENBSD_3_7_BASE:1.59
	OPENBSD_3_6:1.58.0.2
	OPENBSD_3_6_BASE:1.58
	SMP_SYNC_A:1.58
	SMP_SYNC_B:1.58
	OPENBSD_3_5:1.56.0.2
	OPENBSD_3_5_BASE:1.56
	OPENBSD_3_4:1.55.0.2
	OPENBSD_3_4_BASE:1.55
	UBC_SYNC_A:1.51
	OPENBSD_3_3:1.48.0.4
	OPENBSD_3_3_BASE:1.48
	OPENBSD_3_2:1.48.0.2
	OPENBSD_3_2_BASE:1.48
	OPENBSD_3_1:1.47.0.2
	OPENBSD_3_1_BASE:1.47
	UBC_SYNC_B:1.48
	UBC:1.44.0.2
	UBC_BASE:1.44
	OPENBSD_3_0:1.39.0.2
	OPENBSD_3_0_BASE:1.39
	OPENBSD_2_9_BASE:1.25
	OPENBSD_2_9:1.25.0.2
	OPENBSD_2_8:1.20.0.2
	OPENBSD_2_8_BASE:1.20
	OPENBSD_2_7:1.19.0.2
	OPENBSD_2_7_BASE:1.19
	SMP:1.18.0.2
	SMP_BASE:1.18
	kame_19991208:1.18
	OPENBSD_2_6:1.17.0.2
	OPENBSD_2_6_BASE:1.17
	OPENBSD_2_5:1.12.0.2
	OPENBSD_2_5_BASE:1.12
	OPENBSD_2_4:1.9.0.4
	OPENBSD_2_4_BASE:1.9
	OPENBSD_2_3:1.9.0.2
	OPENBSD_2_3_BASE:1.9
	OPENBSD_2_2:1.7.0.4
	OPENBSD_2_2_BASE:1.7
	OPENBSD_2_1:1.7.0.2
	OPENBSD_2_1_BASE:1.7
	OPENBSD_2_0:1.6.0.2
	OPENBSD_2_0_BASE:1.6
	netbsd_1_1:1.1.1.1;
locks; strict;
comment	@ * @;


1.128
date	2015.03.14.03.38.50;	author jsg;	state Exp;
branches;
next	1.127;
commitid	p4LJxGKbi0BU2cG6;

1.127
date	2015.02.13.13.35.03;	author millert;	state Exp;
branches;
next	1.126;
commitid	AdfxL7vCLZYT5vxT;

1.126
date	2014.12.10.02.44.47;	author tedu;	state Exp;
branches;
next	1.125;
commitid	tsoJBlEBSyYO22RG;

1.125
date	2014.11.18.02.37.31;	author tedu;	state Exp;
branches;
next	1.124;
commitid	Z1vcFtHO8wRH0yRt;

1.124
date	2014.11.16.12.31.00;	author deraadt;	state Exp;
branches;
next	1.123;
commitid	yv0ECmCdICvq576h;

1.123
date	2014.11.06.17.29.23;	author tedu;	state Exp;
branches;
next	1.122;
commitid	XEeZbmF7nyLDz1qm;

1.122
date	2014.11.06.03.20.36;	author deraadt;	state Exp;
branches;
next	1.121;
commitid	62Qs0nNMpQxD62cH;

1.121
date	2014.11.05.22.27.40;	author tedu;	state Exp;
branches;
next	1.120;
commitid	2LtL1qU8u5TLDoHc;

1.120
date	2014.11.05.18.08.21;	author tedu;	state Exp;
branches;
next	1.119;
commitid	tyALF6FsA41dbcEU;

1.119
date	2014.11.05.17.44.54;	author tedu;	state Exp;
branches;
next	1.118;
commitid	57mZiZ8BqwplVb0J;

1.118
date	2014.11.05.17.43.04;	author tedu;	state Exp;
branches;
next	1.117;
commitid	Kq1YA377PIeHFNhd;

1.117
date	2014.11.02.05.15.34;	author tedu;	state Exp;
branches;
next	1.116;
commitid	zhemcdp7kIP4z6VC;

1.116
date	2014.11.02.05.12.14;	author tedu;	state Exp;
branches;
next	1.115;
commitid	CScopzqPpCFkBTHw;

1.115
date	2014.09.14.14.17.25;	author jsg;	state Exp;
branches;
next	1.114;
commitid	uzzBR7hz9ncd4O6G;

1.114
date	2014.07.13.14.59.28;	author tedu;	state Exp;
branches;
next	1.113;
commitid	x80t4XZqTM5IywvR;

1.113
date	2014.07.12.18.43.32;	author tedu;	state Exp;
branches;
next	1.112;
commitid	QlVV51SZgNFxsXxC;

1.112
date	2014.07.10.22.16.48;	author tedu;	state Exp;
branches;
next	1.111;
commitid	7UNCxepxt4W7YlBM;

1.111
date	2014.07.10.19.33.16;	author matthew;	state Exp;
branches;
next	1.110;
commitid	V84Gt32TGTrY0uFt;

1.110
date	2014.07.10.10.53.45;	author deraadt;	state Exp;
branches;
next	1.109;
commitid	74QUTCFNcykoAqlN;

1.109
date	2014.07.10.07.50.27;	author tedu;	state Exp;
branches;
next	1.108;
commitid	EldLGVtcRJJgIA98;

1.108
date	2014.06.21.19.24.57;	author daniel;	state Exp;
branches;
next	1.107;
commitid	wEQNWteqrHoCCen2;

1.107
date	2014.05.19.14.30.03;	author tedu;	state Exp;
branches;
next	1.106;

1.106
date	2014.04.03.21.36.59;	author tedu;	state Exp;
branches;
next	1.105;

1.105
date	2014.03.28.17.57.11;	author mpi;	state Exp;
branches;
next	1.104;

1.104
date	2014.01.21.01.48.44;	author tedu;	state Exp;
branches;
next	1.103;

1.103
date	2013.08.08.23.25.06;	author syl;	state Exp;
branches;
next	1.102;

1.102
date	2013.07.04.17.35.52;	author tedu;	state Exp;
branches;
next	1.101;

1.101
date	2013.05.31.20.44.10;	author tedu;	state Exp;
branches;
next	1.100;

1.100
date	2013.05.03.18.26.07;	author tedu;	state Exp;
branches;
next	1.99;

1.99
date	2013.04.06.03.53.25;	author tedu;	state Exp;
branches;
next	1.98;

1.98
date	2013.03.28.16.41.39;	author tedu;	state Exp;
branches;
next	1.97;

1.97
date	2013.03.26.16.36.01;	author tedu;	state Exp;
branches;
next	1.96;

1.96
date	2013.03.21.01.29.41;	author deraadt;	state Exp;
branches;
next	1.95;

1.95
date	2013.03.15.19.10.43;	author tedu;	state Exp;
branches;
next	1.94;

1.94
date	2013.02.17.17.39.29;	author miod;	state Exp;
branches;
next	1.93;

1.93
date	2013.02.09.20.56.35;	author miod;	state Exp;
branches;
next	1.92;

1.92
date	2012.03.30.23.03.42;	author pirofti;	state Exp;
branches;
next	1.91;

1.91
date	2012.03.09.13.01.28;	author ariane;	state Exp;
branches;
next	1.90;

1.90
date	2011.09.22.21.52.36;	author jsing;	state Exp;
branches;
next	1.89;

1.89
date	2011.06.06.17.10.23;	author ariane;	state Exp;
branches;
next	1.88;

1.88
date	2011.06.06.17.05.46;	author deraadt;	state Exp;
branches;
next	1.87;

1.87
date	2011.05.24.15.27.36;	author ariane;	state Exp;
branches;
next	1.86;

1.86
date	2010.09.26.21.03.56;	author tedu;	state Exp;
branches;
next	1.85;

1.85
date	2010.09.21.01.09.10;	author matthew;	state Exp;
branches;
next	1.84;

1.84
date	2010.07.22.06.30.13;	author matthew;	state Exp;
branches;
next	1.83;

1.83
date	2010.07.02.01.25.05;	author art;	state Exp;
branches;
next	1.82;

1.82
date	2010.07.01.19.51.13;	author thib;	state Exp;
branches;
next	1.81;

1.81
date	2009.08.25.18.02.42;	author miod;	state Exp;
branches;
next	1.80;

1.80
date	2009.08.25.17.59.43;	author miod;	state Exp;
branches;
next	1.79;

1.79
date	2009.02.22.19.57.59;	author miod;	state Exp;
branches;
next	1.78;

1.78
date	2008.10.18.12.11.30;	author kettenis;	state Exp;
branches;
next	1.77;

1.77
date	2008.10.11.16.49.56;	author kettenis;	state Exp;
branches;
next	1.76;

1.76
date	2008.10.05.11.12.19;	author miod;	state Exp;
branches;
next	1.75;

1.75
date	2008.09.29.12.34.18;	author art;	state Exp;
branches;
next	1.74;

1.74
date	2008.02.21.10.40.48;	author kettenis;	state Exp;
branches;
next	1.73;

1.73
date	2007.09.15.10.10.37;	author martin;	state Exp;
branches;
next	1.72;

1.72
date	2007.09.07.10.22.15;	author art;	state Exp;
branches;
next	1.71;

1.71
date	2007.09.01.15.14.44;	author martin;	state Exp;
branches;
next	1.70;

1.70
date	2007.05.29.00.17.32;	author thib;	state Exp;
branches;
next	1.69;

1.69
date	2007.04.12.21.47.45;	author miod;	state Exp;
branches;
next	1.68;

1.68
date	2007.04.11.12.10.42;	author art;	state Exp;
branches;
next	1.67;

1.67
date	2007.03.25.02.38.11;	author tedu;	state Exp;
branches;
next	1.66;

1.66
date	2007.01.12.07.41.31;	author art;	state Exp;
branches;
next	1.65;

1.65
date	2006.11.28.11.14.52;	author pedro;	state Exp;
branches;
next	1.64;

1.64
date	2006.11.22.18.59.50;	author thib;	state Exp;
branches;
next	1.63;

1.63
date	2006.09.30.14.31.28;	author mickey;	state Exp;
branches;
next	1.62;

1.62
date	2005.11.28.00.14.28;	author jsg;	state Exp;
branches;
next	1.61;

1.61
date	2005.11.19.02.18.01;	author pedro;	state Exp;
branches;
next	1.60;

1.60
date	2005.09.12.23.05.06;	author miod;	state Exp;
branches;
next	1.59;

1.59
date	2004.12.30.08.28.39;	author niklas;	state Exp;
branches;
next	1.58;

1.58
date	2004.05.23.19.41.23;	author tedu;	state Exp;
branches;
next	1.57;

1.57
date	2004.05.23.19.37.24;	author tedu;	state Exp;
branches;
next	1.56;

1.56
date	2003.12.28.16.35.46;	author tedu;	state Exp;
branches;
next	1.55;

1.55
date	2003.07.21.22.44.50;	author tedu;	state Exp;
branches;
next	1.54;

1.54
date	2003.06.26.01.01.06;	author mickey;	state Exp;
branches;
next	1.53;

1.53
date	2003.06.02.23.28.05;	author millert;	state Exp;
branches;
next	1.52;

1.52
date	2003.06.01.16.23.41;	author art;	state Exp;
branches;
next	1.51;

1.51
date	2003.05.03.21.14.59;	author deraadt;	state Exp;
branches;
next	1.50;

1.50
date	2003.04.10.08.48.34;	author tedu;	state Exp;
branches;
next	1.49;

1.49
date	2003.04.10.02.04.24;	author tedu;	state Exp;
branches;
next	1.48;

1.48
date	2002.06.11.05.58.17;	author art;	state Exp;
branches;
next	1.47;

1.47
date	2002.02.12.17.19.41;	author provos;	state Exp;
branches;
next	1.46;

1.46
date	2002.01.16.20.50.17;	author miod;	state Exp;
branches;
next	1.45;

1.45
date	2001.12.19.08.58.06;	author art;	state Exp;
branches;
next	1.44;

1.44
date	2001.12.05.17.49.06;	author art;	state Exp;
branches
	1.44.2.1;
next	1.43;

1.43
date	2001.12.05.01.57.15;	author provos;	state Exp;
branches;
next	1.42;

1.42
date	2001.11.28.19.28.14;	author art;	state Exp;
branches;
next	1.41;

1.41
date	2001.11.28.16.13.29;	author art;	state Exp;
branches;
next	1.40;

1.40
date	2001.11.06.19.53.20;	author miod;	state Exp;
branches;
next	1.39;

1.39
date	2001.09.19.20.50.58;	author mickey;	state Exp;
branches;
next	1.38;

1.38
date	2001.08.17.23.39.58;	author art;	state Exp;
branches;
next	1.37;

1.37
date	2001.08.02.11.06.38;	author art;	state Exp;
branches;
next	1.36;

1.36
date	2001.07.26.14.23.31;	author art;	state Exp;
branches;
next	1.35;

1.35
date	2001.06.27.04.49.43;	author art;	state Exp;
branches;
next	1.34;

1.34
date	2001.06.22.14.14.08;	author deraadt;	state Exp;
branches;
next	1.33;

1.33
date	2001.06.21.14.28.53;	author niklas;	state Exp;
branches;
next	1.32;

1.32
date	2001.06.21.14.27.13;	author niklas;	state Exp;
branches;
next	1.31;

1.31
date	2001.05.14.08.03.13;	author angelos;	state Exp;
branches;
next	1.30;

1.30
date	2001.05.14.07.01.37;	author angelos;	state Exp;
branches;
next	1.29;

1.29
date	2001.05.14.06.56.30;	author angelos;	state Exp;
branches;
next	1.28;

1.28
date	2001.05.11.06.38.47;	author angelos;	state Exp;
branches;
next	1.27;

1.27
date	2001.05.06.00.47.46;	author art;	state Exp;
branches;
next	1.26;

1.26
date	2001.05.05.20.57.00;	author art;	state Exp;
branches;
next	1.25;

1.25
date	2001.04.06.14.37.50;	author angelos;	state Exp;
branches;
next	1.24;

1.24
date	2001.02.21.23.24.29;	author csapuntz;	state Exp;
branches;
next	1.23;

1.23
date	2001.02.20.23.35.35;	author csapuntz;	state Exp;
branches;
next	1.22;

1.22
date	2001.01.04.07.49.24;	author angelos;	state Exp;
branches;
next	1.21;

1.21
date	2001.01.04.06.04.14;	author angelos;	state Exp;
branches;
next	1.20;

1.20
date	2000.06.06.20.18.20;	author art;	state Exp;
branches;
next	1.19;

1.19
date	2000.03.16.22.11.03;	author art;	state Exp;
branches;
next	1.18;

1.18
date	99.11.25.13.41.30;	author art;	state Exp;
branches
	1.18.2.1;
next	1.17;

1.17
date	99.09.10.22.14.39;	author art;	state Exp;
branches;
next	1.16;

1.16
date	99.07.15.14.07.41;	author art;	state Exp;
branches;
next	1.15;

1.15
date	99.06.23.07.43.30;	author art;	state Exp;
branches;
next	1.14;

1.14
date	99.06.03.14.30.15;	author millert;	state Exp;
branches;
next	1.13;

1.13
date	99.05.06.17.37.13;	author art;	state Exp;
branches;
next	1.12;

1.12
date	99.02.26.04.54.00;	author art;	state Exp;
branches;
next	1.11;

1.11
date	99.01.20.21.47.46;	author art;	state Exp;
branches;
next	1.10;

1.10
date	99.01.11.05.12.23;	author millert;	state Exp;
branches;
next	1.9;

1.9
date	98.02.20.13.43.23;	author niklas;	state Exp;
branches;
next	1.8;

1.8
date	97.12.12.17.13.56;	author gene;	state Exp;
branches;
next	1.7;

1.7
date	97.03.01.21.31.11;	author kstailey;	state Exp;
branches;
next	1.6;

1.6
date	96.06.20.10.53.06;	author deraadt;	state Exp;
branches;
next	1.5;

1.5
date	96.06.10.07.27.12;	author deraadt;	state Exp;
branches;
next	1.4;

1.4
date	96.04.21.22.27.03;	author deraadt;	state Exp;
branches;
next	1.3;

1.3
date	96.04.19.16.08.55;	author niklas;	state Exp;
branches;
next	1.2;

1.2
date	96.03.03.17.19.49;	author niklas;	state Exp;
branches;
next	1.1;

1.1
date	95.10.18.08.52.44;	author deraadt;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	95.10.18.08.52.44;	author deraadt;	state Exp;
branches;
next	;

1.18.2.1
date	2000.03.24.09.09.24;	author niklas;	state Exp;
branches;
next	1.18.2.2;

1.18.2.2
date	2001.05.14.22.32.41;	author niklas;	state Exp;
branches;
next	1.18.2.3;

1.18.2.3
date	2001.07.04.10.48.22;	author niklas;	state Exp;
branches;
next	1.18.2.4;

1.18.2.4
date	2001.10.31.03.26.29;	author nate;	state Exp;
branches;
next	1.18.2.5;

1.18.2.5
date	2001.11.13.23.04.23;	author niklas;	state Exp;
branches;
next	1.18.2.6;

1.18.2.6
date	2001.12.05.01.02.39;	author niklas;	state Exp;
branches;
next	1.18.2.7;

1.18.2.7
date	2002.03.06.02.13.23;	author niklas;	state Exp;
branches;
next	1.18.2.8;

1.18.2.8
date	2003.03.28.00.41.26;	author niklas;	state Exp;
branches;
next	1.18.2.9;

1.18.2.9
date	2003.05.13.19.21.28;	author ho;	state Exp;
branches;
next	1.18.2.10;

1.18.2.10
date	2003.06.07.11.03.40;	author ho;	state Exp;
branches;
next	1.18.2.11;

1.18.2.11
date	2004.02.19.10.56.37;	author niklas;	state Exp;
branches;
next	;

1.44.2.1
date	2002.01.31.22.55.40;	author niklas;	state Exp;
branches;
next	1.44.2.2;

1.44.2.2
date	2002.02.02.03.28.25;	author art;	state Exp;
branches;
next	1.44.2.3;

1.44.2.3
date	2002.06.11.03.29.40;	author art;	state Exp;
branches;
next	1.44.2.4;

1.44.2.4
date	2002.10.29.00.36.44;	author art;	state Exp;
branches;
next	1.44.2.5;

1.44.2.5
date	2003.05.19.22.31.09;	author tedu;	state Exp;
branches;
next	;


desc
@@


1.128
log
@Remove some includes include-what-you-use claims don't
have any direct symbols used.  Tested for indirect use by compiling
amd64/i386/sparc64 kernels.

ok tedu@@ deraadt@@
@
text
@/*	$OpenBSD: kern_malloc.c,v 1.127 2015/02/13 13:35:03 millert Exp $	*/
/*	$NetBSD: kern_malloc.c,v 1.15.4.2 1996/06/13 17:10:56 cgd Exp $	*/

/*
 * Copyright (c) 1987, 1991, 1993
 *	The Regents of the University of California.  All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. Neither the name of the University nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 *	@@(#)kern_malloc.c	8.3 (Berkeley) 1/4/94
 */

#include <sys/param.h>
#include <sys/kernel.h>
#include <sys/malloc.h>
#include <sys/stdint.h>
#include <sys/systm.h>
#include <sys/sysctl.h>
#include <sys/time.h>
#include <sys/rwlock.h>

#include <uvm/uvm_extern.h>

static
#ifndef SMALL_KERNEL
__inline__
#endif
long BUCKETINDX(size_t sz)
{
	long b, d;

	/* note that this relies upon MINALLOCSIZE being 1 << MINBUCKET */
	b = 7 + MINBUCKET; d = 4;
	while (d != 0) {
		if (sz <= (1 << b))
			b -= d;
		else
			b += d;
		d >>= 1;
	}
	if (sz <= (1 << b))
		b += 0;
	else
		b += 1;
	return b;
}

static struct vm_map kmem_map_store;
struct vm_map *kmem_map = NULL;

/*
 * Default number of pages in kmem_map.  We attempt to calculate this
 * at run-time, but allow it to be either patched or set in the kernel
 * config file.
 */
#ifndef NKMEMPAGES
#define	NKMEMPAGES	0
#endif
u_int	nkmempages = NKMEMPAGES;

/*
 * Defaults for lower- and upper-bounds for the kmem_map page count.
 * Can be overridden by kernel config options.
 */
#ifndef	NKMEMPAGES_MIN
#define	NKMEMPAGES_MIN	0
#endif
u_int	nkmempages_min = 0;

#ifndef NKMEMPAGES_MAX
#define	NKMEMPAGES_MAX	NKMEMPAGES_MAX_DEFAULT
#endif
u_int	nkmempages_max = 0;

struct kmembuckets bucket[MINBUCKET + 16];
#ifdef KMEMSTATS
struct kmemstats kmemstats[M_LAST];
#endif
struct kmemusage *kmemusage;
char *kmembase, *kmemlimit;
char buckstring[16 * sizeof("123456,")];
int buckstring_init = 0;
#if defined(KMEMSTATS) || defined(DIAGNOSTIC) || defined(FFS_SOFTUPDATES)
char *memname[] = INITKMEMNAMES;
char *memall = NULL;
struct rwlock sysctl_kmemlock = RWLOCK_INITIALIZER("sysctlklk");
#endif

/*
 * Normally the freelist structure is used only to hold the list pointer
 * for free objects.  However, when running with diagnostics, the first
 * 8 bytes of the structure is unused except for diagnostic information,
 * and the free list pointer is at offset 8 in the structure.  Since the
 * first 8 bytes is the portion of the structure most often modified, this
 * helps to detect memory reuse problems and avoid free list corruption.
 */
struct kmem_freelist {
	int32_t	kf_spare0;
	int16_t	kf_type;
	int16_t	kf_spare1;
	XSIMPLEQ_ENTRY(kmem_freelist) kf_flist;
};

#ifdef DIAGNOSTIC
/*
 * This structure provides a set of masks to catch unaligned frees.
 */
const long addrmask[] = { 0,
	0x00000001, 0x00000003, 0x00000007, 0x0000000f,
	0x0000001f, 0x0000003f, 0x0000007f, 0x000000ff,
	0x000001ff, 0x000003ff, 0x000007ff, 0x00000fff,
	0x00001fff, 0x00003fff, 0x00007fff, 0x0000ffff,
};

#endif /* DIAGNOSTIC */

#ifndef SMALL_KERNEL
struct timeval malloc_errintvl = { 5, 0 };
struct timeval malloc_lasterr;
#endif

/*
 * Allocate a block of memory
 */
void *
malloc(size_t size, int type, int flags)
{
	struct kmembuckets *kbp;
	struct kmemusage *kup;
	struct kmem_freelist *freep;
	long indx, npg, allocsize;
	int s;
	caddr_t va, cp;
#ifdef DIAGNOSTIC
	int freshalloc;
	char *savedtype;
#endif
#ifdef KMEMSTATS
	struct kmemstats *ksp = &kmemstats[type];

	if (((unsigned long)type) <= 1 || ((unsigned long)type) >= M_LAST)
		panic("malloc: bogus type %d", type);
#endif

	KASSERT(flags & (M_WAITOK | M_NOWAIT));

	if ((flags & M_NOWAIT) == 0) {
		extern int pool_debug;
#ifdef DIAGNOSTIC
		assertwaitok();
		if (pool_debug == 2)
			yield();
#endif
		if (!cold && pool_debug) {
			KERNEL_UNLOCK();
			KERNEL_LOCK();
		}
	}

#ifdef MALLOC_DEBUG
	if (debug_malloc(size, type, flags, (void **)&va)) {
		if ((flags & M_ZERO) && va != NULL)
			memset(va, 0, size);
		return (va);
	}
#endif

	if (size > 65535 * PAGE_SIZE) {
		if (flags & M_CANFAIL) {
#ifndef SMALL_KERNEL
			if (ratecheck(&malloc_lasterr, &malloc_errintvl))
				printf("malloc(): allocation too large, "
				    "type = %d, size = %lu\n", type, size);
#endif
			return (NULL);
		} else
			panic("malloc: allocation too large, "
			    "type = %d, size = %lu\n", type, size);
	}

	indx = BUCKETINDX(size);
	kbp = &bucket[indx];
	s = splvm();
#ifdef KMEMSTATS
	while (ksp->ks_memuse >= ksp->ks_limit) {
		if (flags & M_NOWAIT) {
			splx(s);
			return (NULL);
		}
		if (ksp->ks_limblocks < 65535)
			ksp->ks_limblocks++;
		tsleep(ksp, PSWP+2, memname[type], 0);
	}
	ksp->ks_size |= 1 << indx;
#endif
	if (size > MAXALLOCSAVE)
		allocsize = round_page(size);
	else
		allocsize = 1 << indx;
	if (XSIMPLEQ_FIRST(&kbp->kb_freelist) == NULL) {
		npg = atop(round_page(allocsize));
		va = (caddr_t)uvm_km_kmemalloc_pla(kmem_map, NULL,
		    (vsize_t)ptoa(npg), 0,
		    ((flags & M_NOWAIT) ? UVM_KMF_NOWAIT : 0) |
		    ((flags & M_CANFAIL) ? UVM_KMF_CANFAIL : 0),
		    no_constraint.ucr_low, no_constraint.ucr_high,
		    0, 0, 0);
		if (va == NULL) {
			/*
			 * Kmem_malloc() can return NULL, even if it can
			 * wait, if there is no map space available, because
			 * it can't fix that problem.  Neither can we,
			 * right now.  (We should release pages which
			 * are completely free and which are in buckets
			 * with too many free elements.)
			 */
			if ((flags & (M_NOWAIT|M_CANFAIL)) == 0)
				panic("malloc: out of space in kmem_map");
			splx(s);
			return (NULL);
		}
#ifdef KMEMSTATS
		kbp->kb_total += kbp->kb_elmpercl;
#endif
		kup = btokup(va);
		kup->ku_indx = indx;
#ifdef DIAGNOSTIC
		freshalloc = 1;
#endif
		if (allocsize > MAXALLOCSAVE) {
			kup->ku_pagecnt = npg;
#ifdef KMEMSTATS
			ksp->ks_memuse += allocsize;
#endif
			goto out;
		}
#ifdef KMEMSTATS
		kup->ku_freecnt = kbp->kb_elmpercl;
		kbp->kb_totalfree += kbp->kb_elmpercl;
#endif
		cp = va + (npg * PAGE_SIZE) - allocsize;
		for (;;) {
			freep = (struct kmem_freelist *)cp;
#ifdef DIAGNOSTIC
			/*
			 * Copy in known text to detect modification
			 * after freeing.
			 */
			poison_mem(cp, allocsize);
			freep->kf_type = M_FREE;
#endif /* DIAGNOSTIC */
			XSIMPLEQ_INSERT_HEAD(&kbp->kb_freelist, freep, kf_flist);
			if (cp <= va)
				break;
			cp -= allocsize;
		}
	} else {
#ifdef DIAGNOSTIC
		freshalloc = 0;
#endif
	}
	freep = XSIMPLEQ_FIRST(&kbp->kb_freelist);
	XSIMPLEQ_REMOVE_HEAD(&kbp->kb_freelist, kf_flist);
	va = (caddr_t)freep;
#ifdef DIAGNOSTIC
	savedtype = (unsigned)freep->kf_type < M_LAST ?
		memname[freep->kf_type] : "???";
	if (freshalloc == 0 && XSIMPLEQ_FIRST(&kbp->kb_freelist)) {
		int rv;
		vaddr_t addr = (vaddr_t)XSIMPLEQ_FIRST(&kbp->kb_freelist);

		vm_map_lock(kmem_map);
		rv = uvm_map_checkprot(kmem_map, addr,
		    addr + sizeof(struct kmem_freelist), PROT_WRITE);
		vm_map_unlock(kmem_map);

		if (!rv)  {
			printf("%s %zd of object %p size 0x%lx %s %s"
			    " (invalid addr %p)\n",
			    "Data modified on freelist: word", 
			    (int32_t *)&addr - (int32_t *)kbp, va, size,
			    "previous type", savedtype, (void *)addr);
		}
	}

	/* Fill the fields that we've used with poison */
	poison_mem(freep, sizeof(*freep));

	/* and check that the data hasn't been modified. */
	if (freshalloc == 0) {
		size_t pidx;
		uint32_t pval;
		if (poison_check(va, allocsize, &pidx, &pval)) {
			panic("%s %zd of object %p size 0x%lx %s %s"
			    " (0x%x != 0x%x)\n",
			    "Data modified on freelist: word",
			    pidx, va, size, "previous type",
			    savedtype, ((int32_t*)va)[pidx], pval);
		}
	}

	freep->kf_spare0 = 0;
#endif /* DIAGNOSTIC */
#ifdef KMEMSTATS
	kup = btokup(va);
	if (kup->ku_indx != indx)
		panic("malloc: wrong bucket");
	if (kup->ku_freecnt == 0)
		panic("malloc: lost data");
	kup->ku_freecnt--;
	kbp->kb_totalfree--;
	ksp->ks_memuse += 1 << indx;
out:
	kbp->kb_calls++;
	ksp->ks_inuse++;
	ksp->ks_calls++;
	if (ksp->ks_memuse > ksp->ks_maxused)
		ksp->ks_maxused = ksp->ks_memuse;
#else
out:
#endif
	splx(s);

	if ((flags & M_ZERO) && va != NULL)
		memset(va, 0, size);
	return (va);
}

/*
 * Free a block of memory allocated by malloc.
 */
void
free(void *addr, int type, size_t freedsize)
{
	struct kmembuckets *kbp;
	struct kmemusage *kup;
	struct kmem_freelist *freep;
	long size;
	int s;
#ifdef DIAGNOSTIC
	long alloc;
#endif
#ifdef KMEMSTATS
	struct kmemstats *ksp = &kmemstats[type];
#endif

	if (addr == NULL)
		return;

#ifdef MALLOC_DEBUG
	if (debug_free(addr, type))
		return;
#endif

#ifdef DIAGNOSTIC
	if (addr < (void *)kmembase || addr >= (void *)kmemlimit)
		panic("free: non-malloced addr %p type %s", addr,
		    memname[type]);
#endif

	kup = btokup(addr);
	size = 1 << kup->ku_indx;
	kbp = &bucket[kup->ku_indx];
	if (size > MAXALLOCSAVE)
		size = kup->ku_pagecnt << PAGE_SHIFT;
	s = splvm();
#ifdef DIAGNOSTIC
	if (freedsize != 0 && freedsize > size)
		panic("free: size too large %zu > %ld (%p) type %s",
		    freedsize, size, addr, memname[type]);
	if (freedsize != 0 && size > MINALLOCSIZE && freedsize < size / 2)
		panic("free: size too small %zu < %ld / 2 (%p) type %s",
		    freedsize, size, addr, memname[type]);
	/*
	 * Check for returns of data that do not point to the
	 * beginning of the allocation.
	 */
	if (size > PAGE_SIZE)
		alloc = addrmask[BUCKETINDX(PAGE_SIZE)];
	else
		alloc = addrmask[kup->ku_indx];
	if (((u_long)addr & alloc) != 0)
		panic("free: unaligned addr %p, size %ld, type %s, mask %ld",
			addr, size, memname[type], alloc);
#endif /* DIAGNOSTIC */
	if (size > MAXALLOCSAVE) {
		uvm_km_free(kmem_map, (vaddr_t)addr, ptoa(kup->ku_pagecnt));
#ifdef KMEMSTATS
		ksp->ks_memuse -= size;
		kup->ku_indx = 0;
		kup->ku_pagecnt = 0;
		if (ksp->ks_memuse + size >= ksp->ks_limit &&
		    ksp->ks_memuse < ksp->ks_limit)
			wakeup(ksp);
		ksp->ks_inuse--;
		kbp->kb_total -= 1;
#endif
		splx(s);
		return;
	}
	freep = (struct kmem_freelist *)addr;
#ifdef DIAGNOSTIC
	/*
	 * Check for multiple frees. Use a quick check to see if
	 * it looks free before laboriously searching the freelist.
	 */
	if (freep->kf_spare0 == poison_value(freep)) {
		struct kmem_freelist *fp;
		XSIMPLEQ_FOREACH(fp, &kbp->kb_freelist, kf_flist) {
			if (addr != fp)
				continue;
			printf("multiply freed item %p\n", addr);
			panic("free: duplicated free");
		}
	}
	/*
	 * Copy in known text to detect modification after freeing
	 * and to make it look free. Also, save the type being freed
	 * so we can list likely culprit if modification is detected
	 * when the object is reallocated.
	 */
	poison_mem(addr, size);
	freep->kf_spare0 = poison_value(freep);

	freep->kf_type = type;
#endif /* DIAGNOSTIC */
#ifdef KMEMSTATS
	kup->ku_freecnt++;
	if (kup->ku_freecnt >= kbp->kb_elmpercl) {
		if (kup->ku_freecnt > kbp->kb_elmpercl)
			panic("free: multiple frees");
		else if (kbp->kb_totalfree > kbp->kb_highwat)
			kbp->kb_couldfree++;
	}
	kbp->kb_totalfree++;
	ksp->ks_memuse -= size;
	if (ksp->ks_memuse + size >= ksp->ks_limit &&
	    ksp->ks_memuse < ksp->ks_limit)
		wakeup(ksp);
	ksp->ks_inuse--;
#endif
	XSIMPLEQ_INSERT_TAIL(&kbp->kb_freelist, freep, kf_flist);
	splx(s);
}

/*
 * Compute the number of pages that kmem_map will map, that is,
 * the size of the kernel malloc arena.
 */
void
kmeminit_nkmempages(void)
{
	u_int npages;

	if (nkmempages != 0) {
		/*
		 * It's already been set (by us being here before, or
		 * by patching or kernel config options), bail out now.
		 */
		return;
	}

	/*
	 * We can't initialize these variables at compilation time, since
	 * the page size may not be known (on sparc GENERIC kernels, for
	 * example). But we still want the MD code to be able to provide
	 * better values.
	 */
	if (nkmempages_min == 0)
		nkmempages_min = NKMEMPAGES_MIN;
	if (nkmempages_max == 0)
		nkmempages_max = NKMEMPAGES_MAX;

	/*
	 * We use the following (simple) formula:
	 *
	 *	- Starting point is physical memory / 4.
	 *
	 *	- Clamp it down to nkmempages_max.
	 *
	 *	- Round it up to nkmempages_min.
	 */
	npages = physmem / 4;

	if (npages > nkmempages_max)
		npages = nkmempages_max;

	if (npages < nkmempages_min)
		npages = nkmempages_min;

	nkmempages = npages;
}

/*
 * Initialize the kernel memory allocator
 */
void
kmeminit(void)
{
	vaddr_t base, limit;
	long indx;

#ifdef DIAGNOSTIC
	if (sizeof(struct kmem_freelist) > (1 << MINBUCKET))
		panic("kmeminit: minbucket too small/struct freelist too big");
#endif

	/*
	 * Compute the number of kmem_map pages, if we have not
	 * done so already.
	 */
	kmeminit_nkmempages();
	base = vm_map_min(kernel_map);
	kmem_map = uvm_km_suballoc(kernel_map, &base, &limit,
	    (vsize_t)nkmempages << PAGE_SHIFT,
#ifdef KVA_GUARDPAGES
	    VM_MAP_INTRSAFE | VM_MAP_GUARDPAGES,
#else
	    VM_MAP_INTRSAFE,
#endif
	    FALSE, &kmem_map_store);
	kmembase = (char *)base;
	kmemlimit = (char *)limit;
	kmemusage = (struct kmemusage *) uvm_km_zalloc(kernel_map,
		(vsize_t)(nkmempages * sizeof(struct kmemusage)));
	for (indx = 0; indx < MINBUCKET + 16; indx++) {
		XSIMPLEQ_INIT(&bucket[indx].kb_freelist);
	}
#ifdef KMEMSTATS
	for (indx = 0; indx < MINBUCKET + 16; indx++) {
		if (1 << indx >= PAGE_SIZE)
			bucket[indx].kb_elmpercl = 1;
		else
			bucket[indx].kb_elmpercl = PAGE_SIZE / (1 << indx);
		bucket[indx].kb_highwat = 5 * bucket[indx].kb_elmpercl;
	}
	for (indx = 0; indx < M_LAST; indx++)
		kmemstats[indx].ks_limit = nkmempages * PAGE_SIZE * 6 / 10;
#endif
#ifdef MALLOC_DEBUG
	debug_malloc_init();
#endif
}

/*
 * Return kernel malloc statistics information.
 */
int
sysctl_malloc(int *name, u_int namelen, void *oldp, size_t *oldlenp, void *newp,
    size_t newlen, struct proc *p)
{
	struct kmembuckets kb;
#if defined(KMEMSTATS) || defined(DIAGNOSTIC) || defined(FFS_SOFTUPDATES)
	int error;
#endif
	int i, siz;

	if (namelen != 2 && name[0] != KERN_MALLOC_BUCKETS &&
	    name[0] != KERN_MALLOC_KMEMNAMES)
		return (ENOTDIR);		/* overloaded */

	switch (name[0]) {
	case KERN_MALLOC_BUCKETS:
		/* Initialize the first time */
		if (buckstring_init == 0) {
			buckstring_init = 1;
			memset(buckstring, 0, sizeof(buckstring));
			for (siz = 0, i = MINBUCKET; i < MINBUCKET + 16; i++) {
				snprintf(buckstring + siz,
				    sizeof buckstring - siz,
				    "%d,", (u_int)(1<<i));
				siz += strlen(buckstring + siz);
			}
			/* Remove trailing comma */
			if (siz)
				buckstring[siz - 1] = '\0';
		}
		return (sysctl_rdstring(oldp, oldlenp, newp, buckstring));

	case KERN_MALLOC_BUCKET:
		memcpy(&kb, &bucket[BUCKETINDX(name[1])], sizeof(kb));
		memset(&kb.kb_freelist, 0, sizeof(kb.kb_freelist));
		return (sysctl_rdstruct(oldp, oldlenp, newp, &kb, sizeof(kb)));
	case KERN_MALLOC_KMEMSTATS:
#ifdef KMEMSTATS
		if ((name[1] < 0) || (name[1] >= M_LAST))
			return (EINVAL);
		return (sysctl_rdstruct(oldp, oldlenp, newp,
		    &kmemstats[name[1]], sizeof(struct kmemstats)));
#else
		return (EOPNOTSUPP);
#endif
	case KERN_MALLOC_KMEMNAMES:
#if defined(KMEMSTATS) || defined(DIAGNOSTIC) || defined(FFS_SOFTUPDATES)
		error = rw_enter(&sysctl_kmemlock, RW_WRITE|RW_INTR);
		if (error)
			return (error);
		if (memall == NULL) {
			int totlen;

			/* Figure out how large a buffer we need */
			for (totlen = 0, i = 0; i < M_LAST; i++) {
				if (memname[i])
					totlen += strlen(memname[i]);
				totlen++;
			}
			memall = malloc(totlen + M_LAST, M_SYSCTL,
			    M_WAITOK|M_ZERO);
			for (siz = 0, i = 0; i < M_LAST; i++) {
				snprintf(memall + siz, 
				    totlen + M_LAST - siz,
				    "%s,", memname[i] ? memname[i] : "");
				siz += strlen(memall + siz);
			}
			/* Remove trailing comma */
			if (siz)
				memall[siz - 1] = '\0';

			/* Now, convert all spaces to underscores */
			for (i = 0; i < totlen; i++)
				if (memall[i] == ' ')
					memall[i] = '_';
		}
		rw_exit_write(&sysctl_kmemlock);
		return (sysctl_rdstring(oldp, oldlenp, newp, memall));
#else
		return (EOPNOTSUPP);
#endif
	default:
		return (EOPNOTSUPP);
	}
	/* NOTREACHED */
}

/*
 * Round up a size to how much malloc would actually allocate.
 */
size_t
malloc_roundup(size_t sz)
{
	if (sz > MAXALLOCSAVE)
		return round_page(sz);

	return (1 << BUCKETINDX(sz));
}

#if defined(DDB)
#include <machine/db_machdep.h>
#include <ddb/db_output.h>

void
malloc_printit(
    int (*pr)(const char *, ...) __attribute__((__format__(__kprintf__,1,2))))
{
#ifdef KMEMSTATS
	struct kmemstats *km;
	int i;

	(*pr)("%15s %5s  %6s  %7s  %6s %9s %8s %8s\n",
	    "Type", "InUse", "MemUse", "HighUse", "Limit", "Requests",
	    "Type Lim", "Kern Lim");
	for (i = 0, km = kmemstats; i < M_LAST; i++, km++) {
		if (!km->ks_calls || !memname[i])
			continue;

		(*pr)("%15s %5ld %6ldK %7ldK %6ldK %9ld %8d %8d\n",
		    memname[i], km->ks_inuse, km->ks_memuse / 1024,
		    km->ks_maxused / 1024, km->ks_limit / 1024, 
		    km->ks_calls, km->ks_limblocks, km->ks_mapblocks);
	}
#else
	(*pr)("No KMEMSTATS compiled in\n");
#endif
}
#endif /* DDB */

/*
 * Copyright (c) 2008 Otto Moerbeek <otto@@drijf.net>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

/*
 * This is sqrt(SIZE_MAX+1), as s1*s2 <= SIZE_MAX
 * if both s1 < MUL_NO_OVERFLOW and s2 < MUL_NO_OVERFLOW
 */
#define MUL_NO_OVERFLOW	(1UL << (sizeof(size_t) * 4))

void *
mallocarray(size_t nmemb, size_t size, int type, int flags)
{
	if ((nmemb >= MUL_NO_OVERFLOW || size >= MUL_NO_OVERFLOW) &&
	    nmemb > 0 && SIZE_MAX / nmemb < size) {
		if (flags & M_CANFAIL)
			return (NULL);
		panic("mallocarray: overflow %zu * %zu", nmemb, size);
	}
	return (malloc(size * nmemb, type, flags));
}
@


1.127
log
@Include sys/stdint.h for SIZE_MAX instead of relying on the misplaced
define in sys/limits.h.  OK guenther@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.126 2014/12/10 02:44:47 tedu Exp $	*/
a670 1
#include <ddb/db_interface.h>
@


1.126
log
@convert bcopy to memcpy. ok millert
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.125 2014/11/18 02:37:31 tedu Exp $	*/
d38 1
@


1.125
log
@move arc4random prototype to systm.h. more appropriate for most code
to include that than rdnvar.h. ok deraadt dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.124 2014/11/16 12:31:00 deraadt Exp $	*/
d602 1
a602 1
		bcopy(&bucket[BUCKETINDX(name[1])], &kb, sizeof(kb));
@


1.124
log
@Replace a plethora of historical protection options with just
PROT_NONE, PROT_READ, PROT_WRITE, and PROT_EXEC from mman.h.
PROT_MASK is introduced as the one true way of extracting those bits.
Remove UVM_ADV_* wrapper, using the standard names.
ok doug guenther kettenis
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.123 2014/11/06 17:29:23 tedu Exp $	*/
a41 2

#include <dev/rndvar.h>
@


1.123
log
@need to calculate correct size before doing the free checks. the biggest
malloc bucket isn't precise, it can have anything in it.
should fix recent panics. sorry for inconvenience.
ok deraadt millert
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.122 2014/11/06 03:20:36 deraadt Exp $	*/
d297 1
a297 1
		    addr + sizeof(struct kmem_freelist), VM_PROT_WRITE);
@


1.122
log
@let ramdisks compile
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.121 2014/11/05 22:27:40 tedu Exp $	*/
d387 2
a411 1
		size = kup->ku_pagecnt << PAGE_SHIFT;
@


1.121
log
@need to move lock up to prevent more than one malloc. ok guenther
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.120 2014/11/05 18:08:21 tedu Exp $	*/
d575 4
a578 1
	int error, i, siz;
@


1.120
log
@don't use loop variable (i) for not loop things. use a new var.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.119 2014/11/05 17:44:54 tedu Exp $	*/
d575 1
a575 1
	int i, siz;
d614 3
a618 5
			int error;

			error = rw_enter(&sysctl_kmemlock, RW_WRITE|RW_INTR);
			if (error)
				return (error);
a641 1
			rw_exit_write(&sysctl_kmemlock);
d643 1
@


1.119
log
@use memname to print string of type. stolen from deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.118 2014/11/05 17:43:04 tedu Exp $	*/
d616 1
d618 3
a620 3
			i = rw_enter(&sysctl_kmemlock, RW_WRITE|RW_INTR);
			if (i)
				return (i);
@


1.118
log
@also print type when free size is wrong
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.117 2014/11/02 05:15:34 tedu Exp $	*/
d390 2
a391 2
		panic("free: size too large %zu > %ld (%p) type %d",
		    freedsize, size, addr, type);
d393 2
a394 2
		panic("free: size too small %zu < %ld / 2 (%p) type %d",
		    freedsize, size, addr, type);
@


1.117
log
@tweak free panic messages too
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.116 2014/11/02 05:12:14 tedu Exp $	*/
d390 2
a391 1
		panic("free: size too large %zu > %ld (%p)", freedsize, size, addr);
d393 2
a394 2
		panic("free: size too small %zu < %ld / 2 (%p)",
		    freedsize, size, addr);
@


1.116
log
@tweak panic messages for consistency
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.115 2014/09/14 14:17:25 jsg Exp $	*/
d390 1
a390 1
		panic("freed too much: %zu > %ld (%p)", freedsize, size, addr);
d392 1
a392 1
		panic("freed too little: %zu < %ld / 2 (%p)",
@


1.115
log
@remove uneeded proc.h includes
ok mpi@@ kspillner@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.114 2014/07/13 14:59:28 tedu Exp $	*/
d165 1
a165 1
		panic("malloc - bogus type");
d726 1
a726 1
		panic("mallocarray overflow: %zu * %zu", nmemb, size);
@


1.114
log
@if the freedsize isn't zero, check that's reasonable. ok beck
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.113 2014/07/12 18:43:32 tedu Exp $	*/
a35 1
#include <sys/proc.h>
@


1.113
log
@add a size argument to free. will be used soon, but for now default to 0.
after discussions with beck deraadt kettenis.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.112 2014/07/10 22:16:48 tedu Exp $	*/
d357 1
a357 1
free(void *addr, int type, size_t fauxsize)
d390 5
@


1.112
log
@instead of defining two versions of bucketidx, just don't inline for small.
ok deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.111 2014/07/10 19:33:16 matthew Exp $	*/
d357 1
a357 1
free(void *addr, int type)
@


1.111
log
@Add mallocarray(9)

While here, change malloc(9)'s size argument from "unsigned long" to
"size_t".

ok tedu
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.110 2014/07/10 10:53:45 deraadt Exp $	*/
d48 5
a52 1
static __inline__ long BUCKETINDX(size_t sz)
a53 10
#ifdef SMALL_KERNEL
	long b;

	if (sz-- == 0)
		return MINBUCKET;

	for (b = MINBUCKET; b < MINBUCKET + 15; b++)
		if ((sz >> b) == 0)
			break;
#else
a68 2
#endif

@


1.110
log
@pool_debug still needed for non-DIAGNOSTIC kernels
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.109 2014/07/10 07:50:27 tedu Exp $	*/
d158 1
a158 1
malloc(unsigned long size, int type, int flags)
d700 34
@


1.109
log
@hide the biglock thrashing under pool_debug so it can be turned off
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.108 2014/06/21 19:24:57 daniel Exp $	*/
d180 1
a181 1
		extern int pool_debug;
@


1.108
log
@you've had 12+ years to update your kernel config.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.107 2014/05/19 14:30:03 tedu Exp $	*/
d186 1
a186 1
		if (!cold) {
@


1.107
log
@consistent use of uint32_t for poison values
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.106 2014/04/03 21:36:59 tedu Exp $	*/
a81 4

#ifdef NKMEMCLUSTERS
#error NKMEMCLUSTERS is obsolete; remove it from your kernel config file and use NKMEMPAGES instead or let the kernel auto-size
#endif
@


1.106
log
@if it's ok to wait, it must also be ok to give the kernel lock. do so.
(then immediately reacquire it). this has the effect of giving interrupts
on other CPUs to a chance to run and reduces latency in many cases.
ok deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.105 2014/03/28 17:57:11 mpi Exp $	*/
d328 1
a328 1
		int pval;
@


1.105
log
@Reduce uvm include madness.  Use <uvm/uvm_extern.h> instead of
<uvm/uvm.h> if possible and remove double inclusions.

ok beck@@, mlarkin@@, deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.104 2014/01/21 01:48:44 tedu Exp $	*/
d183 1
a184 1
	if ((flags & M_NOWAIT) == 0) {
d189 5
a194 1
#endif
@


1.104
log
@bzero -> memset
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.103 2013/08/08 23:25:06 syl Exp $	*/
d46 1
a46 1
#include <uvm/uvm.h>
@


1.103
log
@Uncomment kprintf format attributes for sys/kern

tested on vax (gcc3) ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.102 2013/07/04 17:35:52 tedu Exp $	*/
d589 1
a589 1
			bzero(buckstring, sizeof(buckstring));
d604 1
a604 1
		bzero(&kb.kb_freelist, sizeof(kb.kb_freelist));
@


1.102
log
@permit free(NULL) to work. ok deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.101 2013/05/31 20:44:10 tedu Exp $	*/
d677 1
a677 1
    int (*pr)(const char *, ...) /* __attribute__((__format__(__kprintf__,1,2))) */)
@


1.101
log
@open up some races. if pool_debug == 2, force a yield() whenever waitok.
ok miod
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.100 2013/05/03 18:26:07 tedu Exp $	*/
d378 3
@


1.100
log
@switch the malloc and pool freelists to using xor simpleq.
this adds a tiny bit more protection from list manipulation.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.99 2013/04/06 03:53:25 tedu Exp $	*/
d183 3
a185 1
	if ((flags & M_NOWAIT) == 0)
d187 4
@


1.99
log
@shuffle around some poison code, prototypes, values...
allow some more pool debug code to be enabled if not compiled in
bump poison size back up to 64
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.98 2013/03/28 16:41:39 tedu Exp $	*/
d44 2
d137 1
a137 1
	SIMPLEQ_ENTRY(kmem_freelist) kf_flist;
d226 1
a226 1
	if (SIMPLEQ_FIRST(&kbp->kb_freelist) == NULL) {
d278 1
a278 1
			SIMPLEQ_INSERT_HEAD(&kbp->kb_freelist, freep, kf_flist);
d288 2
a289 2
	freep = SIMPLEQ_FIRST(&kbp->kb_freelist);
	SIMPLEQ_REMOVE_HEAD(&kbp->kb_freelist, kf_flist);
d294 1
a294 1
	if (freshalloc == 0 && SIMPLEQ_FIRST(&kbp->kb_freelist)) {
d296 1
a296 1
		vaddr_t addr = (vaddr_t)SIMPLEQ_FIRST(&kbp->kb_freelist);
d425 1
a425 1
		SIMPLEQ_FOREACH(fp, &kbp->kb_freelist, kf_flist) {
d458 1
a458 1
	SIMPLEQ_INSERT_TAIL(&kbp->kb_freelist, freep, kf_flist);
d543 1
a543 1
		SIMPLEQ_INIT(&bucket[indx].kb_freelist);
@


1.98
log
@separate memory poisoning code to a new file and make it usable kernel wide
ok deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.97 2013/03/26 16:36:01 tedu Exp $	*/
d123 15
a148 10
/*
 * The FREELIST_MARKER is used as known text to copy into free objects so
 * that modifications after frees can be detected.
 */
#ifdef DEADBEEF0
#define FREELIST_MARKER	((unsigned) DEADBEEF0)
#else
#define FREELIST_MARKER	((unsigned) 0xdeadbeef)
#endif

d421 1
a421 1
	if (freep->kf_spare0 == FREELIST_MARKER) {
d437 1
a437 1
	freep->kf_spare0 = FREELIST_MARKER;
@


1.97
log
@replace kern malloc's hand rolled freelist with simpleq macros.
ok deraadt mpi
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.96 2013/03/21 01:29:41 deraadt Exp $	*/
d135 1
a135 1
 * The WEIRD_ADDR is used as known text to copy into free objects so
d139 1
a139 1
#define WEIRD_ADDR	((unsigned) DEADBEEF0)
d141 1
a141 1
#define WEIRD_ADDR	((unsigned) 0xdeadbeef)
a142 34
#define POISON_SIZE	32

static void
poison(void *v, size_t len)
{
	uint32_t *ip = v;
	size_t i;

	if (len > POISON_SIZE)
		len = POISON_SIZE;
	len = len / sizeof(*ip);
	for (i = 0; i < len; i++) {
		ip[i] = WEIRD_ADDR;
	}
}

static size_t
poison_check(void *v, size_t len)
{

	uint32_t *ip = v;
	size_t i;

	if (len > POISON_SIZE)
		len = POISON_SIZE;
	len = len / sizeof(*ip);
	for (i = 0; i < len; i++) {
		if (ip[i] != WEIRD_ADDR) {
			return i;
		}
	}
	return -1;
}

a163 1
	size_t pidx;
d268 1
a268 1
			poison(cp, allocsize);
d305 2
a306 2
	/* Fill the fields that we've used with WEIRD_ADDR */
	poison(freep, sizeof(*freep));
d310 4
a313 2
		if ((pidx = poison_check(va, allocsize)) != -1) {
			printf("%s %zd of object %p size 0x%lx %s %s"
d317 1
a317 2
			    savedtype, ((int32_t*)va)[pidx], WEIRD_ADDR);
			panic("boom");
d416 1
a416 1
	if (freep->kf_spare0 == WEIRD_ADDR) {
d431 2
a432 1
	poison(addr, size);
@


1.96
log
@use PAGE_SHIFT instead of PGSHIFT
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.95 2013/03/15 19:10:43 tedu Exp $	*/
a177 19

/*
 * Normally the freelist structure is used only to hold the list pointer
 * for free objects.  However, when running with diagnostics, the first
 * 8 bytes of the structure is unused except for diagnostic information,
 * and the free list pointer is at offset 8 in the structure.  Since the
 * first 8 bytes is the portion of the structure most often modified, this
 * helps to detect memory reuse problems and avoid free list corruption.
 */
struct freelist {
	int32_t	spare0;
	int16_t	type;
	int16_t	spare1;
	caddr_t	next;
};
#else /* !DIAGNOSTIC */
struct freelist {
	caddr_t	next;
};
d193 1
a193 1
	struct freelist *freep;
d196 1
a196 1
	caddr_t va, cp, savedlist;
d254 1
a254 1
	if (kbp->kb_next == NULL) {
d295 1
a295 7
		/*
		 * Just in case we blocked while allocating memory,
		 * and someone else also allocated memory for this
		 * bucket, don't assume the list is still empty.
		 */
		savedlist = kbp->kb_next;
		kbp->kb_next = cp = va + (npg * PAGE_SIZE) - allocsize;
d297 1
a297 1
			freep = (struct freelist *)cp;
d304 1
a304 1
			freep->type = M_FREE;
d306 1
a309 1
			freep->next = cp;
a310 3
		freep->next = savedlist;
		if (savedlist == NULL)
			kbp->kb_last = (caddr_t)freep;
d316 7
a322 7
	va = kbp->kb_next;
	kbp->kb_next = ((struct freelist *)va)->next;
#ifdef DIAGNOSTIC
	freep = (struct freelist *)va;
	savedtype = (unsigned)freep->type < M_LAST ?
		memname[freep->type] : "???";
	if (freshalloc == 0 && kbp->kb_next) {
d324 1
a324 1
		vaddr_t addr = (vaddr_t)kbp->kb_next;
d328 1
a328 1
		    addr + sizeof(struct freelist), VM_PROT_WRITE);
d335 1
a335 1
			    (int32_t *)&kbp->kb_next - (int32_t *)kbp, va, size,
a336 1
			kbp->kb_next = NULL;
d355 1
a355 1
	freep->spare0 = 0;
d390 1
a390 1
	struct freelist *freep;
a393 1
	caddr_t cp;
d444 1
a444 1
	freep = (struct freelist *)addr;
d450 4
a453 4
	if (freep->spare0 == WEIRD_ADDR) {
		for (cp = kbp->kb_next; cp;
		    cp = ((struct freelist *)cp)->next) {
			if (addr != cp)
d467 1
a467 1
	freep->type = type;
d484 1
a484 6
	if (kbp->kb_next == NULL)
		kbp->kb_next = addr;
	else
		((struct freelist *)kbp->kb_last)->next = addr;
	freep->next = NULL;
	kbp->kb_last = addr;
a542 1
#ifdef KMEMSTATS
a543 1
#endif
d546 1
a546 1
	if (sizeof(struct freelist) > (1 << MINBUCKET))
d568 3
d621 1
a621 1
		kb.kb_next = kb.kb_last = 0;
@


1.95
log
@factor out the deadbeef code for legibility.
ok deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.94 2013/02/17 17:39:29 miod Exp $	*/
d461 1
a461 1
		size = kup->ku_pagecnt << PGSHIFT;
@


1.94
log
@Comment out recently added __attribute__((__format__(__kprintf__))) annotations
in MI code; gcc 2.95 does not accept such annotation for function pointer
declarations, only function prototypes.
To be uncommented once gcc 2.95 bites the dust.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.93 2013/02/09 20:56:35 miod Exp $	*/
d143 35
a177 1
#define MAX_COPY	32
d217 2
a218 2
	int32_t *end, *lp;
	int copysize, freshalloc;
d269 4
a272 3
#ifdef DIAGNOSTIC
	copysize = 1 << indx < MAX_COPY ? 1 << indx : MAX_COPY;
#endif
a273 4
		if (size > MAXALLOCSAVE)
			allocsize = round_page(size);
		else
			allocsize = 1 << indx;
d328 1
a328 3
			end = (int32_t *)&cp[copysize];
			for (lp = (int32_t *)cp; lp < end; lp++)
				*lp = WEIRD_ADDR;
d370 1
a370 10
#if BYTE_ORDER == BIG_ENDIAN
	freep->type = WEIRD_ADDR >> 16;
#endif
#if BYTE_ORDER == LITTLE_ENDIAN
	freep->type = (short)WEIRD_ADDR;
#endif
	end = (int32_t *)&freep->next +
	    (sizeof(freep->next) / sizeof(int32_t));
	for (lp = (int32_t *)&freep->next; lp < end; lp++)
		*lp = WEIRD_ADDR;
d374 1
a374 4
		end = (int32_t *)&va[copysize];
		for (lp = (int32_t *)va; lp < end; lp++) {
			if (*lp == WEIRD_ADDR)
				continue;
d378 3
a380 3
			    lp - (int32_t *)va, va, size,
			    "previous type", savedtype, *lp, WEIRD_ADDR);
			break;
d424 1
a424 2
	int32_t *end, *lp;
	long alloc, copysize;
d495 2
a496 4
	copysize = size < MAX_COPY ? size : MAX_COPY;
	end = (int32_t *)&((caddr_t)addr)[copysize];
	for (lp = (int32_t *)addr; lp < end; lp++)
		*lp = WEIRD_ADDR;
@


1.93
log
@Add explicit __attribute__ ((__format__(__kprintf__)))) to the functions and
function pointer arguments which are {used as,} wrappers around the kernel
printf function.
No functional change.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.92 2012/03/30 23:03:42 pirofti Exp $	*/
d714 1
a714 1
    int (*pr)(const char *, ...) __attribute__((__format__(__kprintf__,1,2))))
@


1.92
log
@Expand the panic to show the malloc type and size. Okay deraadt@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.91 2012/03/09 13:01:28 ariane Exp $	*/
d331 1
a331 1
			printf("%s %d of object %p size 0x%lx %s %s"
d335 1
a335 1
			    "previous type", savedtype, addr);
d358 1
a358 1
			printf("%s %d of object %p size 0x%lx %s %s"
d713 2
a714 1
malloc_printit(int (*pr)(const char *, ...))
@


1.91
log
@New vmmap implementation.

no oks (it is really a pain to review properly)
extensively tested, I'm confident it'll be stable
'now is the time' from several icb inhabitants

Diff provides:
- ability to specify different allocators for different regions/maps
- a simpler implementation of the current allocator
- currently in compatibility mode: it will generate similar addresses
  as the old allocator
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.90 2011/09/22 21:52:36 jsing Exp $	*/
d216 2
a217 1
			panic("malloc: allocation too large");
@


1.90
log
@Improve kernel malloc type checking.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.88 2011/06/06 17:05:46 deraadt Exp $	*/
d579 7
a585 2
	    (vsize_t)(nkmempages * PAGE_SIZE), VM_MAP_INTRSAFE, FALSE,
	    &kmem_map_store);
@


1.89
log
@Backout vmmap in order to repair virtual address selection algorithms
outside the tree.
@
text
@d190 1
a190 1
	if (((unsigned long)type) >= M_LAST)
@


1.88
log
@push kernel malloc(9) and kernel stacks into non-dma memory, since that
appears to be safe now.  If not, we'll know soon where the bugs lie, so
that we can fix them.  This diff has been in snapshots for many months.
ok oga miod
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.87 2011/05/24 15:27:36 ariane Exp $	*/
d579 2
a580 7
	    (vsize_t)(nkmempages * PAGE_SIZE),
#ifdef KVA_GUARDPAGES
	    VM_MAP_INTRSAFE | VM_MAP_GUARDPAGES,
#else
	    VM_MAP_INTRSAFE,
#endif
	    FALSE, &kmem_map_store);
@


1.87
log
@Reimplement uvm/uvm_map.

vmmap is designed to perform address space randomized allocations,
without letting fragmentation of the address space go through the roof.

Some highlights:
- kernel address space randomization
- proper implementation of guardpages
- roughly 10% system time reduction during kernel build

Tested by alot of people on tech@@ and developers.
Theo's machines are still happy.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.86 2010/09/26 21:03:56 tedu Exp $	*/
d247 1
a247 1
		    dma_constraint.ucr_low, dma_constraint.ucr_high,
@


1.86
log
@unify some pool and malloc flag values.  the important bit is that all flags
have real values, no 0 values anymore.
ok deraadt kettenis krw matthew oga thib
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.85 2010/09/21 01:09:10 matthew Exp $	*/
d579 7
a585 2
	    (vsize_t)(nkmempages * PAGE_SIZE), VM_MAP_INTRSAFE, FALSE,
	    &kmem_map_store);
@


1.85
log
@Add assertwaitok(9) to declare code paths that assume they can sleep.
Currently only checks that we're not in an interrupt context, but will
soon check that we're not holding any mutexes either.

Update malloc(9) and pool(9) to use assertwaitok(9) as appropriate.

"i like it" art@@, oga@@, marco@@; "i see no harm" deraadt@@; too trivial
for me to bother prying actual oks from people.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.84 2010/07/22 06:30:13 matthew Exp $	*/
d193 2
@


1.84
log
@We have this nice KMEMSTATS option to control when we use kmemstats,
so no point in reserving space for kmemstats unless it's enabled.

ok thib@@, deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.83 2010/07/02 01:25:05 art Exp $	*/
d193 3
@


1.83
log
@add an align argument to uvm_km_kmemalloc_pla.

Use uvm_km_kmemalloc_pla with the dma constraint to allocate kernel stacks.

Yes, that means DMA is possible to kernel stacks, but only until we've fixed
all the scary drivers.

deraadt@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.82 2010/07/01 19:51:13 thib Exp $	*/
d110 1
d112 1
@


1.82
log
@constrain malloc to only grab pages from dma reachable memory.
Do this by calling uvm_km_kmemalloc_pla with the dma_constraint.

ok art@@ (ofcourse, he eats his cereal and okeys everything).
OK beck@@, deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.80 2009/08/25 17:59:43 miod Exp $	*/
d237 1
a237 1
		    (vsize_t)ptoa(npg), 
@


1.81
log
@If option DIAGNOSTIC, do not bother doing sanity checks, including an
uvm_map_checkprot() call, if the memory we're about to return has just been
allocated with uvm_km_kmemalloc() instead of coming from the freelist.

No functional change but a very small speedup when the freelist for the given
bucket is empty.
@
text
@d44 1
a44 1
#include <uvm/uvm_extern.h>
d236 1
a236 1
		va = (caddr_t) uvm_km_kmemalloc(kmem_map, NULL,
d239 3
a241 1
		    ((flags & M_CANFAIL) ? UVM_KMF_CANFAIL : 0));
@


1.80
log
@The BUCKETINDX() giant macro is used to compute the base 2 logarithm of its
input, in order to pick the appropriate malloc() bucket.

Replace it with an inline function in kern_malloc.c, which will either
do a tightest-but-slower loop (if option SMALL_KERNEL), or a geometric search
equivalent to what the macro does, but producing smaller code (especially on
platforms which can not load large constants in one instruction).
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.79 2009/02/22 19:57:59 miod Exp $	*/
d182 1
a182 1
	int copysize;
d259 3
d300 4
d311 1
a311 1
	if (kbp->kb_next) {
d321 6
a326 5
		printf("%s %d of object %p size 0x%lx %s %s (invalid addr %p)\n",
			"Data modified on freelist: word", 
			(int32_t *)&kbp->kb_next - (int32_t *)kbp, va, size,
			"previous type", savedtype, kbp->kb_next);
		kbp->kb_next = NULL;
d343 12
a354 8
	end = (int32_t *)&va[copysize];
	for (lp = (int32_t *)va; lp < end; lp++) {
		if (*lp == WEIRD_ADDR)
			continue;
		printf("%s %d of object %p size 0x%lx %s %s (0x%x != 0x%x)\n",
			"Data modified on freelist: word", lp - (int32_t *)va,
			va, size, "previous type", savedtype, *lp, WEIRD_ADDR);
		break;
@


1.79
log
@Don't enforce a minimum size for nkmempages by default; if the computed
value (based on physmem) is below NKMEMPAGES_MIN, we are on a low memory
machine and can not afford more anyway.

ok deraadt@@ tedu@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.78 2008/10/18 12:11:30 kettenis Exp $	*/
d45 32
@


1.78
log
@Revert the change to use pools for <= PAGE_SIZE allocations.  It
changes the pressure on the uvm system, uncovering several bugs.  Some
of those bugs result in provable deadlocks.  We'll have to reconsider
integrating this diff again after fixing those bugs.

ok art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.74 2008/02/21 10:40:48 kettenis Exp $	*/
d68 1
a68 1
#define	NKMEMPAGES_MIN	NKMEMPAGES_MIN_DEFAULT
@


1.77
log
@Since malloc_page_alloc() is a pool allocator it should check for PR_WAITOK
instead of M_NOWAIT.  Checking for M_NOWAIT made many malloc calls that used
that flag actually wait.  This probably explains many if the strange hangs
people have seen recently.

ok miod@@
@
text
@d1 2
a2 1
/*	$OpenBSD: kern_malloc.c,v 1.76 2008/10/05 11:12:19 miod Exp $	*/
a4 1
 * Copyright (c) 2008 Michael Shalayeff
a41 1
#include <sys/pool.h>
a76 4
struct pool mallocpl[MINBUCKET + 16];
char mallocplnames[MINBUCKET + 16][8];	/* wchan for pool */
char mallocplwarn[MINBUCKET + 16][32];  /* warning message for hard limit */

d91 10
a135 41
void	*malloc_page_alloc(struct pool *, int);
void	malloc_page_free(struct pool *, void *);
struct pool_allocator pool_allocator_malloc = {
	malloc_page_alloc, malloc_page_free, 0,
};

void *
malloc_page_alloc(struct pool *pp, int flags)
{
	void *v;
	struct vm_page *pg;
	paddr_t pa;

	v = uvm_km_getpage((flags & PR_WAITOK) ? TRUE : FALSE);
	if (!pmap_extract(pmap_kernel(), (vaddr_t)v, &pa))
		panic("malloc_page_alloc: pmap_extract failed");

	pg = PHYS_TO_VM_PAGE(pa);
	if (pg == NULL)
		panic("malloc_page_alloc: no page");
	pg->wire_count = BUCKETINDX(pp->pr_size);

	return v;
}

void
malloc_page_free(struct pool *pp, void *v)
{
	struct vm_page *pg;
	paddr_t pa;

	if (!pmap_extract(pmap_kernel(), (vaddr_t)v, &pa))
		panic("malloc_page_free: pmap_extract failed");

	pg = PHYS_TO_VM_PAGE(pa);
	if (pg == NULL)
		panic("malloc_page_free: no page");
	pg->wire_count = 0;
	uvm_km_putpage(v);
}

d144 2
a145 1
	vsize_t indx, allocsize;
d147 6
a152 1
	void *va;
d161 1
a161 1
	if (debug_malloc(size, type, flags, &va)) {
d193 4
d198 8
a205 3
	if (size > MAXALLOCSAVE) {
		allocsize = round_page(size);
		va = (void *) uvm_km_kmemalloc(kmem_map, NULL, allocsize,
d223 1
a223 2
		kbp->kb_total++;
		kbp->kb_calls++;
d227 61
a287 7
		kup->ku_pagecnt = atop(allocsize);
	} else {
		allocsize = mallocpl[indx].pr_size;
		va = pool_get(&mallocpl[indx], PR_LIMITFAIL |
		    (flags & M_NOWAIT ? 0 : PR_WAITOK));
		if (!va && (flags & (M_NOWAIT|M_CANFAIL)) == 0)
			panic("malloc: out of space in kmem pool");
d290 25
d316 16
a331 8
	if (va) {
		ksp->ks_memuse += allocsize;
		if (ksp->ks_memuse > ksp->ks_maxused)
			ksp->ks_maxused = ksp->ks_memuse;
		ksp->ks_size |= 1 << indx;
		ksp->ks_inuse++;
		ksp->ks_calls++;
	}
a336 1

d348 1
a348 2
	struct vm_page *pg;
	paddr_t pa;
d351 5
d365 9
a374 4
	if (addr >= (void *)kmembase && addr < (void *)kmemlimit) {
		kup = btokup(addr);
		kbp = &bucket[kup->ku_indx];
		size = ptoa(kup->ku_pagecnt);
d376 11
a386 3
		if ((vaddr_t)addr != round_page((vaddr_t)addr))
			panic("free: unaligned addr %p, size %ld, type %s",
			    addr, size, memname[type]);
d388 2
a389 1
		uvm_km_free(kmem_map, (vaddr_t)addr, size);
d391 2
d395 5
a399 1
		kbp->kb_total--;
d401 4
a404 6
	} else {
		if (!pmap_extract(pmap_kernel(), (vaddr_t)addr, &pa))
			panic("free: pmap_extract failed");
		pg = PHYS_TO_VM_PAGE(pa);
		if (pg == NULL)
			panic("free: no page");
d406 12
a417 8
		if (pg->pg_flags & PQ_FREE)
			panic("free: page %p is free", pg);
		if (pg->wire_count < MINBUCKET ||
		    (1 << pg->wire_count) > MAXALLOCSAVE)
			panic("free: invalid page bucket %d", pg->wire_count);
#endif
		size = mallocpl[pg->wire_count].pr_size;
		pool_put(&mallocpl[pg->wire_count], addr);
d419 12
a430 1

d432 8
a439 1
	ksp->ks_inuse--;
d443 2
a444 1
		wakeup(ksp);		/* unnecessary for pool, whatever */
d446 6
a451 1

d510 3
a512 1
	int i;
a531 11

	/*
	 * init all the sub-page pools
	 */
	for (i = MINBUCKET; (1 << i) <= MAXALLOCSAVE; i++) {
		snprintf(mallocplnames[i], sizeof(mallocplnames[i]),
		    "kmem%d", i);
		pool_init(&mallocpl[i], 1 << i, 1 << i, 0, PR_LIMITFAIL,
		    mallocplnames[i], &pool_allocator_malloc);
	}

d533 3
a535 3
	for (i = 0; i < MINBUCKET + 16; i++) {
		if (1 << i >= PAGE_SIZE)
			bucket[i].kb_elmpercl = 1;
d537 2
a538 2
			bucket[i].kb_elmpercl = PAGE_SIZE / (1 << i);
		bucket[i].kb_highwat = 5 * bucket[i].kb_elmpercl;
d540 2
a541 2
	for (i = 0; i < M_LAST; i++)
		kmemstats[i].ks_limit = nkmempages * PAGE_SIZE * 6 / 10;;
d582 1
a609 1
			bzero(memall, totlen + M_LAST);
d611 1
a611 1
				snprintf(memall + siz,
d669 1
a669 1
		    km->ks_maxused / 1024, km->ks_limit / 1024,
@


1.76
log
@In malloc_page_free(), restore the correct wire_count value.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.75 2008/09/29 12:34:18 art Exp $	*/
d140 1
a140 1
	void *v = uvm_km_getpage(flags & M_NOWAIT? 0 : 1);
d144 1
@


1.75
log
@Use pools to do allocations for all sizes <= PAGE_SIZE.
This will allow us to escape the limitations of kmem_map.
At this moment, the per-type limits are still enforced for all sizes,
but we might loosen that limit in the future after some thinking.

Original diff from Mickey in kernel/5761 , I massaged it a little to
obey the per-type limits.

miod@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.74 2008/02/21 10:40:48 kettenis Exp $	*/
d167 1
a167 1
	pg->wire_count = 1;
@


1.74
log
@Prevent possible free list corruption when malloc(9) sleeps.
From NetBSD, kindly pointed out by YAMAMOTO Takashi.

ok miod@@
@
text
@d1 1
a1 2
/*	$OpenBSD: kern_malloc.c,v 1.73 2007/09/15 10:10:37 martin Exp $	*/
/*	$NetBSD: kern_malloc.c,v 1.15.4.2 1996/06/13 17:10:56 cgd Exp $	*/
d4 1
d42 1
d78 4
a95 10
 * This structure provides a set of masks to catch unaligned frees.
 */
const long addrmask[] = { 0,
	0x00000001, 0x00000003, 0x00000007, 0x0000000f,
	0x0000001f, 0x0000003f, 0x0000007f, 0x000000ff,
	0x000001ff, 0x000003ff, 0x000007ff, 0x00000fff,
	0x00001fff, 0x00003fff, 0x00007fff, 0x0000ffff,
};

/*
d131 40
d179 1
a179 2
	struct freelist *freep;
	long indx, npg, allocsize;
d181 1
a181 6
	caddr_t va, cp, savedlist;
#ifdef DIAGNOSTIC
	int32_t *end, *lp;
	int copysize;
	char *savedtype;
#endif
d190 1
a190 1
	if (debug_malloc(size, type, flags, (void **)&va)) {
a221 1
	ksp->ks_size |= 1 << indx;
d223 3
a225 11
#ifdef DIAGNOSTIC
	copysize = 1 << indx < MAX_COPY ? 1 << indx : MAX_COPY;
#endif
	if (kbp->kb_next == NULL) {
		if (size > MAXALLOCSAVE)
			allocsize = round_page(size);
		else
			allocsize = 1 << indx;
		npg = atop(round_page(allocsize));
		va = (caddr_t) uvm_km_kmemalloc(kmem_map, NULL,
		    (vsize_t)ptoa(npg), 
d243 2
a244 1
		kbp->kb_total += kbp->kb_elmpercl;
d248 7
a254 61
		if (allocsize > MAXALLOCSAVE) {
			kup->ku_pagecnt = npg;
#ifdef KMEMSTATS
			ksp->ks_memuse += allocsize;
#endif
			goto out;
		}
#ifdef KMEMSTATS
		kup->ku_freecnt = kbp->kb_elmpercl;
		kbp->kb_totalfree += kbp->kb_elmpercl;
#endif
		/*
		 * Just in case we blocked while allocating memory,
		 * and someone else also allocated memory for this
		 * bucket, don't assume the list is still empty.
		 */
		savedlist = kbp->kb_next;
		kbp->kb_next = cp = va + (npg * PAGE_SIZE) - allocsize;
		for (;;) {
			freep = (struct freelist *)cp;
#ifdef DIAGNOSTIC
			/*
			 * Copy in known text to detect modification
			 * after freeing.
			 */
			end = (int32_t *)&cp[copysize];
			for (lp = (int32_t *)cp; lp < end; lp++)
				*lp = WEIRD_ADDR;
			freep->type = M_FREE;
#endif /* DIAGNOSTIC */
			if (cp <= va)
				break;
			cp -= allocsize;
			freep->next = cp;
		}
		freep->next = savedlist;
		if (savedlist == NULL)
			kbp->kb_last = (caddr_t)freep;
	}
	va = kbp->kb_next;
	kbp->kb_next = ((struct freelist *)va)->next;
#ifdef DIAGNOSTIC
	freep = (struct freelist *)va;
	savedtype = (unsigned)freep->type < M_LAST ?
		memname[freep->type] : "???";
	if (kbp->kb_next) {
		int rv;
		vaddr_t addr = (vaddr_t)kbp->kb_next;

		vm_map_lock(kmem_map);
		rv = uvm_map_checkprot(kmem_map, addr,
		    addr + sizeof(struct freelist), VM_PROT_WRITE);
		vm_map_unlock(kmem_map);

		if (!rv)  {
		printf("%s %d of object %p size 0x%lx %s %s (invalid addr %p)\n",
			"Data modified on freelist: word", 
			(int32_t *)&kbp->kb_next - (int32_t *)kbp, va, size,
			"previous type", savedtype, kbp->kb_next);
		kbp->kb_next = NULL;
		}
d257 8
a264 21
	/* Fill the fields that we've used with WEIRD_ADDR */
#if BYTE_ORDER == BIG_ENDIAN
	freep->type = WEIRD_ADDR >> 16;
#endif
#if BYTE_ORDER == LITTLE_ENDIAN
	freep->type = (short)WEIRD_ADDR;
#endif
	end = (int32_t *)&freep->next +
	    (sizeof(freep->next) / sizeof(int32_t));
	for (lp = (int32_t *)&freep->next; lp < end; lp++)
		*lp = WEIRD_ADDR;

	/* and check that the data hasn't been modified. */
	end = (int32_t *)&va[copysize];
	for (lp = (int32_t *)va; lp < end; lp++) {
		if (*lp == WEIRD_ADDR)
			continue;
		printf("%s %d of object %p size 0x%lx %s %s (0x%x != 0x%x)\n",
			"Data modified on freelist: word", lp - (int32_t *)va,
			va, size, "previous type", savedtype, *lp, WEIRD_ADDR);
		break;
a265 20

	freep->spare0 = 0;
#endif /* DIAGNOSTIC */
#ifdef KMEMSTATS
	kup = btokup(va);
	if (kup->ku_indx != indx)
		panic("malloc: wrong bucket");
	if (kup->ku_freecnt == 0)
		panic("malloc: lost data");
	kup->ku_freecnt--;
	kbp->kb_totalfree--;
	ksp->ks_memuse += 1 << indx;
out:
	kbp->kb_calls++;
	ksp->ks_inuse++;
	ksp->ks_calls++;
	if (ksp->ks_memuse > ksp->ks_maxused)
		ksp->ks_maxused = ksp->ks_memuse;
#else
out:
d271 1
d283 2
a284 1
	struct freelist *freep;
a286 5
#ifdef DIAGNOSTIC
	caddr_t cp;
	int32_t *end, *lp;
	long alloc, copysize;
#endif
a295 9
#ifdef DIAGNOSTIC
	if (addr < (void *)kmembase || addr >= (void *)kmemlimit)
		panic("free: non-malloced addr %p type %s", addr,
		    memname[type]);
#endif

	kup = btokup(addr);
	size = 1 << kup->ku_indx;
	kbp = &bucket[kup->ku_indx];
d297 4
d302 3
a304 11
	/*
	 * Check for returns of data that do not point to the
	 * beginning of the allocation.
	 */
	if (size > PAGE_SIZE)
		alloc = addrmask[BUCKETINDX(PAGE_SIZE)];
	else
		alloc = addrmask[kup->ku_indx];
	if (((u_long)addr & alloc) != 0)
		panic("free: unaligned addr %p, size %ld, type %s, mask %ld",
			addr, size, memname[type], alloc);
d306 1
a306 2
	if (size > MAXALLOCSAVE) {
		uvm_km_free(kmem_map, (vaddr_t)addr, ptoa(kup->ku_pagecnt));
a307 2
		size = kup->ku_pagecnt << PGSHIFT;
		ksp->ks_memuse -= size;
d310 1
a310 5
		if (ksp->ks_memuse + size >= ksp->ks_limit &&
		    ksp->ks_memuse < ksp->ks_limit)
			wakeup(ksp);
		ksp->ks_inuse--;
		kbp->kb_total -= 1;
d312 6
a317 4
		splx(s);
		return;
	}
	freep = (struct freelist *)addr;
d319 8
a326 12
	/*
	 * Check for multiple frees. Use a quick check to see if
	 * it looks free before laboriously searching the freelist.
	 */
	if (freep->spare0 == WEIRD_ADDR) {
		for (cp = kbp->kb_next; cp;
		    cp = ((struct freelist *)cp)->next) {
			if (addr != cp)
				continue;
			printf("multiply freed item %p\n", addr);
			panic("free: duplicated free");
		}
d328 1
a328 12
	/*
	 * Copy in known text to detect modification after freeing
	 * and to make it look free. Also, save the type being freed
	 * so we can list likely culprit if modification is detected
	 * when the object is reallocated.
	 */
	copysize = size < MAX_COPY ? size : MAX_COPY;
	end = (int32_t *)&((caddr_t)addr)[copysize];
	for (lp = (int32_t *)addr; lp < end; lp++)
		*lp = WEIRD_ADDR;
	freep->type = type;
#endif /* DIAGNOSTIC */
d330 1
a330 8
	kup->ku_freecnt++;
	if (kup->ku_freecnt >= kbp->kb_elmpercl) {
		if (kup->ku_freecnt > kbp->kb_elmpercl)
			panic("free: multiple frees");
		else if (kbp->kb_totalfree > kbp->kb_highwat)
			kbp->kb_couldfree++;
	}
	kbp->kb_totalfree++;
d334 1
a334 2
		wakeup(ksp);
	ksp->ks_inuse--;
d336 1
a336 6
	if (kbp->kb_next == NULL)
		kbp->kb_next = addr;
	else
		((struct freelist *)kbp->kb_last)->next = addr;
	freep->next = NULL;
	kbp->kb_last = addr;
d395 1
a395 3
#ifdef KMEMSTATS
	long indx;
#endif
d415 11
d427 3
a429 3
	for (indx = 0; indx < MINBUCKET + 16; indx++) {
		if (1 << indx >= PAGE_SIZE)
			bucket[indx].kb_elmpercl = 1;
d431 2
a432 2
			bucket[indx].kb_elmpercl = PAGE_SIZE / (1 << indx);
		bucket[indx].kb_highwat = 5 * bucket[indx].kb_elmpercl;
d434 2
a435 2
	for (indx = 0; indx < M_LAST; indx++)
		kmemstats[indx].ks_limit = nkmempages * PAGE_SIZE * 6 / 10;
a475 1
		kb.kb_next = kb.kb_last = 0;
d503 1
d505 1
a505 1
				snprintf(memall + siz, 
d563 1
a563 1
		    km->ks_maxused / 1024, km->ks_limit / 1024, 
@


1.73
log
@replace ctob and btoc with ptoa and atop respectively

help and ok miod@@ thib@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.72 2007/09/07 10:22:15 art Exp $	*/
a198 1
		kbp->kb_last = NULL;
d263 1
a263 1
		if (kbp->kb_last == NULL)
@


1.72
log
@Add the long requested M_ZERO flag to malloc(9).

But the reason for this isn't some kind of "we can make it use the
pre-zeroed pages and zero the freelist in the idle loop and OMG I can
has optimisatiuns" which would require tons of infrastructure and make
everything slower.

The reason is that it shrinks other code. And that's good.

dlg@@ ok, henning@@ ok (before he read the diff)
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.71 2007/09/01 15:14:44 martin Exp $	*/
d204 1
a204 1
		npg = btoc(allocsize);
@


1.71
log
@replace the machine dependant bytes-to-clicks macro by the MI ptoa()
version for i386

more architectures and ctob() replacement is being worked on

prodded by and ok miod
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.70 2007/05/29 00:17:32 thib Exp $	*/
d161 3
a163 1
	if (debug_malloc(size, type, flags, (void **)&va))
d165 1
d335 3
d609 2
a610 2
			memall = malloc(totlen + M_LAST, M_SYSCTL, M_WAITOK);
			bzero(memall, totlen + M_LAST);
@


1.70
log
@Add a name argument to the RWLOCK_INITIALIZER macro.
Pick reasonble names for the locks involved..

ok tedu@@, art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.69 2007/04/12 21:47:45 miod Exp $	*/
d203 1
a203 1
		    (vsize_t)ctob(npg), 
d384 1
a384 1
		uvm_km_free(kmem_map, (vaddr_t)addr, ctob(kup->ku_pagecnt));
@


1.69
log
@Allow machine-dependant overrides for the ``deadbeef'' sentinel values,
and make sure that nothing can ever be mapped at theses addresses.

Only i386 overrides the default for now.

From mickey@@, ok art@@ miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.68 2007/04/11 12:10:42 art Exp $	*/
d86 1
a86 1
struct rwlock sysctl_kmemlock = RWLOCK_INITIALIZER;
@


1.68
log
@Instead of managing pages for intrsafe maps in special objects (aka.
kmem_object) just so that we can remove them, just use pmap_extract
to get the pages to free and simplify a lot of code to not deal with
the list of intrsafe maps, intrsafe objects, etc.

miod@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.67 2007/03/25 02:38:11 tedu Exp $	*/
d104 3
d108 1
@


1.67
log
@remove a few void * casts that are useless
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.66 2007/01/12 07:41:31 art Exp $	*/
d46 1
a46 1
static struct vm_map_intrsafe kmem_map_store;
d198 1
a198 1
		va = (caddr_t) uvm_km_kmemalloc(kmem_map, uvmexp.kmem_object,
d518 1
a518 1
	    &kmem_map_store.vmi_map);
@


1.66
log
@Switch some lockmgr locks to rwlocks.
In this commit:
 - gdt lock on amd64
 - sysctl lock
 - malloc sysctl lock
 - disk sysctl lock
 - swap syscall lock

miod@@, pedro@@ ok (and "looks good" others@@)
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.65 2006/11/28 11:14:52 pedro Exp $	*/
d158 1
a158 1
		return ((void *) va);
d180 1
a180 1
			return ((void *) NULL);
d328 1
a328 1
	return ((void *) va);
@


1.65
log
@Make malloc() print out a warning message when returning NULL due to
M_CANFAIL, idea from miod@@, okay deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.64 2006/11/22 18:59:50 thib Exp $	*/
d42 1
d86 1
a86 1
extern struct lock sysctl_kmemlock;
d589 1
a589 1
			i = lockmgr(&sysctl_kmemlock, LK_EXCLUSIVE, NULL);
d615 1
a615 1
			lockmgr(&sysctl_kmemlock, LK_RELEASE, NULL);
@


1.64
log
@If M_CANFAIL is set and the malloc() size is to big
return NULL instead of panic()'ing.

ok pedro@@, deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.63 2006/09/30 14:31:28 mickey Exp $	*/
d41 1
d126 5
d161 6
a166 1
		if (flags & M_CANFAIL)
d168 1
a168 1
		else
@


1.63
log
@no malloc debug but configured kmemstats allow 'sh mal' to print smth useful; miod@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.62 2005/11/28 00:14:28 jsg Exp $	*/
d154 7
a160 2
	if (size > 65535 * PAGE_SIZE)
		panic("malloc: allocation too large");
@


1.62
log
@ansi/deregister.
'go for it' deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.61 2005/11/19 02:18:01 pedro Exp $	*/
d621 30
@


1.61
log
@Remove unnecessary lockmgr() archaism that was costing too much in terms
of panics and bugfixes. Access curproc directly, do not expect a process
pointer as an argument. Should fix many "process context required" bugs.
Incentive and okay millert@@, okay marc@@. Various testing, thanks.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.60 2005/09/12 23:05:06 miod Exp $	*/
d129 1
a129 3
malloc(size, type, flags)
	unsigned long size;
	int type, flags;
d131 3
a133 3
	register struct kmembuckets *kbp;
	register struct kmemusage *kup;
	register struct freelist *freep;
d143 1
a143 1
	register struct kmemstats *ksp = &kmemstats[type];
d318 1
a318 3
free(addr, type)
	void *addr;
	int type;
d320 3
a322 3
	register struct kmembuckets *kbp;
	register struct kmemusage *kup;
	register struct freelist *freep;
d331 1
a331 1
	register struct kmemstats *ksp = &kmemstats[type];
d434 1
a434 1
kmeminit_nkmempages()
d481 1
a481 1
kmeminit()
d526 2
a527 8
sysctl_malloc(name, namelen, oldp, oldlenp, newp, newlen, p)
	int *name;
	u_int namelen;
	void *oldp;
	size_t *oldlenp;
	void *newp;
	size_t newlen;
	struct proc *p;
@


1.60
log
@Change the NKMEMPAGES range to 4-64MB for 32bit arches, and 8-128MB for 64bit
arches; except on sparc where the range is 4-8 for !sun4m and 4-64 for sun4m,
selected at runtime.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.59 2004/12/30 08:28:39 niklas Exp $	*/
d582 1
a582 1
			i = lockmgr(&sysctl_kmemlock, LK_EXCLUSIVE, NULL, p);
d608 1
a608 1
			lockmgr(&sysctl_kmemlock, LK_RELEASE, NULL, p);
@


1.59
log
@Import M_CANFAIL support from NetBSD, removes a nasty panic during low-mem scenarios, instead generating an ENOMEM backfeed, ok tedu@@, prodded by many
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.58 2004/05/23 19:41:23 tedu Exp $	*/
d59 1
a59 1
int	nkmempages = NKMEMPAGES;
d68 1
d73 1
d440 1
a440 1
	int npages;
d451 11
d466 1
a466 1
	 *	- Clamp it down to NKMEMPAGES_MAX.
d468 1
a468 1
	 *	- Round it up to NKMEMPAGES_MIN.
d472 2
a473 2
	if (npages > NKMEMPAGES_MAX)
		npages = NKMEMPAGES_MAX;
d475 2
a476 2
	if (npages < NKMEMPAGES_MIN)
		npages = NKMEMPAGES_MIN;
@


1.58
log
@bad stuff escaped by accident
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.56 2003/12/28 16:35:46 tedu Exp $	*/
d182 3
a184 2
				(vsize_t)ctob(npg), 
				(flags & M_NOWAIT) ? UVM_KMF_NOWAIT : 0);
d194 1
a194 1
			if ((flags & M_NOWAIT) == 0)
d197 1
a197 1
			return ((void *) NULL);
@


1.57
log
@according to fork1(9), retval is optional.  make it so.
from form@@pdp-11.org.ru via mpech.  ok millert
@
text
@a42 1
#include <ddb/db_output.h>
@


1.56
log
@make check for too large allocations earlier, instead of fiddling with it.
less error prone (no wraparound).  no real functional change though.
ok markus tdeval
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.55 2003/07/21 22:44:50 tedu Exp $	*/
d43 1
@


1.55
log
@remove caddr_t casts.  it's just silly to cast something when the function
takes a void *.  convert uiomove to take a void * as well.  ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.54 2003/06/26 01:01:06 mickey Exp $	*/
d154 2
a203 2
			if (npg > 65535)
				panic("malloc: allocation too large");
@


1.54
log
@addrmask canbe const
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.53 2003/06/02 23:28:05 millert Exp $	*/
d165 1
a165 1
		tsleep((caddr_t)ksp, PSWP+2, memname[type], 0);
d372 1
a372 1
			wakeup((caddr_t)ksp);
d418 1
a418 1
		wakeup((caddr_t)ksp);
@


1.53
log
@Remove the advertising clause in the UCB license which Berkeley
rescinded 22 July 1999.  Proofed by myself and Theo.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.52 2003/06/01 16:23:41 art Exp $	*/
d89 1
a89 1
long addrmask[] = { 0,
@


1.52
log
@uvm_km_suballoc passes the 'min' argument untouched to uvm_map. uvm_map
uses it as a hint for where to steal space from the parent map. We've been
passing random stack garbage as that hint for ages. It's a wonder it didn't
break things until we started working on Hammer.

noone objected for at least a week.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.51 2003/05/03 21:14:59 deraadt Exp $	*/
d16 1
a16 5
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by the University of
 *	California, Berkeley and its contributors.
 * 4. Neither the name of the University nor the names of its contributors
@


1.51
log
@string fixes; tedu ok
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.50 2003/04/10 08:48:34 tedu Exp $	*/
d477 1
d492 6
a497 4

	kmem_map = uvm_km_suballoc(kernel_map, (vaddr_t *)&kmembase,
		(vaddr_t *)&kmemlimit, (vsize_t)(nkmempages * PAGE_SIZE), 
			VM_MAP_INTRSAFE, FALSE, &kmem_map_store.vmi_map);
@


1.50
log
@woah.  last commit contained way too much.  revert, and apply only the change intended.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.48 2002/06/11 05:58:17 art Exp $	*/
d539 6
a544 3
			for (siz = 0, i = MINBUCKET; i < MINBUCKET + 16; i++)
			    siz += sprintf(buckstring + siz,
			    "%d,", (u_int)(1<<i));
d581 6
a586 4
			for (siz = 0, i = 0; i < M_LAST; i++)
				siz += sprintf(memall + siz, "%s,",
				    memname[i] ? memname[i] : "");

@


1.49
log
@off by one bounds check in diag code.  ok art.
@
text
@a526 1
	char *strp, *endp;
d539 3
a541 10
			strp = buckstring;
			endp = strp + sizeof(buckstring) - 1;
			siz = 0;
			for (i = MINBUCKET; i < MINBUCKET + 16; i++) {
				siz = snprintf(strp, (endp - strp), "%d,",
				    (u_int)(1<<i));
				if (strp + siz >= endp)
					break;
				strp += siz;
			}
d544 1
a544 1
				*(strp - 1) = '\0';
d578 2
a579 5
			strp = memall;
			endp = memall + totlen + M_LAST;
			siz = 0;
			for (i = 0; i < M_LAST; i++) {
				siz = snprintf(strp, (endp - strp), "%s,",
a580 4
				if (strp + siz >= endp)
					break;
				strp += siz;
			}
d584 1
a584 1
				*(strp - 1) = '\0';
@


1.48
log
@splvm, not splimp
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.47 2002/02/12 17:19:41 provos Exp $	*/
d149 1
a149 1
	if (((unsigned long)type) > M_LAST)
d527 1
d540 10
a549 3
			for (siz = 0, i = MINBUCKET; i < MINBUCKET + 16; i++)
			    siz += sprintf(buckstring + siz,
			    "%d,", (u_int)(1<<i));
d552 1
a552 1
				buckstring[siz - 1] = '\0';
d586 5
a590 2
			for (siz = 0, i = 0; i < M_LAST; i++)
				siz += sprintf(memall + siz, "%s,",
d592 4
d599 1
a599 1
				memall[siz - 1] = '\0';
@


1.47
log
@malloc_roundup to calculate allocation size malloc will use; from netbsd;
okay art@@
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.46 2002/01/16 20:50:17 miod Exp $	*/
d160 1
a160 1
	s = splimp();
d353 1
a353 1
	s = splimp();
@


1.46
log
@Don't include <sys/map.h> when you don't need what's in it.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.45 2001/12/19 08:58:06 art Exp $	*/
d600 12
@


1.45
log
@UBC was a disaster. It worked very good when it worked, but on some
machines or some configurations or in some phase of the moon (we actually
don't know when or why) files disappeared. Since we've not been able to
track down the problem in two weeks intense debugging and we need -current
to be stable, back out everything to a state it had before UBC.

We apologise for the inconvenience.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.44 2001/12/05 17:49:06 art Exp $	*/
a40 1
#include <sys/map.h>
@


1.44
log
@If we assume (just pure speculation) that there will be a pmap sometime in
the future that wants to allocate pv entries for every pmap_enter and wants
to allocate those pv entries from kmem_map, it might be a good idea to
init the kmem_map before initializing the kmemusage struct (because kmemusage
allocates memory).
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.43 2001/12/05 01:57:15 provos Exp $	*/
d49 1
a49 1
static struct vm_map kmem_map_store;
d495 1
a495 1
			VM_MAP_INTRSAFE, FALSE, &kmem_map_store);
@


1.44.2.1
log
@Merge in -current, builds on i386, otherwise untested
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.46 2002/01/16 20:50:17 miod Exp $	*/
d41 1
@


1.44.2.2
log
@Merge in UBC performance changes from NetBSD.
Fix a bunch of merge errors from yesterday.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.44.2.1 2002/01/31 22:55:40 niklas Exp $	*/
d183 1
a183 1
		va = (caddr_t) uvm_km_kmemalloc(kmem_map, NULL,
a599 12
}

/*
 * Round up a size to how much malloc would actually allocate.
 */
size_t
malloc_roundup(size_t sz)
{
	if (sz > MAXALLOCSAVE)
		return round_page(sz);

	return (1 << BUCKETINDX(sz));
@


1.44.2.3
log
@Sync UBC branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.44.2.2 2002/02/02 03:28:25 art Exp $	*/
@


1.44.2.4
log
@sync to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.44.2.3 2002/06/11 03:29:40 art Exp $	*/
d160 1
a160 1
	s = splvm();
d353 1
a353 1
	s = splvm();
@


1.44.2.5
log
@sync
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d149 1
a149 1
	if (((unsigned long)type) >= M_LAST)
d539 3
a541 6
			for (siz = 0, i = MINBUCKET; i < MINBUCKET + 16; i++) {
				snprintf(buckstring + siz,
				    sizeof buckstring - siz,
				    "%d,", (u_int)(1<<i));
				siz += strlen(buckstring + siz);
			}
d578 4
a581 6
			for (siz = 0, i = 0; i < M_LAST; i++) {
				snprintf(memall + siz, 
				    totlen + M_LAST - siz,
				    "%s,", memname[i] ? memname[i] : "");
				siz += strlen(memall + siz);
			}
@


1.43
log
@make nkmempages dynamic based on memory. okay art@@ from netbsd:
date: 2000/02/11 19:22:52;  author: thorpej;
Add some very simple code to auto-size the kmem_map.  We take the
amount of physical memory, divide it by 4, and then allow machine
dependent code to place upper and lower bounds on the size.  Export
the computed value to userspace via the new "vm.nkmempages" sysctl.

NKMEMCLUSTERS is now deprecated and will generate an error if you
attempt to use it.  The new option, should you choose to use it,
is called NKMEMPAGES, and two new options NKMEMPAGES_MIN and
NKMEMPAGES_MAX allow the user to configure the bounds in the kernel
config file.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.42 2001/11/28 19:28:14 art Exp $	*/
a492 2
	kmemusage = (struct kmemusage *) uvm_km_zalloc(kernel_map,
		(vsize_t)(nkmempages * sizeof(struct kmemusage)));
d496 2
@


1.42
log
@Sync in more uvm from NetBSD. Mostly just cosmetic stuff.
Contains also support for page coloring.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.41 2001/11/28 16:13:29 art Exp $	*/
d52 25
a76 1
int nkmempages;
d436 37
a480 1
	int npg;
d487 6
a492 1
	npg = VM_KMEM_SIZE / PAGE_SIZE;
d494 1
a494 1
		(vsize_t)(npg * sizeof(struct kmemusage)));
d496 1
a496 1
		(vaddr_t *)&kmemlimit, (vsize_t)(npg * PAGE_SIZE), 
d507 1
a507 1
		kmemstats[indx].ks_limit = npg * PAGE_SIZE * 6 / 10;
a511 2

	nkmempages = npg;
@


1.41
log
@zap some typedefs.
vm_map_t -> struct vm_map *
vm_map_entry_t -> struct vm_map_entry *
simple_lock_data_t -> struct simplelock

(uvm not done yet, coming in the next commit)
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.40 2001/11/06 19:53:20 miod Exp $	*/
d49 1
a49 1
static struct vm_map_intrsafe kmem_map_store;
d432 1
a432 1
			VM_MAP_INTRSAFE, FALSE, &kmem_map_store.vmi_map);
@


1.40
log
@Replace inclusion of <vm/foo.h> with the correct <uvm/bar.h> when necessary.
(Look ma, I might have broken the tree)
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.39 2001/09/19 20:50:58 mickey Exp $	*/
d50 1
a50 1
vm_map_t kmem_map = NULL;
@


1.39
log
@merge vm/vm_kern.h into uvm/uvm_extern.h; art@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.38 2001/08/17 23:39:58 art Exp $	*/
a46 1
#include <vm/vm.h>
@


1.38
log
@When this code was imported to NetBSD by Jason Thorpe he did a bunch of
useful changes (and a lot of cleanup). Bring in them.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.37 2001/08/02 11:06:38 art Exp $	*/
a47 2
#include <vm/vm_kern.h>

@


1.37
log
@Sysctl for finding out how many pages there are in kmem_map.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.36 2001/07/26 14:23:31 art Exp $	*/
a66 6
#endif

#ifdef MALLOC_DEBUG
extern int debug_malloc __P((unsigned long, int, int, void **));
extern int debug_free __P((void *, int));
extern void debug_malloc_init __P((void));
@


1.36
log
@Print "data modified on freelist" sizes in hex.
I know at least of two cases where people got confused by this and used
the wrong size to the malloc debugger.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.35 2001/06/27 04:49:43 art Exp $	*/
d55 2
d456 2
@


1.35
log
@remove old vm
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.34 2001/06/22 14:14:08 deraadt Exp $	*/
d246 1
a246 1
		printf("%s %d of object %p size %ld %s %s (invalid addr %p)\n",
d271 1
a271 1
		printf("%s %d of object %p size %ld %s %s (0x%x != 0x%x)\n",
@


1.34
log
@KNF
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.33 2001/06/21 14:28:53 niklas Exp $	*/
a49 1
#if defined(UVM)
a53 1
#endif
a166 1
#if defined(UVM)
a169 4
#else
		va = (caddr_t) kmem_malloc(kmem_map, (vsize_t)ctob(npg),
					   !(flags & M_NOWAIT));
#endif
a235 1
#if defined(UVM)
d245 1
a245 6
		if (!rv)
#else
	if (kbp->kb_next &&
	    !kernacc(kbp->kb_next, sizeof(struct freelist), 0))
#endif
	  {
a250 1
#if defined(UVM)
a251 1
#endif
a351 1
#if defined(UVM)
a352 3
#else
		kmem_free(kmem_map, (vaddr_t)addr, ctob(kup->ku_pagecnt));
#endif
a434 1
#if defined(UVM)
a439 6
#else
	kmemusage = (struct kmemusage *) kmem_alloc(kernel_map,
		(vsize_t)(npg * sizeof(struct kmemusage)));
	kmem_map = kmem_suballoc(kernel_map, (vaddr_t *)&kmembase,
		(vaddr_t *)&kmemlimit, (vsize_t)(npg * PAGE_SIZE), FALSE);
#endif
@


1.33
log
@Canonicalize panic message
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.32 2001/06/21 14:27:13 niklas Exp $	*/
d250 1
a250 2
				       addr + sizeof(struct freelist),
				       VM_PROT_WRITE);
d495 2
a496 2
        struct kmembuckets kb;
        int i, siz;
d504 2
a505 2
	        /* Initialize the first time */
	        if (buckstring_init == 0) {
d508 3
a510 3
		        for (siz = 0, i = MINBUCKET; i < MINBUCKET + 16; i++)
			        siz += sprintf(buckstring + siz,
				    "%d,", (u_int)(1<<i));
d515 1
a515 1
	        return (sysctl_rdstring(oldp, oldlenp, newp, buckstring));
d518 1
a518 1
	        bcopy(&bucket[BUCKETINDX(name[1])], &kb, sizeof(kb));
d532 1
a532 1
	        if (memall == NULL) {
d547 2
a548 2
		        for (siz = 0, i = 0; i < M_LAST; i++)
			        siz += sprintf(memall + siz, "%s,",
d561 1
a561 1
	        return (sysctl_rdstring(oldp, oldlenp, newp, memall));
d566 1
a566 1
	        return (EOPNOTSUPP);
@


1.32
log
@Panic if we free stuff not in malloc region. (ifdef DIAGNOSTIC)
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.31 2001/05/14 08:03:13 angelos Exp $	*/
d346 1
a346 1
		panic("free of non-malloced addr %p type %s", addr,
@


1.31
log
@Use lockmgr locks for kern.malloc.kmemstat and
hw.diskstats/hw.disknames.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.30 2001/05/14 07:01:37 angelos Exp $	*/
d342 6
@


1.30
log
@Be more paranoid about zapping trailing comma.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.29 2001/05/14 06:56:30 angelos Exp $	*/
d66 1
d481 1
a481 1
sysctl_malloc(name, namelen, oldp, oldlenp, newp, newlen)
d488 1
d530 4
d540 1
a540 3
			memall = malloc(totlen + M_LAST, M_SYSCTL, M_NOWAIT);
			if (memall == NULL)
				return (ENOMEM);
d554 1
@


1.29
log
@Use M_SYSCTL, fix a couple of buglets, style. deraadt@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.28 2001/05/11 06:38:47 angelos Exp $	*/
d504 3
a506 1
			buckstring[siz - 1] = '\0'; /* Remove trailing comma */
d541 4
a544 1
			memall[siz - 1] = '\0'; /* Remove trailing comma */
@


1.28
log
@kmemstats, nselcoll, forkstat, and nchstats structures through
sysctl. deraadt@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.27 2001/05/06 00:47:46 art Exp $	*/
d502 2
a503 3
			        siz += snprintf(buckstring + siz,
						sizeof(buckstring) - siz - 1,
					        "%d,", (u_int)(1<<i));
d511 1
a511 2
		return (sysctl_rdstruct(oldp, oldlenp, newp, &kb,
					sizeof(kb)));
d517 1
a517 2
					&kmemstats[name[1]],
					sizeof(struct kmemstats)));
a522 5
		/*
		 * XXX We should use a spinlock here, since
		 * multiple processes could conceivably be "stuck"
		 * waiting for memory to become available.
		 */
d527 1
a527 1
			for (totlen = 1, i = 0; i < M_LAST; i++)
d529 6
a534 5
					totlen += strlen(memname[i]) + 1;
				else
					totlen++;

			memall = malloc(totlen + M_LAST, M_TEMP, M_WAITOK);
a535 1

d538 1
a538 2
					       memname[i] ? memname[i] : "");

@


1.27
log
@Remove the cpp magic for finding incorrect MAXALLOCSAVE.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.26 2001/05/05 20:57:00 art Exp $	*/
d65 1
d491 2
a492 1
	if (namelen != 2 && name[0] != KERN_MALLOC_BUCKETS)
d514 45
@


1.26
log
@Get rid of CLSIZE and all related stuff.
CLSIZE -> 1
CLBYTES -> PAGE_SIZE
OLOFSET -> PAGE_MASK
etc.
At the same time some archs needed some cleaning in vmparam.h so that
goes in at the same time.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.25 2001/04/06 14:37:50 angelos Exp $	*/
d437 1
a437 1
	register long indx;
a439 10

#if	((MAXALLOCSAVE & (MAXALLOCSAVE - 1)) != 0)
		ERROR!_kmeminit:_MAXALLOCSAVE_not_power_of_2
#endif
#if	(MAXALLOCSAVE > MINALLOCSIZE * 32768)
		ERROR!_kmeminit:_MAXALLOCSAVE_too_big
#endif
#if	(MAXALLOCSAVE < PAGE_SIZE)
		ERROR!_kmeminit:_MAXALLOCSAVE_too_small
#endif
@


1.25
log
@Typo in comment (henric@@aimnet.com)
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.24 2001/02/21 23:24:29 csapuntz Exp $	*/
d163 1
a163 1
			allocsize = clrnd(round_page(size));
d166 1
a166 1
		npg = clrnd(btoc(allocsize));
d351 2
a352 2
	if (size > PAGE_SIZE * CLSIZE)
		alloc = addrmask[BUCKETINDX(PAGE_SIZE * CLSIZE)];
d447 1
a447 1
#if	(MAXALLOCSAVE < CLBYTES)
d471 1
a471 1
		if (1 << indx >= CLBYTES)
d474 1
a474 1
			bucket[indx].kb_elmpercl = CLBYTES / (1 << indx);
@


1.24
log
@

Latest soft updates from FreeBSD/Kirk McKusick

Snapshot-related code has been commented out.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.23 2001/02/20 23:35:35 csapuntz Exp $	*/
d95 1
a95 1
 * and the free list pointer is at offst 8 in the structure.  Since the
@


1.23
log
@

Add M_ZERO option to malloc. Causes malloc to return a zero'ed buffer.

Used by the new soft updates code
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.22 2001/01/04 07:49:24 angelos Exp $	*/
d138 1
a138 3
	if (debug_malloc(size, type, flags, (void **)&va)) {
		if ((flags & M_ZERO) && va != NULL)
			bzero(va, size);
a139 1
	}
a311 2
	if ((flags & M_ZERO) && va != NULL)
		bzero(va, size);
@


1.22
log
@Return a kmembuckets structure, rather than individual items, since they may be
out of sync between consecutive calls of sysctl(3).
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.21 2001/01/04 06:04:14 angelos Exp $	*/
d138 3
a140 1
	if (debug_malloc(size, type, flags, (void **)&va))
d142 1
d315 2
@


1.21
log
@sysctl_malloc()
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.20 2000/06/06 20:18:20 art Exp $	*/
d497 1
d500 1
a500 1
	if (namelen != 3 && name[0] != KERN_MALLOC_BUCKETS)
d518 4
a521 23
	    switch (name[2]) {
	    case KERN_MALLOC_CALLS:
		    return (sysctl_rdquad(oldp, oldlenp, newp,
				bucket[BUCKETINDX(name[1])].kb_calls));
	    case KERN_MALLOC_ALLOC:
		    return (sysctl_rdquad(oldp, oldlenp, newp,
				bucket[BUCKETINDX(name[1])].kb_total));
	    case KERN_MALLOC_FREE:
		    return (sysctl_rdquad(oldp, oldlenp, newp,
				bucket[BUCKETINDX(name[1])].kb_totalfree));
	    case KERN_MALLOC_ELEMENTS:
		    return (sysctl_rdquad(oldp, oldlenp, newp,
				bucket[BUCKETINDX(name[1])].kb_elmpercl));
	    case KERN_MALLOC_HIWAT:
		    return (sysctl_rdquad(oldp, oldlenp, newp,
				bucket[BUCKETINDX(name[1])].kb_highwat));
	    case KERN_MALLOC_COULDFREE:
		    return (sysctl_rdquad(oldp, oldlenp, newp,
				bucket[BUCKETINDX(name[1])].kb_couldfree));
	    default:
		    return (EOPNOTSUPP);
	    }

@


1.20
log
@malloc debugging code. Enabled by option MALLOC_DEBUG.
Make sure you read the docs (malloc(9)) before use.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.19 2000/03/16 22:11:03 art Exp $	*/
d45 1
d61 2
d485 60
@


1.19
log
@Bring in some new UVM code from NetBSD (not current).

 - Introduce a new type of map that are interrupt safe and never allow faults
   in them. mb_map and kmem_map are made intrsafe.
 - Add "access protection" to uvm_vslock (to be passed down to uvm_fault and
   later to pmap_enter).
 - madvise(2) now works.
 - various cleanups.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.18 1999/11/25 13:41:30 art Exp $	*/
d64 6
d133 6
d334 5
d477 3
d481 1
@


1.18
log
@Use PAGE_SIZE instead of NBPG.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.17 1999/09/10 22:14:39 art Exp $	*/
d52 1
a52 1
static struct vm_map kmem_map_store;
d231 1
a231 1
		vm_map_lock_read(kmem_map);
d235 1
a235 1
		vm_map_unlock_read(kmem_map);
d442 1
a442 1
			FALSE, FALSE, &kmem_map_store);
@


1.18.2.1
log
@Sync with -current
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d52 1
a52 1
static struct vm_map_intrsafe kmem_map_store;
d231 1
a231 1
		vm_map_lock(kmem_map);
d235 1
a235 1
		vm_map_unlock(kmem_map);
d442 1
a442 1
			VM_MAP_INTRSAFE, FALSE, &kmem_map_store.vmi_map);
@


1.18.2.2
log
@merge in approximately 2.9 into SMP branch
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.25 2001/04/06 14:37:50 angelos Exp $	*/
a44 1
#include <sys/sysctl.h>
a59 2
char buckstring[16 * sizeof("123456,")];
int buckstring_init = 0;
a63 6
#ifdef MALLOC_DEBUG
extern int debug_malloc __P((unsigned long, int, int, void **));
extern int debug_free __P((void *, int));
extern void debug_malloc_init __P((void));
#endif

d86 1
a86 1
 * and the free list pointer is at offset 8 in the structure.  Since the
a126 6

#ifdef MALLOC_DEBUG
	if (debug_malloc(size, type, flags, (void **)&va))
		return ((void *) va);
#endif

a321 5
#ifdef MALLOC_DEBUG
	if (debug_free(addr, type))
		return;
#endif

a459 46
#ifdef MALLOC_DEBUG
	debug_malloc_init();
#endif
}

/*
 * Return kernel malloc statistics information.
 */
int
sysctl_malloc(name, namelen, oldp, oldlenp, newp, newlen)
	int *name;
	u_int namelen;
	void *oldp;
	size_t *oldlenp;
	void *newp;
	size_t newlen;
{
        struct kmembuckets kb;
        int i, siz;

	if (namelen != 2 && name[0] != KERN_MALLOC_BUCKETS)
		return (ENOTDIR);		/* overloaded */

	switch (name[0]) {
	case KERN_MALLOC_BUCKETS:
	        /* Initialize the first time */
	        if (buckstring_init == 0) {
			buckstring_init = 1;
			bzero(buckstring, sizeof(buckstring));
		        for (siz = 0, i = MINBUCKET; i < MINBUCKET + 16; i++)
			        siz += snprintf(buckstring + siz,
						sizeof(buckstring) - siz - 1,
					        "%d,", (u_int)(1<<i));
			buckstring[siz - 1] = '\0'; /* Remove trailing comma */
		}
	        return (sysctl_rdstring(oldp, oldlenp, newp, buckstring));

	case KERN_MALLOC_BUCKET:
	        bcopy(&bucket[BUCKETINDX(name[1])], &kb, sizeof(kb));
		kb.kb_next = kb.kb_last = 0;
		return (sysctl_rdstruct(oldp, oldlenp, newp, &kb,
					sizeof(kb)));
	default:
	        return (EOPNOTSUPP);
	}
	/* NOTREACHED */
@


1.18.2.3
log
@Merge in -current from two days ago in the SMP branch.
As usual with merges, they do not indicate progress, so do not hold
your breath for working SMP, and do not mail me and ask about the
state of it.  It has not changed.  There is work ongoing, but very, very
slowly.  The commit is done in parts as to not lock up the tree in too
big chunks at a time.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.18.2.2 2001/05/14 22:32:41 niklas Exp $	*/
d50 1
d55 1
a64 2
char *memall = NULL;
extern struct lock sysctl_kmemlock;
d163 1
a163 1
			allocsize = round_page(size);
d166 2
a167 1
		npg = btoc(allocsize);
d171 4
d241 1
d248 2
a249 1
		    addr + sizeof(struct freelist), VM_PROT_WRITE);
d252 6
a257 1
		if (!rv)  {
d263 1
d265 1
a341 6
#ifdef DIAGNOSTIC
	if (addr < (void *)kmembase || addr >= (void *)kmemlimit)
		panic("free: non-malloced addr %p type %s", addr,
		    memname[type]);
#endif

d351 2
a352 2
	if (size > PAGE_SIZE)
		alloc = addrmask[BUCKETINDX(PAGE_SIZE)];
d360 1
d362 3
d437 1
a437 1
	long indx;
d441 10
d457 1
d463 6
d471 1
a471 1
		if (1 << indx >= PAGE_SIZE)
d474 1
a474 1
			bucket[indx].kb_elmpercl = PAGE_SIZE / (1 << indx);
d489 1
a489 1
sysctl_malloc(name, namelen, oldp, oldlenp, newp, newlen, p)
a495 1
	struct proc *p;
d497 2
a498 2
	struct kmembuckets kb;
	int i, siz;
d500 1
a500 2
	if (namelen != 2 && name[0] != KERN_MALLOC_BUCKETS &&
	    name[0] != KERN_MALLOC_KMEMNAMES)
d505 2
a506 2
		/* Initialize the first time */
		if (buckstring_init == 0) {
d509 5
a513 6
			for (siz = 0, i = MINBUCKET; i < MINBUCKET + 16; i++)
			    siz += sprintf(buckstring + siz,
			    "%d,", (u_int)(1<<i));
			/* Remove trailing comma */
			if (siz)
				buckstring[siz - 1] = '\0';
d515 1
a515 1
		return (sysctl_rdstring(oldp, oldlenp, newp, buckstring));
d518 1
a518 1
		bcopy(&bucket[BUCKETINDX(name[1])], &kb, sizeof(kb));
d520 2
a521 45
		return (sysctl_rdstruct(oldp, oldlenp, newp, &kb, sizeof(kb)));
	case KERN_MALLOC_KMEMSTATS:
#ifdef KMEMSTATS
		if ((name[1] < 0) || (name[1] >= M_LAST))
			return (EINVAL);
		return (sysctl_rdstruct(oldp, oldlenp, newp,
		    &kmemstats[name[1]], sizeof(struct kmemstats)));
#else
		return (EOPNOTSUPP);
#endif
	case KERN_MALLOC_KMEMNAMES:
#if defined(KMEMSTATS) || defined(DIAGNOSTIC) || defined(FFS_SOFTUPDATES)
		if (memall == NULL) {
			int totlen;

			i = lockmgr(&sysctl_kmemlock, LK_EXCLUSIVE, NULL, p);
			if (i)
				return (i);

			/* Figure out how large a buffer we need */
			for (totlen = 0, i = 0; i < M_LAST; i++) {
				if (memname[i])
					totlen += strlen(memname[i]);
				totlen++;
			}
			memall = malloc(totlen + M_LAST, M_SYSCTL, M_WAITOK);
			bzero(memall, totlen + M_LAST);
			for (siz = 0, i = 0; i < M_LAST; i++)
				siz += sprintf(memall + siz, "%s,",
				    memname[i] ? memname[i] : "");

			/* Remove trailing comma */
			if (siz)
				memall[siz - 1] = '\0';

			/* Now, convert all spaces to underscores */
			for (i = 0; i < totlen; i++)
				if (memall[i] == ' ')
					memall[i] = '_';
			lockmgr(&sysctl_kmemlock, LK_RELEASE, NULL, p);
		}
		return (sysctl_rdstring(oldp, oldlenp, newp, memall));
#else
		return (EOPNOTSUPP);
#endif
d523 1
a523 1
		return (EOPNOTSUPP);
@


1.18.2.4
log
@Sync the SMP branch to something just after 3.0
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.18.2.3 2001/07/04 10:48:22 niklas Exp $	*/
d48 2
a54 2
int nkmempages;

d67 6
d246 1
a246 1
		printf("%s %d of object %p size 0x%lx %s %s (invalid addr %p)\n",
d271 1
a271 1
		printf("%s %d of object %p size 0x%lx %s %s (0x%x != 0x%x)\n",
a453 2

	nkmempages = npg;
@


1.18.2.5
log
@merge in -current
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d47 1
@


1.18.2.6
log
@Merge in -current
@
text
@d49 2
a50 2
static struct vm_map kmem_map_store;
struct vm_map *kmem_map = NULL;
d432 1
a432 1
			VM_MAP_INTRSAFE, FALSE, &kmem_map_store);
@


1.18.2.7
log
@Merge in trunk
@
text
@d41 1
d49 1
a49 1
static struct vm_map_intrsafe kmem_map_store;
d52 1
a52 25
#ifdef NKMEMCLUSTERS
#error NKMEMCLUSTERS is obsolete; remove it from your kernel config file and use NKMEMPAGES instead or let the kernel auto-size
#endif

/*
 * Default number of pages in kmem_map.  We attempt to calculate this
 * at run-time, but allow it to be either patched or set in the kernel
 * config file.
 */
#ifndef NKMEMPAGES
#define	NKMEMPAGES	0
#endif
int	nkmempages = NKMEMPAGES;

/*
 * Defaults for lower- and upper-bounds for the kmem_map page count.
 * Can be overridden by kernel config options.
 */
#ifndef	NKMEMPAGES_MIN
#define	NKMEMPAGES_MIN	NKMEMPAGES_MIN_DEFAULT
#endif

#ifndef NKMEMPAGES_MAX
#define	NKMEMPAGES_MAX	NKMEMPAGES_MAX_DEFAULT
#endif
a411 37
 * Compute the number of pages that kmem_map will map, that is,
 * the size of the kernel malloc arena.
 */
void
kmeminit_nkmempages()
{
	int npages;

	if (nkmempages != 0) {
		/*
		 * It's already been set (by us being here before, or
		 * by patching or kernel config options), bail out now.
		 */
		return;
	}

	/*
	 * We use the following (simple) formula:
	 *
	 *	- Starting point is physical memory / 4.
	 *
	 *	- Clamp it down to NKMEMPAGES_MAX.
	 *
	 *	- Round it up to NKMEMPAGES_MIN.
	 */
	npages = physmem / 4;

	if (npages > NKMEMPAGES_MAX)
		npages = NKMEMPAGES_MAX;

	if (npages < NKMEMPAGES_MIN)
		npages = NKMEMPAGES_MIN;

	nkmempages = npages;
}

/*
d420 1
d427 3
a429 6
	/*
	 * Compute the number of kmem_map pages, if we have not
	 * done so already.
	 */
	kmeminit_nkmempages();

d431 2
a432 4
		(vaddr_t *)&kmemlimit, (vsize_t)(nkmempages * PAGE_SIZE), 
			VM_MAP_INTRSAFE, FALSE, &kmem_map_store.vmi_map);
	kmemusage = (struct kmemusage *) uvm_km_zalloc(kernel_map,
		(vsize_t)(nkmempages * sizeof(struct kmemusage)));
d442 1
a442 1
		kmemstats[indx].ks_limit = nkmempages * PAGE_SIZE * 6 / 10;
d447 2
a537 12
}

/*
 * Round up a size to how much malloc would actually allocate.
 */
size_t
malloc_roundup(size_t sz)
{
	if (sz > MAXALLOCSAVE)
		return round_page(sz);

	return (1 << BUCKETINDX(sz));
@


1.18.2.8
log
@Sync the SMP branch with 3.3
@
text
@d160 1
a160 1
	s = splvm();
d353 1
a353 1
	s = splvm();
@


1.18.2.9
log
@Sync the SMP branch to -current. This includes moving to ELF.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.18.2.8 2003/03/28 00:41:26 niklas Exp $	*/
d149 1
a149 1
	if (((unsigned long)type) >= M_LAST)
d539 3
a541 6
			for (siz = 0, i = MINBUCKET; i < MINBUCKET + 16; i++) {
				snprintf(buckstring + siz,
				    sizeof buckstring - siz,
				    "%d,", (u_int)(1<<i));
				siz += strlen(buckstring + siz);
			}
d578 4
a581 6
			for (siz = 0, i = 0; i < M_LAST; i++) {
				snprintf(memall + siz, 
				    totlen + M_LAST - siz,
				    "%s,", memname[i] ? memname[i] : "");
				siz += strlen(memall + siz);
			}
@


1.18.2.10
log
@Sync SMP branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.18.2.9 2003/05/13 19:21:28 ho Exp $	*/
d16 5
a20 1
 * 3. Neither the name of the University nor the names of its contributors
a476 1
	vaddr_t base, limit;
d491 4
a494 6
	base = vm_map_min(kernel_map);
	kmem_map = uvm_km_suballoc(kernel_map, &base, &limit,
	    (vsize_t)(nkmempages * PAGE_SIZE), VM_MAP_INTRSAFE, FALSE,
	    &kmem_map_store.vmi_map);
	kmembase = (char *)base;
	kmemlimit = (char *)limit;
@


1.18.2.11
log
@Merge of current from two weeks agointo the SMP branch
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d89 1
a89 1
const long addrmask[] = { 0,
a153 2
	if (size > 65535 * PAGE_SIZE)
		panic("malloc: allocation too large");
d165 1
a165 1
		tsleep(ksp, PSWP+2, memname[type], 0);
d202 2
d372 1
a372 1
			wakeup(ksp);
d418 1
a418 1
		wakeup(ksp);
@


1.17
log
@use clrnd(round_page(size)) instead of roundup(size, CLBYTES).
They do the same thing, but the former is noticeably faster on sparc
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.16 1999/07/15 14:07:41 art Exp $	*/
d198 1
a198 1
		kbp->kb_next = cp = va + (npg * NBPG) - allocsize;
d331 2
a332 2
	if (size > NBPG * CLSIZE)
		alloc = addrmask[BUCKETINDX(NBPG * CLSIZE)];
d436 1
a436 1
	npg = VM_KMEM_SIZE/ NBPG;
d441 1
a441 1
		(vaddr_t *)&kmemlimit, (vsize_t)(npg * NBPG), 
d447 1
a447 1
		(vaddr_t *)&kmemlimit, (vsize_t)(npg * NBPG), FALSE);
d458 1
a458 1
		kmemstats[indx].ks_limit = npg * NBPG * 6 / 10;
@


1.16
log
@vm_offset_t -> {v,p}addr_t ; vm_size_t -> {v,p}size_t
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.15 1999/06/23 07:43:30 art Exp $	*/
d148 1
a148 1
			allocsize = roundup(size, CLBYTES);
@


1.15
log
@apparently we need to have kmemstats in the kernel even if we don't use it.
vmstat will fail if we don't have symbol even when it doesn't need it. XXX
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.14 1999/06/03 14:30:15 millert Exp $	*/
d157 1
a157 1
		va = (caddr_t) kmem_malloc(kmem_map, (vm_size_t)ctob(npg),
d343 1
a343 1
		kmem_free(kmem_map, (vm_offset_t)addr, ctob(kup->ku_pagecnt));
d445 3
a447 3
		(vm_size_t)(npg * sizeof(struct kmemusage)));
	kmem_map = kmem_suballoc(kernel_map, (vm_offset_t *)&kmembase,
		(vm_offset_t *)&kmemlimit, (vm_size_t)(npg * NBPG), FALSE);
@


1.14
log
@Also define memname if FFS_SOFTUPDATES is defined.  FFS_SOFTUPDATES should really only use memname ifdef DIAGNOSTIC but that isn't feasible right now
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.13 1999/05/06 17:37:13 art Exp $	*/
a56 1
#ifdef KMEMSTATS
a57 1
#endif
@


1.13
log
@put a sanity check behind DIAGNOSTIC and give it a better panic message
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.12 1999/02/26 04:54:00 art Exp $	*/
d62 1
a62 1
#if defined(KMEMSTATS) || defined(DIAGNOSTIC)
@


1.12
log
@kmem allocation changes for uvm
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.11 1999/01/20 21:47:46 art Exp $	*/
d433 1
d435 2
a436 1
		panic("minbucket too small/struct freelist too big");
@


1.11
log
@put some more stuff behind #ifdef KMEMSTATS
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.10 1999/01/11 05:12:23 millert Exp $	*/
d49 7
d154 5
d161 1
d228 13
d242 3
a244 1
	    !kernacc(kbp->kb_next, sizeof(struct freelist), 0)) {
d250 3
d342 3
d346 1
d437 7
d448 1
@


1.10
log
@panic prints a newline for you, don't do it in the panic string
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.9 1998/02/20 13:43:23 niklas Exp $	*/
d50 1
d52 1
d55 1
d57 1
@


1.9
log
@Please GCC 2.8 -Wall
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.8 1997/12/12 17:13:56 gene Exp $	*/
d303 1
a303 1
		panic("free: unaligned addr %p, size %ld, type %s, mask %ld\n",
@


1.8
log
@Fixed spelling in a comment.
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.7 1997/03/01 21:31:11 kstailey Exp $	*/
d351 1
a351 1
	if (kup->ku_freecnt >= kbp->kb_elmpercl)
d356 1
@


1.7
log
@prevent warning about unused variable when NO_KMEMSTATS is in effect
@
text
@d1 1
a1 1
/*	$OpenBSD: kern_malloc.c,v 1.5 1996/06/10 07:27:12 deraadt Exp $	*/
d148 1
a148 1
			 * wait, if there is no map space avaiable, because
@


1.6
log
@kern_malloc() can fail in canwait case if no more map space; return NULL in
that case so that callers can deal with shortage rather than deadlocking.
@
text
@d378 1
d380 1
@


1.5
log
@data structure handling fix
@
text
@d1 2
a2 2
/*	$OpenBSD: kern_malloc.c,v 1.3 1996/04/19 16:08:55 niklas Exp $	*/
/*	$NetBSD: kern_malloc.c,v 1.15.4.1 1996/06/06 19:14:30 cgd Exp $	*/
d146 10
@


1.4
log
@partial sync with netbsd 960418, more to come
@
text
@d2 1
a2 1
/*	$NetBSD: kern_malloc.c,v 1.15 1996/03/16 23:17:06 christos Exp $	*/
d319 2
a320 1
		for (cp = kbp->kb_next; cp; cp = *(caddr_t *)cp) {
@


1.3
log
@NetBSD 960317 merge
@
text
@d1 2
a2 2
/*	$OpenBSD: kern_malloc.c,v 1.2 1996/03/03 17:19:49 niklas Exp $	*/
/*	$NetBSD: kern_malloc.c,v 1.14 1996/02/20 23:56:16 cgd Exp $	*/
d203 1
a203 1
		printf("%s %d of object %p size %d %s %s (invalid addr %p)\n",
d227 1
a227 1
		printf("%s %d of object %p size %d %s %s (0x%x != 0x%x)\n",
d293 1
a293 1
		panic("free: unaligned addr 0x%x, size %d, type %s, mask %d\n",
@


1.2
log
@From NetBSD: 960217 merge
@
text
@d1 2
a2 2
/*	$OpenBSD$	*/
/*	$NetBSD: kern_malloc.c,v 1.13 1996/02/09 18:59:39 christos Exp $	*/
d227 1
a227 1
		printf("%s %d of object %p size %d %s %s (%p != %p)\n",
d229 1
a229 2
			va, size, "previous type", savedtype, (void *)*lp,
			(void *) WEIRD_ADDR);
@


1.1
log
@Initial revision
@
text
@d1 2
a2 1
/*	$NetBSD: kern_malloc.c,v 1.11 1995/05/01 22:39:11 cgd Exp $	*/
d44 1
d70 1
a70 1
#define WEIRD_ADDR	0xdeadbeef
d229 2
a230 1
			va, size, "previous type", savedtype, *lp, WEIRD_ADDR);
d365 1
@


1.1.1.1
log
@initial import of NetBSD tree
@
text
@@
