head	1.8;
access;
symbols
	OPENBSD_6_2:1.8.0.2
	OPENBSD_6_2_BASE:1.8
	OPENBSD_6_1:1.7.0.4
	OPENBSD_6_1_BASE:1.7;
locks; strict;
comment	@ * @;


1.8
date	2017.09.08.05.36.53;	author deraadt;	state Exp;
branches;
next	1.7;
commitid	uRv5pa9QDlZaYgwD;

1.7
date	2017.02.05.16.23.38;	author jca;	state Exp;
branches;
next	1.6;
commitid	b4PzKhPOLWkSDY9t;

1.6
date	2017.01.11.17.46.28;	author bluhm;	state Exp;
branches;
next	1.5;
commitid	e637hVOJDl3DnWwW;

1.5
date	2016.10.27.09.40.20;	author dlg;	state Exp;
branches;
next	1.4;
commitid	TUQ6YfQI11ANR5LF;

1.4
date	2016.10.24.23.58.33;	author dlg;	state Exp;
branches;
next	1.3;
commitid	3TeGbJaxAzwxTMGK;

1.3
date	2016.10.24.03.15.38;	author deraadt;	state Exp;
branches;
next	1.2;
commitid	IwNyiJ0JM3Lxbhzy;

1.2
date	2016.10.21.06.41.52;	author dlg;	state Exp;
branches;
next	1.1;
commitid	HqhbQZQBaP56Ht1x;

1.1
date	2016.10.21.06.27.50;	author dlg;	state Exp;
branches;
next	;
commitid	D5WUiCvZ665NhpbX;


desc
@@


1.8
log
@If you use sys/param.h, you don't need sys/types.h
@
text
@/*	$OpenBSD: subr_percpu.c,v 1.7 2017/02/05 16:23:38 jca Exp $ */

/*
 * Copyright (c) 2016 David Gwynne <dlg@@openbsd.org>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/pool.h>
#include <sys/malloc.h>

#include <sys/percpu.h>

#ifdef MULTIPROCESSOR
struct pool cpumem_pl;

void
percpu_init(void)
{
	pool_init(&cpumem_pl, sizeof(struct cpumem) * ncpusfound, 0,
	    IPL_NONE, PR_WAITOK, "percpumem", &pool_allocator_single);
}

struct cpumem *
cpumem_get(struct pool *pp)
{
	struct cpumem *cm;
	unsigned int cpu;

	cm = pool_get(&cpumem_pl, PR_WAITOK);

	for (cpu = 0; cpu < ncpusfound; cpu++)
		cm[cpu].mem = pool_get(pp, PR_WAITOK | PR_ZERO);

	return (cm);
}

void
cpumem_put(struct pool *pp, struct cpumem *cm)
{
	unsigned int cpu;

	for (cpu = 0; cpu < ncpusfound; cpu++)
		pool_put(pp, cm[cpu].mem);

	pool_put(&cpumem_pl, cm);
}

struct cpumem *
cpumem_malloc(size_t sz, int type)
{
	struct cpumem *cm;
	unsigned int cpu;

	sz = roundup(sz, CACHELINESIZE);

	cm = pool_get(&cpumem_pl, PR_WAITOK);

	for (cpu = 0; cpu < ncpusfound; cpu++)
		cm[cpu].mem = malloc(sz, type, M_WAITOK | M_ZERO);

	return (cm);
}

struct cpumem *
cpumem_malloc_ncpus(struct cpumem *bootcm, size_t sz, int type)
{
	struct cpumem *cm;
	unsigned int cpu;

	sz = roundup(sz, CACHELINESIZE);

	cm = pool_get(&cpumem_pl, PR_WAITOK);

	cm[0].mem = bootcm[0].mem;
	for (cpu = 1; cpu < ncpusfound; cpu++)
		cm[cpu].mem = malloc(sz, type, M_WAITOK | M_ZERO);

	return (cm);
}

void
cpumem_free(struct cpumem *cm, int type, size_t sz)
{
	unsigned int cpu;

	sz = roundup(sz, CACHELINESIZE);

	for (cpu = 0; cpu < ncpusfound; cpu++)
		free(cm[cpu].mem, type, sz);

	pool_put(&cpumem_pl, cm);
}

void *
cpumem_first(struct cpumem_iter *i, struct cpumem *cm)
{
	i->cpu = 0;

	return (cm[0].mem);
}

void *
cpumem_next(struct cpumem_iter *i, struct cpumem *cm)
{
	unsigned int cpu = ++i->cpu;

	if (cpu >= ncpusfound)
		return (NULL);

	return (cm[cpu].mem);
}

struct cpumem *
counters_alloc(unsigned int n)
{
	struct cpumem *cm;
	struct cpumem_iter cmi;
	uint64_t *counters;
	unsigned int i;

	KASSERT(n > 0);

	n++; /* add space for a generation number */
	cm = cpumem_malloc(n * sizeof(uint64_t), M_COUNTERS);

	CPUMEM_FOREACH(counters, &cmi, cm) {
		for (i = 0; i < n; i++)
			counters[i] = 0;
	}

	return (cm);
}

struct cpumem *
counters_alloc_ncpus(struct cpumem *cm, unsigned int n)
{
	n++; /* the generation number */
	return (cpumem_malloc_ncpus(cm, n * sizeof(uint64_t), M_COUNTERS));
}

void
counters_free(struct cpumem *cm, unsigned int n)
{
	n++; /* generation number */
	cpumem_free(cm, M_COUNTERS, n * sizeof(uint64_t));
}

void
counters_read(struct cpumem *cm, uint64_t *output, unsigned int n)
{
	struct cpumem_iter cmi;
	uint64_t *gen, *counters, *temp;
	uint64_t enter, leave;
	unsigned int i;

	for (i = 0; i < n; i++)
		output[i] = 0;

	temp = mallocarray(n, sizeof(uint64_t), M_TEMP, M_WAITOK);

	gen = cpumem_first(&cmi, cm);
	do {
		counters = gen + 1;

		enter = *gen;
		for (;;) {
			/* the generation number is odd during an update */
			while (enter & 1) {
				yield();
				enter = *gen;
			}

			membar_consumer();
			for (i = 0; i < n; i++)
				temp[i] = counters[i];

			membar_consumer();
			leave = *gen;

			if (enter == leave)
				break;

			enter = leave;
		}

		for (i = 0; i < n; i++)
			output[i] += temp[i];

		gen = cpumem_next(&cmi, cm);
	} while (gen != NULL);

	free(temp, M_TEMP, n * sizeof(uint64_t));
}

void
counters_zero(struct cpumem *cm, unsigned int n)
{
	struct cpumem_iter cmi;
	uint64_t *counters;
	unsigned int i;

	counters = cpumem_first(&cmi, cm);
	do {
		for (i = 0; i < n; i++)
			counters[i] = 0;
		/* zero the generation numbers too */
		membar_producer();
		counters[i] = 0;

		counters = cpumem_next(&cmi, cm);
	} while (counters != NULL);
}

#else /* MULTIPROCESSOR */

/*
 * Uniprocessor implementation of per-CPU data structures.
 *
 * UP percpu memory is a single memory allocation cast to/from the
 * cpumem struct. It is not scaled up to the size of cacheline because
 * there's no other cache to contend with.
 */

void
percpu_init(void)
{
	/* nop */
}

struct cpumem *
cpumem_get(struct pool *pp)
{
	return (pool_get(pp, PR_WAITOK | PR_ZERO));
}

void
cpumem_put(struct pool *pp, struct cpumem *cm)
{
	pool_put(pp, cm);
}

struct cpumem *
cpumem_malloc(size_t sz, int type)
{
	return (malloc(sz, type, M_WAITOK | M_ZERO));
}

struct cpumem *
cpumem_malloc_ncpus(struct cpumem *cm, size_t sz, int type)
{
	return (cm);
}

void
cpumem_free(struct cpumem *cm, int type, size_t sz)
{
	free(cm, type, sz);
}

void *
cpumem_first(struct cpumem_iter *i, struct cpumem *cm)
{
	return (cm);
}

void *
cpumem_next(struct cpumem_iter *i, struct cpumem *cm)
{
	return (NULL);
}

struct cpumem *
counters_alloc(unsigned int n)
{
	KASSERT(n > 0);

	return (cpumem_malloc(n * sizeof(uint64_t), M_COUNTERS));
}

struct cpumem *
counters_alloc_ncpus(struct cpumem *cm, unsigned int n)
{
	/* this is unecessary, but symmetrical */
	return (cpumem_malloc_ncpus(cm, n * sizeof(uint64_t), M_COUNTERS));
}

void
counters_free(struct cpumem *cm, unsigned int n)
{
	cpumem_free(cm, M_COUNTERS, n * sizeof(uint64_t));
}

void
counters_read(struct cpumem *cm, uint64_t *output, unsigned int n)
{
	uint64_t *counters;
	unsigned int i;
	int s;

	counters = (uint64_t *)cm;

	s = splhigh();
	for (i = 0; i < n; i++)
		output[i] = counters[i];
	splx(s);
}

void
counters_zero(struct cpumem *cm, unsigned int n)
{
	uint64_t *counters;
	unsigned int i;
	int s;

	counters = (uint64_t *)cm;

	s = splhigh();
	for (i = 0; i < n; i++)
		counters[i] = 0;
	splx(s);
}

#endif /* MULTIPROCESSOR */
@


1.7
log
@Always allocate counters memory using type M_COUNTERS.

This makes the API simpler, and is probably more useful than spreading
counters memory other several types, making it harder to track.

Prodded by mpi, ok mpi@@ stsp@@
@
text
@d1 1
a1 1
/*	$OpenBSD: subr_percpu.c,v 1.6 2017/01/11 17:46:28 bluhm Exp $ */
a22 1
#include <sys/types.h>
@


1.6
log
@Move the membar in counters_read().  It has to be between reading
the generation number and the counters.  In counters_zero() put a
membar after resetting the counters, but before writing the generation
number.
OK mpi@@ patrick@@
@
text
@d1 1
a1 1
/*	$OpenBSD: subr_percpu.c,v 1.5 2016/10/27 09:40:20 dlg Exp $ */
d128 1
a128 1
counters_alloc(unsigned int n, int type)
d138 1
a138 1
	cm = cpumem_malloc(n * sizeof(uint64_t), type);
d149 1
a149 1
counters_alloc_ncpus(struct cpumem *cm, unsigned int n, int type)
d152 1
a152 1
	return (cpumem_malloc_ncpus(cm, n * sizeof(uint64_t), type));
d156 1
a156 1
counters_free(struct cpumem *cm, int type, unsigned int n)
d159 1
a159 1
	cpumem_free(cm, type, n * sizeof(uint64_t));
d287 1
a287 1
counters_alloc(unsigned int n, int type)
d291 1
a291 1
	return (cpumem_malloc(n * sizeof(uint64_t), type));
d295 1
a295 1
counters_alloc_ncpus(struct cpumem *cm, unsigned int n, int type)
d298 1
a298 1
	return (cpumem_malloc_ncpus(cm, n * sizeof(uint64_t), type));
d302 1
a302 1
counters_free(struct cpumem *cm, int type, unsigned int n)
d304 1
a304 1
	cpumem_free(cm, type, n * sizeof(uint64_t));
@


1.5
log
@use ncpusfound to size the percpu allocations.

ncpus is used on half the architectures to indicate the number of
cpus that have been hatched, and is used on them in things like ddb
to figure out how many cpus to shut down again.

ncpusfound is incremented during autoconf on MP machines to show
how big ncpus will probably become. percpu is initted after autoconf
but before cpus are hatched, so this works well.
@
text
@d1 1
a1 1
/*	$OpenBSD: subr_percpu.c,v 1.4 2016/10/24 23:58:33 dlg Exp $ */
a183 1
				membar_consumer();
d187 1
a215 2
	n++; /* zero the generation numbers too */

d220 3
a337 1

@


1.4
log
@avoid using realloc in the name of things that dont work like realloc.

cpumem_realloc and counters_realloc actually allocated new per cpu data
for new cpus, they didnt resize the existing allocation.

specifically, this renames cpumem_reallod to cpumem_malloc_ncpus, and
counters_realloc to counters_alloc_ncpus.

ok (and with some fixes by) bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: subr_percpu.c,v 1.3 2016/10/24 03:15:38 deraadt Exp $ */
d33 2
a34 2
	pool_init(&cpumem_pl, sizeof(struct cpumem) * ncpus, 0, IPL_NONE,
	    PR_WAITOK, "percpumem", &pool_allocator_single);
d45 1
a45 1
	for (cpu = 0; cpu < ncpus; cpu++)
d56 1
a56 1
	for (cpu = 0; cpu < ncpus; cpu++)
d72 1
a72 1
	for (cpu = 0; cpu < ncpus; cpu++)
d89 1
a89 1
	for (cpu = 1; cpu < ncpus; cpu++)
d102 1
a102 1
	for (cpu = 0; cpu < ncpus; cpu++)
d121 1
a121 1
	if (cpu >= ncpus)
@


1.3
log
@non-MP vs MP codepaths were confusingly split between the .c and .h file.
Unify these by placing #ifdef MULTIPROCESSOR inside the functions, then
collapse further to reduce _KERNEL blocks
ok dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: subr_percpu.c,v 1.2 2016/10/21 06:41:52 dlg Exp $ */
d79 1
a79 1
cpumem_realloc(struct cpumem *bootcm, size_t sz, int type)
d149 1
a149 1
counters_realloc(struct cpumem *cm, unsigned int n, int type)
d152 1
a152 1
	return (cpumem_realloc(cm, n * sizeof(uint64_t), type));
d262 1
a262 1
cpumem_realloc(struct cpumem *cm, size_t sz, int type)
d294 1
a294 1
counters_realloc(struct cpumem *cm, unsigned int n, int type)
d297 1
a297 1
	return (cpumem_realloc(cm, n * sizeof(uint64_t), type));
@


1.2
log
@consistently zero the allocated memory in both the MP and UP cases.

from markus@@
@
text
@d1 1
a1 1
/*	$OpenBSD: subr_percpu.c,v 1.1 2016/10/21 06:27:50 dlg Exp $ */
d271 12
@


1.1
log
@add generalised access to per cpu data structures and counters.

both the cpumem and counters api simply allocates memory for each cpu in
the system that can be used for arbitrary per cpu data (via cpumem), or
a versioned set of counters per cpu (counters).

there is an alternate backend for uniprocessor systems that basically
turns the percpu data access into an immediate access to a single
allocation.

there is also support for percpu data structures that are available at
boot time by providing an allocation for the boot cpu. after autoconf,
these allocations have to be resized to provide for all cpus that were
enumerated by boot.

ok mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD$ */
d246 1
a246 1
	return (pool_get(pp, PR_WAITOK));
d258 1
a258 1
	return (malloc(sz, type, M_WAITOK));
@

