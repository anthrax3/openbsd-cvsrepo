head	1.17;
access;
symbols
	SMP_SYNC_A:1.17
	SMP_SYNC_B:1.17
	UBC_SYNC_A:1.17
	UBC_SYNC_B:1.17
	OPENBSD_2_9_BASE:1.15
	OPENBSD_2_9:1.15.0.2
	OPENBSD_2_8:1.12.0.8
	OPENBSD_2_8_BASE:1.12
	OPENBSD_2_7:1.12.0.6
	OPENBSD_2_7_BASE:1.12
	SMP:1.12.0.4
	SMP_BASE:1.12
	kame_19991208:1.12
	OPENBSD_2_6:1.12.0.2
	OPENBSD_2_6_BASE:1.12
	OPENBSD_2_5:1.8.0.6
	OPENBSD_2_5_BASE:1.8
	OPENBSD_2_4:1.8.0.4
	OPENBSD_2_4_BASE:1.8
	OPENBSD_2_3:1.8.0.2
	OPENBSD_2_3_BASE:1.8
	OPENBSD_2_2:1.6.0.2
	OPENBSD_2_2_BASE:1.6
	OPENBSD_2_1:1.5.0.2
	OPENBSD_2_1_BASE:1.5
	OPENBSD_2_0:1.2.0.2
	OPENBSD_2_0_BASE:1.2
	netbsd_1_1:1.1.1.1;
locks; strict;
comment	@ * @;


1.17
date	2001.06.27.04.53.31;	author art;	state dead;
branches;
next	1.16;

1.16
date	2001.05.05.20.57.04;	author art;	state Exp;
branches;
next	1.15;

1.15
date	2001.03.09.03.13.48;	author deraadt;	state Exp;
branches;
next	1.14;

1.14
date	2001.03.01.21.38.35;	author csapuntz;	state Exp;
branches;
next	1.13;

1.13
date	2001.02.24.19.07.12;	author csapuntz;	state Exp;
branches;
next	1.12;

1.12
date	99.10.11.18.04.08;	author deraadt;	state Exp;
branches
	1.12.4.1;
next	1.11;

1.11
date	99.07.06.16.53.04;	author deraadt;	state Exp;
branches;
next	1.10;

1.10
date	99.05.24.17.08.37;	author weingart;	state Exp;
branches;
next	1.9;

1.9
date	99.05.22.21.22.34;	author weingart;	state Exp;
branches;
next	1.8;

1.8
date	97.12.02.16.55.52;	author csapuntz;	state Exp;
branches;
next	1.7;

1.7
date	97.11.13.18.35.40;	author deraadt;	state Exp;
branches;
next	1.6;

1.6
date	97.08.18.13.55.59;	author niklas;	state Exp;
branches;
next	1.5;

1.5
date	97.05.22.07.26.53;	author deraadt;	state Exp;
branches;
next	1.4;

1.4
date	97.04.10.13.48.51;	author deraadt;	state Exp;
branches;
next	1.3;

1.3
date	97.02.17.07.38.20;	author mickey;	state Exp;
branches;
next	1.2;

1.2
date	96.03.03.17.45.38;	author niklas;	state Exp;
branches;
next	1.1;

1.1
date	95.10.18.08.53.38;	author deraadt;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	95.10.18.08.53.38;	author deraadt;	state Exp;
branches;
next	;

1.12.4.1
date	2001.05.14.22.47.51;	author niklas;	state Exp;
branches;
next	1.12.4.2;

1.12.4.2
date	2001.07.04.11.01.29;	author niklas;	state dead;
branches;
next	;


desc
@@


1.17
log
@Die!
@
text
@/*	$OpenBSD: vm_swap.c,v 1.16 2001/05/05 20:57:04 art Exp $	*/
/*	$NetBSD: vm_swap.c,v 1.64 1998/11/08 19:45:17 mycroft Exp $	*/

/*
 * Copyright (c) 1995, 1996, 1997 Matthew R. Green, Tobias Weingartner
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. The name of the author may not be used to endorse or promote products
 *    derived from this software without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR
 * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
 * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
 * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,
 * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
 * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
 * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/buf.h>
#include <sys/proc.h>
#include <sys/namei.h>
#include <sys/disklabel.h>
#include <sys/dmap.h>
#include <sys/errno.h>
#include <sys/kernel.h>
#include <sys/malloc.h>
#include <sys/lock.h>
#include <sys/vnode.h>
#include <sys/map.h>
#include <sys/file.h>
#include <sys/stat.h>
#include <sys/extent.h>
#include <sys/swap.h>
#include <sys/mount.h>
#include <sys/syscallargs.h>

#include <machine/vmparam.h>

#include <vm/vm_conf.h>

#include <miscfs/specfs/specdev.h>

/*
 * The idea here is to provide a single interface for multiple swap devices,
 * of any kind and priority in a simple and fast way.
 *
 * Each swap device has these properties:
 *	* swap in use.
 *	* swap enabled.
 *	* map information in `/dev/drum'.
 *	* vnode pointer.
 * Files have these additional properties:
 *	* block size.
 *	* maximum byte count in buffer.
 *	* buffer.
 *	* credentials.
 *
 * The arguments to swapctl(2) are:
 *	int cmd;
 *	void *arg;
 *	int misc;
 * The cmd can be one of:
 *	SWAP_NSWAP - swapctl(2) returns the number of swap devices currently in
 *		use.
 *	SWAP_STATS - swapctl(2) takes a struct ent * in (void *arg) and writes
 *		misc or fewer (to zero) entries of configured swap devices,
 *		and returns the number of entries written or -1 on error.
 *	SWAP_ON - swapctl(2) takes a (char *) in arg to be the pathname of a
 *		device or file to begin swapping on, with it's priority in
 *		misc, returning 0 on success and -1 on error.
 *	SWAP_OFF - swapctl(2) takes a (char *) n arg to be the pathname of a
 *		device or file to stop swapping on.  returning 0 or -1.
 *		XXX unwritten.
 *	SWAP_CTL - swapctl(2) changes the priority of a swap device, using the
 *		misc value.
 */

#ifdef SWAPDEBUG
#define STATIC
#define VMSDB_SWON	0x0001
#define VMSDB_SWOFF	0x0002
#define VMSDB_SWINIT	0x0004
#define VMSDB_SWALLOC	0x0008
#define VMSDB_SWFLOW	0x0010
#define VMSDB_INFO	0x0020
int vmswapdebug = 0;
int vmswap_domount = 1;

#define DPRINTF(f, m) do {		\
	if (vmswapdebug & (f))		\
		printf m;		\
} while(0)
#else
#define STATIC static
#define DPRINTF(f, m)
#endif

#define SWAP_TO_FILES

struct swapdev {
	struct swapent		swd_se;
#define swd_dev			swd_se.se_dev
#define swd_flags		swd_se.se_flags
#define swd_nblks		swd_se.se_nblks
#define swd_inuse		swd_se.se_inuse
#define swd_priority		swd_se.se_priority
#define swd_path		swd_se.se_path
	daddr_t			swd_mapoffset;
	int			swd_mapsize;
	struct extent		*swd_ex;
	struct vnode		*swd_vp;
	CIRCLEQ_ENTRY(swapdev)	swd_next;

#ifdef SWAP_TO_FILES
	int			swd_bsize;
	int			swd_maxactive;
	struct buf		swd_tab;
	struct ucred		*swd_cred;
#endif
};

/*
 * Swap device priority entry; the list is kept sorted on `spi_priority'.
 */
struct swappri {
	int			spi_priority;
	CIRCLEQ_HEAD(spi_swapdev, swapdev)	spi_swapdev;
	LIST_ENTRY(swappri)	spi_swappri;
};




/*
 * The following two structures are used to keep track of data transfers
 * on swap devices associated with regular files.
 * NOTE: this code is more or less a copy of vnd.c; we use the same
 * structure names here to ease porting..
 */


struct vndxfer {
	struct buf	*vx_bp;			/* Pointer to parent buffer */
	struct swapdev	*vx_sdp;
	int		vx_error;
	int		vx_pending;		/* # of pending aux buffers */
	int		vx_flags;
#define VX_BUSY		1
#define VX_DEAD		2
};


struct vndbuf {
	struct buf	vb_buf;
	struct vndxfer	*vb_xfer;
};

/* To get from a buffer to the encapsulating vndbuf */
#define BUF_TO_VNDBUF(bp) \
	((struct vndbuf *)((long)bp - ((long)&((struct vndbuf *)0)->vb_buf)))

/* vnd macro stuff, rewritten to use malloc()/free() */
#define getvndxfer()							\
	(struct vndxfer *)malloc(sizeof(struct vndxfer), M_VMSWAP, M_WAITOK);

#define putvndxfer(vnx)							\
	free(vnx, M_VMSWAP)

#define getvndbuf()							\
	(struct vndbuf *)malloc(sizeof(struct vndbuf), M_VMSWAP, M_WAITOK);

#define putvndbuf(vbp)							\
	free(vbp, M_VMSWAP)


int nswapdev;
int swflags;
struct extent *swapmap;
LIST_HEAD(swap_priority, swappri) swap_priority;

STATIC int swap_on __P((struct proc *, struct swapdev *));
#ifdef SWAP_OFF_WORKS
STATIC int swap_off __P((struct proc *, struct swapdev *));
#endif
STATIC struct swapdev *swap_getsdpfromaddr __P((daddr_t));
STATIC void swap_addmap __P((struct swapdev *, int));

#ifdef SWAP_TO_FILES
STATIC void sw_reg_strategy __P((struct swapdev *, struct buf *, int));
STATIC void sw_reg_iodone __P((struct buf *));
STATIC void sw_reg_start __P((struct swapdev *));
#endif

STATIC void insert_swapdev __P((struct swapdev *, int));
STATIC struct swapdev *find_swapdev __P((struct vnode *, int));
STATIC void swaplist_trim __P((void));

STATIC void swapmount __P((void));

/*
 * We use two locks to protect the swap device lists.
 * The long-term lock is used only used to prevent races in
 * concurrently executing swapctl(2) system calls.
 */
struct simplelock	swaplist_lock;
struct lock		swaplist_change_lock;

/*
 * Insert a swap device on the priority list.
 */
void
insert_swapdev(sdp, priority)
	struct swapdev *sdp;
	int priority;
{
	struct swappri *spp, *pspp;

again:
	simple_lock(&swaplist_lock);

	/*
	 * Find entry at or after which to insert the new device.
	 */
	for (pspp = NULL, spp = swap_priority.lh_first; spp != NULL;
	     spp = spp->spi_swappri.le_next) {
		if (priority <= spp->spi_priority)
			break;
		pspp = spp;
	}

	if (spp == NULL || spp->spi_priority != priority) {
		spp = (struct swappri *)
			malloc(sizeof *spp, M_VMSWAP, M_NOWAIT);

		if (spp == NULL) {
			simple_unlock(&swaplist_lock);
			tsleep((caddr_t)&lbolt, PSWP, "memory", 0);
			goto again;
		}
		DPRINTF(VMSDB_SWFLOW,
			("sw: had to create a new swappri = %d\n", priority));

		spp->spi_priority = priority;
		CIRCLEQ_INIT(&spp->spi_swapdev);

		if (pspp)
			LIST_INSERT_AFTER(pspp, spp, spi_swappri);
		else
			LIST_INSERT_HEAD(&swap_priority, spp, spi_swappri);

	}
	/* Onto priority list */
	CIRCLEQ_INSERT_TAIL(&spp->spi_swapdev, sdp, swd_next);
	sdp->swd_priority = priority;
	simple_unlock(&swaplist_lock);
}

/*
 * Find and optionally remove a swap device from the priority list.
 */
struct swapdev *
find_swapdev(vp, remove)
	struct vnode *vp;
	int remove;
{
	struct swapdev *sdp;
	struct swappri *spp;

	simple_lock(&swaplist_lock);
	for (spp = swap_priority.lh_first; spp != NULL;
	     spp = spp->spi_swappri.le_next) {
		for (sdp = spp->spi_swapdev.cqh_first;
		     sdp != (void *)&spp->spi_swapdev;
		     sdp = sdp->swd_next.cqe_next)
			if (sdp->swd_vp == vp) {
				if (remove)
					CIRCLEQ_REMOVE(&spp->spi_swapdev, sdp,
							swd_next);
				simple_unlock(&swaplist_lock);
				return (sdp);
			}
	}
	simple_unlock(&swaplist_lock);
	return (NULL);
}

/*
 * Scan priority list for empty priority entries.
 */
void
swaplist_trim()
{
	struct swappri *spp;

	simple_lock(&swaplist_lock);
restart:
	for (spp = swap_priority.lh_first; spp != NULL;
	     spp = spp->spi_swappri.le_next) {
		if (spp->spi_swapdev.cqh_first != (void *)&spp->spi_swapdev)
			continue;
		LIST_REMOVE(spp, spi_swappri);
		free((caddr_t)spp, M_VMSWAP);
		goto restart;
	}
	simple_unlock(&swaplist_lock);
}

int
sys_swapctl(p, v, retval)
	struct proc *p;
	void *v;
	register_t *retval;
{
	struct sys_swapctl_args /* {
		syscallarg(int) cmd;
		syscallarg(const void *) arg;
		syscallarg(int) misc;
	} */ *uap = (struct sys_swapctl_args *)v;
	struct vnode *vp;
	struct nameidata nd;
	struct swappri *spp;
	struct swapdev *sdp;
	struct swapent *sep;
	char	userpath[MAXPATHLEN];
	int	count, error, misc;
	size_t	len;
	int	priority;

	misc = SCARG(uap, misc);

	DPRINTF(VMSDB_SWFLOW, ("entering sys_swapctl\n"));
	
	/* how many swap devices */
	if (SCARG(uap, cmd) == SWAP_NSWAP) {
		DPRINTF(VMSDB_SWFLOW,("did SWAP_NSWAP: leaving sys_swapctl\n"));
		*retval = nswapdev;
		return (0);
	}

	/* stats on the swap devices. */
	if (SCARG(uap, cmd) == SWAP_STATS) {
		sep = (struct swapent *)SCARG(uap, arg);
		count = 0;

		error = lockmgr(&swaplist_change_lock, LK_SHARED, (void *)0, p);
		if (error)
			return (error);
		for (spp = swap_priority.lh_first; spp != NULL;
		    spp = spp->spi_swappri.le_next) {
			for (sdp = spp->spi_swapdev.cqh_first;
			     sdp != (void *)&spp->spi_swapdev && misc-- > 0;
			     sdp = sdp->swd_next.cqe_next, sep++, count++) {
			  	/*
				 * We do not do NetBSD 1.3 compat call.
				 */
				error = copyout((caddr_t)&sdp->swd_se,
				    (caddr_t)sep, sizeof(struct swapent));

				if (error)
					goto out;
			}
		}
out:
		(void)lockmgr(&swaplist_change_lock, LK_RELEASE, (void *)0, p);
		if (error)
			return (error);

		DPRINTF(VMSDB_SWFLOW,("did SWAP_STATS: leaving sys_swapctl\n"));

		*retval = count;
		return (0);
	} 
	if ((error = suser(p->p_ucred, &p->p_acflag)))
		return (error);

	if (SCARG(uap, arg) == NULL) {
		/* XXX - interface - arg==NULL: miniroot */
		vp = rootvp;
		if (vget(vp, LK_EXCLUSIVE, p))
			return (EBUSY);
		if (SCARG(uap, cmd) == SWAP_ON &&
		    copystr("miniroot", userpath, sizeof userpath, &len))
			panic("swapctl: miniroot copy failed");
	} else {
		int	space;
		char	*where;

		if (SCARG(uap, cmd) == SWAP_ON) {
			if ((error = copyinstr(SCARG(uap, arg), userpath,
			    sizeof userpath, &len)))
				return (error);
			space = UIO_SYSSPACE;
			where = userpath;
		} else {
			space = UIO_USERSPACE;
			where = (char *)SCARG(uap, arg);
		}
		NDINIT(&nd, LOOKUP, FOLLOW|LOCKLEAF, space, where, p);
		if ((error = namei(&nd)))
			return (error);

		vp = nd.ni_vp;
	}

	error = lockmgr(&swaplist_change_lock, LK_EXCLUSIVE, (void *)0, p);
	if (error)
		goto bad2;

	switch(SCARG(uap, cmd)) {
	case SWAP_CTL:
		priority = SCARG(uap, misc);
		if ((sdp = find_swapdev(vp, 1)) == NULL) {
			error = ENOENT;
			break;
		}
		insert_swapdev(sdp, priority);
		swaplist_trim();
		break;

	case SWAP_ON:
		priority = SCARG(uap, misc);

		/* Check for duplicates */
		if ((sdp = find_swapdev(vp, 0)) != NULL) {
			if (!bcmp(sdp->swd_path, "swap_device", 12)) {
				copystr(userpath, sdp->swd_path, len, 0);
				error = 0;
			} else
				error = EBUSY;
			goto bad;
		}

		sdp = (struct swapdev *)
			malloc(sizeof *sdp, M_VMSWAP, M_WAITOK);
		bzero(sdp, sizeof(*sdp));

		sdp->swd_vp = vp;
		sdp->swd_dev = (vp->v_type == VBLK) ? vp->v_rdev : NODEV;

		if ((error = swap_on(p, sdp)) != 0) {
			free((caddr_t)sdp, M_VMSWAP);
			break;
		}
#ifdef SWAP_TO_FILES
		/*
		 * XXX Is NFS elaboration necessary?
		 */
		if (vp->v_type == VREG)
			sdp->swd_cred = crdup(p->p_ucred);
#endif
		if (copystr(userpath, sdp->swd_path, len, 0) != 0)
			panic("swapctl: copystr");
		insert_swapdev(sdp, priority);

		/* Keep reference to vnode */
		vref(vp);
		break;

	case SWAP_OFF:
		DPRINTF(VMSDB_SWFLOW, ("doing SWAP_OFF...\n"));
#ifdef SWAP_OFF_WORKS
		if ((sdp = find_swapdev(vp, 0)) == NULL) {
			error = ENXIO;
			break;
		}
		/*
		 * If a device isn't in use or enabled, we
		 * can't stop swapping from it (again).
		 */
		if ((sdp->swd_flags &
		    (SWF_INUSE|SWF_ENABLE)) == 0) {
			error = EBUSY;
			goto bad;
		}
		if ((error = swap_off(p, sdp)) != 0)
			goto bad;

		/* Find again and remove this time */
		if ((sdp = find_swapdev(vp, 1)) == NULL) {
			error = ENXIO;
			break;
		}
		free((caddr_t)sdp, M_VMSWAP);
#else
		error = ENODEV;
#endif
		break;

	default:
		DPRINTF(VMSDB_SWFLOW,
			("unhandled command: %x\n", SCARG(uap, cmd)));
		error = EINVAL;
	}

bad:
	(void)lockmgr(&swaplist_change_lock, LK_RELEASE, (void *)0, p);
bad2:
	vput(vp);

	DPRINTF(VMSDB_SWFLOW, ("leaving sys_swapctl: error %d\n", error));
	return (error);
}

/*
 * swap_on() attempts to begin swapping on a swapdev.  we check that this
 * device is OK to swap from, miss the start of any disk (to avoid any
 * disk labels that may exist).
 */
STATIC int
swap_on(p, sdp)
	struct proc *p;
	struct swapdev *sdp;
{
	static int count = 0;
	struct vnode *vp = sdp->swd_vp;
	int error, nblks, size;
	long addr;
	char *storage;
	int storagesize;
#ifdef SWAP_TO_FILES
	struct vattr va;
#endif
#ifdef NFSCLIENT
	extern int (**nfsv2_vnodeop_p) __P((void *));
#endif /* NFSCLIENT */
	dev_t dev = sdp->swd_dev;
	char *name;


	/* If root on swap, then the skip open/close operations. */
	if (vp != rootvp) {
		if ((error = VOP_OPEN(vp, FREAD|FWRITE, p->p_ucred, p)))
			return (error);
		vp->v_writecount++;
	}

	DPRINTF(VMSDB_INFO,
		("swap_on: dev = %d, major(dev) = %d\n", dev, major(dev)));

	switch (vp->v_type) {
	case VBLK:
		if (bdevsw[major(dev)].d_psize == 0 ||
		    (nblks = (*bdevsw[major(dev)].d_psize)(dev)) == -1) {
			error = ENXIO;
			goto bad;
		}
		break;

#ifdef SWAP_TO_FILES
	case VREG:
		if ((error = VOP_GETATTR(vp, &va, p->p_ucred, p)))
			goto bad;
		nblks = (int)btodb(va.va_size);
		if ((error =
		     VFS_STATFS(vp->v_mount, &vp->v_mount->mnt_stat, p)) != 0)
			goto bad;

		sdp->swd_bsize = vp->v_mount->mnt_stat.f_iosize;
#ifdef NFSCLIENT
		if (vp->v_op == nfsv2_vnodeop_p)
			sdp->swd_maxactive = 2; /* XXX */
		else
#endif /* NFSCLIENT */
			sdp->swd_maxactive = 8; /* XXX */
		break;
#endif

	default:
		error = ENXIO;
		goto bad;
	}
	if (nblks == 0) {
		DPRINTF(VMSDB_SWFLOW, ("swap_on: nblks == 0\n"));
		error = EINVAL;
		goto bad;
	}

	sdp->swd_flags |= SWF_INUSE;
	sdp->swd_nblks = nblks;

	/*
	 * skip over first cluster of a device in case of labels or
	 * boot blocks.
	 */
	if (vp->v_type == VBLK) {
		size = (int)(nblks - ctod(1));
		addr = (long)ctod(1);
	} else {
		size = (int)nblks;
		addr = (long)0;
	}

	DPRINTF(VMSDB_SWON,
		("swap_on: dev %x: size %d, addr %ld\n", dev, size, addr));

	name = malloc(12, M_VMSWAP, M_WAITOK);
	sprintf(name, "swap0x%04x", count++);
	/* XXX make this based on ram as well. */
	storagesize = EXTENT_FIXED_STORAGE_SIZE(maxproc * 2);
	storage = malloc(storagesize, M_VMSWAP, M_WAITOK);
	sdp->swd_ex = extent_create(name, 0, nblks, M_VMSWAP,
				    storage, storagesize, EX_WAITOK);
	if (addr) {
		if (extent_alloc_region(sdp->swd_ex, 0, addr, EX_WAITOK))
			panic("disklabel region");
		sdp->swd_inuse += addr;
	}


	if (vp == rootvp) {
		struct mount *mp;
		struct statfs *sp;
		int rootblks;

		/* Get size from root FS (mountroot did statfs) */
		mp = rootvnode->v_mount;
		sp = &mp->mnt_stat;
		rootblks = sp->f_blocks * (sp->f_bsize / DEV_BSIZE);
		if (rootblks > nblks)
			panic("miniroot size");

		if (extent_alloc_region(sdp->swd_ex, addr, rootblks, EX_WAITOK))
			panic("miniroot region");

		printf("Preserved %d blocks, leaving %d pages of swap\n",
		    rootblks, dtoc(size - rootblks));
	}

	swap_addmap(sdp, size);
	nswapdev++;
	sdp->swd_flags |= SWF_ENABLE;
	return (0);

bad:
	if (vp != rootvp) {
		vp->v_writecount--;
		(void)VOP_CLOSE(vp, FREAD|FWRITE, p->p_ucred, p);
	}
	return (error);
}

#ifdef SWAP_OFF_WORKS
STATIC int
swap_off(p, sdp)
	struct proc *p;
	struct swapdev *sdp;
{
	char	*name;

	/* turn off the enable flag */
	sdp->swd_flags &= ~SWF_ENABLE;

	DPRINTF(VMSDB_SWOFF, ("swap_off: %x\n", sdp->swd_dev));

	/*
	 * XXX write me
	 *
	 * the idea is to find out which processes are using this swap
	 * device, and page them all in.
	 *
	 * eventually, we should try to move them out to other swap areas
	 * if available.
	 *
	 * The alternative is to create a redirection map for this swap
	 * device.  This should work by moving all the pages of data from
	 * the ex-swap device to another one, and making an entry in the
	 * redirection map for it.  locking is going to be important for
	 * this!
	 *
	 * There might be an easier way to do a "soft" swapoff.  First
	 * we mark the particular swap partition as not desirable anymore.
	 * Then we use the pager to page a couple of pages in, each time
	 * it has the memory, and the chance to do so.  Thereby moving pages
	 * back into memory.  Once they are in memory, when they get paged
	 * out again, they do not go back onto the "undesirable" device
	 * anymore, but to good devices.  This might take longer, but it
	 * can certainly work.  If need be, the user process can sleep on
	 * the particular sdp entry, and the swapper can then wake him up
	 * when everything is done.
	 */

	/* until the above code is written, we must ENODEV */
	return ENODEV;

	extent_free(swapmap, sdp->swd_mapoffset, sdp->swd_mapsize, EX_WAITOK);
	nswapdev--;
	name = sdp->swd_ex->ex_name;
	extent_destroy(sdp->swd_ex);
	free(name, M_VMSWAP);
	free((caddr_t)sdp->swd_ex, M_VMSWAP);
	if (sdp->swp_vp != rootvp) {
		vp->v_writecount--;
		(void) VOP_CLOSE(sdp->swd_vp, FREAD|FWRITE, p->p_ucred, p);
	}
	if (sdp->swd_vp)
		vrele(sdp->swd_vp);
	free((caddr_t)sdp, M_VMSWAP);
	return (0);
}
#endif

/*
 * To decide where to allocate what part of swap, we must "round robin"
 * the swap devices in swap_priority of the same priority until they are
 * full.  we do this with a list of swap priorities that have circle
 * queues of swapdevs.
 *
 * The following functions control allocation and freeing of part of the
 * swap area.  you call swap_alloc() with a size and it returns an address.
 * later you call swap_free() and it frees the use of that swap area.
 *
 *	daddr_t swap_alloc(int size);
 *	void swap_free(int size, daddr_t addr);
 */

daddr_t
swap_alloc(size)
	int size;
{
	struct swapdev *sdp;
	struct swappri *spp;
	u_long	result;

	if (nswapdev < 1)
		return 0;
	
	simple_lock(&swaplist_lock);
	for (spp = swap_priority.lh_first; spp != NULL;
	     spp = spp->spi_swappri.le_next) {
		for (sdp = spp->spi_swapdev.cqh_first;
		     sdp != (void *)&spp->spi_swapdev;
		     sdp = sdp->swd_next.cqe_next) {
			/* if it's not enabled, then we can't swap from it */
			if ((sdp->swd_flags & SWF_ENABLE) == 0 ||
			    /* XXX IS THIS CORRECT ? */
#if 1
			    (sdp->swd_inuse + size > sdp->swd_nblks) ||
#endif
			    extent_alloc(sdp->swd_ex, size, EX_NOALIGN,
					 EX_NOBOUNDARY, EX_MALLOCOK|EX_NOWAIT,
					 &result) != 0) {
				continue;
			}
			CIRCLEQ_REMOVE(&spp->spi_swapdev, sdp, swd_next);
			CIRCLEQ_INSERT_TAIL(&spp->spi_swapdev, sdp, swd_next);
			sdp->swd_inuse += size;
			simple_unlock(&swaplist_lock);
			return (daddr_t)(result + sdp->swd_mapoffset);
		}
	}
	simple_unlock(&swaplist_lock);
	return 0;
}

void
swap_free(size, addr)
	int size;
	daddr_t addr;
{
	struct swapdev *sdp = swap_getsdpfromaddr(addr);

#ifdef DIAGNOSTIC
	if (sdp == NULL)
		panic("swap_free: unmapped address\n");
	if (nswapdev < 1)
		panic("swap_free: nswapdev < 1\n");
#endif
	extent_free(sdp->swd_ex, addr - sdp->swd_mapoffset, size,
		    EX_MALLOCOK|EX_NOWAIT);
	sdp->swd_inuse -= size;
#ifdef DIAGNOSTIC
	if (sdp->swd_inuse < 0)
		panic("swap_free: inuse < 0");
#endif
}

/*
 * We have a physical -> virtual mapping to address here.  There are several
 * different physical address spaces (one for each swap partition) that are
 * to be mapped onto a single virtual address space.
 */
#define ADDR_IN_MAP(addr, sdp) \
	(((addr) >= (sdp)->swd_mapoffset) && \
 	 ((addr) < ((sdp)->swd_mapoffset + (sdp)->swd_mapsize)))

struct swapdev *
swap_getsdpfromaddr(addr)
	daddr_t addr;
{
	struct swapdev *sdp;
	struct swappri *spp;
	
	simple_lock(&swaplist_lock);
	for (spp = swap_priority.lh_first; spp != NULL;
	     spp = spp->spi_swappri.le_next)
		for (sdp = spp->spi_swapdev.cqh_first;
		     sdp != (void *)&spp->spi_swapdev;
		     sdp = sdp->swd_next.cqe_next)
			if (ADDR_IN_MAP(addr, sdp)) {
				simple_unlock(&swaplist_lock);
				return sdp;
			}
	simple_unlock(&swaplist_lock);
	return NULL;
}

void
swap_addmap(sdp, size)
	struct swapdev *sdp;
	int	size;
{
	u_long result;

	if (extent_alloc(swapmap, size, EX_NOALIGN, EX_NOBOUNDARY,
			 EX_WAITOK, &result))
		panic("swap_addmap");

	sdp->swd_mapoffset = result;
	sdp->swd_mapsize = size;
}

/*ARGSUSED*/
int
swread(dev, uio, ioflag)
	dev_t dev;
	struct uio *uio;
	int ioflag;
{

	return (physio(swstrategy, NULL, dev, B_READ, minphys, uio));
}

/*ARGSUSED*/
int
swwrite(dev, uio, ioflag)
	dev_t dev;
	struct uio *uio;
	int ioflag;
{

	return (physio(swstrategy, NULL, dev, B_WRITE, minphys, uio));
}

void
swstrategy(bp)
	struct buf *bp;
{
	struct swapdev *sdp;
	daddr_t	bn;
	int s;

	bn = bp->b_blkno;
	sdp = swap_getsdpfromaddr(bn);
	if (sdp == NULL) {
		bp->b_error = EINVAL;
		bp->b_flags |= B_ERROR;
		biodone(bp);
		return;
	}

	bn -= sdp->swd_mapoffset;

	DPRINTF(VMSDB_SWFLOW,
		("swstrategy(%s): mapoff %x, bn %x, bcount %ld\n",
			((bp->b_flags & B_READ) == 0) ? "write" : "read",
			sdp->swd_mapoffset, bn, bp->b_bcount));

	switch (sdp->swd_vp->v_type) {
	default:
		panic("swstrategy: vnode type %x", sdp->swd_vp->v_type);
	case VBLK:
		s = splbio();
		buf_replacevnode(bp, sdp->swd_vp);
		bp->b_blkno = bn + ctod(1);
		splx(s);
		VOP_STRATEGY(bp);
		return;
#ifdef SWAP_TO_FILES
	case VREG:
		sw_reg_strategy(sdp, bp, bn);
		return;
#endif
	}
	/* NOTREACHED */
}

#ifdef SWAP_TO_FILES

STATIC void
sw_reg_strategy(sdp, bp, bn)
	struct swapdev	*sdp;
	struct buf	*bp;
	int		bn;
{
	struct vnode	*vp;
	struct vndxfer	*vnx;
	daddr_t		nbn;
	caddr_t		addr;
	int		s, off, nra, error, sz, resid;

	/*
	 * Translate the device logical block numbers into physical
	 * block numbers of the underlying filesystem device.
	 */
	bp->b_resid = bp->b_bcount;
	addr = bp->b_data;
	bn   = dbtob(bn);

	/* Allocate a header for this transfer and link it to the buffer */
	vnx = getvndxfer();
	vnx->vx_flags = VX_BUSY;
	vnx->vx_error = 0;
	vnx->vx_pending = 0;
	vnx->vx_bp = bp;
	vnx->vx_sdp = sdp;

	error = 0;
	for (resid = bp->b_resid; resid; resid -= sz) {
		struct vndbuf	*nbp;

		nra = 0;
		error = VOP_BMAP(sdp->swd_vp, bn / sdp->swd_bsize,
				 	&vp, &nbn, &nra);

		if (error == 0 && (long)nbn == -1)
			error = EIO;

		/*
		 * If there was an error or a hole in the file...punt.
		 * Note that we may have to wait for any operations
		 * that we have already fired off before releasing
		 * the buffer.
		 *
		 * XXX we could deal with holes here but it would be
		 * a hassle (in the write case).
		 */
		if (error) {
			s = splbio();
			vnx->vx_error = error;
			goto out;
		}

		if ((off = bn % sdp->swd_bsize) != 0)
			sz = sdp->swd_bsize - off;
		else
			sz = (1 + nra) * sdp->swd_bsize;

		if (resid < sz)
			sz = resid;

		DPRINTF(VMSDB_SWFLOW,
			("sw_reg_strategy: vp %p/%p bn 0x%x/0x%x"
				" sz 0x%x\n", sdp->swd_vp, vp, bn, nbn, sz));

		nbp = getvndbuf();
		nbp->vb_buf.b_flags    = bp->b_flags | B_NOCACHE | B_CALL;
		nbp->vb_buf.b_bcount   = sz;
		nbp->vb_buf.b_bufsize  = bp->b_bufsize;
		nbp->vb_buf.b_error    = 0;
		nbp->vb_buf.b_data     = addr;
		nbp->vb_buf.b_blkno    = nbn + btodb(off);
		nbp->vb_buf.b_proc     = bp->b_proc;
		nbp->vb_buf.b_iodone   = sw_reg_iodone;
		nbp->vb_buf.b_vp       = NULLVP;
		nbp->vb_buf.b_rcred    = sdp->swd_cred;
		nbp->vb_buf.b_wcred    = sdp->swd_cred;
		if (bp->b_dirtyend == 0) {
			nbp->vb_buf.b_dirtyoff = 0;
			nbp->vb_buf.b_dirtyend = sz;
		} else {
			nbp->vb_buf.b_dirtyoff =
			    max(0, bp->b_dirtyoff - (bp->b_bcount-resid));
			nbp->vb_buf.b_dirtyend =
			    min(sz,
				max(0, bp->b_dirtyend - (bp->b_bcount-resid)));
		}
		if (bp->b_validend == 0) {
			nbp->vb_buf.b_validoff = 0;
			nbp->vb_buf.b_validend = sz;
		} else {
			nbp->vb_buf.b_validoff =
			    max(0, bp->b_validoff - (bp->b_bcount-resid));
			nbp->vb_buf.b_validend =
			    min(sz,
				max(0, bp->b_validend - (bp->b_bcount-resid)));
		}

		nbp->vb_xfer = vnx;

		/*
		 * Just sort by block number
		 */
		nbp->vb_buf.b_cylinder = nbp->vb_buf.b_blkno;
		s = splbio();
		if (vnx->vx_error != 0) {
			putvndbuf(nbp);
			goto out;
		}
		vnx->vx_pending++;
		bgetvp(vp, &nbp->vb_buf);
		disksort(&sdp->swd_tab, &nbp->vb_buf);
		sw_reg_start(sdp);
		splx(s);

		bn   += sz;
		addr += sz;
	}

	s = splbio();

out: /* Arrive here at splbio */
	vnx->vx_flags &= ~VX_BUSY;
	if (vnx->vx_pending == 0) {
		if (vnx->vx_error != 0) {
			bp->b_error = vnx->vx_error;
			bp->b_flags |= B_ERROR;
		}
		putvndxfer(vnx);
		biodone(bp);
	}
	splx(s);
}

/*
 * Feed requests sequentially.
 * We do it this way to keep from flooding NFS servers if we are connected
 * to an NFS file.  This places the burden on the client rather than the
 * server.
 */
STATIC void
sw_reg_start(sdp)
	struct swapdev	*sdp;
{
	struct buf	*bp;

	if ((sdp->swd_flags & SWF_BUSY) != 0)
		/* Recursion control */
		return;

	sdp->swd_flags |= SWF_BUSY;

	while (sdp->swd_tab.b_active < sdp->swd_maxactive) {
		bp = sdp->swd_tab.b_actf;
		if (bp == NULL)
			break;
		sdp->swd_tab.b_actf = bp->b_actf;
		sdp->swd_tab.b_active++;

		DPRINTF(VMSDB_SWFLOW,
			("sw_reg_start: bp %p vp %p blkno %x addr %p cnt %lx\n",
			bp, bp->b_vp, bp->b_blkno,bp->b_data, bp->b_bcount));

		if ((bp->b_flags & B_READ) == 0)
			bp->b_vp->v_numoutput++;
		VOP_STRATEGY(bp);
	}
	sdp->swd_flags &= ~SWF_BUSY;
}

STATIC void
sw_reg_iodone(bp)
	struct buf *bp;
{
	register struct vndbuf *vbp = BUF_TO_VNDBUF(bp);
	register struct vndxfer *vnx = (struct vndxfer *)vbp->vb_xfer;
	register struct buf *pbp = vnx->vx_bp;
	struct swapdev	*sdp = vnx->vx_sdp;
	int		s, resid;

	DPRINTF(VMSDB_SWFLOW,
		("sw_reg_iodone: vbp %p vp %p blkno %x addr %p "
			"cnt %lx(%lx)\n",
			vbp, vbp->vb_buf.b_vp, vbp->vb_buf.b_blkno,
			vbp->vb_buf.b_data, vbp->vb_buf.b_bcount,
			vbp->vb_buf.b_resid));

	s = splbio();
	resid = vbp->vb_buf.b_bcount - vbp->vb_buf.b_resid;
	pbp->b_resid -= resid;
	vnx->vx_pending--;

	if (vbp->vb_buf.b_error) {
		DPRINTF(VMSDB_INFO, ("sw_reg_iodone: vbp %p error %d\n", vbp,
					vbp->vb_buf.b_error));

		vnx->vx_error = vbp->vb_buf.b_error;
	}

	if (vbp->vb_buf.b_vp != NULLVP)
		brelvp(&vbp->vb_buf);

	putvndbuf(vbp);

	/*
	 * Wrap up this transaction if it has run to completion or, in
	 * case of an error, when all auxiliary buffers have returned.
	 */
	if (vnx->vx_error != 0) {
		pbp->b_flags |= B_ERROR;
		pbp->b_error = vnx->vx_error;
		if ((vnx->vx_flags & VX_BUSY) == 0 && vnx->vx_pending == 0) {

			DPRINTF(VMSDB_SWFLOW,
				("swiodone: pbp %p iodone: error %d\n",
				pbp, vnx->vx_error));
			putvndxfer(vnx);
			biodone(pbp);
		}
	} else if (pbp->b_resid == 0) {

#ifdef DIAGNOSTIC
		if (vnx->vx_pending != 0)
			panic("swiodone: vnx pending: %d", vnx->vx_pending);
#endif

		if ((vnx->vx_flags & VX_BUSY) == 0) {
			DPRINTF(VMSDB_SWFLOW,
				("swiodone: pbp %p iodone\n", pbp));
			putvndxfer(vnx);
			biodone(pbp);
		}
	}

	sdp->swd_tab.b_active--;
	sw_reg_start(sdp);

	splx(s);
}
#endif /* SWAP_TO_FILES */

void
swapinit()
{
	struct buf *sp = swbuf;
	struct proc *p = &proc0;       /* XXX */
	int i;

	DPRINTF(VMSDB_SWINIT, ("swapinit\n"));

	nswapdev = 0;
	if (bdevvp(swapdev, &swapdev_vp))
		panic("swapinit: can not setup swapdev_vp");

	simple_lock_init(&swaplist_lock);
	lockinit(&swaplist_change_lock, PSWP, "swap change", 0, 0);
	LIST_INIT(&swap_priority);

	/*
	 * Create swap block resource map. The range [1..INT_MAX] allows
	 * for a grand total of 2 gigablocks of swap resource.
	 * (start at 1 because "block #0" will be interpreted as
	 *  an allocation failure).
	 */
	swapmap = extent_create("swapmap", 1, INT_MAX,
				M_VMSWAP, 0, 0, EX_WAITOK);
	if (swapmap == 0)
		panic("swapinit: extent_create failed");

	/*
	 * Now set up swap buffer headers.
	 */
	bswlist.b_actf = sp;
	for (i = 0; i < nswbuf - 1; i++, sp++) {
		sp->b_actf = sp + 1;
		sp->b_rcred = sp->b_wcred = p->p_ucred;
		sp->b_vnbufs.le_next = NOLIST;
	}
	sp->b_rcred = sp->b_wcred = p->p_ucred;
	sp->b_vnbufs.le_next = NOLIST;
	sp->b_actf = NULL;

	/* Mount primary swap if available */
#ifdef SWAPDEBUG
	if(vmswap_domount)
#endif
	swapmount();

	DPRINTF(VMSDB_SWINIT, ("leaving swapinit\n"));
}

/*
 * Mount the primary swap device pointed to by 'swdevt[0]'.
 */
STATIC void
swapmount()
{
	extern int getdevvp(dev_t, struct vnode **, enum vtype);
	struct swapdev *sdp;
	struct vnode *vp = NULL;
	struct proc *p = curproc;
	dev_t swap_dev = swdevt[0].sw_dev;

	/* Make sure we have a device */
	if (swap_dev == NODEV) {
		printf("swapmount: No swap device!\n");
		return;
	}

	/* Malloc needed things */
	sdp = (struct swapdev *)malloc(sizeof *sdp, M_VMSWAP, M_WAITOK);
	bzero(sdp, sizeof(*sdp));

	/* Do swap_on() stuff */
	if(bdevvp(swap_dev, &vp)){
		printf("swapmount: bdevvp() failed\n");
		return;
	}

#ifdef SWAPDEBUG
	vprint("swapmount", vp);
#endif

	sdp->swd_vp = vp;
	sdp->swd_dev = (vp->v_type == VBLK) ? vp->v_rdev : NODEV;
	if(copystr("swap_device", sdp->swd_path, sizeof sdp->swd_path, 0) != 0){
		printf("swapmount: copystr() failed\n");
		return;
	}
		
	/* Look for a swap device */
	if (swap_on(p, sdp) != 0) {
		free((caddr_t)sdp, M_VMSWAP);
		return;
	}

#ifdef SWAP_TO_FILES
	/*
	 * XXX Is NFS elaboration necessary?
	 */
	if (vp->v_type == VREG)
		sdp->swd_cred = crdup(p->p_ucred);
#endif
	insert_swapdev(sdp, 0);
}
@


1.16
log
@Get rid of CLSIZE and all related stuff.
CLSIZE -> 1
CLBYTES -> PAGE_SIZE
OLOFSET -> PAGE_MASK
etc.
At the same time some archs needed some cleaning in vmparam.h so that
goes in at the same time.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_swap.c,v 1.15 2001/03/09 03:13:48 deraadt Exp $	*/
@


1.15
log
@PATH_MAX+1 is wrong.  Not cranking libc/libc_r majors over this, since they just got cranked a little while ago. discussion with millert
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_swap.c,v 1.14 2001/03/01 21:38:35 csapuntz Exp $	*/
d600 2
a601 2
		size = (int)(nblks - ctod(CLSIZE));
		addr = (long)ctod(CLSIZE);
d888 1
a888 1
		bp->b_blkno = bn + ctod(CLSIZE);
@


1.14
log
@

Fix compilation problems caused by last update
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_swap.c,v 1.13 2001/02/24 19:07:12 csapuntz Exp $	*/
d338 1
a338 1
	char	userpath[PATH_MAX + 1];
@


1.13
log
@

Cleanup of vnode interface continues. Get rid of VHOLD/HOLDRELE.
Change VM/UVM to use buf_replacevnode to change the vnode associated
with a buffer.

Addition v_bioflag for flags written in interrupt handlers
(and read at splbio, though not strictly necessary)

Add vwaitforio and use it instead of a while loop of v_numoutput.

Fix race conditions when manipulation vnode free list
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_swap.c,v 1.12 1999/10/11 18:04:08 deraadt Exp $	*/
d864 1
@


1.12
log
@permit builds with NFSSERVER, without NFSCLIENT; cmetz
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_swap.c,v 1.11 1999/07/06 16:53:04 deraadt Exp $	*/
a862 1
	struct vnode *vp;
d885 2
d888 1
a888 14
		vp = sdp->swd_vp;
		bp->b_dev = sdp->swd_dev;
		VHOLD(vp);
		if ((bp->b_flags & B_READ) == 0) {
			int s = splbio();
			vwakeup(bp);
			vp->v_numoutput++;
			splx(s);
		}

		if (bp->b_vp != NULL)
			brelvp(bp);

		bp->b_vp = vp;
@


1.12.4.1
log
@merge in approximately 2.9 into SMP branch
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_swap.c,v 1.15 2001/03/09 03:13:48 deraadt Exp $	*/
d338 1
a338 1
	char	userpath[MAXPATHLEN];
d863 1
a864 1
	int s;
a885 2
		s = splbio();
		buf_replacevnode(bp, sdp->swd_vp);
d887 14
a900 1
		splx(s);
@


1.12.4.2
log
@Merge in -current from two days ago in the SMP branch.
As usual with merges, they do not indicate progress, so do not hold
your breath for working SMP, and do not mail me and ask about the
state of it.  It has not changed.  There is work ongoing, but very, very
slowly.  The commit is done in parts as to not lock up the tree in too
big chunks at a time.
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_swap.c,v 1.12.4.1 2001/05/14 22:47:51 niklas Exp $	*/
@


1.11
log
@use NFSSERVER || NFSCLIENT instead of NFS
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_swap.c,v 1.10 1999/05/24 17:08:37 weingart Exp $	*/
d537 1
a537 1
#if defined(NFSSERVER) || defined(NFSCLIENT)
d539 1
a539 1
#endif /* defined(NFSSERVER) || defined(NFSCLIENT) */
d573 1
a573 1
#if defined(NFSSERVER) || defined(NFSCLIENT)
d577 1
a577 1
#endif /* defined(NFSSERVER) || defined(NFSCLIENT) */
@


1.10
log
@quieter operation during initial mounting of primary swap
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_swap.c,v 1.9 1999/05/22 21:22:34 weingart Exp $	*/
d537 1
a537 1
#ifdef NFS
d539 1
a539 1
#endif /* NFS */
d573 1
a573 1
#ifdef NFS
d577 1
a577 1
#endif /* NFS */
@


1.9
log
@Add new vm_swap code for dynamic swap.  From netbsd, munged some by me, and
others.   syscall commit pending.
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
a1245 2
	printf("Adding swap(%d, %d):", major(swap_dev), minor(swap_dev));

a1246 1
		printf(" failed!\n");
d1249 2
a1250 2
	} else
		printf(" done.\n");
@


1.8
log
@Protect some more vnode operation with splbio. Needed for correct interaction
with soft updates code.
@
text
@d1 2
a2 2
/*	$OpenBSD: vm_swap.c,v 1.7 1997/11/13 18:35:40 deraadt Exp $	*/
/*	$NetBSD: vm_swap.c,v 1.32 1996/02/05 01:54:09 christos Exp $	*/
d5 2
a6 2
 * Copyright (c) 1982, 1986, 1989, 1993
 *	The Regents of the University of California.  All rights reserved.
d16 2
a17 7
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by the University of
 *	California, Berkeley and its contributors.
 * 4. Neither the name of the University nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
d19 10
a28 13
 * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 *	@@(#)vm_swap.c	8.5 (Berkeley) 2/17/94
d36 6
a41 1
#include <sys/dmap.h>		/* XXX */
d45 3
a47 2
#include <sys/mman.h>

d51 2
a52 1
#include <vm/vm.h>
d58 95
a152 1
 * Indirect driver for multi-controller paging.
d155 43
a197 4
int	nswap, nswdev;
#ifdef SEQSWAP
int	niswdev;		/* number of interleaved swap devices */
int	niswap;			/* size of interleaved swap area */
d199 12
d212 1
a212 1
int swfree __P((struct proc *, int));
d215 9
a223 5
 * Set up swap devices.
 * Initialize linked list of free swap
 * headers. These do not actually point
 * to buffers, but rather to pages that
 * are being swapped in and out.
d226 3
a228 1
swapinit()
d230 4
a233 5
	register int i;
	register struct buf *sp = swbuf;
	register struct proc *p = &proc0;	/* XXX */
	struct swdevt *swp;
	int error;
d236 1
a236 13
	 * Count swap devices, and adjust total swap space available.
	 * Some of the space will not be countable until later (dynamically
	 * configurable devices) and some of the counted space will not be
	 * available until a swapon() system call is issued, both usually
	 * happen when the system goes multi-user.
	 *
	 * If using NFS for swap, swdevt[0] will already be bdevvp'd.	XXX
	 */
#ifdef SEQSWAP
	nswdev = niswdev = 0;
	nswap = niswap = 0;
	/*
	 * All interleaved devices must come first
d238 3
a240 2
	for (swp = swdevt; swp->sw_dev != NODEV || swp->sw_vp != NULL; swp++) {
		if (swp->sw_flags & SW_SEQUENTIAL)
d242 11
a252 20
		niswdev++;
		if (swp->sw_nblks > niswap)
			niswap = swp->sw_nblks;
	}
	niswap = roundup(niswap, dmmax);
	niswap *= niswdev;
	if (swdevt[0].sw_vp == NULL &&
	    bdevvp(swdevt[0].sw_dev, &swdevt[0].sw_vp))
		panic("swapvp");
	/*
	 * The remainder must be sequential
	 */
	for ( ; swp->sw_dev != NODEV; swp++) {
		if ((swp->sw_flags & SW_SEQUENTIAL) == 0)
			panic("binit: mis-ordered swap devices");
		nswdev++;
		if (swp->sw_nblks > 0) {
			if (swp->sw_nblks % dmmax)
				swp->sw_nblks -= (swp->sw_nblks % dmmax);
			nswap += swp->sw_nblks;
d254 11
d266 30
a295 28
	nswdev += niswdev;
	if (nswdev == 0)
		panic("swapinit");
	nswap += niswap;
#else
	nswdev = 0;
	nswap = 0;
	for (swp = swdevt; swp->sw_dev != NODEV || swp->sw_vp != NULL; swp++) {
		nswdev++;
		if (swp->sw_nblks > nswap)
			nswap = swp->sw_nblks;
	}
	if (nswdev == 0)
		panic("swapinit");
	if (nswdev > 1)
		nswap = ((nswap + dmmax - 1) / dmmax) * dmmax;
	nswap *= nswdev;
	if (swdevt[0].sw_vp == NULL &&
	    bdevvp(swdevt[0].sw_dev, &swdevt[0].sw_vp))
		panic("swapvp");
#endif
	if (nswap == 0)
		printf("WARNING: no swap space found\n");
	else if ((error = swfree(p, 0)) == ENXIO)
		printf("WARNING: primary swap device not configured\n");
	else if (error) {
		printf("swfree errno %d\n", error);	/* XXX */
		panic("swapinit swfree 0");
d297 11
d309 9
a317 8
	/*
	 * Now set up swap buffer headers.
	 */
	bswlist.b_actf = sp;
	for (i = 0; i < nswbuf - 1; i++, sp++) {
		sp->b_actf = sp + 1;
		sp->b_rcred = sp->b_wcred = p->p_ucred;
		sp->b_vnbufs.le_next = NOLIST;
d319 1
a319 3
	sp->b_rcred = sp->b_wcred = p->p_ucred;
	sp->b_vnbufs.le_next = NOLIST;
	sp->b_actf = NULL;
d322 5
a326 3
void
swstrategy(bp)
	register struct buf *bp;
d328 5
a332 2
	int s, sz, off, seg, index;
	register struct swdevt *sp;
d334 38
d373 44
a416 6
	sz = howmany(bp->b_bcount, DEV_BSIZE);
	if (bp->b_blkno + sz > nswap) {
		bp->b_error = EINVAL;
		bp->b_flags |= B_ERROR;
		biodone(bp);
		return;
d418 24
a441 15
	if (nswdev > 1) {
#ifdef SEQSWAP
		if (bp->b_blkno < niswap) {
			if (niswdev > 1) {
				off = bp->b_blkno % dmmax;
				if (off+sz > dmmax) {
					bp->b_error = EINVAL;
					bp->b_flags |= B_ERROR;
					biodone(bp);
					return;
				}
				seg = bp->b_blkno / dmmax;
				index = seg % niswdev;
				seg /= niswdev;
				bp->b_blkno = seg*dmmax + off;
d443 48
a490 3
				index = 0;
		} else {
			register struct swdevt *swp;
d492 4
a495 16
			bp->b_blkno -= niswap;
			for (index = niswdev, swp = &swdevt[niswdev];
			     swp->sw_dev != NODEV;
			     swp++, index++) {
				if (bp->b_blkno < swp->sw_nblks)
					break;
				bp->b_blkno -= swp->sw_nblks;
			}
			if (swp->sw_dev == NODEV ||
			    bp->b_blkno+sz > swp->sw_nblks) {
				bp->b_error = swp->sw_dev == NODEV ?
					ENODEV : EINVAL;
				bp->b_flags |= B_ERROR;
				biodone(bp);
				return;
			}
d497 1
d499 61
a559 6
		off = bp->b_blkno % dmmax;
		if (off+sz > dmmax) {
			bp->b_error = EINVAL;
			bp->b_flags |= B_ERROR;
			biodone(bp);
			return;
d561 19
a579 4
		seg = bp->b_blkno / dmmax;
		index = seg % nswdev;
		seg /= nswdev;
		bp->b_blkno = seg*dmmax + off;
d581 127
a707 8
	} else
		index = 0;
	sp = &swdevt[index];
	if (sp->sw_vp == NULL) {
		bp->b_error = ENODEV;
		bp->b_flags |= B_ERROR;
		biodone(bp);
		return;
d709 48
a756 10
	if ((bp->b_dev = sp->sw_dev) == NODEV && sp->sw_vp->v_type != VREG)
		panic("swstrategy");
	VHOLD(sp->sw_vp);
	s = splbio();
	if ((bp->b_flags & B_READ) == 0) {
		if ((vp = bp->b_vp) != NULL) {
			vp->v_numoutput--;
			if ((vp->v_flag & VBWAIT) && vp->v_numoutput <= 0) {
				vp->v_flag &= ~VBWAIT;
				wakeup((caddr_t)&vp->v_numoutput);
d758 5
a763 1
		sp->sw_vp->v_numoutput++;
d765 69
a833 5
	if (bp->b_vp != NULL)
		brelvp(bp);
	splx(s);
	bp->b_vp = sp->sw_vp;
	VOP_STRATEGY(bp);
d858 61
a918 11
/*
 * System call swapon(name) enables swapping on device name,
 * which must be in the swdevsw.  Return EBUSY
 * if already swapping on this device.
 */
/* ARGSUSED */
int
sys_swapon(p, v, retval)
	struct proc *p;
	void *v;
	register_t *retval;
d920 47
a966 8
	struct sys_swapon_args /* {
		syscallarg(char *) name;
	} */ *uap = v;
	register struct vnode *vp;
	register struct swdevt *sp;
	dev_t dev;
	int error;
	struct nameidata nd;
d968 43
a1010 27
	if ((error = suser(p->p_ucred, &p->p_acflag)) != 0)
		return (error);
	NDINIT(&nd, LOOKUP, FOLLOW, UIO_USERSPACE, SCARG(uap, name), p);
	if ((error = namei(&nd)) != 0)
		return (error);
	vp = nd.ni_vp;
	if (vp->v_type != VBLK) {
		vrele(vp);
		return (ENOTBLK);
	}
	dev = (dev_t)vp->v_rdev;
	if (major(dev) >= nblkdev) {
		vrele(vp);
		return (ENXIO);
	}
	for (sp = &swdevt[0]; sp->sw_dev != NODEV; sp++) {
		if (sp->sw_dev == dev) {
			if (sp->sw_flags & SW_FREED) {
				vrele(vp);
				return (EBUSY);
			}
			sp->sw_vp = vp;
			if ((error = swfree(p, sp - swdevt)) != 0) {
				vrele(vp);
				return (error);
			}
			return (0);
d1012 3
a1014 1
#ifdef SEQSWAP
d1016 1
a1016 4
		 * If we have reached a non-freed sequential device without
		 * finding what we are looking for, it is an error.
		 * That is because all interleaved devices must come first
		 * and sequential devices must be freed in order.
d1018 27
a1044 3
		if ((sp->sw_flags & (SW_SEQUENTIAL|SW_FREED)) == SW_SEQUENTIAL)
			break;
#endif
d1046 1
a1046 2
	vrele(vp);
	return (EINVAL);
d1050 4
a1053 4
 * Swfree(index) frees the index'th portion of the swap map.
 * Each of the nswdev devices provides 1/nswdev'th of the swap
 * space, which is laid out with blocks of dmmax pages circularly
 * among the devices.
d1055 33
a1087 4
int
swfree(p, index)
	struct proc *p;
	int index;
d1089 21
a1109 7
	register struct swdevt *sp;
	register swblk_t vsbase;
	register long blk;
	struct vnode *vp;
	register swblk_t dvbase;
	register int nblks;
	int error;
d1111 1
a1111 6
	sp = &swdevt[index];
	vp = sp->sw_vp;
	/* If root on swap, then the skip open/close operations. */
	if (vp != rootvp) {
		if ((error = VOP_OPEN(vp, FREAD|FWRITE, p->p_ucred, p)) != 0)
			return (error);
d1113 6
a1118 2
	sp->sw_flags |= SW_FREED;
	nblks = sp->sw_nblks;
d1120 2
a1121 2
	 * Some devices may not exist til after boot time.
	 * If so, their nblk count will be 0.
d1123 12
a1134 3
	if (nblks <= 0) {
		int perdev;
		dev_t dev = sp->sw_dev;
d1136 10
a1145 16
		if (bdevsw[major(dev)].d_psize == 0 ||
		    (nblks = (*bdevsw[major(dev)].d_psize)(dev)) == -1) {
			if (vp != rootvp)
				(void) VOP_CLOSE(vp, FREAD|FWRITE, p->p_ucred, p);
			sp->sw_flags &= ~SW_FREED;
			return (ENXIO);
		}
#ifdef SEQSWAP
		if (index < niswdev) {
			perdev = niswap / niswdev;
			if (nblks > perdev)
				nblks = perdev;
		} else {
			if (nblks % dmmax)
				nblks -= (nblks % dmmax);
			nswap += nblks;
a1146 55
#else
		if (nswap > 0) {
			perdev = nswap / nswdev;
			if (nblks > perdev)
				nblks = perdev;
		} else
			nswap = nblks;
#endif
		sp->sw_nblks = nblks;
	}
	if (nblks == 0) {
		if (vp != rootvp)
			(void) VOP_CLOSE(vp, FREAD|FWRITE, p->p_ucred, p);
		sp->sw_flags &= ~SW_FREED;
		return (0);	/* XXX error? */
	}
#ifdef SEQSWAP
	if (sp->sw_flags & SW_SEQUENTIAL) {
		register struct swdevt *swp;

		blk = niswap;
		for (swp = &swdevt[niswdev]; swp != sp; swp++)
			blk += swp->sw_nblks;
		rmfree(swapmap, nblks, blk);
		return (0);
	}
#endif
	for (dvbase = 0; dvbase < nblks; dvbase += dmmax) {
		blk = nblks - dvbase;
#ifdef SEQSWAP
		if ((vsbase = index*dmmax + dvbase*niswdev) >= niswap)
			panic("swfree");
#else
		if ((vsbase = index*dmmax + dvbase*nswdev) >= nswap)
			panic("swfree");
#endif
		if (blk > dmmax)
			blk = dmmax;
		if (vsbase == 0) {
			/*
			 * First of all chunks... initialize the swapmap.
			 * Don't use the first cluster of the device
			 * in case it starts with a label or boot block.
			 */
			rminit(swapmap, blk - ctod(btoc(SWAPSKIPBYTES)),
			    vsbase + ctod(btoc(SWAPSKIPBYTES)), "swap", nswapmap);
		} else if (dvbase == 0) {
			/*
			 * Don't use the first cluster of the device
			 * in case it starts with a label or boot block.
			 */
			rmfree(swapmap, blk - ctod(btoc(SWAPSKIPBYTES)),
			    vsbase + ctod(btoc(SWAPSKIPBYTES)));
		} else
			rmfree(swapmap, blk, vsbase);
d1148 35
d1185 1
a1185 7
	 * Preserve the mini-root if appropriate:
	 * Note: this requires !SEQSWAP && nswdev==1
	 *
	 * A mini-root gets copied into the front of the swap
	 * and we run over top of the swap area just long
	 * enough for us to do a mkfs and restor of the real
	 * root (sure beats rewriting standalone restor).
d1187 9
a1195 7
	if (vp == rootvp) {
#ifndef MINIROOTSIZE
		struct mount *mp;
		struct statfs *sp;
#endif
		long firstblk;
		int rootblks;
d1197 3
a1199 7
#ifdef	MINIROOTSIZE
		rootblks = MINIROOTSIZE;
#else
		/* Get size from root FS (mountroot did statfs) */
		mp = rootvnode->v_mount;
		sp = &mp->mnt_stat;
		rootblks = sp->f_blocks * (sp->f_bsize / DEV_BSIZE);
d1201 1
a1201 9
		if (rootblks > nblks)
			panic("swfree miniroot size");
		/* First ctod(btoc(SWAPSKIPBYTES)) blocks are not in the map. */
		firstblk = rmalloc(swapmap, rootblks - ctod(btoc(SWAPSKIPBYTES)));
		if (firstblk != ctod(btoc(SWAPSKIPBYTES)))
			panic("swfree miniroot save");
		printf("Preserved %d blocks of miniroot leaving %d pages of swap\n",
		       rootblks, dtoc(nblks - rootblks));
	}
d1203 1
a1203 1
	return (0);
d1206 5
a1210 5
int
sys_omsync(p, v, retval)
	struct proc *p;
	void *v;
	register_t *retval;
d1212 50
a1261 10
	struct sys_msync_args ua;
	struct sys_omsync_args /* {
	        syscallarg(caddr_t) addr;
	        syscallarg(size_t) len;
	} */ *uap = v;

	SCARG(&ua, addr) = SCARG(uap, addr);;
	SCARG(&ua, len) = SCARG(uap, len);;
	SCARG(&ua, flags) = MS_SYNC | MS_INVALIDATE;
	return (sys_msync(p, &ua, retval));
@


1.7
log
@make msync() have 3 args
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_swap.c,v 1.6 1997/08/18 13:55:59 niklas Exp $	*/
d174 1
a174 1
	int sz, off, seg, index;
d247 1
d260 1
@


1.6
log
@if no swap has been configured at boot time, swapon could not add
the first swap partition.  This was a problem with ccd- or vnd-only swap
setups
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_swap.c,v 1.5 1997/05/22 07:26:53 deraadt Exp $	*/
d48 1
d495 18
@


1.5
log
@use SWAPSKIPBYTES for miniroot preservation, too
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_swap.c,v 1.4 1997/04/10 13:48:51 deraadt Exp $	*/
d402 6
a407 3
		perdev = nswap / nswdev;
		if (nblks > perdev)
			nblks = perdev;
@


1.4
log
@always skip the first 8K of swap. Yes, 8K, not some manufactured number that ends up being 4K
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_swap.c,v 1.3 1997/02/17 07:38:20 mickey Exp $	*/
d482 3
a484 3
		/* First ctod(CLSIZE) blocks are not in the map. */
		firstblk = rmalloc(swapmap, rootblks - ctod(CLSIZE));
		if (firstblk != ctod(CLSIZE))
@


1.3
log
@kill unused variables w/ MINIROOTSIZE defined in config
@
text
@d1 1
a1 1
/*	$OpenBSD: vm_swap.c,v 1.2 1996/03/03 17:45:38 niklas Exp $	*/
d442 2
a443 2
			rminit(swapmap, blk - ctod(CLSIZE),
			    vsbase + ctod(CLSIZE), "swap", nswapmap);
d449 2
a450 2
			rmfree(swapmap, blk - ctod(CLSIZE),
			    vsbase + ctod(CLSIZE));
@


1.2
log
@From NetBSD: merge with 960217
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d465 1
d468 1
@


1.1
log
@Initial revision
@
text
@d1 2
a2 1
/*	$NetBSD: vm_swap.c,v 1.31 1995/10/07 06:29:02 mycroft Exp $	*/
a41 1
#include <sys/conf.h>
d52 3
d67 2
d247 1
a247 1
		if (vp = bp->b_vp) {
d262 1
d264 1
a264 1
swread(dev, uio)
d267 1
d273 1
d275 1
a275 1
swwrite(dev, uio)
d278 1
d305 1
a305 1
	if (error = suser(p->p_ucred, &p->p_acflag))
d308 1
a308 1
	if (error = namei(&nd))
d327 1
a327 1
			if (error = swfree(p, sp - swdevt)) {
d371 1
a371 1
		if (error = VOP_OPEN(vp, FREAD|FWRITE, p->p_ucred, p))
@


1.1.1.1
log
@initial import of NetBSD tree
@
text
@@
