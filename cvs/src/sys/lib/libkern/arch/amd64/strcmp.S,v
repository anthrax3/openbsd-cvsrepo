head	1.3;
access;
symbols
	OPENBSD_6_1:1.3.0.10
	OPENBSD_6_1_BASE:1.3
	OPENBSD_6_0:1.3.0.8
	OPENBSD_6_0_BASE:1.3
	OPENBSD_5_9:1.3.0.4
	OPENBSD_5_9_BASE:1.3
	OPENBSD_5_8:1.3.0.6
	OPENBSD_5_8_BASE:1.3
	OPENBSD_5_7:1.3.0.2
	OPENBSD_5_7_BASE:1.3
	OPENBSD_5_6:1.2.0.30
	OPENBSD_5_6_BASE:1.2
	OPENBSD_5_5:1.2.0.28
	OPENBSD_5_5_BASE:1.2
	OPENBSD_5_4:1.2.0.24
	OPENBSD_5_4_BASE:1.2
	OPENBSD_5_3:1.2.0.22
	OPENBSD_5_3_BASE:1.2
	OPENBSD_5_2:1.2.0.20
	OPENBSD_5_2_BASE:1.2
	OPENBSD_5_1_BASE:1.2
	OPENBSD_5_1:1.2.0.18
	OPENBSD_5_0:1.2.0.16
	OPENBSD_5_0_BASE:1.2
	OPENBSD_4_9:1.2.0.14
	OPENBSD_4_9_BASE:1.2
	OPENBSD_4_8:1.2.0.12
	OPENBSD_4_8_BASE:1.2
	OPENBSD_4_7:1.2.0.8
	OPENBSD_4_7_BASE:1.2
	OPENBSD_4_6:1.2.0.10
	OPENBSD_4_6_BASE:1.2
	OPENBSD_4_5:1.2.0.6
	OPENBSD_4_5_BASE:1.2
	OPENBSD_4_4:1.2.0.4
	OPENBSD_4_4_BASE:1.2
	OPENBSD_4_3:1.2.0.2
	OPENBSD_4_3_BASE:1.2
	OPENBSD_4_2:1.1.0.18
	OPENBSD_4_2_BASE:1.1
	OPENBSD_4_1:1.1.0.16
	OPENBSD_4_1_BASE:1.1
	OPENBSD_4_0:1.1.0.14
	OPENBSD_4_0_BASE:1.1
	OPENBSD_3_9:1.1.0.12
	OPENBSD_3_9_BASE:1.1
	OPENBSD_3_8:1.1.0.10
	OPENBSD_3_8_BASE:1.1
	OPENBSD_3_7:1.1.0.8
	OPENBSD_3_7_BASE:1.1
	OPENBSD_3_6:1.1.0.6
	OPENBSD_3_6_BASE:1.1
	SMP_SYNC_A:1.1
	SMP_SYNC_B:1.1
	OPENBSD_3_5:1.1.0.4
	OPENBSD_3_5_BASE:1.1
	SMP:1.1.0.2;
locks; strict;
comment	@# @;


1.3
date	2014.12.09.15.13.57;	author reyk;	state Exp;
branches;
next	1.2;
commitid	JJgbPyzWXRvH0tuk;

1.2
date	2007.11.24.19.28.25;	author deraadt;	state Exp;
branches;
next	1.1;

1.1
date	2004.01.28.01.39.40;	author mickey;	state Exp;
branches
	1.1.2.1;
next	;

1.1.2.1
date	2004.02.19.10.57.18;	author niklas;	state Exp;
branches;
next	;


desc
@@


1.3
log
@Like libc, also for the kernel: Import new amd64 assembly versions of
strchr/index, strrchr/rindex, and strlen that provide a significantly
faster performance than our previous .c or .S implementations.  Based
on NetBSD's code.

Tested with different amd64 CPUs.

ok deraadt@@ mikeb@@
@
text
@/*	$OpenBSD$	*/
/*	$NetBSD: strcmp.S,v 1.2 2014/03/22 19:16:34 jakllsch Exp $	*/

/*
 * Written by J.T. Conklin <jtc@@acorntoolworks.com>
 * Public domain.
 */

#include <machine/asm.h>

ENTRY(strcmp)
	/*
	 * Align s1 to word boundary.
	 * Consider unrolling loop?
	 */
.Ls1align:
	testb	$7,%dil
	je	.Ls1aligned
	movb	(%rdi),%al
	incq	%rdi
	movb	(%rsi),%dl
	incq	%rsi
	testb	%al,%al
	je	.Ldone
	cmpb	%al,%dl
	je	.Ls1align
	jmp	.Ldone

	/*
	 * Check whether s2 is aligned to a word boundary.  If it is, we
	 * can compare by words.  Otherwise we have to compare by bytes.
	 */
.Ls1aligned:
	testb	$7,%sil
	jne	.Lbyte_loop

	movabsq	$0x0101010101010101,%r8
	subq	$8,%rdi
	movabsq	$0x8080808080808080,%r9
	subq	$8,%rsi

	_ALIGN_TEXT
.Lword_loop:
	movq	8(%rdi),%rax
	addq	$8,%rdi
	movq	8(%rsi),%rdx
	addq	$8,%rsi
	cmpq	%rax,%rdx
	jne	.Lbyte_loop
	subq	%r8,%rdx
	notq	%rax
	andq	%rax,%rdx
	testq	%r9,%rdx
	je	.Lword_loop

	_ALIGN_TEXT
.Lbyte_loop:
	movb	(%rdi),%al
	incq	%rdi
	movb	(%rsi),%dl
	incq	%rsi
	testb	%al,%al
	je	.Ldone
	cmpb	%al,%dl
	je	.Lbyte_loop

.Ldone:
	movzbq	%al,%rax
	movzbq	%dl,%rdx
	subq	%rdx,%rax
	ret
@


1.2
log
@delete unused junk RCS ids
@
text
@d1 3
d5 1
a5 1
 * Written by J.T. Conklin <jtc@@netbsd.org>.
a6 1
 * Adapted for NetBSD/x86_64 by Frank van der Linden <fvdl@@wasabisystems.com>
a10 6
/*
 * NOTE: I've unrolled the loop eight times: large enough to make a
 * significant difference, and small enough not to totally trash the
 * cache.
 */

d12 59
a70 68
	jmp	L2			/* Jump into the loop. */

L1:	incq	%rdi
	incq	%rsi
L2:	movb	(%rdi),%cl
	testb	%cl,%cl			/* null terminator */
	jz	L3
	cmpb	%cl,(%rsi)		/* chars match */
	jne	L3

	incq	%rdi
	incq	%rsi
	movb	(%rdi),%cl
	testb	%cl,%cl
	jz	L3
	cmpb	%cl,(%rsi)
	jne	L3

	incq	%rdi
	incq	%rsi
	movb	(%rdi),%cl
	testb	%cl,%cl
	jz	L3
	cmpb	%cl,(%rsi)
	jne	L3

	incq	%rdi
	incq	%rsi
	movb	(%rdi),%cl
	testb	%cl,%cl
	jz	L3
	cmpb	%cl,(%rsi)
	jne	L3

	incq	%rdi
	incq	%rsi
	movb	(%rdi),%cl
	testb	%cl,%cl
	jz	L3
	cmpb	%cl,(%rsi)
	jne	L3

	incq	%rdi
	incq	%rsi
	movb	(%rdi),%cl
	testb	%cl,%cl
	jz	L3
	cmpb	%cl,(%rsi)
	jne	L3

	incq	%rdi
	incq	%rsi
	movb	(%rdi),%cl
	testb	%cl,%cl
	jz	L3
	cmpb	%cl,(%rsi)
	jne	L3

	incq	%rdi
	incq	%rsi
	movb	(%rdi),%cl
	testb	%cl,%cl
	jz	L3
	cmpb	%cl,(%rsi)
	je	L1
L3:	movzbl	(%rdi),%eax		/* unsigned comparison */
	movzbl	(%rsi),%edx
	subl	%edx,%eax
@


1.1
log
@an amd64 arch support.
hacked by art@@ from netbsd sources and then later debugged
by me into the shape where it can host itself.
no bootloader yet as needs redoing from the
recent advanced i386 sources (anyone? ;)
@
text
@a8 4
#if defined(LIBC_SCCS)
	RCSID("$NetBSD: strcmp.S,v 1.1 2001/06/19 00:22:47 fvdl Exp $")
#endif

@


1.1.2.1
log
@Merge of current from two weeks agointo the SMP branch
@
text
@@

