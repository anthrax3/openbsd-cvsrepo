head	1.5;
access;
symbols
	OPENBSD_6_0:1.4.0.14
	OPENBSD_6_0_BASE:1.4
	OPENBSD_5_9:1.4.0.10
	OPENBSD_5_9_BASE:1.4
	OPENBSD_5_8:1.4.0.12
	OPENBSD_5_8_BASE:1.4
	OPENBSD_5_7:1.4.0.4
	OPENBSD_5_7_BASE:1.4
	OPENBSD_5_6:1.4.0.8
	OPENBSD_5_6_BASE:1.4
	OPENBSD_5_5:1.4.0.6
	OPENBSD_5_5_BASE:1.4
	OPENBSD_5_4:1.4.0.2
	OPENBSD_5_4_BASE:1.4
	OPENBSD_5_3:1.2.0.22
	OPENBSD_5_3_BASE:1.2
	OPENBSD_5_2:1.2.0.20
	OPENBSD_5_2_BASE:1.2
	OPENBSD_5_1_BASE:1.2
	OPENBSD_5_1:1.2.0.18
	OPENBSD_5_0:1.2.0.16
	OPENBSD_5_0_BASE:1.2
	OPENBSD_4_9:1.2.0.14
	OPENBSD_4_9_BASE:1.2
	OPENBSD_4_8:1.2.0.12
	OPENBSD_4_8_BASE:1.2
	OPENBSD_4_7:1.2.0.8
	OPENBSD_4_7_BASE:1.2
	OPENBSD_4_6:1.2.0.10
	OPENBSD_4_6_BASE:1.2
	OPENBSD_4_5:1.2.0.6
	OPENBSD_4_5_BASE:1.2
	OPENBSD_4_4:1.2.0.4
	OPENBSD_4_4_BASE:1.2
	OPENBSD_4_3:1.2.0.2
	OPENBSD_4_3_BASE:1.2;
locks; strict;
comment	@# @;


1.5
date	2016.11.14.15.02.54;	author visa;	state Exp;
branches;
next	1.4;
commitid	2dNiOg9xZExxXwze;

1.4
date	2013.06.13.15.03.08;	author deraadt;	state Exp;
branches;
next	1.3;

1.3
date	2013.06.03.05.39.02;	author tedu;	state Exp;
branches;
next	1.2;

1.2
date	2007.11.28.11.46.35;	author deraadt;	state Exp;
branches;
next	1.1;

1.1
date	2007.11.26.14.28.03;	author deraadt;	state Exp;
branches;
next	;


desc
@@


1.5
log
@Copy data by using 64-bit loads and stores rather than 32-bit
operations. This about doubles the routine's throughput.

No binary change on the 32-bit bootblocks
Discussed with miod@@ long ago
@
text
@/*	$OpenBSD: memmove.S,v 1.4 2013/06/13 15:03:08 deraadt Exp $	*/
/*-
 * Copyright (c) 1991, 1993
 *      The Regents of the University of California.  All rights reserved.
 *
 * This code is derived from software contributed to Berkeley by
 * Ralph Campbell.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. Neither the name of the University nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 */

#include "DEFS.h"


/*
 * memcpy(to, from, len)
	always copy forward
 *
 * memmove(to, from, len), bcopy(from, to, len)
 *	both handle overlap
 */
LEAF(memcpy, 0)
	.set	noreorder
	move	v0, a0			# swap from and to
	move	a0, a1
	move	a1, v0
	PTR_ADDU t0, a0, a2		# t0 = end of s1 region
	sltu	t1, a1, t0
	sltu	t2, a0, a1
	j	forward			# do forward copy
	slt	t2, a2, 12		# check for small copy

ALEAF(memmove)
	.set	noreorder
	move	v0, a0			# swap from and to
	move	a0, a1
	move	a1, v0
ALEAF(bcopy)
	.set	noreorder
	PTR_ADDU t0, a0, a2		# t0 = end of s1 region
	sltu	t1, a1, t0
	sltu	t2, a0, a1
	and	t1, t1, t2		# t1 = true if from < to < (from+len)
	beq	t1, zero, forward	# non overlapping, do forward copy
	slt	t2, a2, 12		# check for small copy

	ble	a2, zero, 2f
	PTR_ADDU t1, a1, a2		# t1 = end of to region
1:
	lb	v1, -1(t0)		# copy bytes backwards,
	PTR_SUBU t0, t0, 1		#   doesnt happen often so do slow way
	PTR_SUBU t1, t1, 1
	bne	t0, a0, 1b
	sb	v1, 0(t1)
2:
	j	ra
	nop
forward:
#ifdef _STANDALONE
	bne	t2, zero, smallcpy	# do a small bcopy
	xor	v1, a0, a1		# compare low two bits of addresses
	and	v1, v1, 3
	PTR_SUBU a3, zero, a1		# compute # bytes to word align address
	beq	v1, zero, aligned	# addresses can be word aligned
	and	a3, a3, 3

	beq	a3, zero, 1f
	PTR_SUBU a2, a2, a3		# subtract from remaining count
	LWHI	v1, 0(a0)		# get next 4 bytes (unaligned)
	LWLO	v1, 3(a0)
	PTR_ADDU a0, a0, a3
	SWHI	v1, 0(a1)		# store 1, 2, or 3 bytes to align a1
	PTR_ADDU a1, a1, a3
1:
	and	v1, a2, 3		# compute number of words left
	PTR_SUBU a3, a2, v1
	move	a2, v1
	PTR_ADDU a3, a3, a0		# compute ending address
2:
	LWHI	v1, 0(a0)		# copy words a0 unaligned, a1 aligned
	LWLO	v1, 3(a0)
	PTR_ADDU a0, a0, 4
	sw	v1, 0(a1)
	PTR_ADDU a1, a1, 4
	bne	a0, a3, 2b
	nop				# We have to do this mmu-bug.
	b	smallcpy
	nop
aligned:
	beq	a3, zero, 1f
	PTR_SUBU a2, a2, a3		# subtract from remaining count
	LWHI	v1, 0(a0)		# copy 1, 2, or 3 bytes to align
	PTR_ADDU a0, a0, a3
	SWHI	v1, 0(a1)
	PTR_ADDU a1, a1, a3
1:
	and	v1, a2, 3		# compute number of whole words left
	PTR_SUBU a3, a2, v1
	move	a2, v1
	PTR_ADDU a3, a3, a0		# compute ending address
2:
	lw	v1, 0(a0)		# copy words
	PTR_ADDU a0, a0, 4
	sw	v1, 0(a1)
	bne	a0, a3, 2b
	PTR_ADDU a1, a1, 4
#else
	bne	t2, zero, smallcpy	# do a small bcopy
	xor	v1, a0, a1		# compare low three bits of addresses
	and	v1, v1, 7
	PTR_SUBU a3, zero, a1		# compute # bytes to dword align address
	beq	v1, zero, aligned	# addresses can be dword aligned
	and	a3, a3, 7

	beq	a3, zero, 1f
	PTR_SUBU a2, a2, a3		# subtract from remaining count
	LDHI	v1, 0(a0)		# get next 8 bytes (unaligned)
	LDLO	v1, 7(a0)
	PTR_ADDU a0, a0, a3
	SDHI	v1, 0(a1)		# store 1-7 bytes to align a1
	PTR_ADDU a1, a1, a3
1:
	and	v1, a2, 7		# compute number of dwords left
	PTR_SUBU a3, a2, v1
	beq	a3, zero, smallcpy
	move	a2, v1
	PTR_ADDU a3, a3, a0		# compute ending address
2:
	LDHI	v1, 0(a0)		# copy dwords a0 unaligned, a1 aligned
	LDLO	v1, 7(a0)
	PTR_ADDU a0, a0, 8
	sd	v1, 0(a1)
	PTR_ADDU a1, a1, 8
	bne	a0, a3, 2b
	nop				# We have to do this mmu-bug.
	b	smallcpy
	nop
aligned:
	beq	a3, zero, 1f
	PTR_SUBU a2, a2, a3		# subtract from remaining count
	LDHI	v1, 0(a0)		# copy 1-7 bytes to align
	PTR_ADDU a0, a0, a3
	SDHI	v1, 0(a1)
	PTR_ADDU a1, a1, a3
1:
	and	v1, a2, 7		# compute number of whole dwords left
	PTR_SUBU a3, a2, v1
	beq	a3, zero, smallcpy
	move	a2, v1
	PTR_ADDU a3, a3, a0		# compute ending address
2:
	ld	v1, 0(a0)		# copy dwords
	PTR_ADDU a0, a0, 8
	sd	v1, 0(a1)
	bne	a0, a3, 2b
	PTR_ADDU a1, a1, 8
#endif
smallcpy:
	ble	a2, zero, 2f
	PTR_ADDU a3, a2, a0		# compute ending address
1:
	lbu	v1, 0(a0)		# copy bytes
	PTR_ADDU a0, a0, 1
	sb	v1, 0(a1)
	bne	a0, a3, 1b
	PTR_ADDU a1, a1, 1	# MMU BUG ? can not do -1(a1) at 0x80000000!!
2:
	j	ra
	nop
END(memcpy)
@


1.4
log
@merged bcopy/memmove/memcpy
tested by bcallah, proofed by jasper, ok tedu
@
text
@d1 1
a1 1
/*	$OpenBSD: bcopy.S,v 1.4 2004/10/08 14:42:09 pefo Exp $	*/
d81 1
d129 51
@


1.3
log
@fix an oft copied typo that i'm tired of looking at
@
text
@d1 140
a140 1
/* No code here since kernel implements this itself */
@


1.2
log
@place a comment as to why these are otherwise empty
@
text
@d1 1
a1 1
/* No code here since kernel impliments this itself */
@


1.1
log
@mips64 needs at least these to build; spotted by jsing
@
text
@d1 1
@

