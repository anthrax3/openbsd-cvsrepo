head	1.163;
access;
symbols
	OPENBSD_6_1:1.160.0.4
	OPENBSD_6_1_BASE:1.160
	OPENBSD_6_0:1.143.0.4
	OPENBSD_6_0_BASE:1.143
	OPENBSD_5_9:1.135.0.2
	OPENBSD_5_9_BASE:1.135
	OPENBSD_5_8:1.120.0.4
	OPENBSD_5_8_BASE:1.120
	OPENBSD_5_7:1.118.0.2
	OPENBSD_5_7_BASE:1.118
	OPENBSD_5_6:1.103.0.4
	OPENBSD_5_6_BASE:1.103
	OPENBSD_5_5:1.90.0.4
	OPENBSD_5_5_BASE:1.90
	OPENBSD_5_4:1.83.0.4
	OPENBSD_5_4_BASE:1.83
	OPENBSD_5_3:1.83.0.2
	OPENBSD_5_3_BASE:1.83
	OPENBSD_5_2:1.80.0.2
	OPENBSD_5_2_BASE:1.80
	OPENBSD_5_1_BASE:1.79
	OPENBSD_5_1:1.79.0.2
	OPENBSD_5_0:1.78.0.2
	OPENBSD_5_0_BASE:1.78
	OPENBSD_4_9:1.77.0.2
	OPENBSD_4_9_BASE:1.77
	OPENBSD_4_8:1.75.0.4
	OPENBSD_4_8_BASE:1.75
	OPENBSD_4_7:1.75.0.2
	OPENBSD_4_7_BASE:1.75
	OPENBSD_4_6:1.71.0.6
	OPENBSD_4_6_BASE:1.71
	OPENBSD_4_5:1.71.0.2
	OPENBSD_4_5_BASE:1.71
	OPENBSD_4_4:1.68.0.4
	OPENBSD_4_4_BASE:1.68
	OPENBSD_4_3:1.68.0.2
	OPENBSD_4_3_BASE:1.68
	OPENBSD_4_2:1.66.0.2
	OPENBSD_4_2_BASE:1.66
	OPENBSD_4_1:1.64.0.2
	OPENBSD_4_1_BASE:1.64
	OPENBSD_4_0:1.63.0.2
	OPENBSD_4_0_BASE:1.63
	OPENBSD_3_9:1.60.0.2
	OPENBSD_3_9_BASE:1.60
	OPENBSD_3_8:1.59.0.2
	OPENBSD_3_8_BASE:1.59
	OPENBSD_3_7:1.56.0.2
	OPENBSD_3_7_BASE:1.56
	OPENBSD_3_6:1.52.0.2
	OPENBSD_3_6_BASE:1.52
	SMP_SYNC_A:1.48
	SMP_SYNC_B:1.48
	OPENBSD_3_5:1.44.0.2
	OPENBSD_3_5_BASE:1.44
	OPENBSD_3_4:1.37.0.2
	OPENBSD_3_4_BASE:1.37
	UBC_SYNC_A:1.34
	OPENBSD_3_3:1.33.0.4
	OPENBSD_3_3_BASE:1.33
	OPENBSD_3_2:1.33.0.2
	OPENBSD_3_2_BASE:1.33
	OPENBSD_3_1:1.32.0.2
	OPENBSD_3_1_BASE:1.32
	UBC_SYNC_B:1.33
	UBC:1.30.0.4
	UBC_BASE:1.30
	OPENBSD_3_0:1.30.0.2
	OPENBSD_3_0_BASE:1.30
	OPENBSD_2_9_BASE:1.25
	OPENBSD_2_9:1.25.0.2
	OPENBSD_2_8:1.22.0.2
	OPENBSD_2_8_BASE:1.22
	OPENBSD_2_7:1.20.0.2
	OPENBSD_2_7_BASE:1.20
	SMP:1.18.0.4
	SMP_BASE:1.18
	kame_19991208:1.18
	OPENBSD_2_6:1.18.0.2
	OPENBSD_2_6_BASE:1.18
	OPENBSD_2_5:1.14.0.2
	OPENBSD_2_5_BASE:1.14
	OPENBSD_2_4:1.13.0.2
	OPENBSD_2_4_BASE:1.13
	OPENBSD_2_3:1.12.0.4
	OPENBSD_2_3_BASE:1.12
	OPENBSD_2_2:1.12.0.2
	OPENBSD_2_2_BASE:1.12
	OPENBSD_2_1:1.9.0.2
	OPENBSD_2_1_BASE:1.9
	OPENBSD_2_0:1.5.0.2
	OPENBSD_2_0_BASE:1.5
	netbsd_1_1:1.1.1.1;
locks; strict;
comment	@ * @;


1.163
date	2017.05.24.16.26.58;	author bluhm;	state Exp;
branches;
next	1.162;
commitid	srSpIyCK7TG7327R;

1.162
date	2017.05.04.15.00.24;	author bluhm;	state Exp;
branches;
next	1.161;
commitid	Gef6NNDxonzfVaq2;

1.161
date	2017.04.20.14.13.00;	author visa;	state Exp;
branches;
next	1.160;
commitid	GnoPKa34InShCqYl;

1.160
date	2017.01.24.22.40.55;	author mpi;	state Exp;
branches;
next	1.159;
commitid	0xOVyH9WgONFe0Xp;

1.159
date	2017.01.24.10.08.30;	author krw;	state Exp;
branches;
next	1.158;
commitid	6c6qq5OdS4VVnyVM;

1.158
date	2017.01.09.19.15.01;	author mpi;	state Exp;
branches;
next	1.157;
commitid	gY9uoXPuboETv0Ph;

1.157
date	2017.01.03.19.28.50;	author mpi;	state Exp;
branches;
next	1.156;
commitid	j0M5Y0DG9i3fG0eI;

1.156
date	2017.01.02.11.07.31;	author mpi;	state Exp;
branches;
next	1.155;
commitid	2jYH2wzuBTM9zLGf;

1.155
date	2016.11.28.10.16.08;	author mpi;	state Exp;
branches;
next	1.154;
commitid	boEenhz3lcSsjNST;

1.154
date	2016.11.21.09.15.40;	author mpi;	state Exp;
branches;
next	1.153;
commitid	BFpdQ0ebyJmyZeqa;

1.153
date	2016.11.21.09.12.18;	author mpi;	state Exp;
branches;
next	1.152;
commitid	dAdn4MpyAjRNPhyt;

1.152
date	2016.11.16.14.13.00;	author mpi;	state Exp;
branches;
next	1.151;
commitid	0SqIOlopi7vRgUM6;

1.151
date	2016.11.16.09.00.01;	author mpi;	state Exp;
branches;
next	1.150;
commitid	DTKU6m8G5Kt5hWVx;

1.150
date	2016.10.16.18.05.41;	author jca;	state Exp;
branches;
next	1.149;
commitid	VOhgFtQfCCOGxRAO;

1.149
date	2016.09.12.16.24.37;	author krw;	state Exp;
branches;
next	1.148;
commitid	RJDGNn3vwOF2QQ11;

1.148
date	2016.08.22.10.40.36;	author mpi;	state Exp;
branches;
next	1.147;
commitid	6FqmydzsIfw5T27V;

1.147
date	2016.08.15.07.20.14;	author mpi;	state Exp;
branches;
next	1.146;
commitid	kkuCOsB0evNLa72O;

1.146
date	2016.08.15.07.17.10;	author mpi;	state Exp;
branches;
next	1.145;
commitid	JqO6Fb5vHCKp6g7i;

1.145
date	2016.08.15.07.12.11;	author mpi;	state Exp;
branches;
next	1.144;
commitid	d2kwy9jXVcDTHnVP;

1.144
date	2016.08.15.07.03.47;	author mpi;	state Exp;
branches;
next	1.143;
commitid	ESLAR3gFelzaZwO5;

1.143
date	2016.07.25.13.19.32;	author natano;	state Exp;
branches;
next	1.142;
commitid	NGz1ODfO2fm6s6nK;

1.142
date	2016.06.10.20.33.29;	author vgross;	state Exp;
branches;
next	1.141;
commitid	qJaxh4rw41tBg4CK;

1.141
date	2016.05.18.03.46.03;	author dlg;	state Exp;
branches;
next	1.140;
commitid	q5zkugIMulsP5tHa;

1.140
date	2016.05.10.23.48.07;	author dlg;	state Exp;
branches;
next	1.139;
commitid	if1SGq8o06Yb7jtJ;

1.139
date	2016.04.14.08.27.24;	author natano;	state Exp;
branches;
next	1.138;
commitid	rDUjVAJoqYcTKda5;

1.138
date	2016.04.02.08.49.49;	author dlg;	state Exp;
branches;
next	1.137;
commitid	BPyrNLQIxS9UMvYc;

1.137
date	2016.03.30.12.33.10;	author dlg;	state Exp;
branches;
next	1.136;
commitid	INNrVhF0rco4JJYt;

1.136
date	2016.03.29.10.38.27;	author dlg;	state Exp;
branches;
next	1.135;
commitid	89OUI52hmN8GbHJi;

1.135
date	2016.02.12.18.56.12;	author stefan;	state Exp;
branches;
next	1.134;
commitid	ooihO32Cof6D28ap;

1.134
date	2016.02.10.04.34.14;	author dlg;	state Exp;
branches;
next	1.133;
commitid	tqdpjhaBydEHRZsk;

1.133
date	2016.02.05.13.17.37;	author dlg;	state Exp;
branches;
next	1.132;
commitid	rEiKN41Xy51XysMN;

1.132
date	2016.01.07.05.31.17;	author guenther;	state Exp;
branches;
next	1.131;
commitid	SRBGEkRcMG3FAm8C;

1.131
date	2015.12.05.10.07.55;	author tedu;	state Exp;
branches;
next	1.130;
commitid	ILbVM1M3uPNjwswz;

1.130
date	2015.10.07.08.41.01;	author mpi;	state Exp;
branches;
next	1.129;
commitid	GDJlgw6xfORhJ4DD;

1.129
date	2015.09.29.10.58.51;	author dlg;	state Exp;
branches;
next	1.128;
commitid	u27lekA1DCEmcYVP;

1.128
date	2015.09.29.10.11.40;	author deraadt;	state Exp;
branches;
next	1.127;
commitid	L3Bwt4zBOCs33Zbo;

1.127
date	2015.09.13.17.53.44;	author mpi;	state Exp;
branches;
next	1.126;
commitid	zZXiESHR0g5lNO0l;

1.126
date	2015.09.12.20.26.06;	author mpi;	state Exp;
branches;
next	1.125;
commitid	UM7jfgLT8vWQUBm1;

1.125
date	2015.09.11.08.59.48;	author mpi;	state Exp;
branches;
next	1.124;
commitid	I5HDMJ6TvrDlpeEp;

1.124
date	2015.09.09.11.55.37;	author dlg;	state Exp;
branches;
next	1.123;
commitid	yzxE5xegGlAC9CXF;

1.123
date	2015.09.01.04.50.27;	author dlg;	state Exp;
branches;
next	1.122;
commitid	zhzN4J5NBYqh1Jfl;

1.122
date	2015.08.23.10.14.25;	author dlg;	state Exp;
branches;
next	1.121;
commitid	nmKb4l0Xabz9Ytks;

1.121
date	2015.08.16.12.17.16;	author dlg;	state Exp;
branches;
next	1.120;
commitid	1LM3GdO8Sc7UxIGJ;

1.120
date	2015.06.16.11.09.39;	author mpi;	state Exp;
branches;
next	1.119;
commitid	h7z8lokZ0dFyuWpg;

1.119
date	2015.05.13.10.42.46;	author jsg;	state Exp;
branches;
next	1.118;
commitid	hN5bFCE56DrAjl99;

1.118
date	2015.02.10.21.56.10;	author miod;	state Exp;
branches;
next	1.117;
commitid	C5iGb36LQxjM60Q3;

1.117
date	2015.02.10.00.53.55;	author pelikan;	state Exp;
branches;
next	1.116;
commitid	gfoM2KwSYVDTr1Yq;

1.116
date	2015.01.29.19.44.32;	author tedu;	state Exp;
branches;
next	1.115;
commitid	SRbe9wF8qeNKBOcm;

1.115
date	2015.01.28.00.31.07;	author dlg;	state Exp;
branches;
next	1.114;
commitid	TGD3Yps8xWQ6N0X8;

1.114
date	2015.01.09.04.59.54;	author tedu;	state Exp;
branches;
next	1.113;
commitid	PmxasaH0Xybx2Mmu;

1.113
date	2014.12.16.18.30.04;	author tedu;	state Exp;
branches;
next	1.112;
commitid	P6Av4XGqOi3rFasL;

1.112
date	2014.12.02.18.11.56;	author tedu;	state Exp;
branches;
next	1.111;
commitid	R6VIBSqPh5FMhwGK;

1.111
date	2014.11.23.07.39.02;	author deraadt;	state Exp;
branches;
next	1.110;
commitid	mdGXHklUZmESVFlY;

1.110
date	2014.10.07.11.16.23;	author dlg;	state Exp;
branches;
next	1.109;
commitid	p6HaTuy2dxbTD4Pm;

1.109
date	2014.09.23.00.26.11;	author dlg;	state Exp;
branches;
next	1.108;
commitid	O4vZJQfW9tHTaM8N;

1.108
date	2014.09.22.23.48.58;	author dlg;	state Exp;
branches;
next	1.107;
commitid	9Btpn3b41NxicY3x;

1.107
date	2014.09.22.23.40.46;	author dlg;	state Exp;
branches;
next	1.106;
commitid	cHKdNhe9zYYxN9lL;

1.106
date	2014.09.22.23.19.59;	author dlg;	state Exp;
branches;
next	1.105;
commitid	YXw57MRbqjPhwhp9;

1.105
date	2014.09.22.23.16.30;	author dlg;	state Exp;
branches;
next	1.104;
commitid	KHN9ejAiNCneBilA;

1.104
date	2014.09.19.02.52.55;	author dlg;	state Exp;
branches;
next	1.103;
commitid	cx7MRXjXQx4Lp6RI;

1.103
date	2014.07.12.18.44.22;	author tedu;	state Exp;
branches;
next	1.102;
commitid	B4dZSbxas1X1IpXI;

1.102
date	2014.07.12.11.27.45;	author henning;	state Exp;
branches;
next	1.101;
commitid	iVDXwxqOCkDe7I0T;

1.101
date	2014.07.10.11.48.14;	author henning;	state Exp;
branches;
next	1.100;
commitid	NpTKujly3RBFQlVg;

1.100
date	2014.07.10.11.44.56;	author henning;	state Exp;
branches;
next	1.99;
commitid	isfrqbsLYFvHBgNK;

1.99
date	2014.07.10.11.03.24;	author henning;	state Exp;
branches;
next	1.98;
commitid	ngH5nD6hM1kgnJbo;

1.98
date	2014.07.10.09.46.29;	author henning;	state Exp;
branches;
next	1.97;
commitid	K02ipswh8Nqemdsh;

1.97
date	2014.07.09.13.52.35;	author yasuoka;	state Exp;
branches;
next	1.96;
commitid	2Xyz26ranIs600lp;

1.96
date	2014.07.09.11.39.07;	author henning;	state Exp;
branches;
next	1.95;
commitid	sIIYeJ2PFHtZUirt;

1.95
date	2014.07.09.11.03.04;	author henning;	state Exp;
branches;
next	1.94;
commitid	mfsvjrJC7UBF4ZGt;

1.94
date	2014.07.09.09.30.49;	author henning;	state Exp;
branches;
next	1.93;
commitid	Nnxg8ONtI4Ep9pUb;

1.93
date	2014.04.23.10.50.18;	author jca;	state Exp;
branches;
next	1.92;

1.92
date	2014.04.14.09.06.42;	author mpi;	state Exp;
branches;
next	1.91;

1.91
date	2014.03.30.21.54.48;	author guenther;	state Exp;
branches;
next	1.90;

1.90
date	2013.12.24.23.29.38;	author tedu;	state Exp;
branches;
next	1.89;

1.89
date	2013.11.29.19.28.55;	author tedu;	state Exp;
branches;
next	1.88;

1.88
date	2013.11.17.08.58.35;	author dlg;	state Exp;
branches;
next	1.87;

1.87
date	2013.11.15.21.41.54;	author dlg;	state Exp;
branches;
next	1.86;

1.86
date	2013.11.12.01.12.09;	author dlg;	state Exp;
branches;
next	1.85;

1.85
date	2013.11.11.16.21.08;	author sthen;	state Exp;
branches;
next	1.84;

1.84
date	2013.11.11.03.06.43;	author dlg;	state Exp;
branches;
next	1.83;

1.83
date	2012.12.28.17.52.06;	author gsoares;	state Exp;
branches;
next	1.82;

1.82
date	2012.12.21.11.17.22;	author mikeb;	state Exp;
branches;
next	1.81;

1.81
date	2012.12.21.11.13.43;	author mikeb;	state Exp;
branches;
next	1.80;

1.80
date	2012.04.14.09.39.46;	author yasuoka;	state Exp;
branches;
next	1.79;

1.79
date	2012.01.16.03.34.58;	author guenther;	state Exp;
branches;
next	1.78;

1.78
date	2011.07.02.22.20.08;	author nicm;	state Exp;
branches;
next	1.77;

1.77
date	2011.01.04.15.24.11;	author deraadt;	state Exp;
branches;
next	1.76;

1.76
date	2010.09.21.04.06.37;	author henning;	state Exp;
branches;
next	1.75;

1.75
date	2009.11.09.17.53.39;	author nicm;	state Exp;
branches;
next	1.74;

1.74
date	2009.10.26.18.22.58;	author claudio;	state Exp;
branches;
next	1.73;

1.73
date	2009.09.21.16.33.42;	author canacar;	state Exp;
branches;
next	1.72;

1.72
date	2009.09.07.23.47.51;	author deraadt;	state Exp;
branches;
next	1.71;

1.71
date	2008.11.26.18.01.43;	author dlg;	state Exp;
branches;
next	1.70;

1.70
date	2008.11.09.15.08.26;	author naddy;	state Exp;
branches;
next	1.69;

1.69
date	2008.09.17.20.10.37;	author chl;	state Exp;
branches;
next	1.68;

1.68
date	2008.01.25.16.14.56;	author mglocker;	state Exp;
branches;
next	1.67;

1.67
date	2007.09.15.16.43.51;	author henning;	state Exp;
branches;
next	1.66;

1.66
date	2007.07.25.23.11.53;	author art;	state Exp;
branches;
next	1.65;

1.65
date	2007.03.24.16.01.22;	author art;	state Exp;
branches;
next	1.64;

1.64
date	2007.03.04.23.36.34;	author canacar;	state Exp;
branches;
next	1.63;

1.63
date	2006.07.18.11.52.12;	author dlg;	state Exp;
branches;
next	1.62;

1.62
date	2006.03.25.22.41.47;	author djm;	state Exp;
branches;
next	1.61;

1.61
date	2006.03.04.22.40.15;	author brad;	state Exp;
branches;
next	1.60;

1.60
date	2005.11.03.20.00.18;	author reyk;	state Exp;
branches;
next	1.59;

1.59
date	2005.07.31.03.52.18;	author pascoe;	state Exp;
branches;
next	1.58;

1.58
date	2005.04.20.19.52.42;	author reyk;	state Exp;
branches;
next	1.57;

1.57
date	2005.04.20.17.03.22;	author reyk;	state Exp;
branches;
next	1.56;

1.56
date	2005.01.07.16.28.38;	author reyk;	state Exp;
branches;
next	1.55;

1.55
date	2004.12.17.15.56.58;	author reyk;	state Exp;
branches;
next	1.54;

1.54
date	2004.10.09.19.55.28;	author brad;	state Exp;
branches;
next	1.53;

1.53
date	2004.09.23.03.31.08;	author brad;	state Exp;
branches;
next	1.52;

1.52
date	2004.09.12.09.35.50;	author claudio;	state Exp;
branches;
next	1.51;

1.51
date	2004.06.22.04.58.27;	author canacar;	state Exp;
branches;
next	1.50;

1.50
date	2004.06.22.04.04.19;	author canacar;	state Exp;
branches;
next	1.49;

1.49
date	2004.06.21.23.05.10;	author markus;	state Exp;
branches;
next	1.48;

1.48
date	2004.05.31.13.04.13;	author markus;	state Exp;
branches;
next	1.47;

1.47
date	2004.05.28.08.16.23;	author grange;	state Exp;
branches;
next	1.46;

1.46
date	2004.05.25.17.36.49;	author canacar;	state Exp;
branches;
next	1.45;

1.45
date	2004.05.08.20.54.13;	author canacar;	state Exp;
branches;
next	1.44;

1.44
date	2004.02.24.21.43.55;	author tedu;	state Exp;
branches;
next	1.43;

1.43
date	2004.02.06.22.38.58;	author tedu;	state Exp;
branches;
next	1.42;

1.42
date	2003.12.10.07.22.42;	author itojun;	state Exp;
branches;
next	1.41;

1.41
date	2003.10.24.04.26.16;	author canacar;	state Exp;
branches;
next	1.40;

1.40
date	2003.10.22.18.42.40;	author canacar;	state Exp;
branches;
next	1.39;

1.39
date	2003.10.04.01.03.49;	author deraadt;	state Exp;
branches;
next	1.38;

1.38
date	2003.09.23.16.51.13;	author millert;	state Exp;
branches;
next	1.37;

1.37
date	2003.07.29.23.02.52;	author itojun;	state Exp;
branches;
next	1.36;

1.36
date	2003.06.18.22.47.54;	author henning;	state Exp;
branches;
next	1.35;

1.35
date	2003.06.02.23.28.11;	author millert;	state Exp;
branches;
next	1.34;

1.34
date	2003.04.01.23.42.24;	author art;	state Exp;
branches;
next	1.33;

1.33
date	2002.06.06.21.34.16;	author provos;	state Exp;
branches;
next	1.32;

1.32
date	2002.03.14.03.16.10;	author millert;	state Exp;
branches;
next	1.31;

1.31
date	2002.03.14.01.27.09;	author millert;	state Exp;
branches;
next	1.30;

1.30
date	2001.10.02.18.04.35;	author deraadt;	state Exp;
branches
	1.30.4.1;
next	1.29;

1.29
date	2001.09.15.20.40.46;	author frantzen;	state Exp;
branches;
next	1.28;

1.28
date	2001.06.08.04.19.24;	author angelos;	state Exp;
branches;
next	1.27;

1.27
date	2001.05.28.19.51.06;	author dugsong;	state Exp;
branches;
next	1.26;

1.26
date	2001.05.16.12.53.34;	author ho;	state Exp;
branches;
next	1.25;

1.25
date	2001.04.04.02.39.17;	author jason;	state Exp;
branches;
next	1.24;

1.24
date	2001.03.25.02.44.42;	author csapuntz;	state Exp;
branches;
next	1.23;

1.23
date	2001.03.13.05.09.51;	author mickey;	state Exp;
branches;
next	1.22;

1.22
date	2000.06.19.03.00.51;	author jason;	state Exp;
branches;
next	1.21;

1.21
date	2000.06.08.22.25.24;	author niklas;	state Exp;
branches;
next	1.20;

1.20
date	2000.03.23.16.36.36;	author art;	state Exp;
branches;
next	1.19;

1.19
date	2000.02.19.08.59.04;	author niklas;	state Exp;
branches;
next	1.18;

1.18
date	99.08.10.02.42.30;	author deraadt;	state Exp;
branches
	1.18.4.1;
next	1.17;

1.17
date	99.08.08.00.43.00;	author niklas;	state Exp;
branches;
next	1.16;

1.16
date	99.05.26.19.26.11;	author brad;	state Exp;
branches;
next	1.15;

1.15
date	99.04.22.20.02.42;	author art;	state Exp;
branches;
next	1.14;

1.14
date	98.11.12.16.35.02;	author deraadt;	state Exp;
branches;
next	1.13;

1.13
date	98.06.26.09.13.10;	author deraadt;	state Exp;
branches;
next	1.12;

1.12
date	97.09.30.02.31.04;	author millert;	state Exp;
branches;
next	1.11;

1.11
date	97.09.05.20.17.30;	author deraadt;	state Exp;
branches;
next	1.10;

1.10
date	97.08.31.20.42.29;	author deraadt;	state Exp;
branches;
next	1.9;

1.9
date	97.03.17.16.29.37;	author niklas;	state Exp;
branches;
next	1.8;

1.8
date	97.02.12.03.35.11;	author deraadt;	state Exp;
branches;
next	1.7;

1.7
date	97.01.27.23.21.18;	author deraadt;	state Exp;
branches;
next	1.6;

1.6
date	96.12.07.09.17.46;	author deraadt;	state Exp;
branches;
next	1.5;

1.5
date	96.06.18.16.12.17;	author deraadt;	state Exp;
branches;
next	1.4;

1.4
date	96.05.10.12.31.05;	author deraadt;	state Exp;
branches;
next	1.3;

1.3
date	96.04.21.22.28.27;	author deraadt;	state Exp;
branches;
next	1.2;

1.2
date	96.03.03.21.07.00;	author niklas;	state Exp;
branches;
next	1.1;

1.1
date	95.10.18.08.53.05;	author deraadt;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	95.10.18.08.53.05;	author deraadt;	state Exp;
branches;
next	;

1.18.4.1
date	2000.02.20.11.57.19;	author niklas;	state Exp;
branches;
next	1.18.4.2;

1.18.4.2
date	2000.03.24.09.09.31;	author niklas;	state Exp;
branches;
next	1.18.4.3;

1.18.4.3
date	2001.05.14.22.39.58;	author niklas;	state Exp;
branches;
next	1.18.4.4;

1.18.4.4
date	2001.07.04.10.53.50;	author niklas;	state Exp;
branches;
next	1.18.4.5;

1.18.4.5
date	2001.10.31.03.29.02;	author nate;	state Exp;
branches;
next	1.18.4.6;

1.18.4.6
date	2002.03.28.14.57.36;	author niklas;	state Exp;
branches;
next	1.18.4.7;

1.18.4.7
date	2003.03.28.00.41.28;	author niklas;	state Exp;
branches;
next	1.18.4.8;

1.18.4.8
date	2003.05.13.19.36.14;	author ho;	state Exp;
branches;
next	1.18.4.9;

1.18.4.9
date	2003.06.07.11.06.06;	author ho;	state Exp;
branches;
next	1.18.4.10;

1.18.4.10
date	2004.02.19.10.57.20;	author niklas;	state Exp;
branches;
next	1.18.4.11;

1.18.4.11
date	2004.06.05.23.11.23;	author niklas;	state Exp;
branches;
next	;

1.30.4.1
date	2002.06.11.03.30.45;	author art;	state Exp;
branches;
next	1.30.4.2;

1.30.4.2
date	2003.05.19.22.29.06;	author tedu;	state Exp;
branches;
next	;


desc
@@


1.163
log
@When using "tcpdump proto 128" the filter never matched.  A sign
expansion bug in bpf prevented protocols above 127.  m_data is
signed, bpf_mbuf_ldb() returns unsigned.
bug report Matthias Pitzl; OK deraadt@@ millert@@
@
text
@/*	$OpenBSD: bpf.c,v 1.162 2017/05/04 15:00:24 bluhm Exp $	*/
/*	$NetBSD: bpf.c,v 1.33 1997/02/21 23:59:35 thorpej Exp $	*/

/*
 * Copyright (c) 1990, 1991, 1993
 *	The Regents of the University of California.  All rights reserved.
 * Copyright (c) 2010, 2014 Henning Brauer <henning@@openbsd.org>
 *
 * This code is derived from the Stanford/CMU enet packet filter,
 * (net/enet.c) distributed as part of 4.3BSD, and code contributed
 * to Berkeley by Steven McCanne and Van Jacobson both of Lawrence
 * Berkeley Laboratory.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. Neither the name of the University nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 *	@@(#)bpf.c	8.2 (Berkeley) 3/28/94
 */

#include "bpfilter.h"

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/mbuf.h>
#include <sys/proc.h>
#include <sys/signalvar.h>
#include <sys/ioctl.h>
#include <sys/conf.h>
#include <sys/vnode.h>
#include <sys/file.h>
#include <sys/socket.h>
#include <sys/poll.h>
#include <sys/kernel.h>
#include <sys/sysctl.h>
#include <sys/rwlock.h>
#include <sys/atomic.h>
#include <sys/srp.h>
#include <sys/specdev.h>
#include <sys/selinfo.h>
#include <sys/task.h>

#include <net/if.h>
#include <net/bpf.h>
#include <net/bpfdesc.h>

#include <netinet/in.h>
#include <netinet/if_ether.h>

#include "vlan.h"
#if NVLAN > 0
#include <net/if_vlan_var.h>
#endif

#define BPF_BUFSIZE 32768

#define PRINET  26			/* interruptible */

/* from kern/kern_clock.c; incremented each clock tick. */
extern int ticks;

/*
 * The default read buffer size is patchable.
 */
int bpf_bufsize = BPF_BUFSIZE;
int bpf_maxbufsize = BPF_MAXBUFSIZE;

/*
 *  bpf_iflist is the list of interfaces; each corresponds to an ifnet
 *  bpf_d_list is the list of descriptors
 */
struct bpf_if	*bpf_iflist;
LIST_HEAD(, bpf_d) bpf_d_list;

int	bpf_allocbufs(struct bpf_d *);
void	bpf_ifname(struct ifnet *, struct ifreq *);
int	_bpf_mtap(caddr_t, const struct mbuf *, u_int,
	    void (*)(const void *, void *, size_t));
void	bpf_mcopy(const void *, void *, size_t);
int	bpf_movein(struct uio *, u_int, struct mbuf **,
	    struct sockaddr *, struct bpf_insn *);
int	bpf_setif(struct bpf_d *, struct ifreq *);
int	bpfpoll(dev_t, int, struct proc *);
int	bpfkqfilter(dev_t, struct knote *);
void	bpf_wakeup(struct bpf_d *);
void	bpf_wakeup_cb(void *);
void	bpf_catchpacket(struct bpf_d *, u_char *, size_t, size_t,
	    void (*)(const void *, void *, size_t), struct timeval *);
int	bpf_getdltlist(struct bpf_d *, struct bpf_dltlist *);
int	bpf_setdlt(struct bpf_d *, u_int);

void	filt_bpfrdetach(struct knote *);
int	filt_bpfread(struct knote *, long);

int	bpf_sysctl_locked(int *, u_int, void *, size_t *, void *, size_t);

struct bpf_d *bpfilter_lookup(int);

/*
 * Called holding ``bd_mtx''.
 */
void	bpf_attachd(struct bpf_d *, struct bpf_if *);
void	bpf_detachd(struct bpf_d *);
void	bpf_resetd(struct bpf_d *);

/*
 * Reference count access to descriptor buffers
 */
void	bpf_get(struct bpf_d *);
void	bpf_put(struct bpf_d *);

/*
 * garbage collector srps
 */

void bpf_d_ref(void *, void *);
void bpf_d_unref(void *, void *);
struct srpl_rc bpf_d_rc = SRPL_RC_INITIALIZER(bpf_d_ref, bpf_d_unref, NULL);

void bpf_insn_dtor(void *, void *);
struct srp_gc bpf_insn_gc = SRP_GC_INITIALIZER(bpf_insn_dtor, NULL);

struct rwlock bpf_sysctl_lk = RWLOCK_INITIALIZER("bpfsz");

int
bpf_movein(struct uio *uio, u_int linktype, struct mbuf **mp,
    struct sockaddr *sockp, struct bpf_insn *filter)
{
	struct mbuf *m;
	struct m_tag *mtag;
	int error;
	u_int hlen;
	u_int len;
	u_int slen;

	/*
	 * Build a sockaddr based on the data link layer type.
	 * We do this at this level because the ethernet header
	 * is copied directly into the data field of the sockaddr.
	 * In the case of SLIP, there is no header and the packet
	 * is forwarded as is.
	 * Also, we are careful to leave room at the front of the mbuf
	 * for the link level header.
	 */
	switch (linktype) {

	case DLT_SLIP:
		sockp->sa_family = AF_INET;
		hlen = 0;
		break;

	case DLT_PPP:
		sockp->sa_family = AF_UNSPEC;
		hlen = 0;
		break;

	case DLT_EN10MB:
		sockp->sa_family = AF_UNSPEC;
		/* XXX Would MAXLINKHDR be better? */
		hlen = ETHER_HDR_LEN;
		break;

	case DLT_IEEE802_11:
	case DLT_IEEE802_11_RADIO:
		sockp->sa_family = AF_UNSPEC;
		hlen = 0;
		break;

	case DLT_RAW:
	case DLT_NULL:
		sockp->sa_family = AF_UNSPEC;
		hlen = 0;
		break;

	case DLT_LOOP:
		sockp->sa_family = AF_UNSPEC;
		hlen = sizeof(u_int32_t);
		break;

	default:
		return (EIO);
	}

	if (uio->uio_resid > MAXMCLBYTES)
		return (EIO);
	len = uio->uio_resid;

	MGETHDR(m, M_WAIT, MT_DATA);
	m->m_pkthdr.ph_ifidx = 0;
	m->m_pkthdr.len = len - hlen;

	if (len > MHLEN) {
		MCLGETI(m, M_WAIT, NULL, len);
		if ((m->m_flags & M_EXT) == 0) {
			error = ENOBUFS;
			goto bad;
		}
	}
	m->m_len = len;
	*mp = m;

	error = uiomove(mtod(m, caddr_t), len, uio);
	if (error)
		goto bad;

	slen = bpf_filter(filter, mtod(m, u_char *), len, len);
	if (slen < len) {
		error = EPERM;
		goto bad;
	}

	if (m->m_len < hlen) {
		error = EPERM;
		goto bad;
	}
	/*
	 * Make room for link header, and copy it to sockaddr
	 */
	if (hlen != 0) {
		if (linktype == DLT_LOOP) {
			u_int32_t af;

			/* the link header indicates the address family */
			KASSERT(hlen == sizeof(u_int32_t));
			memcpy(&af, m->m_data, hlen);
			sockp->sa_family = ntohl(af);
		} else
			memcpy(sockp->sa_data, m->m_data, hlen);
		m->m_len -= hlen;
		m->m_data += hlen; /* XXX */
	}

	/*
	 * Prepend the data link type as a mbuf tag
	 */
	mtag = m_tag_get(PACKET_TAG_DLT, sizeof(u_int), M_WAIT);
	*(u_int *)(mtag + 1) = linktype;
	m_tag_prepend(m, mtag);

	return (0);
 bad:
	m_freem(m);
	return (error);
}

/*
 * Attach file to the bpf interface, i.e. make d listen on bp.
 */
void
bpf_attachd(struct bpf_d *d, struct bpf_if *bp)
{
	MUTEX_ASSERT_LOCKED(&d->bd_mtx);

	/*
	 * Point d at bp, and add d to the interface's list of listeners.
	 * Finally, point the driver's bpf cookie at the interface so
	 * it will divert packets to bpf.
	 */

	d->bd_bif = bp;

	KERNEL_ASSERT_LOCKED();
	SRPL_INSERT_HEAD_LOCKED(&bpf_d_rc, &bp->bif_dlist, d, bd_next);

	*bp->bif_driverp = bp;
}

/*
 * Detach a file from its interface.
 */
void
bpf_detachd(struct bpf_d *d)
{
	struct bpf_if *bp;

	MUTEX_ASSERT_LOCKED(&d->bd_mtx);

	bp = d->bd_bif;
	/* Not attached. */
	if (bp == NULL)
		return;

	/* Remove ``d'' from the interface's descriptor list. */
	KERNEL_ASSERT_LOCKED();
	SRPL_REMOVE_LOCKED(&bpf_d_rc, &bp->bif_dlist, d, bpf_d, bd_next);

	if (SRPL_EMPTY_LOCKED(&bp->bif_dlist)) {
		/*
		 * Let the driver know that there are no more listeners.
		 */
		*bp->bif_driverp = NULL;
	}

	d->bd_bif = NULL;

	/*
	 * Check if this descriptor had requested promiscuous mode.
	 * If so, turn it off.
	 */
	if (d->bd_promisc) {
		int error;

		d->bd_promisc = 0;

		bpf_get(d);
		mtx_leave(&d->bd_mtx);
		error = ifpromisc(bp->bif_ifp, 0);
		mtx_enter(&d->bd_mtx);
		bpf_put(d);

		if (error && !(error == EINVAL || error == ENODEV))
			/*
			 * Something is really wrong if we were able to put
			 * the driver into promiscuous mode, but can't
			 * take it out.
			 */
			panic("bpf: ifpromisc failed");
	}
}

void
bpfilterattach(int n)
{
	LIST_INIT(&bpf_d_list);
}

/*
 * Open ethernet device.  Returns ENXIO for illegal minor device number,
 * EBUSY if file is open by another process.
 */
int
bpfopen(dev_t dev, int flag, int mode, struct proc *p)
{
	struct bpf_d *bd;
	int unit = minor(dev);

	if (unit & ((1 << CLONE_SHIFT) - 1))
		return (ENXIO);

	KASSERT(bpfilter_lookup(unit) == NULL);

	/* create on demand */
	if ((bd = malloc(sizeof(*bd), M_DEVBUF, M_NOWAIT|M_ZERO)) == NULL)
		return (EBUSY);

	/* Mark "free" and do most initialization. */
	bd->bd_unit = unit;
	bd->bd_bufsize = bpf_bufsize;
	bd->bd_sig = SIGIO;
	mtx_init(&bd->bd_mtx, IPL_NET);
	task_set(&bd->bd_wake_task, bpf_wakeup_cb, bd);

	if (flag & FNONBLOCK)
		bd->bd_rtout = -1;

	bpf_get(bd);
	LIST_INSERT_HEAD(&bpf_d_list, bd, bd_list);

	return (0);
}

/*
 * Close the descriptor by detaching it from its interface,
 * deallocating its buffers, and marking it free.
 */
int
bpfclose(dev_t dev, int flag, int mode, struct proc *p)
{
	struct bpf_d *d;

	d = bpfilter_lookup(minor(dev));
	mtx_enter(&d->bd_mtx);
	bpf_detachd(d);
	bpf_wakeup(d);
	LIST_REMOVE(d, bd_list);
	mtx_leave(&d->bd_mtx);
	bpf_put(d);

	return (0);
}

/*
 * Rotate the packet buffers in descriptor d.  Move the store buffer
 * into the hold slot, and the free buffer into the store slot.
 * Zero the length of the new store buffer.
 */
#define ROTATE_BUFFERS(d) \
	KASSERT(d->bd_in_uiomove == 0); \
	MUTEX_ASSERT_LOCKED(&d->bd_mtx); \
	(d)->bd_hbuf = (d)->bd_sbuf; \
	(d)->bd_hlen = (d)->bd_slen; \
	(d)->bd_sbuf = (d)->bd_fbuf; \
	(d)->bd_slen = 0; \
	(d)->bd_fbuf = NULL;
/*
 *  bpfread - read next chunk of packets from buffers
 */
int
bpfread(dev_t dev, struct uio *uio, int ioflag)
{
	struct bpf_d *d;
	caddr_t hbuf;
	int hlen, error;

	KERNEL_ASSERT_LOCKED();

	d = bpfilter_lookup(minor(dev));
	if (d->bd_bif == NULL)
		return (ENXIO);

	bpf_get(d);
	mtx_enter(&d->bd_mtx);

	/*
	 * Restrict application to use a buffer the same size as
	 * as kernel buffers.
	 */
	if (uio->uio_resid != d->bd_bufsize) {
		error = EINVAL;
		goto out;
	}

	/*
	 * If there's a timeout, bd_rdStart is tagged when we start the read.
	 * we can then figure out when we're done reading.
	 */
	if (d->bd_rtout != -1 && d->bd_rdStart == 0)
		d->bd_rdStart = ticks;
	else
		d->bd_rdStart = 0;

	/*
	 * If the hold buffer is empty, then do a timed sleep, which
	 * ends when the timeout expires or when enough packets
	 * have arrived to fill the store buffer.
	 */
	while (d->bd_hbuf == NULL) {
		if (d->bd_bif == NULL) {
			/* interface is gone */
			if (d->bd_slen == 0) {
				error = EIO;
				goto out;
			}
			ROTATE_BUFFERS(d);
			break;
		}
		if (d->bd_immediate && d->bd_slen != 0) {
			/*
			 * A packet(s) either arrived since the previous
			 * read or arrived while we were asleep.
			 * Rotate the buffers and return what's here.
			 */
			ROTATE_BUFFERS(d);
			break;
		}
		if (d->bd_rtout == -1) {
			/* User requested non-blocking I/O */
			error = EWOULDBLOCK;
		} else {
			if ((d->bd_rdStart + d->bd_rtout) < ticks) {
				error = msleep(d, &d->bd_mtx, PRINET|PCATCH,
				    "bpf", d->bd_rtout);
			} else
				error = EWOULDBLOCK;
		}
		if (error == EINTR || error == ERESTART)
			goto out;
		if (error == EWOULDBLOCK) {
			/*
			 * On a timeout, return what's in the buffer,
			 * which may be nothing.  If there is something
			 * in the store buffer, we can rotate the buffers.
			 */
			if (d->bd_hbuf != NULL)
				/*
				 * We filled up the buffer in between
				 * getting the timeout and arriving
				 * here, so we don't need to rotate.
				 */
				break;

			if (d->bd_slen == 0) {
				error = 0;
				goto out;
			}
			ROTATE_BUFFERS(d);
			break;
		}
	}
	/*
	 * At this point, we know we have something in the hold slot.
	 */
	hbuf = d->bd_hbuf;
	hlen = d->bd_hlen;
	d->bd_hbuf = NULL;
	d->bd_hlen = 0;
	d->bd_fbuf = NULL;
	d->bd_in_uiomove = 1;

	/*
	 * Move data from hold buffer into user space.
	 * We know the entire buffer is transferred since
	 * we checked above that the read buffer is bpf_bufsize bytes.
	 */
	mtx_leave(&d->bd_mtx);
	error = uiomove(hbuf, hlen, uio);
	mtx_enter(&d->bd_mtx);

	/* Ensure that bpf_resetd() or ROTATE_BUFFERS() haven't been called. */
	KASSERT(d->bd_fbuf == NULL);
	KASSERT(d->bd_hbuf == NULL);
	d->bd_fbuf = hbuf;
	d->bd_in_uiomove = 0;
out:
	mtx_leave(&d->bd_mtx);
	bpf_put(d);

	return (error);
}


/*
 * If there are processes sleeping on this descriptor, wake them up.
 */
void
bpf_wakeup(struct bpf_d *d)
{
	MUTEX_ASSERT_LOCKED(&d->bd_mtx);

	/*
	 * As long as csignal() and selwakeup() need to be protected
	 * by the KERNEL_LOCK() we have to delay the wakeup to
	 * another context to keep the hot path KERNEL_LOCK()-free.
	 */
	bpf_get(d);
	if (!task_add(systq, &d->bd_wake_task))
		bpf_put(d);
}

void
bpf_wakeup_cb(void *xd)
{
	struct bpf_d *d = xd;

	KERNEL_ASSERT_LOCKED();

	wakeup(d);
	if (d->bd_async && d->bd_sig)
		csignal(d->bd_pgid, d->bd_sig, d->bd_siguid, d->bd_sigeuid);

	selwakeup(&d->bd_sel);
	bpf_put(d);
}

int
bpfwrite(dev_t dev, struct uio *uio, int ioflag)
{
	struct bpf_d *d;
	struct ifnet *ifp;
	struct mbuf *m;
	struct bpf_program *bf;
	struct bpf_insn *fcode = NULL;
	int error, s;
	struct sockaddr_storage dst;
	u_int dlt;

	KERNEL_ASSERT_LOCKED();

	d = bpfilter_lookup(minor(dev));
	if (d->bd_bif == NULL)
		return (ENXIO);

	bpf_get(d);
	ifp = d->bd_bif->bif_ifp;

	if ((ifp->if_flags & IFF_UP) == 0) {
		error = ENETDOWN;
		goto out;
	}

	if (uio->uio_resid == 0) {
		error = 0;
		goto out;
	}

	KERNEL_ASSERT_LOCKED(); /* for accessing bd_wfilter */
	bf = srp_get_locked(&d->bd_wfilter);
	if (bf != NULL)
		fcode = bf->bf_insns;

	dlt = d->bd_bif->bif_dlt;

	error = bpf_movein(uio, dlt, &m, sstosa(&dst), fcode);
	if (error)
		goto out;

	if (m->m_pkthdr.len > ifp->if_mtu) {
		m_freem(m);
		error = EMSGSIZE;
		goto out;
	}

	m->m_pkthdr.ph_rtableid = ifp->if_rdomain;
	m->m_pkthdr.pf.prio = ifp->if_llprio;

	if (d->bd_hdrcmplt && dst.ss_family == AF_UNSPEC)
		dst.ss_family = pseudo_AF_HDRCMPLT;

	NET_LOCK(s);
	error = ifp->if_output(ifp, m, sstosa(&dst), NULL);
	NET_UNLOCK(s);

out:
	bpf_put(d);
	return (error);
}

/*
 * Reset a descriptor by flushing its packet buffer and clearing the
 * receive and drop counts.
 */
void
bpf_resetd(struct bpf_d *d)
{
	MUTEX_ASSERT_LOCKED(&d->bd_mtx);
	KASSERT(d->bd_in_uiomove == 0);

	if (d->bd_hbuf != NULL) {
		/* Free the hold buffer. */
		d->bd_fbuf = d->bd_hbuf;
		d->bd_hbuf = NULL;
	}
	d->bd_slen = 0;
	d->bd_hlen = 0;
	d->bd_rcount = 0;
	d->bd_dcount = 0;
}

/*
 *  FIONREAD		Check for read packet available.
 *  BIOCGBLEN		Get buffer len [for read()].
 *  BIOCSETF		Set ethernet read filter.
 *  BIOCFLUSH		Flush read packet buffer.
 *  BIOCPROMISC		Put interface into promiscuous mode.
 *  BIOCGDLTLIST	Get supported link layer types.
 *  BIOCGDLT		Get link layer type.
 *  BIOCSDLT		Set link layer type.
 *  BIOCGETIF		Get interface name.
 *  BIOCSETIF		Set interface.
 *  BIOCSRTIMEOUT	Set read timeout.
 *  BIOCGRTIMEOUT	Get read timeout.
 *  BIOCGSTATS		Get packet stats.
 *  BIOCIMMEDIATE	Set immediate mode.
 *  BIOCVERSION		Get filter language version.
 *  BIOCGHDRCMPLT	Get "header already complete" flag
 *  BIOCSHDRCMPLT	Set "header already complete" flag
 */
int
bpfioctl(dev_t dev, u_long cmd, caddr_t addr, int flag, struct proc *p)
{
	struct bpf_d *d;
	int error = 0;

	d = bpfilter_lookup(minor(dev));
	if (d->bd_locked && suser(p, 0) != 0) {
		/* list of allowed ioctls when locked and not root */
		switch (cmd) {
		case BIOCGBLEN:
		case BIOCFLUSH:
		case BIOCGDLT:
		case BIOCGDLTLIST:
		case BIOCGETIF:
		case BIOCGRTIMEOUT:
		case BIOCGSTATS:
		case BIOCVERSION:
		case BIOCGRSIG:
		case BIOCGHDRCMPLT:
		case FIONREAD:
		case BIOCLOCK:
		case BIOCSRTIMEOUT:
		case BIOCIMMEDIATE:
		case TIOCGPGRP:
		case BIOCGDIRFILT:
			break;
		default:
			return (EPERM);
		}
	}

	bpf_get(d);

	switch (cmd) {
	default:
		error = EINVAL;
		break;

	/*
	 * Check for read packet available.
	 */
	case FIONREAD:
		{
			int n;

			mtx_enter(&d->bd_mtx);
			n = d->bd_slen;
			if (d->bd_hbuf != NULL)
				n += d->bd_hlen;
			mtx_leave(&d->bd_mtx);

			*(int *)addr = n;
			break;
		}

	/*
	 * Get buffer len [for read()].
	 */
	case BIOCGBLEN:
		*(u_int *)addr = d->bd_bufsize;
		break;

	/*
	 * Set buffer length.
	 */
	case BIOCSBLEN:
		if (d->bd_bif != NULL)
			error = EINVAL;
		else {
			u_int size = *(u_int *)addr;

			if (size > bpf_maxbufsize)
				*(u_int *)addr = size = bpf_maxbufsize;
			else if (size < BPF_MINBUFSIZE)
				*(u_int *)addr = size = BPF_MINBUFSIZE;
			mtx_enter(&d->bd_mtx);
			d->bd_bufsize = size;
			mtx_leave(&d->bd_mtx);
		}
		break;

	/*
	 * Set link layer read filter.
	 */
	case BIOCSETF:
		error = bpf_setf(d, (struct bpf_program *)addr, 0);
		break;

	/*
	 * Set link layer write filter.
	 */
	case BIOCSETWF:
		error = bpf_setf(d, (struct bpf_program *)addr, 1);
		break;

	/*
	 * Flush read packet buffer.
	 */
	case BIOCFLUSH:
		mtx_enter(&d->bd_mtx);
		bpf_resetd(d);
		mtx_leave(&d->bd_mtx);
		break;

	/*
	 * Put interface into promiscuous mode.
	 */
	case BIOCPROMISC:
		if (d->bd_bif == NULL) {
			/*
			 * No interface attached yet.
			 */
			error = EINVAL;
		} else {
			if (d->bd_promisc == 0) {
				MUTEX_ASSERT_UNLOCKED(&d->bd_mtx);
				error = ifpromisc(d->bd_bif->bif_ifp, 1);
				if (error == 0)
					d->bd_promisc = 1;
			}
		}
		break;

	/*
	 * Get a list of supported device parameters.
	 */
	case BIOCGDLTLIST:
		if (d->bd_bif == NULL)
			error = EINVAL;
		else
			error = bpf_getdltlist(d, (struct bpf_dltlist *)addr);
		break;

	/*
	 * Get device parameters.
	 */
	case BIOCGDLT:
		if (d->bd_bif == NULL)
			error = EINVAL;
		else
			*(u_int *)addr = d->bd_bif->bif_dlt;
		break;

	/*
	 * Set device parameters.
	 */
	case BIOCSDLT:
		if (d->bd_bif == NULL)
			error = EINVAL;
		else {
			mtx_enter(&d->bd_mtx);
			error = bpf_setdlt(d, *(u_int *)addr);
			mtx_leave(&d->bd_mtx);
		}
		break;

	/*
	 * Set interface name.
	 */
	case BIOCGETIF:
		if (d->bd_bif == NULL)
			error = EINVAL;
		else
			bpf_ifname(d->bd_bif->bif_ifp, (struct ifreq *)addr);
		break;

	/*
	 * Set interface.
	 */
	case BIOCSETIF:
		error = bpf_setif(d, (struct ifreq *)addr);
		break;

	/*
	 * Set read timeout.
	 */
	case BIOCSRTIMEOUT:
		{
			struct timeval *tv = (struct timeval *)addr;

			/* Compute number of ticks. */
			d->bd_rtout = tv->tv_sec * hz + tv->tv_usec / tick;
			if (d->bd_rtout == 0 && tv->tv_usec != 0)
				d->bd_rtout = 1;
			break;
		}

	/*
	 * Get read timeout.
	 */
	case BIOCGRTIMEOUT:
		{
			struct timeval *tv = (struct timeval *)addr;

			tv->tv_sec = d->bd_rtout / hz;
			tv->tv_usec = (d->bd_rtout % hz) * tick;
			break;
		}

	/*
	 * Get packet stats.
	 */
	case BIOCGSTATS:
		{
			struct bpf_stat *bs = (struct bpf_stat *)addr;

			bs->bs_recv = d->bd_rcount;
			bs->bs_drop = d->bd_dcount;
			break;
		}

	/*
	 * Set immediate mode.
	 */
	case BIOCIMMEDIATE:
		d->bd_immediate = *(u_int *)addr;
		break;

	case BIOCVERSION:
		{
			struct bpf_version *bv = (struct bpf_version *)addr;

			bv->bv_major = BPF_MAJOR_VERSION;
			bv->bv_minor = BPF_MINOR_VERSION;
			break;
		}

	case BIOCGHDRCMPLT:	/* get "header already complete" flag */
		*(u_int *)addr = d->bd_hdrcmplt;
		break;

	case BIOCSHDRCMPLT:	/* set "header already complete" flag */
		d->bd_hdrcmplt = *(u_int *)addr ? 1 : 0;
		break;

	case BIOCLOCK:		/* set "locked" flag (no reset) */
		d->bd_locked = 1;
		break;

	case BIOCGFILDROP:	/* get "filter-drop" flag */
		*(u_int *)addr = d->bd_fildrop;
		break;

	case BIOCSFILDROP:	/* set "filter-drop" flag */
		d->bd_fildrop = *(u_int *)addr ? 1 : 0;
		break;

	case BIOCGDIRFILT:	/* get direction filter */
		*(u_int *)addr = d->bd_dirfilt;
		break;

	case BIOCSDIRFILT:	/* set direction filter */
		d->bd_dirfilt = (*(u_int *)addr) &
		    (BPF_DIRECTION_IN|BPF_DIRECTION_OUT);
		break;

	case FIONBIO:		/* Non-blocking I/O */
		if (*(int *)addr)
			d->bd_rtout = -1;
		else
			d->bd_rtout = 0;
		break;

	case FIOASYNC:		/* Send signal on receive packets */
		d->bd_async = *(int *)addr;
		break;

	/*
	 * N.B.  ioctl (FIOSETOWN) and fcntl (F_SETOWN) both end up doing
	 * the equivalent of a TIOCSPGRP and hence end up here.  *However*
	 * TIOCSPGRP's arg is a process group if it's positive and a process
	 * id if it's negative.  This is exactly the opposite of what the
	 * other two functions want!  Therefore there is code in ioctl and
	 * fcntl to negate the arg before calling here.
	 */
	case TIOCSPGRP:		/* Process or group to send signals to */
		d->bd_pgid = *(int *)addr;
		d->bd_siguid = p->p_ucred->cr_ruid;
		d->bd_sigeuid = p->p_ucred->cr_uid;
		break;

	case TIOCGPGRP:
		*(int *)addr = d->bd_pgid;
		break;

	case BIOCSRSIG:		/* Set receive signal */
		{
			u_int sig;

			sig = *(u_int *)addr;

			if (sig >= NSIG)
				error = EINVAL;
			else
				d->bd_sig = sig;
			break;
		}
	case BIOCGRSIG:
		*(u_int *)addr = d->bd_sig;
		break;
	}

	bpf_put(d);
	return (error);
}

/*
 * Set d's packet filter program to fp.  If this file already has a filter,
 * free it and replace it.  Returns EINVAL for bogus requests.
 */
int
bpf_setf(struct bpf_d *d, struct bpf_program *fp, int wf)
{
	struct bpf_program *bf;
	struct srp *filter;
	struct bpf_insn *fcode;
	u_int flen, size;

	KERNEL_ASSERT_LOCKED();
	filter = wf ? &d->bd_wfilter : &d->bd_rfilter;

	if (fp->bf_insns == 0) {
		if (fp->bf_len != 0)
			return (EINVAL);
		srp_update_locked(&bpf_insn_gc, filter, NULL);
		mtx_enter(&d->bd_mtx);
		bpf_resetd(d);
		mtx_leave(&d->bd_mtx);
		return (0);
	}
	flen = fp->bf_len;
	if (flen > BPF_MAXINSNS)
		return (EINVAL);

	fcode = mallocarray(flen, sizeof(*fp->bf_insns), M_DEVBUF,
	    M_WAITOK | M_CANFAIL);
	if (fcode == NULL)
		return (ENOMEM);

	size = flen * sizeof(*fp->bf_insns);
	if (copyin(fp->bf_insns, fcode, size) != 0 ||
	    bpf_validate(fcode, (int)flen) == 0) {
		free(fcode, M_DEVBUF, size);
		return (EINVAL);
	}

	bf = malloc(sizeof(*bf), M_DEVBUF, M_WAITOK);
	bf->bf_len = flen;
	bf->bf_insns = fcode;

	srp_update_locked(&bpf_insn_gc, filter, bf);

	mtx_enter(&d->bd_mtx);
	bpf_resetd(d);
	mtx_leave(&d->bd_mtx);
	return (0);
}

/*
 * Detach a file from its current interface (if attached at all) and attach
 * to the interface indicated by the name stored in ifr.
 * Return an errno or 0.
 */
int
bpf_setif(struct bpf_d *d, struct ifreq *ifr)
{
	struct bpf_if *bp, *candidate = NULL;
	int error = 0;

	/*
	 * Look through attached interfaces for the named one.
	 */
	for (bp = bpf_iflist; bp != NULL; bp = bp->bif_next) {
		struct ifnet *ifp = bp->bif_ifp;

		if (ifp == NULL ||
		    strcmp(ifp->if_xname, ifr->ifr_name) != 0)
			continue;

		if (candidate == NULL || candidate->bif_dlt > bp->bif_dlt)
			candidate = bp;
	}

	/* Not found. */
	if (candidate == NULL)
		return (ENXIO);

	/*
	 * Allocate the packet buffers if we need to.
	 * If we're already attached to requested interface,
	 * just flush the buffer.
	 */
	mtx_enter(&d->bd_mtx);
	if (d->bd_sbuf == NULL) {
		if ((error = bpf_allocbufs(d)))
			goto out;
	}
	if (candidate != d->bd_bif) {
		/*
		 * Detach if attached to something else.
		 */
		bpf_detachd(d);
		bpf_attachd(d, candidate);
	}
	bpf_resetd(d);
out:
	mtx_leave(&d->bd_mtx);
	return (error);
}

/*
 * Copy the interface name to the ifreq.
 */
void
bpf_ifname(struct ifnet *ifp, struct ifreq *ifr)
{
	bcopy(ifp->if_xname, ifr->ifr_name, IFNAMSIZ);
}

/*
 * Support for poll() system call
 */
int
bpfpoll(dev_t dev, int events, struct proc *p)
{
	struct bpf_d *d;
	int revents;

	KERNEL_ASSERT_LOCKED();

	/*
	 * An imitation of the FIONREAD ioctl code.
	 */
	d = bpfilter_lookup(minor(dev));

	/*
	 * XXX The USB stack manages it to trigger some race condition
	 * which causes bpfilter_lookup to return NULL when a USB device
	 * gets detached while it is up and has an open bpf handler (e.g.
	 * dhclient).  We still should recheck if we can fix the root
	 * cause of this issue.
	 */
	if (d == NULL)
		return (POLLERR);

	/* Always ready to write data */
	revents = events & (POLLOUT | POLLWRNORM);

	if (events & (POLLIN | POLLRDNORM)) {
		mtx_enter(&d->bd_mtx);
		if (d->bd_hlen != 0 || (d->bd_immediate && d->bd_slen != 0))
			revents |= events & (POLLIN | POLLRDNORM);
		else {
			/*
			 * if there's a timeout, mark the time we
			 * started waiting.
			 */
			if (d->bd_rtout != -1 && d->bd_rdStart == 0)
				d->bd_rdStart = ticks;
			selrecord(p, &d->bd_sel);
		}
		mtx_leave(&d->bd_mtx);
	}
	return (revents);
}

struct filterops bpfread_filtops =
	{ 1, NULL, filt_bpfrdetach, filt_bpfread };

int
bpfkqfilter(dev_t dev, struct knote *kn)
{
	struct bpf_d *d;
	struct klist *klist;

	KERNEL_ASSERT_LOCKED();

	d = bpfilter_lookup(minor(dev));

	switch (kn->kn_filter) {
	case EVFILT_READ:
		klist = &d->bd_sel.si_note;
		kn->kn_fop = &bpfread_filtops;
		break;
	default:
		return (EINVAL);
	}

	bpf_get(d);
	kn->kn_hook = d;
	SLIST_INSERT_HEAD(klist, kn, kn_selnext);

	mtx_enter(&d->bd_mtx);
	if (d->bd_rtout != -1 && d->bd_rdStart == 0)
		d->bd_rdStart = ticks;
	mtx_leave(&d->bd_mtx);

	return (0);
}

void
filt_bpfrdetach(struct knote *kn)
{
	struct bpf_d *d = kn->kn_hook;

	KERNEL_ASSERT_LOCKED();

	SLIST_REMOVE(&d->bd_sel.si_note, kn, knote, kn_selnext);
	bpf_put(d);
}

int
filt_bpfread(struct knote *kn, long hint)
{
	struct bpf_d *d = kn->kn_hook;

	KERNEL_ASSERT_LOCKED();

	mtx_enter(&d->bd_mtx);
	kn->kn_data = d->bd_hlen;
	if (d->bd_immediate)
		kn->kn_data += d->bd_slen;
	mtx_leave(&d->bd_mtx);

	return (kn->kn_data > 0);
}

/*
 * Copy data from an mbuf chain into a buffer.  This code is derived
 * from m_copydata in sys/uipc_mbuf.c.
 */
void
bpf_mcopy(const void *src_arg, void *dst_arg, size_t len)
{
	const struct mbuf *m;
	u_int count;
	u_char *dst;

	m = src_arg;
	dst = dst_arg;
	while (len > 0) {
		if (m == NULL)
			panic("bpf_mcopy");
		count = min(m->m_len, len);
		bcopy(mtod(m, caddr_t), (caddr_t)dst, count);
		m = m->m_next;
		dst += count;
		len -= count;
	}
}

/*
 * like bpf_mtap, but copy fn can be given. used by various bpf_mtap*
 */
int
_bpf_mtap(caddr_t arg, const struct mbuf *m, u_int direction,
    void (*cpfn)(const void *, void *, size_t))
{
	struct bpf_if *bp = (struct bpf_if *)arg;
	struct srp_ref sr;
	struct bpf_d *d;
	size_t pktlen, slen;
	const struct mbuf *m0;
	struct timeval tv;
	int gottime = 0;
	int drop = 0;

	if (m == NULL)
		return (0);

	if (cpfn == NULL)
		cpfn = bpf_mcopy;

	if (bp == NULL)
		return (0);

	pktlen = 0;
	for (m0 = m; m0 != NULL; m0 = m0->m_next)
		pktlen += m0->m_len;

	SRPL_FOREACH(d, &sr, &bp->bif_dlist, bd_next) {
		atomic_inc_long(&d->bd_rcount);

		if ((direction & d->bd_dirfilt) != 0)
			slen = 0;
		else {
			struct srp_ref bsr;
			struct bpf_program *bf;
			struct bpf_insn *fcode = NULL;

			bf = srp_enter(&bsr, &d->bd_rfilter);
			if (bf != NULL)
				fcode = bf->bf_insns;
			slen = bpf_mfilter(fcode, m, pktlen);
			srp_leave(&bsr);
		}

		if (slen > 0) {
			if (!gottime++)
				microtime(&tv);

			mtx_enter(&d->bd_mtx);
			bpf_catchpacket(d, (u_char *)m, pktlen, slen, cpfn,
			    &tv);
			mtx_leave(&d->bd_mtx);

			if (d->bd_fildrop)
				drop = 1;
		}
	}
	SRPL_LEAVE(&sr);

	return (drop);
}

/*
 * Incoming linkage from device drivers, when packet is in an mbuf chain.
 */
int
bpf_mtap(caddr_t arg, const struct mbuf *m, u_int direction)
{
	return _bpf_mtap(arg, m, direction, NULL);
}

/*
 * Incoming linkage from device drivers, where we have a mbuf chain
 * but need to prepend some arbitrary header from a linear buffer.
 *
 * Con up a minimal dummy header to pacify bpf.  Allocate (only) a
 * struct m_hdr on the stack.  This is safe as bpf only reads from the
 * fields in this header that we initialize, and will not try to free
 * it or keep a pointer to it.
 */
int
bpf_mtap_hdr(caddr_t arg, caddr_t data, u_int dlen, const struct mbuf *m,
    u_int direction, void (*cpfn)(const void *, void *, size_t))
{
	struct m_hdr mh;
	const struct mbuf *m0;

	if (dlen > 0) {
		mh.mh_flags = 0;
		mh.mh_next = (struct mbuf *)m;
		mh.mh_len = dlen;
		mh.mh_data = data;
		m0 = (struct mbuf *)&mh;
	} else 
		m0 = m;

	return _bpf_mtap(arg, m0, direction, cpfn);
}

/*
 * Incoming linkage from device drivers, where we have a mbuf chain
 * but need to prepend the address family.
 *
 * Con up a minimal dummy header to pacify bpf.  We allocate (only) a
 * struct m_hdr on the stack.  This is safe as bpf only reads from the
 * fields in this header that we initialize, and will not try to free
 * it or keep a pointer to it.
 */
int
bpf_mtap_af(caddr_t arg, u_int32_t af, const struct mbuf *m, u_int direction)
{
	u_int32_t    afh;

	afh = htonl(af);

	return bpf_mtap_hdr(arg, (caddr_t)&afh, sizeof(afh),
	    m, direction, NULL);
}

/*
 * Incoming linkage from device drivers, where we have a mbuf chain
 * but need to prepend a VLAN encapsulation header.
 *
 * Con up a minimal dummy header to pacify bpf.  Allocate (only) a
 * struct m_hdr on the stack.  This is safe as bpf only reads from the
 * fields in this header that we initialize, and will not try to free
 * it or keep a pointer to it.
 */
int
bpf_mtap_ether(caddr_t arg, const struct mbuf *m, u_int direction)
{
#if NVLAN > 0
	struct ether_vlan_header evh;
	struct m_hdr mh;
	uint8_t prio;

	if ((m->m_flags & M_VLANTAG) == 0)
#endif
	{
		return bpf_mtap(arg, m, direction);
	}

#if NVLAN > 0
	KASSERT(m->m_len >= ETHER_HDR_LEN);

	prio = m->m_pkthdr.pf.prio;
	if (prio <= 1)
		prio = !prio;

	memcpy(&evh, mtod(m, char *), ETHER_HDR_LEN);
	evh.evl_proto = evh.evl_encap_proto;
	evh.evl_encap_proto = htons(ETHERTYPE_VLAN);
	evh.evl_tag = htons(m->m_pkthdr.ether_vtag |
	    (prio << EVL_PRIO_BITS));

	mh.mh_flags = 0;
	mh.mh_data = m->m_data + ETHER_HDR_LEN;
	mh.mh_len = m->m_len - ETHER_HDR_LEN;
	mh.mh_next = m->m_next;

	return bpf_mtap_hdr(arg, (caddr_t)&evh, sizeof(evh),
	    (struct mbuf *)&mh, direction, NULL);
#endif
}

/*
 * Move the packet data from interface memory (pkt) into the
 * store buffer.  Wake up listeners if needed.
 * "copy" is the routine called to do the actual data
 * transfer.  bcopy is passed in to copy contiguous chunks, while
 * bpf_mcopy is passed in to copy mbuf chains.  In the latter case,
 * pkt is really an mbuf.
 */
void
bpf_catchpacket(struct bpf_d *d, u_char *pkt, size_t pktlen, size_t snaplen,
    void (*cpfn)(const void *, void *, size_t), struct timeval *tv)
{
	struct bpf_hdr *hp;
	int totlen, curlen;
	int hdrlen, do_wakeup = 0;

	MUTEX_ASSERT_LOCKED(&d->bd_mtx);
	if (d->bd_bif == NULL)
		return;

	hdrlen = d->bd_bif->bif_hdrlen;

	/*
	 * Figure out how many bytes to move.  If the packet is
	 * greater or equal to the snapshot length, transfer that
	 * much.  Otherwise, transfer the whole packet (unless
	 * we hit the buffer size limit).
	 */
	totlen = hdrlen + min(snaplen, pktlen);
	if (totlen > d->bd_bufsize)
		totlen = d->bd_bufsize;

	/*
	 * Round up the end of the previous packet to the next longword.
	 */
	curlen = BPF_WORDALIGN(d->bd_slen);
	if (curlen + totlen > d->bd_bufsize) {
		/*
		 * This packet will overflow the storage buffer.
		 * Rotate the buffers if we can, then wakeup any
		 * pending reads.
		 */
		if (d->bd_fbuf == NULL) {
			/*
			 * We haven't completed the previous read yet,
			 * so drop the packet.
			 */
			++d->bd_dcount;
			return;
		}
		ROTATE_BUFFERS(d);
		do_wakeup = 1;
		curlen = 0;
	}

	/*
	 * Append the bpf header.
	 */
	hp = (struct bpf_hdr *)(d->bd_sbuf + curlen);
	hp->bh_tstamp.tv_sec = tv->tv_sec;
	hp->bh_tstamp.tv_usec = tv->tv_usec;
	hp->bh_datalen = pktlen;
	hp->bh_hdrlen = hdrlen;
	/*
	 * Copy the packet data into the store buffer and update its length.
	 */
	(*cpfn)(pkt, (u_char *)hp + hdrlen, (hp->bh_caplen = totlen - hdrlen));
	d->bd_slen = curlen + totlen;

	if (d->bd_immediate) {
		/*
		 * Immediate mode is set.  A packet arrived so any
		 * reads should be woken up.
		 */
		do_wakeup = 1;
	}

	if (d->bd_rdStart && (d->bd_rtout + d->bd_rdStart < ticks)) {
		/*
		 * we could be selecting on the bpf, and we
		 * may have timeouts set.  We got here by getting
		 * a packet, so wake up the reader.
		 */
		if (d->bd_fbuf != NULL) {
			d->bd_rdStart = 0;
			ROTATE_BUFFERS(d);
			do_wakeup = 1;
		}
	}

	if (do_wakeup)
		bpf_wakeup(d);
}

/*
 * Initialize all nonzero fields of a descriptor.
 */
int
bpf_allocbufs(struct bpf_d *d)
{
	MUTEX_ASSERT_LOCKED(&d->bd_mtx);

	d->bd_fbuf = malloc(d->bd_bufsize, M_DEVBUF, M_NOWAIT);
	if (d->bd_fbuf == NULL)
		return (ENOMEM);

	d->bd_sbuf = malloc(d->bd_bufsize, M_DEVBUF, M_NOWAIT);
	if (d->bd_sbuf == NULL) {
		free(d->bd_fbuf, M_DEVBUF, d->bd_bufsize);
		return (ENOMEM);
	}

	d->bd_slen = 0;
	d->bd_hlen = 0;

	return (0);
}

void
bpf_get(struct bpf_d *bd)
{
	atomic_inc_int(&bd->bd_ref);
}

/*
 * Free buffers currently in use by a descriptor
 * when the reference count drops to zero.
 */
void
bpf_put(struct bpf_d *bd)
{
	if (atomic_dec_int_nv(&bd->bd_ref) > 0)
		return;

	free(bd->bd_sbuf, M_DEVBUF, 0);
	free(bd->bd_hbuf, M_DEVBUF, 0);
	free(bd->bd_fbuf, M_DEVBUF, 0);
	KERNEL_ASSERT_LOCKED();
	srp_update_locked(&bpf_insn_gc, &bd->bd_rfilter, NULL);
	srp_update_locked(&bpf_insn_gc, &bd->bd_wfilter, NULL);

	free(bd, M_DEVBUF, sizeof(*bd));
}

/*
 * Attach an interface to bpf.  driverp is a pointer to a (struct bpf_if *)
 * in the driver's softc; dlt is the link layer type; hdrlen is the fixed
 * size of the link header (variable length headers not yet supported).
 */
void
bpfattach(caddr_t *driverp, struct ifnet *ifp, u_int dlt, u_int hdrlen)
{
	struct bpf_if *bp;

	if ((bp = malloc(sizeof(*bp), M_DEVBUF, M_NOWAIT)) == NULL)
		panic("bpfattach");
	SRPL_INIT(&bp->bif_dlist);
	bp->bif_driverp = (struct bpf_if **)driverp;
	bp->bif_ifp = ifp;
	bp->bif_dlt = dlt;

	bp->bif_next = bpf_iflist;
	bpf_iflist = bp;

	*bp->bif_driverp = NULL;

	/*
	 * Compute the length of the bpf header.  This is not necessarily
	 * equal to SIZEOF_BPF_HDR because we want to insert spacing such
	 * that the network layer header begins on a longword boundary (for
	 * performance reasons and to alleviate alignment restrictions).
	 */
	bp->bif_hdrlen = BPF_WORDALIGN(hdrlen + SIZEOF_BPF_HDR) - hdrlen;
}

/* Detach an interface from its attached bpf device.  */
void
bpfdetach(struct ifnet *ifp)
{
	struct bpf_if *bp, *nbp, **pbp = &bpf_iflist;
	struct bpf_d *bd;
	int maj;

	KERNEL_ASSERT_LOCKED();

	for (bp = bpf_iflist; bp; bp = nbp) {
		nbp= bp->bif_next;
		if (bp->bif_ifp == ifp) {
			*pbp = nbp;

			/* Locate the major number. */
			for (maj = 0; maj < nchrdev; maj++)
				if (cdevsw[maj].d_open == bpfopen)
					break;

			while ((bd = SRPL_FIRST_LOCKED(&bp->bif_dlist)))
				vdevgone(maj, bd->bd_unit, bd->bd_unit, VCHR);

			free(bp, M_DEVBUF, sizeof *bp);
		} else
			pbp = &bp->bif_next;
	}
	ifp->if_bpf = NULL;
}

int
bpf_sysctl_locked(int *name, u_int namelen, void *oldp, size_t *oldlenp,
    void *newp, size_t newlen)
{
	int newval;
	int error;

	switch (name[0]) {
	case NET_BPF_BUFSIZE:
		newval = bpf_bufsize;
		error = sysctl_int(oldp, oldlenp, newp, newlen, &newval);
		if (error)
			return (error);
		if (newval < BPF_MINBUFSIZE || newval > bpf_maxbufsize)
			return (EINVAL);
		bpf_bufsize = newval;
		break;
	case NET_BPF_MAXBUFSIZE:
		newval = bpf_maxbufsize;
		error = sysctl_int(oldp, oldlenp, newp, newlen, &newval);
		if (error)
			return (error);
		if (newval < BPF_MINBUFSIZE)
			return (EINVAL);
		bpf_maxbufsize = newval;
		break;
	default:
		return (EOPNOTSUPP);
	}
	return (0);
}

int
bpf_sysctl(int *name, u_int namelen, void *oldp, size_t *oldlenp, void *newp,
    size_t newlen)
{
	int flags = RW_INTR;
	int error;

	if (namelen != 1)
		return (ENOTDIR);

	flags |= (newp == NULL) ? RW_READ : RW_WRITE;

	error = rw_enter(&bpf_sysctl_lk, flags);
	if (error != 0)
		return (error);

	error = bpf_sysctl_locked(name, namelen, oldp, oldlenp, newp, newlen);

	rw_exit(&bpf_sysctl_lk);

	return (error);
}

struct bpf_d *
bpfilter_lookup(int unit)
{
	struct bpf_d *bd;

	KERNEL_ASSERT_LOCKED();

	LIST_FOREACH(bd, &bpf_d_list, bd_list)
		if (bd->bd_unit == unit)
			return (bd);
	return (NULL);
}

/*
 * Get a list of available data link type of the interface.
 */
int
bpf_getdltlist(struct bpf_d *d, struct bpf_dltlist *bfl)
{
	int n, error;
	struct ifnet *ifp;
	struct bpf_if *bp;

	ifp = d->bd_bif->bif_ifp;
	n = 0;
	error = 0;
	for (bp = bpf_iflist; bp != NULL; bp = bp->bif_next) {
		if (bp->bif_ifp != ifp)
			continue;
		if (bfl->bfl_list != NULL) {
			if (n >= bfl->bfl_len)
				return (ENOMEM);
			error = copyout(&bp->bif_dlt,
			    bfl->bfl_list + n, sizeof(u_int));
			if (error)
				break;
		}
		n++;
	}

	bfl->bfl_len = n;
	return (error);
}

/*
 * Set the data link type of a BPF instance.
 */
int
bpf_setdlt(struct bpf_d *d, u_int dlt)
{
	struct ifnet *ifp;
	struct bpf_if *bp;

	MUTEX_ASSERT_LOCKED(&d->bd_mtx);
	if (d->bd_bif->bif_dlt == dlt)
		return (0);
	ifp = d->bd_bif->bif_ifp;
	for (bp = bpf_iflist; bp != NULL; bp = bp->bif_next) {
		if (bp->bif_ifp == ifp && bp->bif_dlt == dlt)
			break;
	}
	if (bp == NULL)
		return (EINVAL);
	bpf_detachd(d);
	bpf_attachd(d, bp);
	bpf_resetd(d);
	return (0);
}

void
bpf_d_ref(void *null, void *d)
{
	bpf_get(d);
}

void
bpf_d_unref(void *null, void *d)
{
	bpf_put(d);
}

void
bpf_insn_dtor(void *null, void *f)
{
	struct bpf_program *bf = f;
	struct bpf_insn *insns = bf->bf_insns;

	free(insns, M_DEVBUF, bf->bf_len * sizeof(*insns));
	free(bf, M_DEVBUF, sizeof(*bf));
}

u_int32_t	bpf_mbuf_ldw(const void *, u_int32_t, int *);
u_int32_t	bpf_mbuf_ldh(const void *, u_int32_t, int *);
u_int32_t	bpf_mbuf_ldb(const void *, u_int32_t, int *);

int		bpf_mbuf_copy(const struct mbuf *, u_int32_t,
		    void *, u_int32_t);

const struct bpf_ops bpf_mbuf_ops = {
	bpf_mbuf_ldw,
	bpf_mbuf_ldh,
	bpf_mbuf_ldb,
};

int
bpf_mbuf_copy(const struct mbuf *m, u_int32_t off, void *buf, u_int32_t len)
{
	u_int8_t *cp = buf;
	u_int32_t count;

	while (off >= m->m_len) {
		off -= m->m_len;

		m = m->m_next;
		if (m == NULL)
			return (-1);
	}

	for (;;) {
		count = min(m->m_len - off, len);
		
		memcpy(cp, m->m_data + off, count);
		len -= count;

		if (len == 0)
			return (0);

		m = m->m_next;
		if (m == NULL)
			break;

		cp += count;
		off = 0;
	}

	return (-1);
}

u_int32_t
bpf_mbuf_ldw(const void *m0, u_int32_t k, int *err)
{
	u_int32_t v;

	if (bpf_mbuf_copy(m0, k, &v, sizeof(v)) != 0) {
		*err = 1;
		return (0);
	}

	*err = 0;
	return ntohl(v);
}

u_int32_t
bpf_mbuf_ldh(const void *m0, u_int32_t k, int *err)
{
	u_int16_t v;

	if (bpf_mbuf_copy(m0, k, &v, sizeof(v)) != 0) {
		*err = 1;
		return (0);
	}

	*err = 0;
	return ntohs(v);
}

u_int32_t
bpf_mbuf_ldb(const void *m0, u_int32_t k, int *err)
{
	const struct mbuf *m = m0;
	u_int8_t v;

	while (k >= m->m_len) {
		k -= m->m_len;

		m = m->m_next;
		if (m == NULL) {
			*err = 1;
			return (0);
		}
	}
	v = m->m_data[k];

	*err = 0;
	return v;
}

u_int
bpf_mfilter(const struct bpf_insn *pc, const struct mbuf *m, u_int wirelen)
{
	return _bpf_filter(pc, &bpf_mbuf_ops, m, wirelen);
}
@


1.162
log
@Introduce sstosa() for converting sockaddr_storage with a type safe
inline function instead of casting it to sockaddr.  While there,
use inline instead of __inline for all these conversions.  Some
struct sockaddr casts can be avoided completely.
OK dhill@@ mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.161 2017/04/20 14:13:00 visa Exp $	*/
d1827 1
d1838 1
d1841 1
a1841 1
	return (m->m_data[k]);
@


1.161
log
@Tweak lock inits to make the system runnable with witness(4)
on amd64 and i386.
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.160 2017/01/24 22:40:55 mpi Exp $	*/
d613 1
a613 1
	error = bpf_movein(uio, dlt, &m, (struct sockaddr *)&dst, fcode);
d630 1
a630 1
	error = ifp->if_output(ifp, m, (struct sockaddr *)&dst, NULL);
@


1.160
log
@splsoftnet() to  NET_LOCK() in bpfwrite().

ok dlg@@, visa@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.159 2017/01/24 10:08:30 krw Exp $	*/
d143 2
a1637 1
	static struct rwlock bpf_sysctl_lk = RWLOCK_INITIALIZER("bpfsz");
@


1.159
log
@A space here, a space there. Soon we're talking real whitespace
rectification.
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.158 2017/01/09 19:15:01 mpi Exp $	*/
d627 1
a627 1
	s = splsoftnet();
d629 1
a629 1
	splx(s);
@


1.158
log
@Use a mutex to serialize accesses to buffer slots.

With this change bpf_catchpacket() no longer need the KERNEL_LOCK().

Tested by Hrvoje Popovski who reported a recursion in the previous
attempt.

ok bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.157 2017/01/03 19:28:50 mpi Exp $	*/
d11 1
a11 1
 * to Berkeley by Steven McCanne and Van Jacobson both of Lawrence 
@


1.157
log
@Revert previous, there's still a problem with recursive entries in
bpf_mpath_ether().

Problem reported by Hrvoje Popovski.
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.155 2016/11/28 10:16:08 mpi Exp $	*/
d119 3
a265 1
 * Must be called at splnet.
d270 2
d294 2
d322 3
d326 3
d368 1
a387 1
	int s;
d390 1
a390 1
	s = splnet();
d394 1
a395 1
	splx(s);
d406 2
d412 1
a412 1
	(d)->bd_fbuf = 0;
d420 4
a423 2
	int error;
	int s;
a428 1
	s = splnet();
d430 1
d479 2
a480 2
				error = tsleep((caddr_t)d, PRINET|PCATCH, "bpf",
				    d->bd_rtout);
d511 6
a516 1
	splx(s);
d523 9
a531 6
	error = uiomove(d->bd_hbuf, d->bd_hlen, uio);

	s = splnet();
	d->bd_fbuf = d->bd_hbuf;
	d->bd_hbuf = NULL;
	d->bd_hlen = 0;
d533 1
a534 1
	splx(s);
d546 2
d585 2
d638 1
a638 1
 * receive and drop counts.  Should be called at splnet.
d643 4
a646 1
	if (d->bd_hbuf) {
d680 1
a680 1
	int s, error = 0;
d708 2
a710 1

d722 1
a722 1
			s = splnet();
d724 1
a724 1
			if (d->bd_hbuf)
d726 1
a726 1
			splx(s);
d752 1
d754 1
d776 1
a776 1
		s = splnet();
d778 1
a778 1
		splx(s);
d790 7
a796 7
			break;
		}
		s = splnet();
		if (d->bd_promisc == 0) {
			error = ifpromisc(d->bd_bif->bif_ifp, 1);
			if (error == 0)
				d->bd_promisc = 1;
a797 1
		splx(s);
d826 2
a827 1
		else
d829 2
d978 2
a993 1
	int s;
d1002 1
a1002 1
		s = splnet();
d1004 1
a1004 1
		splx(s);
d1029 1
a1029 1
	s = splnet();
d1031 1
a1031 1
	splx(s);
a1044 1
	int s;
d1069 1
a1069 1
	s = splnet();
d1083 1
a1083 1
	splx(s);
d1103 3
a1105 1
	int s, revents;
d1126 1
a1126 1
		s = splnet();
d1138 1
a1138 1
		splx(s);
d1151 2
a1152 1
	int s;
d1155 1
d1165 1
d1167 1
d1169 1
a1169 3
	s = splnet();
	bpf_get(d);
	SLIST_INSERT_HEAD(klist, kn, kn_selnext);
d1172 1
a1172 1
	splx(s);
a1180 1
	int s;
d1182 2
a1183 1
	s = splnet();
a1185 1
	splx(s);
d1193 3
d1199 2
a1242 1
	int s;
d1278 1
a1278 2
			KERNEL_LOCK();
			s = splnet();
d1281 1
a1281 2
			splx(s);
			KERNEL_UNLOCK();
d1411 1
d1495 2
d1516 1
a1516 1
	bd->bd_ref++;
d1526 1
a1526 1
	if (--bd->bd_ref > 0)
d1661 2
a1705 1
	int s;
d1709 1
a1718 1
	s = splnet();
a1721 1
	splx(s);
@


1.156
log
@Use a mutex to serialize accesses to buffer slots.

With this change bpf_catchpacket() no longer need the KERNEL_LOCK().

ok bluhm@@, jmatthew@@
@
text
@a118 3
/*
 * Called holding ``bd_mtx''.
 */
d263 1
a267 2
	MUTEX_ASSERT_LOCKED(&d->bd_mtx);

a289 2
	MUTEX_ASSERT_LOCKED(&d->bd_mtx);

a315 3

		bpf_get(d);
		mtx_leave(&d->bd_mtx);
a316 3
		mtx_enter(&d->bd_mtx);
		bpf_put(d);

a355 1
	mtx_init(&bd->bd_mtx, IPL_NET);
d375 1
d378 1
a378 1
	mtx_enter(&d->bd_mtx);
a381 1
	mtx_leave(&d->bd_mtx);
d383 1
a393 2
	KASSERT(d->bd_in_uiomove == 0); \
	MUTEX_ASSERT_LOCKED(&d->bd_mtx); \
d398 1
a398 1
	(d)->bd_fbuf = NULL;
d406 2
a407 4
	caddr_t hbuf;
	int hlen, error;

	KERNEL_ASSERT_LOCKED();
d413 1
a414 1
	mtx_enter(&d->bd_mtx);
d463 2
a464 2
				error = msleep(d, &d->bd_mtx, PRINET|PCATCH,
				    "bpf", d->bd_rtout);
d495 1
a495 6
	hbuf = d->bd_hbuf;
	hlen = d->bd_hlen;
	d->bd_hbuf = NULL;
	d->bd_hlen = 0;
	d->bd_fbuf = NULL;
	d->bd_in_uiomove = 1;
d502 6
a507 9
	mtx_leave(&d->bd_mtx);
	error = uiomove(hbuf, hlen, uio);
	mtx_enter(&d->bd_mtx);

	/* Ensure that bpf_resetd() or ROTATE_BUFFERS() haven't been called. */
	KASSERT(d->bd_fbuf == NULL);
	KASSERT(d->bd_hbuf == NULL);
	d->bd_fbuf = hbuf;
	d->bd_in_uiomove = 0;
a508 1
	mtx_leave(&d->bd_mtx);
d510 1
a521 2
	MUTEX_ASSERT_LOCKED(&d->bd_mtx);

d555 1
a557 1
	int error;
d559 3
a561 1
	KERNEL_ASSERT_LOCKED();
a562 1
	d = bpfilter_lookup(minor(dev));
d564 1
a564 5
	mtx_enter(&d->bd_mtx);
	if (d->bd_bif == NULL) {
		error = ENXIO;
		goto out;
	}
a565 1
	ifp = d->bd_bif->bif_ifp;
a582 1
	mtx_leave(&d->bd_mtx);
a583 1
	mtx_enter(&d->bd_mtx);
d599 1
d601 2
a603 1
	mtx_leave(&d->bd_mtx);
a604 1

d610 1
a610 1
 * receive and drop counts.
d615 1
a615 4
	MUTEX_ASSERT_LOCKED(&d->bd_mtx);
	KASSERT(d->bd_in_uiomove == 0);

	if (d->bd_hbuf != NULL) {
d649 1
a649 1
	int error = 0;
d677 1
a677 1
	bpf_get(d);
a678 1
	switch (cmd) {
d690 1
a690 1
			mtx_enter(&d->bd_mtx);
d692 1
a692 1
			if (d->bd_hbuf != NULL)
d694 1
a694 1
			mtx_leave(&d->bd_mtx);
a719 1
			mtx_enter(&d->bd_mtx);
a720 1
			mtx_leave(&d->bd_mtx);
d742 1
a742 1
		mtx_enter(&d->bd_mtx);
d744 1
a744 1
		mtx_leave(&d->bd_mtx);
d756 7
a762 7
		} else {
			if (d->bd_promisc == 0) {
				MUTEX_ASSERT_UNLOCKED(&d->bd_mtx);
				error = ifpromisc(d->bd_bif->bif_ifp, 1);
				if (error == 0)
					d->bd_promisc = 1;
			}
d764 1
d793 1
a793 2
		else {
			mtx_enter(&d->bd_mtx);
a794 2
			mtx_leave(&d->bd_mtx);
		}
a941 2

	bpf_put(d);
d956 1
d965 1
a965 1
		mtx_enter(&d->bd_mtx);
d967 1
a967 1
		mtx_leave(&d->bd_mtx);
d992 1
a992 1
	mtx_enter(&d->bd_mtx);
d994 1
a994 1
	mtx_leave(&d->bd_mtx);
d1008 1
d1033 1
a1033 1
	mtx_enter(&d->bd_mtx);
d1047 1
a1047 1
	mtx_leave(&d->bd_mtx);
d1067 1
a1067 3
	int revents;

	KERNEL_ASSERT_LOCKED();
d1088 1
a1088 1
		mtx_enter(&d->bd_mtx);
d1100 1
a1100 1
		mtx_leave(&d->bd_mtx);
d1113 1
a1113 2

	KERNEL_ASSERT_LOCKED();
a1115 1

d1125 3
a1128 1
	kn->kn_hook = d;
a1129 2

	mtx_enter(&d->bd_mtx);
d1132 1
a1132 1
	mtx_leave(&d->bd_mtx);
d1141 1
d1143 1
a1143 2
	KERNEL_ASSERT_LOCKED();

d1146 1
a1153 3
	KERNEL_ASSERT_LOCKED();

	mtx_enter(&d->bd_mtx);
a1156 2
	mtx_leave(&d->bd_mtx);

d1199 1
d1235 2
a1236 1
			mtx_enter(&d->bd_mtx);
d1239 2
a1240 1
			mtx_leave(&d->bd_mtx);
a1369 1
	MUTEX_ASSERT_LOCKED(&d->bd_mtx);
a1452 2
	MUTEX_ASSERT_LOCKED(&d->bd_mtx);

d1472 1
a1472 1
	atomic_inc_int(&bd->bd_ref);
d1482 1
a1482 1
	if (atomic_dec_int_nv(&bd->bd_ref) > 0)
a1616 2
	KERNEL_ASSERT_LOCKED();

d1660 1
a1663 1
	MUTEX_ASSERT_LOCKED(&d->bd_mtx);
d1673 1
d1677 1
@


1.155
log
@Make sure the descriptor has been removed from the interface list
before we call ifpromisc() and possibly sleep.

ok bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.154 2016/11/21 09:15:40 mpi Exp $	*/
d119 3
a265 1
 * Must be called at splnet.
d270 2
d294 2
d322 3
d326 3
d368 1
a387 1
	int s;
d390 1
a390 1
	s = splnet();
d394 1
a395 1
	splx(s);
d406 2
d412 1
a412 1
	(d)->bd_fbuf = 0;
d420 4
a423 2
	int error;
	int s;
a428 1
	s = splnet();
d430 1
d479 2
a480 2
				error = tsleep((caddr_t)d, PRINET|PCATCH, "bpf",
				    d->bd_rtout);
d511 6
a516 1
	splx(s);
d523 9
a531 6
	error = uiomove(d->bd_hbuf, d->bd_hlen, uio);

	s = splnet();
	d->bd_fbuf = d->bd_hbuf;
	d->bd_hbuf = NULL;
	d->bd_hlen = 0;
d533 1
a534 1
	splx(s);
d546 2
a580 1
	int error, s;
d583 3
d588 6
a593 2
	if (d->bd_bif == NULL)
		return (ENXIO);
a594 1
	bpf_get(d);
a595 1

d613 1
d615 1
a630 1
	s = splsoftnet();
a631 2
	splx(s);

d633 1
d635 1
d641 1
a641 1
 * receive and drop counts.  Should be called at splnet.
d646 4
a649 1
	if (d->bd_hbuf) {
d683 1
a683 1
	int s, error = 0;
d711 2
a713 1

d725 1
a725 1
			s = splnet();
d727 1
a727 1
			if (d->bd_hbuf)
d729 1
a729 1
			splx(s);
d755 1
d757 1
d779 1
a779 1
		s = splnet();
d781 1
a781 1
		splx(s);
d793 7
a799 7
			break;
		}
		s = splnet();
		if (d->bd_promisc == 0) {
			error = ifpromisc(d->bd_bif->bif_ifp, 1);
			if (error == 0)
				d->bd_promisc = 1;
a800 1
		splx(s);
d829 2
a830 1
		else
d832 2
d981 2
a996 1
	int s;
d1005 1
a1005 1
		s = splnet();
d1007 1
a1007 1
		splx(s);
d1032 1
a1032 1
	s = splnet();
d1034 1
a1034 1
	splx(s);
a1047 1
	int s;
d1072 1
a1072 1
	s = splnet();
d1086 1
a1086 1
	splx(s);
d1106 3
a1108 1
	int s, revents;
d1129 1
a1129 1
		s = splnet();
d1141 1
a1141 1
		splx(s);
d1154 2
a1155 1
	int s;
d1158 1
d1168 1
d1170 1
d1172 1
a1172 3
	s = splnet();
	bpf_get(d);
	SLIST_INSERT_HEAD(klist, kn, kn_selnext);
d1175 1
a1175 1
	splx(s);
a1183 1
	int s;
d1185 2
a1186 1
	s = splnet();
a1188 1
	splx(s);
d1196 3
d1202 2
a1245 1
	int s;
d1281 1
a1281 2
			KERNEL_LOCK();
			s = splnet();
d1284 1
a1284 2
			splx(s);
			KERNEL_UNLOCK();
d1414 1
d1498 2
d1519 1
a1519 1
	bd->bd_ref++;
d1529 1
a1529 1
	if (--bd->bd_ref > 0)
d1664 2
a1708 1
	int s;
d1712 1
a1721 1
	s = splnet();
a1724 1
	splx(s);
@


1.154
log
@Make sure bpf_wakeup() is called at most once when matching conditions
are fulfilled in bpf_catchpacket().
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.153 2016/11/21 09:12:18 mpi Exp $	*/
d291 17
a324 13

	/* Remove d from the interface's descriptor list. */
	KERNEL_ASSERT_LOCKED();
	SRPL_REMOVE_LOCKED(&bpf_d_rc, &bp->bif_dlist, d, bpf_d, bd_next);

	if (SRPL_EMPTY_LOCKED(&bp->bif_dlist)) {
		/*
		 * Let the driver know that there are no more listeners.
		 */
		*d->bd_bif->bif_driverp = 0;
	}

	d->bd_bif = NULL;
d379 1
a379 2
	if (d->bd_bif)
		bpf_detachd(d);
d1039 4
a1042 6
		if (d->bd_bif)
			/*
			 * Detach if attached to something else.
			 */
			bpf_detachd(d);

@


1.153
log
@Rename bpf_reset_d() to match bpf_{attach,reset}d().
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.152 2016/11/16 14:13:00 mpi Exp $	*/
d1367 1
a1367 1
	int hdrlen;
d1403 1
a1403 1
		bpf_wakeup(d);
d1426 1
a1426 1
		bpf_wakeup(d);
d1435 1
a1435 1
		if (d->bd_fbuf) {
d1438 1
a1438 1
			bpf_wakeup(d);
d1441 3
@


1.152
log
@Use goto in bpf{read,write}() to ease review of locked sections.

While here properly account for used reference in bpfwrite().

ok bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.151 2016/11/16 09:00:01 mpi Exp $	*/
a101 2
void	bpf_attachd(struct bpf_d *, struct bpf_if *);
void	bpf_detachd(struct bpf_d *);
a108 1
void	bpf_reset_d(struct bpf_d *);
d119 4
d610 1
a610 1
bpf_reset_d(struct bpf_d *d)
d740 1
a740 1
		bpf_reset_d(d);
d963 1
a963 1
		bpf_reset_d(d);
d990 1
a990 1
	bpf_reset_d(d);
d1044 1
a1044 1
	bpf_reset_d(d);
d1672 1
a1672 1
	bpf_reset_d(d);
@


1.151
log
@Allow bpf_allocbufs() to fail when allocating memory.

This will help trading the KERNEL_LOCK for a mutex.

ok bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.150 2016/10/16 18:05:41 jca Exp $	*/
d409 3
d416 4
a419 6
	if (uio->uio_resid != d->bd_bufsize)
		return (EINVAL);

	s = splnet();

	bpf_get(d);
d435 1
a435 1
	while (d->bd_hbuf == 0) {
d439 2
a440 3
				bpf_put(d);
				splx(s);
				return (EIO);
d464 2
a465 5
		if (error == EINTR || error == ERESTART) {
			bpf_put(d);
			splx(s);
			return (error);
		}
d472 1
a472 1
			if (d->bd_hbuf)
d481 2
a482 3
				bpf_put(d);
				splx(s);
				return (0);
d504 1
a504 1

d553 1
d559 1
d562 4
a565 2
	if ((ifp->if_flags & IFF_UP) == 0)
		return (ENETDOWN);
d567 4
a570 2
	if (uio->uio_resid == 0)
		return (0);
d577 3
a579 2
	error = bpf_movein(uio, d->bd_bif->bif_dlt, &m,
	    (struct sockaddr *)&dst, fcode);
d581 1
a581 1
		return (error);
d585 2
a586 1
		return (EMSGSIZE);
d598 3
a600 3
	/*
	 * The driver frees the mbuf.
	 */
@


1.150
log
@Fix bpf_catchpacket comment.
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.149 2016/09/12 16:24:37 krw Exp $	*/
d95 1
a95 1
void	bpf_allocbufs(struct bpf_d *);
d999 1
d1016 20
a1035 15
	if (candidate != NULL) {
		/*
		 * Allocate the packet buffers if we need to.
		 * If we're already attached to requested interface,
		 * just flush the buffer.
		 */
		if (d->bd_sbuf == NULL)
			bpf_allocbufs(d);
		s = splnet();
		if (candidate != d->bd_bif) {
			if (d->bd_bif)
				/*
				 * Detach if attached to something else.
				 */
				bpf_detachd(d);
d1037 1
a1037 5
			bpf_attachd(d, candidate);
		}
		bpf_reset_d(d);
		splx(s);
		return (0);
d1039 4
a1042 2
	/* Not found. */
	return (ENXIO);
d1441 1
a1441 1
void
d1444 10
a1453 2
	d->bd_fbuf = malloc(d->bd_bufsize, M_DEVBUF, M_WAITOK);
	d->bd_sbuf = malloc(d->bd_bufsize, M_DEVBUF, M_WAITOK);
d1456 2
@


1.149
log
@bpf_tap() is long dead! Long live bpf_mtap() & friends.

ok natano@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.148 2016/08/22 10:40:36 mpi Exp $	*/
d1346 2
a1347 2
 * store buffer.  Return 1 if it's time to wakeup a listener (buffer full),
 * otherwise 0.  "copy" is the routine called to do the actual data
@


1.148
log
@Call csignal() and selwakeup() from a KERNEL_LOCK'd task.

This will allow us make bpf_tap() KERNEL_LOCK() free.

Discussed with dlg@@ and input from guenther@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.147 2016/08/15 07:20:14 mpi Exp $	*/
a1147 56
}

/*
 * Incoming linkage from device drivers.  Process the packet pkt, of length
 * pktlen, which is stored in a contiguous buffer.  The packet is parsed
 * by each process' filter, and if accepted, stashed into the corresponding
 * buffer.
 */
int
bpf_tap(caddr_t arg, u_char *pkt, u_int pktlen, u_int direction)
{
	struct bpf_if *bp = (struct bpf_if *)arg;
	struct srp_ref sr;
	struct bpf_d *d;
	size_t slen;
	struct timeval tv;
	int drop = 0, gottime = 0;
	int s;

	if (bp == NULL)
		return (0);

	SRPL_FOREACH(d, &sr, &bp->bif_dlist, bd_next) {
		atomic_inc_long(&d->bd_rcount);

		if ((direction & d->bd_dirfilt) != 0)
			slen = 0;
		else {
			struct srp_ref sr;
			struct bpf_program *bf;
			struct bpf_insn *fcode = NULL;

			bf = srp_enter(&sr, &d->bd_rfilter);
			if (bf != NULL)
				fcode = bf->bf_insns;
			slen = bpf_filter(fcode, pkt, pktlen, pktlen);
			srp_leave(&sr);
		}

		if (slen > 0) {
			if (!gottime++)
				microtime(&tv);

			KERNEL_LOCK();
			s = splnet();
			bpf_catchpacket(d, pkt, pktlen, slen, bcopy, &tv);
			splx(s);
			KERNEL_UNLOCK();

			if (d->bd_fildrop)
				drop = 1;
		}
	}
	SRPL_LEAVE(&sr);

	return (drop);
@


1.147
log
@No need to reset si_selpid after calling selwakeup() the function
already does it.
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.146 2016/08/15 07:17:10 mpi Exp $	*/
d60 2
d108 1
d351 1
d522 18
a539 1
	wakeup((caddr_t)d);
d541 1
a541 2
		csignal(d->bd_pgid, d->bd_sig,
		    d->bd_siguid, d->bd_sigeuid);
d544 1
@


1.146
log
@Introduce bpf_put() and bpf_get() instead of mixing macro and functions
for the reference counting.

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.145 2016/08/15 07:12:11 mpi Exp $	*/
a523 2
	/* XXX */
	d->bd_sel.si_selpid = 0;
@


1.145
log
@Check if ``bd_bif'' is NULL inside bpf_catchpacket() to match bpfread()
and bpfwrite(), all of which will need to grabe a lock to protect the
buffers.

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.144 2016/08/15 07:03:47 mpi Exp $	*/
a93 1
void	bpf_freed(struct bpf_d *);
d122 2
a123 2
#define D_GET(d) ((d)->bd_ref++)
#define D_PUT(d) bpf_freed(d)
d352 1
a352 1
	D_GET(bd);
d374 1
a374 1
	D_PUT(d);
d414 1
a414 1
	D_GET(d);
d434 1
a434 1
				D_PUT(d);
d461 1
a461 1
			D_PUT(d);
d480 1
a480 1
				D_PUT(d);
d505 1
a505 1
	D_PUT(d);
d1099 1
a1099 1
	D_GET(d);
d1116 1
a1116 1
	D_PUT(d);
d1483 6
d1494 1
a1494 1
bpf_freed(struct bpf_d *d)
d1496 1
a1496 1
	if (--d->bd_ref > 0)
d1499 3
a1501 3
	free(d->bd_sbuf, M_DEVBUF, 0);
	free(d->bd_hbuf, M_DEVBUF, 0);
	free(d->bd_fbuf, M_DEVBUF, 0);
d1503 2
a1504 2
	srp_update_locked(&bpf_insn_gc, &d->bd_rfilter, NULL);
	srp_update_locked(&bpf_insn_gc, &d->bd_wfilter, NULL);
d1506 1
a1506 1
	free(d, M_DEVBUF, sizeof(*d));
d1698 1
a1698 1
	D_GET((struct bpf_d *)d);
d1704 1
a1704 1
	D_PUT(d);
@


1.144
log
@Merge bpfilter_create() into bpfopen() and make it such that the
descriptor is referenced before it is inserted in the global list.

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.143 2016/07/25 13:19:32 natano Exp $	*/
d1175 1
a1175 4
			if (d->bd_bif != NULL) {
				bpf_catchpacket(d, pkt, pktlen, slen,
				    bcopy, &tv);
			}
d1265 2
a1266 4
			if (d->bd_bif != NULL) {
				bpf_catchpacket(d, (u_char *)m, pktlen, slen,
				    cpfn, &tv);
			}
d1396 6
a1401 1
	int hdrlen = d->bd_bif->bif_hdrlen;
@


1.143
log
@Make sure closed bpf devices are removed from bpf_d_list to free the
minor number for reuse by the device cloning code. This fixes a panic
reported by bluhm@@.

initial diff from tedu
ok deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.142 2016/06/10 20:33:29 vgross Exp $	*/
a118 1
struct bpf_d *bpfilter_create(int);
d333 2
a334 1
	struct bpf_d *d;
d336 1
a336 1
	if (minor(dev) & ((1 << CLONE_SHIFT) - 1))
d339 2
d342 1
a342 1
	if ((d = bpfilter_create(minor(dev))) == NULL)
d346 3
a348 2
	d->bd_bufsize = bpf_bufsize;
	d->bd_sig = SIGIO;
d351 1
a351 1
		d->bd_rtout = -1;
d353 2
a354 1
	D_GET(d);
a1629 14
}

struct bpf_d *
bpfilter_create(int unit)
{
	struct bpf_d *bd;

	KASSERT(bpfilter_lookup(unit) == NULL);

	if ((bd = malloc(sizeof(*bd), M_DEVBUF, M_NOWAIT|M_ZERO)) != NULL) {
		bd->bd_unit = unit;
		LIST_INSERT_HEAD(&bpf_d_list, bd, bd_list);
	}
	return (bd);
@


1.142
log
@Add the "llprio" field to struct ifnet, and the corresponding keyword
to ifconfig.

"llprio" allows one to set the priority of packets that do not go through
pf(4), as the case is for arp(4) or bpf(4).

ok sthen@@ mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.141 2016/05/18 03:46:03 dlg Exp $	*/
a119 1
void bpfilter_destroy(struct bpf_d *);
d370 1
d1497 1
a1497 1
	bpfilter_destroy(d);
d1551 2
a1552 14
			while ((bd = SRPL_FIRST_LOCKED(&bp->bif_dlist))) {
				struct bpf_d *d;

				/*
				 * Locate the minor number and nuke the vnode
				 * for any open instance.
				 */
				LIST_FOREACH(d, &bpf_d_list, bd_list)
					if (d == bd) {
						vdevgone(maj, d->bd_unit,
						    d->bd_unit, VCHR);
						break;
					}
			}
a1639 7
}

void
bpfilter_destroy(struct bpf_d *bd)
{
	LIST_REMOVE(bd, bd_list);
	free(bd, M_DEVBUF, sizeof(*bd));
@


1.141
log
@rework the srp api so it takes an srp_ref struct that the caller provides.

the srp_ref struct is used to track the location of the callers
hazard pointer so later calls to srp_follow and srp_enter already
know what to clear. this in turn means most of the caveats around
using srps go away. specifically, you can now:

- switch cpus while holding an srp ref
  - ie, you can sleep while holding an srp ref
- you can take and release srp refs in any order

the original intent was to simplify use of the api when dealing
with complicated data structures. the caller now no longer has to
track the location of the srp a value was fetched from, the srp_ref
effectively does that for you.

srp lists have been refactored to use srp_refs instead of srpl_iter
structs.

this is in preparation of using srps inside the ART code. ART is a
complicated data structure, and lookups require overlapping holds
of srp references.

ok mpi@@ jmatthew@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.140 2016/05/10 23:48:07 dlg Exp $	*/
d564 1
@


1.140
log
@make the bpf tap functions take const struct mbuf *

this makes it more obvious that the bpf code should only read
packets, never modify them.

now possible because the paths that care about M_FILDROP set it
after calling bpf_mtap.

ok mpi@@ visa@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.139 2016/04/14 08:27:24 natano Exp $	*/
d1137 1
a1137 1
	struct srpl_iter i;
d1147 1
a1147 1
	SRPL_FOREACH(d, &bp->bif_dlist, &i, bd_next) {
d1153 1
d1157 1
a1157 1
			bf = srp_enter(&d->bd_rfilter);
d1161 1
a1161 1
			srp_leave(&d->bd_rfilter, bf);
d1181 1
a1181 1
	SRPL_LEAVE(&i, d);
d1218 1
a1218 1
	struct srpl_iter i;
d1240 1
a1240 1
	SRPL_FOREACH(d, &bp->bif_dlist, &i, bd_next) {
d1246 1
d1250 1
a1250 1
			bf = srp_enter(&d->bd_rfilter);
d1254 1
a1254 1
			srp_leave(&d->bd_rfilter, bf);
d1274 1
a1274 1
	SRPL_LEAVE(&i, d);
@


1.139
log
@Enable device cloning for bpf. This allows to have just one bpf device
node in /dev, that services all bpf consumers (up to 1024). Also,
disallow the usage of all but the first minor device, so accidental use
of another minor device will attract attention.

Cloning bpf offers some advantages:

- Users with high bpf usage won't have to clutter their /dev with device
  nodes.

- A lot of programs in base use a pattern like this to acces bpf:

	int fd, n = 0;
	do {
		(void)snprintf(device, sizeof device, "/dev/bpf%d", n++);
		fd = open(device, mode);
	} while (fd < 0 && errno == EBUSY);

  Those can now be replaced by a simple open(), without loop.

ok mikeb
"right time in the cycle to try" deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.138 2016/04/02 08:49:49 dlg Exp $	*/
d96 1
a96 1
int	_bpf_mtap(caddr_t, struct mbuf *, u_int,
d1213 1
a1213 1
_bpf_mtap(caddr_t arg, struct mbuf *m, u_int direction,
d1220 1
a1220 1
	struct mbuf *m0;
a1273 3
	if (drop)
		m->m_flags |= M_FILDROP;

d1281 1
a1281 1
bpf_mtap(caddr_t arg, struct mbuf *m, u_int direction)
d1296 1
a1296 1
bpf_mtap_hdr(caddr_t arg, caddr_t data, u_int dlen, struct mbuf *m,
d1299 2
a1300 3
	struct m_hdr	 mh;
	struct mbuf	*m0;
	int		drop;
d1304 1
a1304 1
		mh.mh_next = m;
d1311 1
a1311 6
	drop = _bpf_mtap(arg, m0, direction, cpfn);

	if (m0 != m)
		m->m_flags |= m0->m_flags & M_FILDROP;

	return (drop);
d1324 1
a1324 1
bpf_mtap_af(caddr_t arg, u_int32_t af, struct mbuf *m, u_int direction)
d1344 1
a1344 1
bpf_mtap_ether(caddr_t arg, struct mbuf *m, u_int direction)
@


1.138
log
@refactor bpf_filter a bit.

the code was confusing around how it dealt with packets in mbufs
vs plain memory buffers with a lenght.

this renames bpf_filter to _bpf_filter, and changes it so the packet
memory is referred to by an opaque pointer, and callers have to
provide a set of operations to extra values from that opaque pointer.

bpf_filter is now provided as a wrapper around _bpf_filter. it
provides a set of operators that work on a straight buffer with a
lenght.

this also adds a bpf_mfilter function which takes an mbuf instead
of a buffer, and it provides explicit operations for extracting
values from mbufs.

if we want to use bpf filters against other data structures (usb
or scsi packets maybe?) we are able to provide functions for
extracting payloads from them and use _bpf_filter as is.

ok canacar@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.116 2015/01/29 19:44:32 tedu Exp $	*/
d59 1
d337 3
d1651 2
a1652 2
	if ((bd = bpfilter_lookup(unit)) != NULL)
		return (NULL);
@


1.137
log
@remove support for BIOCGQUEUE and BIOSGQUEUE

nothing uses them, and the implementation make incorrect assumptions
about mbufs within bpf processing that could lead to some weird
failures.

ok sthen@@ deraadt@@ mpi@@
@
text
@d1155 1
a1155 1
			slen = bpf_filter(fcode, pkt, pktlen, 0);
d1247 1
a1247 1
			slen = bpf_filter(fcode, (u_char *)m, pktlen, 0);
d1741 100
@


1.136
log
@make bpf_mtap et al return whether the mbuf should be dropped

ok mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.135 2016/02/12 18:56:12 stefan Exp $	*/
a861 8
	case BIOCGQUEUE:	/* get queue */
		*(u_int *)addr = d->bd_queue;
		break;

	case BIOCSQUEUE:	/* set queue */
		d->bd_queue = *(u_int *)addr;
		break;

a1238 2
			slen = 0;
		else if (d->bd_queue && m->m_pkthdr.pf.qid != d->bd_queue)
@


1.135
log
@Convert to uiomove. From Martin Natano.
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.134 2016/02/10 04:34:14 dlg Exp $	*/
d95 1
a95 1
void	_bpf_mtap(caddr_t, struct mbuf *, u_int,
d1181 1
a1181 1
				drop++;
d1216 1
a1216 1
void
d1227 1
d1231 1
a1231 1
		return;
d1237 1
a1237 1
		return;
d1275 1
a1275 1
				m->m_flags |= M_FILDROP;
d1279 5
d1289 1
a1289 1
void
d1292 1
a1292 1
	_bpf_mtap(arg, m, direction, NULL);
d1304 1
a1304 1
void
d1310 1
d1321 2
a1322 1
	_bpf_mtap(arg, m0, direction, cpfn);
d1325 2
d1338 1
a1338 1
void
d1344 3
a1346 1
	bpf_mtap_hdr(arg, (caddr_t)&afh, sizeof(afh), m, direction, NULL);
d1358 1
a1358 1
void
d1363 2
d1369 1
a1369 2
		bpf_mtap(arg, m, direction);
		return;
d1373 7
a1379 1
	bcopy(mtod(m, char *), &evh, ETHER_HDR_LEN);
d1382 2
a1383 3
	evh.evl_tag = htons(m->m_pkthdr.ether_vtag);
	m->m_len -= ETHER_HDR_LEN;
	m->m_data += ETHER_HDR_LEN;
d1385 4
a1388 1
	bpf_mtap_hdr(arg, (caddr_t)&evh, sizeof(evh), m, direction, NULL);
d1390 2
a1391 2
	m->m_len += ETHER_HDR_LEN;
	m->m_data -= ETHER_HDR_LEN;
@


1.134
log
@protect the bpf ring with splnet as well as the kernel lock.

kernel lock protects it against other cpus, but splnet prevents bpf
code running at splsoftnet (eg, like bridge does) from having the
rings trampled by a hardware interrupt on the same cpu.

ok mpi@@ jmatthew@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.133 2016/02/05 13:17:37 dlg Exp $	*/
d215 1
a215 1
	error = uiomovei(mtod(m, caddr_t), len, uio);
d491 1
a491 1
	error = uiomovei(d->bd_hbuf, d->bd_hlen, uio);
@


1.133
log
@return if the bpf_if passed to bpf_tap and _bpf_mtap are NULL.

this works around a toctou bug in a very common idiom in our tree,
in between the two lines below:

	if (ifp->if_bpf)
		bpf_mtap(ifp->if_bpf, m, BPF_DIRECTION_OUT);

figured out by and diff from haesbart
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.132 2016/01/07 05:31:17 guenther Exp $	*/
d1146 1
d1172 1
d1177 1
d1227 1
d1265 1
d1270 1
@


1.132
log
@Make open(O_NONBLOCK) of tun, tap, and bpf behave like open+ioctl(FIONBIO)

problem noted by yasuoka@@
ok yasuoka@@ millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.131 2015/12/05 10:07:55 tedu Exp $	*/
d1147 3
d1230 3
@


1.131
log
@remove old lint annotations
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.130 2015/10/07 08:41:01 mpi Exp $	*/
d343 3
@


1.130
log
@Do not call bpf_catchpacket() if another CPU detached a file from the
corresponding interface.

bfp_tap() and _bpf_mtap() are mostly run without the KERNEL_LOCK.  The
use of SRPs in these functions gives us the guarantees that manipulated
BPF descriptors are alive but not the associated interface desctiptor!
And indeed they can be cleared by another CPU running bpf_detachd().

Prevent a race reported by Hrvoje Popovski when closing tcpdump(8) with
an IPL_MPSAFE ix(4).

ok mikeb@@, dlg@@, deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.129 2015/09/29 10:58:51 dlg Exp $	*/
a320 1
/* ARGSUSED */
a330 1
/* ARGSUSED */
a352 1
/* ARGSUSED */
a606 1
/* ARGSUSED */
@


1.129
log
@make the bpf filters a bpf_program instead of an array of bpf_insn.

bpf_program contains a pointer to that same array, but also the
number of elements in it. this allows us to know the size when we
want to free them.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.128 2015/09/29 10:11:40 deraadt Exp $	*/
d1169 4
a1172 1
			bpf_catchpacket(d, pkt, pktlen, slen, bcopy, &tv);
d1256 4
a1259 2
			bpf_catchpacket(d, (u_char *)m, pktlen, slen,
			    cpfn, &tv);
@


1.128
log
@add sizes to some of the simpler free calls
ok mpi
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.127 2015/09/13 17:53:44 mpi Exp $	*/
d527 2
d545 4
d550 1
a550 1
	    (struct sockaddr *)&dst, srp_get_locked(&d->bd_wfilter));
d926 1
d948 5
a952 1
	fcode = mallocarray(flen, sizeof(*fp->bf_insns), M_DEVBUF, M_WAITOK);
d954 4
a957 7
	if (copyin(fp->bf_insns, fcode, size) == 0 &&
	    bpf_validate(fcode, (int)flen)) {
		srp_update_locked(&bpf_insn_gc, filter, fcode);
		s = splnet();
		bpf_reset_d(d);
		splx(s);
		return (0);
d959 11
a969 2
	free(fcode, M_DEVBUF, size);
	return (EINVAL);
d1154 6
a1159 2
			struct bpf_insn *fcode;
			fcode = srp_enter(&d->bd_rfilter);
d1161 1
a1161 1
			srp_leave(&d->bd_rfilter, fcode);
d1238 6
a1243 2
			struct bpf_insn *fcode;
			fcode = srp_enter(&d->bd_rfilter);
d1245 1
a1245 1
			srp_leave(&d->bd_rfilter, fcode);
d1707 1
a1707 1
bpf_insn_dtor(void *null, void *fcode)
d1709 5
a1713 1
	free(fcode, M_DEVBUF, 0);
@


1.127
log
@There's no point in abstracting ifp->if_output() as long as pf_test()
needs to see lo0 in the output path.

ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.126 2015/09/12 20:26:06 mpi Exp $	*/
d1516 1
a1516 1
			free(bp, M_DEVBUF, 0);
@


1.126
log
@Stop overwriting the rt_ifp pointer of RTF_LOCAL routes with lo0ifp.

Use instead the RTF_LOCAL flag to loop local traffic back to the
corresponding protocol queue.

With this change rt_ifp is now always the same as rt_ifa->ifa_ifp.

ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.125 2015/09/11 08:59:48 mpi Exp $	*/
d559 1
a559 1
	error = if_output(ifp, m, (struct sockaddr *)&dst, NULL);
@


1.125
log
@FOREACH macro is not safe to use when removing elements on a list.

Should fix a NULL dereference reported by guenther@@.

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.124 2015/09/09 11:55:37 dlg Exp $	*/
d559 1
a559 1
	error = (*ifp->if_output)(ifp, m, (struct sockaddr *)&dst, NULL);
@


1.124
log
@convert bpf to using an srp list for the list of descriptors.

this replaces the hand rolled list. the code has always used hand
rolled lists, but that gets a bit cumbersome when theyre SRPs.

requested ages ago by mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.123 2015/09/01 04:50:27 dlg Exp $	*/
d1501 1
a1501 1
			SRPL_FOREACH_LOCKED(bd, &bp->bif_dlist, bd_next) {
@


1.123
log
@reintroduce bpf.c r1.121.

this differs slightly from 1.121 in that it uses the new srp_follow()
to walk the list of descriptors on an interface. this is instead
of interleaving srp_enter() and srp_leave(), which can lead to races
and corruption if you're touching the same SRPs at different IPLs
on the same CPU.

ok deraadt@@ jmatthew@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.122 2015/08/23 10:14:25 dlg Exp $	*/
d131 4
a134 2
void bpf_d_dtor(void *, void *);
struct srp_gc bpf_d_gc = SRP_GC_INITIALIZER(bpf_d_dtor, NULL);
a265 2
	struct bpf_d *head;

a272 1
	srp_init(&d->bd_next);
d275 1
a275 7
	head = srp_get_locked(&bp->bif_dlist);
	if (head != NULL) {
		D_GET(head);
		srp_update_locked(&bpf_d_gc, &d->bd_next, head);
	}
	D_GET(d);
	srp_update_locked(&bpf_d_gc, &bp->bif_dlist, d);
a285 2
	struct srp *dref;
	struct bpf_d *p, *next;
d309 1
a309 16
	dref = &bp->bif_dlist;
	for (;;) {
		p = srp_get_locked(dref);
		if (p == NULL)
			panic("bpf_detachd: descriptor not in list");
		if (d == p)
			break;

		dref = &p->bd_next;
	}

	next = srp_get_locked(&d->bd_next);
	if (next != NULL)
		D_GET(next);
	srp_update_locked(&bpf_d_gc, dref, next);
	srp_update_locked(&bpf_d_gc, &d->bd_next, NULL);
d311 1
a311 1
	if (srp_get_locked(&bp->bif_dlist) == NULL) {
d1125 2
a1126 2
	struct srp *dref, *nref;
	struct bpf_d *d, *next;
d1131 1
a1131 3
	dref = &bp->bif_dlist;
	d = srp_enter(dref);
	while (d != NULL) {
a1153 5

		nref = &d->bd_next;
		next = srp_follow(dref, d, nref);
		dref = nref;
		d = next;
d1155 1
a1155 1
	srp_leave(dref, d);
d1192 2
a1193 2
	struct srp *dref, *nref;
	struct bpf_d *d, *next;
d1209 1
a1209 3
	dref = &bp->bif_dlist;
	d = srp_enter(dref);
	while (d != NULL) {
a1234 5

		nref = &d->bd_next;
		next = srp_follow(dref, d, nref);
		dref = nref;
		d = next;
d1236 1
a1236 1
	srp_leave(dref, d);
d1462 1
a1462 1
	srp_init(&bp->bif_dlist);
d1501 1
a1501 2
			for (bd = srp_get_locked(&bp->bif_dlist);
			    bd != NULL; bd = srp_get_locked(&bp->bif_dlist)) {
d1670 7
a1676 1
bpf_d_dtor(void *null, void *d)
@


1.122
log
@back out bpf+srp. its blowing up in a bridge setup.

ill debug this out of the tree.
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.25 2001/04/04 02:39:17 jason Exp $	*/
d57 2
d121 15
d264 2
d271 1
d273 10
a282 2
	d->bd_next = bp->bif_dlist;
	bp->bif_dlist = d;
d293 2
a294 1
	struct bpf_d **p;
d315 1
d317 5
a321 4
	p = &bp->bif_dlist;
	while (*p != d) {
		p = &(*p)->bd_next;
		if (*p == 0)
d323 4
d328 8
a335 2
	*p = (*p)->bd_next;
	if (bp->bif_dlist == 0)
d340 2
a344 6
/*
 * Reference count access to descriptor buffers
 */
#define D_GET(d) ((d)->bd_ref++)
#define D_PUT(d) bpf_freed(d)

d566 1
d568 1
a568 1
	    (struct sockaddr *)&dst, d->bd_wfilter);
d944 2
a945 1
	struct bpf_insn *fcode, *old;
d949 3
a951 1
	old = wf ? d->bd_wfilter : d->bd_rfilter;
d955 1
a956 4
		if (wf)
			d->bd_wfilter = NULL;
		else
			d->bd_rfilter = NULL;
a958 1
		free(old, M_DEVBUF, 0);
d967 1
a967 1
	if (copyin((caddr_t)fp->bf_insns, (caddr_t)fcode, size) == 0 &&
d969 1
a970 4
		if (wf)
			d->bd_wfilter = fcode;
		else
			d->bd_rfilter = fcode;
a972 2
		free(old, M_DEVBUF, 0);

d1148 3
a1150 2
	struct bpf_if *bp;
	struct bpf_d *d;
d1155 5
a1159 8
	/*
	 * Note that the ipl does not have to be raised at this point.
	 * The only problem that could arise here is that if two different
	 * interfaces shared any data.  This is not the case.
	 */
	bp = (struct bpf_if *)arg;
	for (d = bp->bif_dlist; d != NULL; d = d->bd_next) {
		++d->bd_rcount;
d1162 8
a1169 3
		else
			slen = bpf_filter(d->bd_rfilter, pkt, pktlen, pktlen);
		if (slen != 0) {
d1172 2
d1175 2
d1180 5
d1186 1
d1223 2
a1224 1
	struct bpf_d *d;
d1240 5
a1244 2
	for (d = bp->bif_dlist; d != NULL; d = d->bd_next) {
		++d->bd_rcount;
d1249 15
a1263 3
		else
			slen = bpf_filter(d->bd_rfilter, (u_char *)m,
			    pktlen, 0);
d1265 3
a1267 2
		if (slen == 0)
			continue;
d1269 4
a1272 5
		if (!gottime++)
			microtime(&tv);
		bpf_catchpacket(d, (u_char *)m, pktlen, slen, cpfn, &tv);
		if (d->bd_fildrop)
			m->m_flags |= M_FILDROP;
d1274 1
d1481 3
a1483 2
	free(d->bd_rfilter, M_DEVBUF, 0);
	free(d->bd_wfilter, M_DEVBUF, 0);
d1500 1
a1500 1
	bp->bif_dlist = 0;
d1527 2
d1539 2
a1540 1
			for (bd = bp->bif_dlist; bd; bd = bp->bif_dlist) {
d1706 12
@


1.121
log
@make bpf_mtap mpsafe by using SRPs.

this was originally implemented by jmatthew@@ last year, and updated
by us both during s2k15.

there are four data structures that need to be looked after.

the first is the bpf interface itself. it is allocated and freed
at the same time as an actual interface, so if you're able to send
or receive packets, you're able to run bpf on an interface too.
dont need to do any work there.

the second are bpf descriptors. these represent userland attaching
to a bpf interface, so you can have many of them on a single bpf
interface. they were arranged in a singly linked list before. now
the head and next pointers are replaced with SRP pointers and
followed by srp_enter. the list updates are serialised by the kernel
lock.

the third are the bpf filters. there is an inbound and outbound
filter on each bpf descriptor, ann a process can replace them at
any time. the pointers from the descriptor to those is also changed
to be accessed via srp_enter. updates are serialised by the kernel
lock.

the fourth thing is the ring that bpf writes to for userland to
read. there's one of these per descriptor. because these are only
updated when a filter matches (which is hopefully a relatively rare
event), we take the kernel lock to serialise the writes to the ring.

all this together means you can run bpf against a packet without
taking the kernel lock unless you actually caught a packet and need
to send it to userland. even better, you can run bpf in parallel,
so if we ever support multiple rings on a single interface, we can
run bpf on each ring on different cpus safely.

ive hit this pretty hard in production at work (yay dhcrelay) on
myx (which does rx outside the biglock).

ok jmatthew@@ mpi@@ millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.120 2015/06/16 11:09:39 mpi Exp $	*/
a56 2
#include <sys/atomic.h>
#include <sys/srp.h>
a118 15
/*
 * Reference count access to descriptor buffers
 */
#define D_GET(d) ((d)->bd_ref++)
#define D_PUT(d) bpf_freed(d)

/*
 * garbage collector srps
 */

void bpf_d_dtor(void *, void *);
struct srp_gc bpf_d_gc = SRP_GC_INITIALIZER(bpf_d_dtor, NULL);
void bpf_insn_dtor(void *, void *);
struct srp_gc bpf_insn_gc = SRP_GC_INITIALIZER(bpf_insn_dtor, NULL);

a246 2
	struct bpf_d *head;

a251 1

d253 2
a254 10
	srp_init(&d->bd_next);

	KERNEL_ASSERT_LOCKED();
	head = srp_get_locked(&bp->bif_dlist);
	if (head != NULL) {
		D_GET(head);
		srp_update_locked(&bpf_d_gc, &d->bd_next, head);
	}
	D_GET(d);
	srp_update_locked(&bpf_d_gc, &bp->bif_dlist, d);
d265 1
a265 2
	struct srp *dref;
	struct bpf_d *p, *next;
a285 1

d287 4
a290 5
	KERNEL_ASSERT_LOCKED();
	dref = &bp->bif_dlist;
	for (;;) {
		p = srp_get_locked(dref);
		if (p == NULL)
a291 4
		if (d == p)
			break;

		dref = &p->bd_next;
d293 2
a294 8

	next = srp_get_locked(&d->bd_next);
	if (next != NULL)
		D_GET(next);
	srp_update_locked(&bpf_d_gc, dref, next);
	srp_update_locked(&bpf_d_gc, &d->bd_next, NULL);

	if (srp_get_locked(&bp->bif_dlist) == NULL) {
a298 2
	}

d302 6
a528 1
	KERNEL_ASSERT_LOCKED(); /* for accessing bd_wfilter */
d530 1
a530 1
	    (struct sockaddr *)&dst, srp_get_locked(&d->bd_wfilter));
d906 1
a906 2
	struct srp *filter;
	struct bpf_insn *fcode;
d910 1
a910 3
	KERNEL_ASSERT_LOCKED();
	filter = wf ? &d->bd_wfilter : &d->bd_rfilter;

a913 1
		srp_update_locked(&bpf_insn_gc, filter, NULL);
d915 4
d921 1
d930 1
a930 1
	if (copyin(fp->bf_insns, fcode, size) == 0 &&
a931 1
		srp_update_locked(&bpf_insn_gc, filter, fcode);
d933 4
d939 2
d1116 2
a1117 3
	struct bpf_if *bp = (struct bpf_if *)arg;
	struct srp *dref, *nref;
	struct bpf_d *d, *next;
d1122 8
a1129 5
	dref = &bp->bif_dlist;
	d = srp_enter(dref);
	while (d != NULL) {
		atomic_inc_long(&d->bd_rcount);

d1132 3
a1134 8
		else {
			struct bpf_insn *fcode;
			fcode = srp_enter(&d->bd_rfilter);
			slen = bpf_filter(fcode, pkt, pktlen, 0);
			srp_leave(&d->bd_rfilter, fcode);
		}

		if (slen > 0) {
a1136 2

			KERNEL_LOCK();
a1137 2
			KERNEL_UNLOCK();

a1140 6

		nref = &d->bd_next;
		next = srp_enter(nref);
		srp_leave(dref, d);
		dref = nref;
		d = next;
a1141 1
	srp_leave(dref, d);
d1178 1
a1178 2
	struct srp *dref, *nref;
	struct bpf_d *d, *next;
d1194 2
a1195 5
	dref = &bp->bif_dlist;
	d = srp_enter(dref);
	while (d != NULL) {
		atomic_inc_long(&d->bd_rcount);

d1200 3
a1202 6
		else {
			struct bpf_insn *fcode;
			fcode = srp_enter(&d->bd_rfilter);
			slen = bpf_filter(fcode, (u_char *)m, pktlen, 0);
			srp_leave(&d->bd_rfilter, fcode);
		}
d1204 2
a1205 12
		if (slen > 0) {
			if (!gottime++)
				microtime(&tv);

			KERNEL_LOCK();
			bpf_catchpacket(d, (u_char *)m, pktlen, slen,
			    cpfn, &tv);
			KERNEL_UNLOCK();

			if (d->bd_fildrop)
				m->m_flags |= M_FILDROP;
		}
d1207 5
a1211 5
		nref = &d->bd_next;
		next = srp_enter(nref);
		srp_leave(dref, d);
		dref = nref;
		d = next;
a1212 1
	srp_leave(dref, d);
d1419 2
a1420 3
	KERNEL_ASSERT_LOCKED();
	srp_update_locked(&bpf_insn_gc, &d->bd_rfilter, NULL);
	srp_update_locked(&bpf_insn_gc, &d->bd_wfilter, NULL);
d1437 1
a1437 1
	srp_init(&bp->bif_dlist);
a1463 2
	KERNEL_ASSERT_LOCKED();

d1474 1
a1474 2
			for (bd = srp_get_locked(&bp->bif_dlist);
			    bd != NULL; bd = srp_get_locked(&bp->bif_dlist)) {
a1639 12
}

void
bpf_d_dtor(void *null, void *d)
{
	D_PUT(d);
}

void
bpf_insn_dtor(void *null, void *fcode)
{
	free(fcode, M_DEVBUF, 0);
@


1.120
log
@Store a unique ID, an interface index, rather than a pointer to the
receiving interface in the packet header of every mbuf.

The interface pointer should now be retrieved when necessary with
if_get().  If a NULL pointer is returned by if_get(), the interface
has probably been destroy/removed and the mbuf should be freed.

Such mechanism will simplify garbage collection of mbufs and limit
problems with dangling ifp pointers.

Tested by jmatthew@@ and krw@@, discussed with many.

ok mikeb@@, bluhm@@, dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.119 2015/05/13 10:42:46 jsg Exp $	*/
d57 2
d121 15
d264 2
d271 1
d273 10
a282 2
	d->bd_next = bp->bif_dlist;
	bp->bif_dlist = d;
d293 2
a294 1
	struct bpf_d **p;
d315 1
d317 5
a321 4
	p = &bp->bif_dlist;
	while (*p != d) {
		p = &(*p)->bd_next;
		if (*p == 0)
d323 4
d328 8
a335 2
	*p = (*p)->bd_next;
	if (bp->bif_dlist == 0)
d340 2
a344 6
/*
 * Reference count access to descriptor buffers
 */
#define D_GET(d) ((d)->bd_ref++)
#define D_PUT(d) bpf_freed(d)

d566 1
d568 1
a568 1
	    (struct sockaddr *)&dst, d->bd_wfilter);
d944 2
a945 1
	struct bpf_insn *fcode, *old;
d949 3
a951 1
	old = wf ? d->bd_wfilter : d->bd_rfilter;
d955 1
a956 4
		if (wf)
			d->bd_wfilter = NULL;
		else
			d->bd_rfilter = NULL;
a958 1
		free(old, M_DEVBUF, 0);
d967 1
a967 1
	if (copyin((caddr_t)fp->bf_insns, (caddr_t)fcode, size) == 0 &&
d969 1
a970 4
		if (wf)
			d->bd_wfilter = fcode;
		else
			d->bd_rfilter = fcode;
a972 2
		free(old, M_DEVBUF, 0);

d1148 3
a1150 2
	struct bpf_if *bp;
	struct bpf_d *d;
d1155 5
a1159 8
	/*
	 * Note that the ipl does not have to be raised at this point.
	 * The only problem that could arise here is that if two different
	 * interfaces shared any data.  This is not the case.
	 */
	bp = (struct bpf_if *)arg;
	for (d = bp->bif_dlist; d != NULL; d = d->bd_next) {
		++d->bd_rcount;
d1162 8
a1169 3
		else
			slen = bpf_filter(d->bd_rfilter, pkt, pktlen, pktlen);
		if (slen != 0) {
d1172 2
d1175 2
d1180 6
d1187 1
d1224 2
a1225 1
	struct bpf_d *d;
d1241 5
a1245 2
	for (d = bp->bif_dlist; d != NULL; d = d->bd_next) {
		++d->bd_rcount;
d1250 15
a1264 3
		else
			slen = bpf_filter(d->bd_rfilter, (u_char *)m,
			    pktlen, 0);
d1266 3
a1268 2
		if (slen == 0)
			continue;
d1270 5
a1274 5
		if (!gottime++)
			microtime(&tv);
		bpf_catchpacket(d, (u_char *)m, pktlen, slen, cpfn, &tv);
		if (d->bd_fildrop)
			m->m_flags |= M_FILDROP;
d1276 1
d1483 3
a1485 2
	free(d->bd_rfilter, M_DEVBUF, 0);
	free(d->bd_wfilter, M_DEVBUF, 0);
d1502 1
a1502 1
	bp->bif_dlist = 0;
d1529 2
d1541 2
a1542 1
			for (bd = bp->bif_dlist; bd; bd = bp->bif_dlist) {
d1708 12
@


1.119
log
@test mbuf pointers against NULL not 0
ok krw@@ miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.118 2015/02/10 21:56:10 miod Exp $	*/
d183 1
a183 1
	m->m_pkthdr.rcvif = NULL;
@


1.118
log
@First step towards making uiomove() take a size_t size argument:
- rename uiomove() to uiomovei() and update all its users.
- introduce uiomove(), which is similar to uiomovei() but with a size_t.
- rewrite uiomovei() as an uiomove() wrapper.
ok kettenis@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.117 2015/02/10 00:53:55 pelikan Exp $	*/
d1160 1
a1160 1
		if (m == 0)
@


1.117
log
@make bpf(4) able to filter based on a pf(4) queue ID for tcpdump -Q qname

ALTQ version has been on tech@@ for years, people were generally ok with it.

ok henning
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.116 2015/01/29 19:44:32 tedu Exp $	*/
d196 1
a196 1
	error = uiomove(mtod(m, caddr_t), len, uio);
d478 1
a478 1
	error = uiomove(d->bd_hbuf, d->bd_hlen, uio);
@


1.116
log
@back bpf.c down to 1.113, from before most recent timeout changes.
nmap is broken, as reported by kent fritz.
pending further investigation, we should keep nmap working until a
better fix is developed for the original problem.
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.113 2014/12/16 18:30:04 tedu Exp $	*/
d843 8
d1197 2
@


1.115
log
@when doing a blocking read with a timeout, after the sleep reset
the start time so the next read behaves the same.

from Simon Mages
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.114 2015/01/09 04:59:54 tedu Exp $	*/
a432 2
		} else if (d->bd_rtout == 0) {
			error = tsleep(d, PRINET|PCATCH, "bpf", 0);
d434 3
a436 5
			int elapsed = ticks - d->bd_rdStart;
			if (elapsed < d->bd_rtout) {
				error = tsleep(d, PRINET|PCATCH, "bpf",
				    d->bd_rtout - elapsed);
				d->bd_rdStart = 0;
@


1.114
log
@correctly handle no timeouts and make timeout handling in general better.
problem reported by Mages Simon
ok guenther
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.113 2014/12/16 18:30:04 tedu Exp $	*/
d440 1
@


1.113
log
@primary change: move uvm_vnode out of vnode, keeping only a pointer.
objective: vnode.h doesn't include uvm_extern.h anymore.
followup changes: include uvm_extern.h or lock.h where necessary.
ok and help from deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.112 2014/12/02 18:11:56 tedu Exp $	*/
d433 2
d436 4
a439 3
			if ((d->bd_rdStart + d->bd_rtout) < ticks) {
				error = tsleep((caddr_t)d, PRINET|PCATCH, "bpf",
				    d->bd_rtout);
@


1.112
log
@replace some malloc multiplies with mallocarry. ok deraadt henning
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.111 2014/11/23 07:39:02 deraadt Exp $	*/
d44 1
@


1.111
log
@length argument for some free() calls; ok doug
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.110 2014/10/07 11:16:23 dlg Exp $	*/
d919 1
a920 1
	fcode = (struct bpf_insn *)malloc(size, M_DEVBUF, M_WAITOK);
@


1.110
log
@when running bpf on an outgoing vlan interface that doesnt have a
parent that doesnt offload the tag insertion, we need to chop the
vlan subheader out before the filter is run, not after.

this moves the mbuf surgery out from the bpf layer into the vlan
layer.

ok henning@@ jmatthew@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.109 2014/09/23 00:26:11 dlg Exp $	*/
d934 1
a934 1
	free(fcode, M_DEVBUF, 0);
d1570 1
a1570 1
	free(bd, M_DEVBUF, 0);
@


1.109
log
@lock around the sysctl code that sets the bpf buffer sizes so if we ever
get multiple processes in the kernel these sets cant race and allow people
to set the default greater than the max.
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.108 2014/09/22 23:48:58 dlg Exp $	*/
a94 1
void	bpf_mcopy_stripvlan(const void *, void *, size_t);
a1161 40
 * Copy an ethernet frame from an mbuf chain into a buffer, strip the
 * vlan header bits
 */
void
bpf_mcopy_stripvlan(const void *src_arg, void *dst_arg, size_t len)
{
#if NVLAN > 0
	const struct mbuf		*m;
	u_int				 count, copied = 0, hdrdone = 0;
	u_char				*dst;
	struct ether_vlan_header	*evh;

	m = src_arg;
	dst = dst_arg;
	evh = dst_arg;
	while (len > 0) {
		if (m == 0)
			panic("bpf_mcopy_stripvlan");
		count = min(m->m_len, len);
		bcopy(mtod(m, caddr_t), (caddr_t)dst, count);
		m = m->m_next;
		dst += count;
		len -= count;
		copied += count;
		if (!hdrdone && copied >= sizeof(struct ether_vlan_header) &&
		    (ntohs(evh->evl_encap_proto) == ETHERTYPE_VLAN ||
		    ntohs(evh->evl_encap_proto) == ETHERTYPE_QINQ)) {
			/* move up by 4 bytes, overwrite encap_proto + tag */
			memmove(&evh->evl_encap_proto, &evh->evl_proto, copied -
			    offsetof(struct ether_vlan_header, evl_proto));
			dst -= (offsetof(struct ether_vlan_header, evl_proto) -
			    offsetof(struct ether_vlan_header,
			    evl_encap_proto)); /* long expression for "4" */
			hdrdone = 1;
		}
	}
#endif
}

/*
a1210 7
}

/* like bpf_mtap, but strip the vlan header, leave regular ethernet hdr */
void
bpf_mtap_stripvlan(caddr_t arg, struct mbuf *m, u_int direction)
{
	_bpf_mtap(arg, m, direction, bpf_mcopy_stripvlan);
@


1.108
log
@remove a stupid comment above bpfilterattach about how we dont do anything
in it cos its only called on new systems, when it actually does.

we dont care about old or new systems, just ours. the code is called, the
fact that it exists is enough to demonstrate that.
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.107 2014/09/22 23:40:46 dlg Exp $	*/
d55 1
d113 2
d1534 2
a1535 2
bpf_sysctl(int *name, u_int namelen, void *oldp, size_t *oldlenp, void *newp,
    size_t newlen)
a1539 3
	if (namelen != 1)
		return (ENOTDIR);

d1563 24
@


1.107
log
@stash a pointer to bpf_d in the knotes kn_hook instead of the device id.
we refcount the bpf_d memory correctly so it cant go away. possibly worse
is the bpf minor id could be reused between the kq calls, so this seems
safer to me. also avoids a list walk on each op cos the ptr is just there.
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.106 2014/09/22 23:19:59 dlg Exp $	*/
a304 4
/*
 * bpfilterattach() is called at boot time in new systems.  We do
 * nothing here since old systems will not call this.
 */
@


1.106
log
@it's easy to allow bpfwrites bigger than MCLBYTES now that we have
large cluster pools and MCLGETI.

we could chain mbufs if we want to go even bigger.

with a fix from Mathieu- <naabed at poolp dot org>
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.105 2014/09/22 23:16:30 dlg Exp $	*/
d1065 1
a1065 1
	kn->kn_hook = (caddr_t)((u_long)dev);
d1080 1
a1080 2
	dev_t dev = (dev_t)((u_long)kn->kn_hook);
	struct bpf_d *d;
a1082 1
	d = bpfilter_lookup(minor(dev));
d1092 1
a1092 2
	dev_t dev = (dev_t)((u_long)kn->kn_hook);
	struct bpf_d *d;
a1093 1
	d = bpfilter_lookup(minor(dev));
@


1.105
log
@if you request a read timeout and then use kqueues to wait for them, you
end up waiting until the ring is full cos the timeout doesnt get set up
when the knote is registered.
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.104 2014/09/19 02:52:55 dlg Exp $	*/
d175 1
a175 1
	if (uio->uio_resid > MCLBYTES)
d184 1
a184 1
		MCLGET(m, M_WAIT);
@


1.104
log
@passing M_NOWAIT to m_tag_get means it can fail, which could hit
the failure path which leaks all the stuff the previous code in
bpf_movein allocates.

since it's only called from bpfwrite, use M_WAIT instead to make
it reliable and just get rid of the bogus failure code.

ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.103 2014/07/12 18:44:22 tedu Exp $	*/
d1070 2
@


1.103
log
@add a size argument to free. will be used soon, but for now default to 0.
after discussions with beck deraadt kettenis.
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.102 2014/07/12 11:27:45 henning Exp $	*/
d227 1
a227 3
	mtag = m_tag_get(PACKET_TAG_DLT, sizeof(u_int), M_NOWAIT);
	if (mtag == NULL)
		return (ENOMEM);
@


1.102
log
@sizeof(afh), afh being uint32, is cooler than literal "4"
spotted by Kent R. Spillner <kspillner acm org>
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.100 2014/07/10 11:44:56 henning Exp $	*/
d916 1
a916 1
		free(old, M_DEVBUF);
d934 1
a934 1
		free(old, M_DEVBUF);
d938 1
a938 1
	free(fcode, M_DEVBUF);
d1458 5
a1462 5
	free(d->bd_sbuf, M_DEVBUF);
	free(d->bd_hbuf, M_DEVBUF);
	free(d->bd_fbuf, M_DEVBUF);
	free(d->bd_rfilter, M_DEVBUF);
	free(d->bd_wfilter, M_DEVBUF);
d1531 1
a1531 1
			free(bp, M_DEVBUF);
d1602 1
a1602 1
	free(bd, M_DEVBUF);
@


1.101
log
@time to claim copyright
@
text
@d1311 1
a1311 1
	bpf_mtap_hdr(arg, (caddr_t)&afh, 4, m, direction, NULL);
@


1.100
log
@some say you don't need NULL checks before free(). Not 0 either.
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.99 2014/07/10 11:03:24 henning Exp $	*/
d7 1
@


1.99
log
@introduce the revolutionary concept of NULL pointers. ok gcc
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.98 2014/07/10 09:46:29 henning Exp $	*/
d915 1
a915 2
		if (old != NULL)
			free(old, M_DEVBUF);
d933 1
a933 2
		if (old != NULL)
			free(old, M_DEVBUF);
d1457 5
a1461 11
	if (d->bd_sbuf != NULL) {
		free(d->bd_sbuf, M_DEVBUF);
		if (d->bd_hbuf != NULL)
			free(d->bd_hbuf, M_DEVBUF);
		if (d->bd_fbuf != NULL)
			free(d->bd_fbuf, M_DEVBUF);
	}
	if (d->bd_rfilter)
		free(d->bd_rfilter, M_DEVBUF);
	if (d->bd_wfilter)
		free(d->bd_wfilter, M_DEVBUF);
@


1.98
log
@introduce bpf_mcopy_stripvlan, which cuts the 4 extra bytes out of the
ether_vlan_header to make it a regular ether_header while copying into
the bpf buffer.
add bpf_mtap_stripvlan, which is a 1-line wrapper around _bpf_mtap passing
this copy function in.
ok benno
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.97 2014/07/09 13:52:35 yasuoka Exp $	*/
d179 1
a179 1
	m->m_pkthdr.rcvif = 0;
d297 1
a297 1
	d->bd_bif = 0;
d384 1
a384 1
	if (d->bd_bif == 0)
d484 1
a484 1
	d->bd_hbuf = 0;
d520 1
a520 1
	if (d->bd_bif == 0)
d547 1
a547 2
	error = (*ifp->if_output)(ifp, m, (struct sockaddr *)&dst,
	    (struct rtentry *)0);
d565 1
a565 1
		d->bd_hbuf = 0;
d659 1
a659 1
		if (d->bd_bif != 0)
d699 1
a699 1
		if (d->bd_bif == 0) {
d729 1
a729 1
		if (d->bd_bif == 0)
d749 1
a749 1
		if (d->bd_bif == 0)
d910 1
a910 1
			d->bd_wfilter = 0;
d912 1
a912 1
			d->bd_rfilter = 0;
d915 2
a916 2
		if (old != 0)
			free((caddr_t)old, M_DEVBUF);
d934 2
a935 2
		if (old != 0)
			free((caddr_t)old, M_DEVBUF);
d939 1
a939 1
	free((caddr_t)fcode, M_DEVBUF);
d957 1
a957 1
	for (bp = bpf_iflist; bp != 0; bp = bp->bif_next) {
d960 1
a960 1
		if (ifp == 0 ||
a963 3
		/*
		 * We found the requested interface.
		 */
d974 1
a974 1
		if (d->bd_sbuf == 0)
d1126 1
a1126 1
	for (d = bp->bif_dlist; d != 0; d = d->bd_next) {
d1229 1
a1229 1
	for (m0 = m; m0 != 0; m0 = m0->m_next)
d1232 1
a1232 1
	for (d = bp->bif_dlist; d != 0; d = d->bd_next) {
d1388 1
a1388 1
		if (d->bd_fbuf == 0) {
d1459 1
a1459 1
	if (d->bd_sbuf != 0) {
d1461 1
a1461 1
		if (d->bd_hbuf != 0)
d1463 1
a1463 1
		if (d->bd_fbuf != 0)
d1467 1
a1467 1
		free((caddr_t)d->bd_rfilter, M_DEVBUF);
d1469 1
a1469 1
		free((caddr_t)d->bd_wfilter, M_DEVBUF);
a1482 1
	bp = (struct bpf_if *)malloc(sizeof(*bp), M_DEVBUF, M_NOWAIT);
d1484 1
a1484 1
	if (bp == 0)
a1485 1

@


1.97
log
@Add support bpfwrite on DLT_LOOP interfaces.

ok guenther
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.96 2014/07/09 11:39:07 henning Exp $	*/
d93 1
d1173 40
d1262 7
@


1.96
log
@Herr Reyk correctly pointed out that we don't need the if_pflog.h include
here any more
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.95 2014/07/09 11:03:04 henning Exp $	*/
d164 5
d209 9
a217 1
		bcopy(m->m_data, sockp->sa_data, hlen);
d542 1
a542 1
	if (d->bd_hdrcmplt)
@


1.95
log
@tedu bpf_mtap_pflog().
now that it is a trivial wrapper around the extended bpf_mtap_hdr, we can
use bpf_mtap_hdr directly. added benefit: pflog_bpfcopy doesn't need to
be exported any more and can stay private to if_pflog.c
ok benno bluhm reyk
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.94 2014/07/09 09:30:49 henning Exp $	*/
a64 5
#endif

#include "pflog.h"
#if NPFLOG > 0
#include <net/if_pflog.h>
@


1.94
log
@bpf code surgery / shuffling / simplification.
the various bpf_mtap_* are very similiar, they differ in what (and to some
extent how) they prepend something, and what copy function they pass to
bpf_catchpacket.
use an internal _bpf_mtap as "backend" for bpf_mtap and friends.
extend bpf_mtap_hdr so that it covers all common cases:
if dlen is 0, nothing gets prepended.
copy function can be given, if NULL the default bpf_mcopy is used.
adjust the existing bpf_mtap_hdr users to pass a NULL ptr for the copy fn.
re-implement bpf_mtap_af as simple wrapper for bpf_mtap_hdr.
re-implement bpf_mtap_ether using bpf_map_hdr
re-implement bpf_mtap_pflog as trivial bpf_mtap_hdr wrapper
ok bluhm benno
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.92 2014/04/14 09:06:42 mpi Exp $	*/
a1298 13

void
bpf_mtap_pflog(caddr_t arg, caddr_t data, struct mbuf *m)
{
#if NPFLOG > 0
	if (m == NULL)
		return;

	bpf_mtap_hdr(arg, data, PFLOG_HDRLEN, m, BPF_DIRECTION_OUT,
	    pflog_bpfcopy);
#endif
}

@


1.93
log
@Don't attempt to deal with link types supported by no drivers in the
tree.  ok henning@@
@
text
@d95 2
d1164 1
a1164 1
 * Incoming linkage from device drivers, when packet is in an mbuf chain.
d1167 2
a1168 1
bpf_mtap(caddr_t arg, struct mbuf *m, u_int direction)
d1180 3
d1200 1
a1200 1
		bpf_catchpacket(d, (u_char *)m, pktlen, slen, bpf_mcopy, &tv);
d1207 9
d1226 1
a1226 1
    u_int direction)
d1228 2
a1229 6
	struct m_hdr mh;

	mh.mh_flags = 0;
	mh.mh_next = m;
	mh.mh_len = dlen;
	mh.mh_data = data;
d1231 12
a1242 2
	bpf_mtap(arg, (struct mbuf *) &mh, direction);
	m->m_flags |= mh.mh_flags & M_FILDROP;
a1256 1
	struct m_hdr mh;
a1258 3
	mh.mh_flags = 0;
	mh.mh_next = m;
	mh.mh_len = 4;
d1260 1
a1260 4
	mh.mh_data = (caddr_t)&afh;

	bpf_mtap(arg, (struct mbuf *) &mh, direction);
	m->m_flags |= mh.mh_flags & M_FILDROP;
a1275 1
	struct m_hdr mh;
d1293 1
a1293 7
	mh.mh_flags = 0;
	mh.mh_next = m;
	mh.mh_len = sizeof(evh);
	mh.mh_data = (caddr_t)&evh;

	bpf_mtap(arg, (struct mbuf *) &mh, direction);
	m->m_flags |= mh.mh_flags & M_FILDROP;
a1303 8
	struct m_hdr mh;
	struct bpf_if *bp = (struct bpf_if *)arg;
	struct bpf_d *d;
	size_t pktlen, slen;
	struct mbuf *m0;
	struct timeval tv;
	int gottime = 0;

d1307 2
a1308 25
	mh.mh_flags = 0;
	mh.mh_next = m;
	mh.mh_len = PFLOG_HDRLEN;
	mh.mh_data = data;

	pktlen = mh.mh_len;
	for (m0 = m; m0 != 0; m0 = m0->m_next)
		pktlen += m0->m_len;

	for (d = bp->bif_dlist; d != 0; d = d->bd_next) {
		++d->bd_rcount;
		if ((BPF_DIRECTION_OUT & d->bd_dirfilt) != 0)
			slen = 0;
		else
			slen = bpf_filter(d->bd_rfilter, (u_char *)&mh,
			    pktlen, 0);

		if (slen == 0)
			continue;

		if (!gottime++)
			microtime(&tv);
		bpf_catchpacket(d, (u_char *)&mh, pktlen, slen, pflog_bpfcopy,
		    &tv);
	}
@


1.92
log
@"struct pkthdr" holds a routing table ID, not a routing domain one.
Avoid the confusion by using an appropriate name for the variable.

Note that since routing domain IDs are a subset of the set of routing
table IDs, the following idiom is correct:

	rtableid = rdomain

But to get the routing domain ID corresponding to a given routing table
ID, you must call rtable_l2(9).

claudio@@ likes it, ok mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.91 2014/03/30 21:54:48 guenther Exp $	*/
a154 6
	case DLT_FDDI:
		sockp->sa_family = AF_UNSPEC;
		/* XXX 4(FORMAC)+6(dst)+6(src)+3(LLC)+5(SNAP) */
		hlen = 24;
		break;

a164 10
		break;

	case DLT_ATM_RFC1483:
		/*
		 * An ATM driver requires 4-byte ATM pseudo header.
		 * Though it isn't standard, vpi:vci needs to be
		 * specified anyway.
		 */
		sockp->sa_family = AF_UNSPEC;
		hlen = 12; 	/* XXX 4(ATM_PH) + 3(LLC) + 5(SNAP) */
@


1.91
log
@Eliminates struct pcred by moving the real and saved ugids into
struct ucred; struct process then directly links to the ucred

Based on a discussion at c2k10 or so before noting that FreeBSD and
NetBSD did this too.

ok matthew@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.90 2013/12/24 23:29:38 tedu Exp $	*/
d546 1
a546 1
	m->m_pkthdr.rdomain = ifp->if_rdomain;
@


1.90
log
@rearrange/correct timeout conditionals to work better.
fixes negative timeout panics. tested by sthen.
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.89 2013/11/29 19:28:55 tedu Exp $	*/
d872 1
a872 1
		d->bd_siguid = p->p_cred->p_ruid;
@


1.89
log
@panics still being reported. send bpf.c back to 1.85
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.85 2013/11/11 16:21:08 sthen Exp $	*/
d437 3
a439 4
		if ((d->bd_rtout != -1) ||
		    (d->bd_rdStart + d->bd_rtout) < ticks) {
			error = tsleep((caddr_t)d, PRINET|PCATCH, "bpf",
			    d->bd_rtout);
d441 4
a444 2
			if (d->bd_rtout == -1) {
				/* User requested non-blocking I/O */
a445 2
			} else
				error = 0;
@


1.88
log
@speeling
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.87 2013/11/15 21:41:54 dlg Exp $	*/
d1425 1
a1425 2
	if (d->bd_fbuf && d->bd_rdStart &&
	    (ticks - (d->bd_rtout + d->bd_rdStart) > 0)) {
d1431 5
a1435 3
		d->bd_rdStart = 0;
		ROTATE_BUFFERS(d);
		bpf_wakeup(d);
@


1.87
log
@calculate the line in the sand before comparing it to ticks, which looks
more like the original conditional.

if this doesnt fix rd thrushs panic, then this should be reverted to
r1.85.
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.86 2013/11/12 01:12:09 dlg Exp $	*/
d175 2
a176 2
		 * en atm driver requires 4-byte atm pseudo header.
		 * though it isn't standard, vpi:vci needs to be
d404 1
a404 1
	 * bd_rdStart is tagged when we start the read, iff there's a timeout.
@


1.86
log
@try bpf.c r1.84 again, this time without semantic changes to if statements.

cheers to sthen@@ and krw@@ for properly dealing with the fallout of my
first commit.
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.85 2013/11/11 16:21:08 sthen Exp $	*/
d1426 1
a1426 1
	    (ticks - d->bd_rdStart > d->bd_rtout)) {
@


1.85
log
@Revert bpf.c 1.84 / bpfdesc.h 1.19 for now, "panic: timeout_add: to_ticks (-1)
< 0" seen by RD Thrush, http://article.gmane.org/gmane.os.openbsd.bugs/20113
where he has a long-running process using bpf which is active at the time of
panic.  krw@@ agrees with reverting for now.
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.83 2012/12/28 17:52:06 gsoares Exp $	*/
d1425 2
a1426 1
	if (d->bd_rdStart && (d->bd_rtout + d->bd_rdStart < ticks)) {
d1432 3
a1434 5
		if (d->bd_fbuf) {
			d->bd_rdStart = 0;
			ROTATE_BUFFERS(d);
			bpf_wakeup(d);
		}
@


1.84
log
@replace the user of ticks in a condition like "interval + start < ticks"
with "ticks - start > interval" because the latter copes with the ticks
value wrapping.

pointed out by guenther@@
ok krw@@
@
text
@d1423 3
a1425 2
	} else if (d->bd_fbuf && d->bd_rdStart &&
	    (ticks - d->bd_rdStart > d->bd_rtout)) {
d1431 5
a1435 3
		d->bd_rdStart = 0;
		ROTATE_BUFFERS(d);
		bpf_wakeup(d);
@


1.83
log
@change the malloc(9) flags from M_DONTWAIT to M_NOWAIT; OK millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.82 2012/12/21 11:17:22 mikeb Exp $	*/
d1423 2
a1424 3
	}

	if (d->bd_rdStart && (d->bd_rtout + d->bd_rdStart < ticks)) {
d1430 3
a1432 5
		if (d->bd_fbuf) {
			d->bd_rdStart = 0;
			ROTATE_BUFFERS(d);
			bpf_wakeup(d);
		}
@


1.82
log
@Rather than calling mircotime in bpf_catchpacket each time it's called
on a packet, make bpf_catchpacket take a timeval indicating when the
packet was captured.  Move microtime to the calling functions and grab
the timestamp as soon as we know that we're going to call catchpacket
at least once.

From NetBSD, ok deraadt, claudio, sthen
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.81 2012/12/21 11:13:43 mikeb Exp $	*/
d1485 1
a1485 1
	bp = (struct bpf_if *)malloc(sizeof(*bp), M_DEVBUF, M_DONTWAIT);
@


1.81
log
@bpf allocates packet buffers in the ioctl path and can sleep
waiting for memory to become available

obtained from netbsd with tweaks, with input from deraadt and
blambert, ok deraadt, claudio
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.80 2012/04/14 09:39:46 yasuoka Exp $	*/
d105 1
a105 1
	    void (*)(const void *, void *, size_t));
d1127 2
a1128 1
	int drop = 0;
d1143 3
a1145 1
			bpf_catchpacket(d, pkt, pktlen, slen, bcopy);
d1188 2
d1207 1
a1207 1
		    continue;
d1209 3
a1211 1
		bpf_catchpacket(d, (u_char *)m, pktlen, slen, bpf_mcopy);
d1319 2
d1343 1
a1343 1
		    continue;
d1345 4
a1348 1
		bpf_catchpacket(d, (u_char *)&mh, pktlen, slen, pflog_bpfcopy);
d1364 1
a1364 1
    void (*cpfn)(const void *, void *, size_t))
a1368 1
	struct timeval tv;
d1407 2
a1408 3
	microtime(&tv);
	hp->bh_tstamp.tv_sec = tv.tv_sec;
	hp->bh_tstamp.tv_usec = tv.tv_usec;
@


1.80
log
@Use DLT_LOOP for all tunneling interfaces.
Byte order adjustment for bpf was hidden behind bpf_mtap_af() and
sizeof(u_int32_t) is used for length of the bpf header.

tested by sebastia and mxb at alumni.chalmers.se.
ok claudio
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.79 2012/01/16 03:34:58 guenther Exp $	*/
d92 1
a92 1
int	bpf_allocbufs(struct bpf_d *);
d959 1
a959 1
	int s, error;
d984 2
a985 5
		if (d->bd_sbuf == 0) {
			error = bpf_allocbufs(d);
			if (error != 0)
				return (error);
		}
d1432 1
a1432 1
int
d1435 2
a1436 8
	d->bd_fbuf = (caddr_t)malloc(d->bd_bufsize, M_DEVBUF, M_NOWAIT);
	if (d->bd_fbuf == NULL)
		return (ENOBUFS);
	d->bd_sbuf = (caddr_t)malloc(d->bd_bufsize, M_DEVBUF, M_NOWAIT);
	if (d->bd_sbuf == NULL) {
		free(d->bd_fbuf, M_DEVBUF);
		return (ENOBUFS);
	}
a1438 1
	return (0);
@


1.79
log
@bpf devices behave similar to raw sockets and never block on write,
so always show as writable to poll()/select().

Behavior pointed out by Fernando Gont.  ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.78 2011/07/02 22:20:08 nicm Exp $	*/
d1250 1
d1255 2
a1256 1
	mh.mh_data = (caddr_t)&af;
@


1.78
log
@kqueue attach functions should return an errno or 0, not a plain 1. Fix
the obvious cases to return EINVAL and ENXIO.

ok tedu deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.77 2011/01/04 15:24:11 deraadt Exp $	*/
a1024 4
	revents = events & (POLLIN | POLLRDNORM);
	if (revents == 0)
		return (0);		/* only support reading */

d1029 1
d1039 18
a1056 9
	s = splnet();
	if (d->bd_hlen == 0 && (!d->bd_immediate || d->bd_slen == 0)) {
		revents = 0;		/* no data waiting */
		/*
		 * if there's a timeout, mark the time we started waiting.
		 */
		if (d->bd_rtout != -1 && d->bd_rdStart == 0)
			d->bd_rdStart = ticks;
		selrecord(p, &d->bd_sel);
a1057 1
	splx(s);
@


1.77
log
@in bpf_movein(), range-check mbuf size against MCLBYTES before
size_t to int truncation
ok claudio
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.76 2010/09/21 04:06:37 henning Exp $	*/
d1073 1
a1073 1
		return (1);
@


1.76
log
@pflog overhaul
pflog was logging the "wrong" as in not yet rewritten (nat/rdr) addresses.
to address this without making an extra copy of the mbuf chain:
-introduce bpf_mtap_pflog, which is a 1:1 copy of bpf_mtap_hdr, except that
it supplies bpf_catchpacket with pflog_bpfcopy as copy function instead of
plain bcopy
-said new shiny pflog_bpfcopy knows what a pflog packet looks like, copies
everything into bpf's buffer, contructs a fake mbuf (which is allocated once
at attach time and reused over and over) which points to the bpf buffer
as data storage
-call pf_setup_pdesc on said fake mbuf
-then call pf_translate to rewrite the addresses as needed right in the
bpf buffer
this changes the pflog header as we have to pass the new addresses/ports
around. relies on canacar's awesome work in libpcap to work olrite with the
new, longer pflog header as well as with the old, shorter one.
almost completely written at c2k10 in canada, finished here at j2k10 in
japan. ok ryan dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.75 2009/11/09 17:53:39 nicm Exp $	*/
d187 2
a189 2
	if (len > MCLBYTES)
		return (EIO);
@


1.75
log
@Every selwakeup() should have a matching KNOTE() (even if kqueue isn't
supported it doesn't do any harm), so put the KNOTE() in selwakeup() itself and
remove it from any occurences where both are used, except one for kqueue itself
and one in sys_pipe.c (where the selwakeup is under a PIPE_SEL flag).

Based on a diff from tedu.

ok deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.74 2009/10/26 18:22:58 claudio Exp $	*/
d67 5
d1298 39
@


1.74
log
@Set the rdomain in bpfwrite() to the interface rdomain so that bpf sender
like dhcpd/dhclinet can send packets out of interfaces in other rdomains
without hitting the check in ether_output().
With and ok phessler@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.73 2009/09/21 16:33:42 canacar Exp $	*/
a508 1
	KNOTE(&d->bd_sel.si_note, 0);
@


1.73
log
@Properly reference count bpf descriptors when using kqueue.
Reported and fix tested by weerd@@, ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.72 2009/09/07 23:47:51 deraadt Exp $	*/
d542 2
@


1.72
log
@de-inline a function which gains absolutely no benefit at all from it
ok canacar
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.71 2008/11/26 18:01:43 dlg Exp $	*/
d1073 1
d1090 1
@


1.71
log
@dont have bpf.h expose the kernel ticks variable wherever it is includeing.

it is very confusing like this.

ok deraadt@@ canacar@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.70 2008/11/09 15:08:26 naddy Exp $	*/
d98 1
a98 1
static __inline void bpf_wakeup(struct bpf_d *);
d498 1
a498 1
static __inline void
@


1.70
log
@Introduce bpf_mtap_ether(), which for the benefit of bpf listeners
creates the VLAN encapsulation from the tag stored in the mbuf
header.  Idea from FreeBSD, input from claudio@@ and canacar@@.

Switch all hardware VLAN enabled drivers to the new function.

ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.69 2008/09/17 20:10:37 chl Exp $	*/
d70 3
@


1.69
log
@remove dead stores and newly created unused variables.

fix potential use of uninitialized value in trunk_port_ioctl() function.

Found by LLVM/Clang Static Analyzer.

ok mpf@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.68 2008/01/25 16:14:56 mglocker Exp $	*/
d62 5
d1242 44
@


1.68
log
@Prevent USB network devices to generate a page fault trap when detached
while UP and holding an open bpf handler by checking bpfilter_lookup()
for returning NULL in bpfpoll().  Added an XXX comment which reminds us
to recheck why this race condition happens in conjunction with the USB
stack.

Commented by miod@@ and thib@@ (would prefer to directly fix race condition,
if this is possible at all).

lot of help and OK claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.67 2007/09/15 16:43:51 henning Exp $	*/
a1321 1
			curlen = 0;
@


1.67
log
@malloc sweep:
-remove useless casts
-MALLOC/FREE -> malloc/free
-use M_ZERO where appropriate instead of seperate bzero
feedback & ok krw, hshoexer
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.66 2007/07/25 23:11:53 art Exp $	*/
d1019 9
@


1.66
log
@Back out the tracking of procs in struct selinfo. There's one serious
bug in the code, but as soon as I try to fix it, it seems to trigger
some other bugs. Instead of trying to figure out what's going on
while everyone suffers, it's better to back out and figure out
the bugs outside the tree.
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.64 2007/03/04 23:36:34 canacar Exp $	*/
d1488 1
a1488 2
	if ((bd = malloc(sizeof(*bd), M_DEVBUF, M_NOWAIT)) != NULL) {
		bzero(bd, sizeof(*bd));
@


1.65
log
@Kill the horrible hack of storing the pid in struct selinfo.

Instead, keep the proc pointer in it and put the selinfo on a list
in struct proc in selrecord. Then clean up the list when leaving
sys_select and sys_poll.

miod@@ ok, testing by many, including Bobs spamd boxes.
@
text
@d499 2
@


1.64
log
@Make sure a bpf device can only be opened once.
Previously the descriptor was locked only after
an interface is set, leading to a race condition.
Reported by Jon Steel < jon.steel at esentire com >
tested by otto@@, looks correct deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.63 2006/07/18 11:52:12 dlg Exp $	*/
a498 2
	/* XXX */
	d->bd_sel.si_selpid = 0;
@


1.63
log
@get rid of arc network support. we have no users of it so this is dead
code. however, it is still cluttering up the kernel namespace a bit. it is
better gone.

ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.62 2006/03/25 22:41:47 djm Exp $	*/
a291 10

/*
 * Mark a descriptor free by making it point to itself.
 * This is probably cheaper than marking with a constant since
 * the address should be in a register anyway.
 */
#define D_ISFREE(d) ((d) == (d)->bd_next)
#define D_MARKFREE(d) ((d)->bd_next = (d))
#define D_MARKUSED(d) ((d)->bd_next = 0)

a320 6
		return (ENXIO);
	/*
	 * Each minor can be opened by only one process.  If the requested
	 * minor is in use, return EBUSY.
	 */
	if (!D_ISFREE(d))
d1384 1
a1384 1
	*bp->bif_driverp = 0;
d1487 1
a1487 1
		return (bd);
a1490 1
		D_MARKFREE(bd);
@


1.62
log
@allow bpf(4) to ignore packets based on their direction (inbound or
outbound), using a new BIOCSDIRFILT ioctl;
guidance, feedback and ok canacar@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.61 2006/03/04 22:40:15 brad Exp $	*/
a59 1
#include <netinet/if_arc.h>
a139 5
		break;

	case DLT_ARCNET:
		sockp->sa_family = AF_UNSPEC;
		hlen = ARC_HDRLEN;
@


1.61
log
@With the exception of two other small uncommited diffs this moves
the remainder of the network stack from splimp to splnet.

ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.60 2005/11/03 20:00:18 reyk Exp $	*/
d633 1
d851 9
d1117 1
a1117 1
bpf_tap(caddr_t arg, u_char *pkt, u_int pktlen)
d1132 4
a1135 1
		slen = bpf_filter(d->bd_rfilter, pkt, pktlen, pktlen);
d1174 1
a1174 1
bpf_mtap(caddr_t arg, struct mbuf *m)
d1190 5
a1194 1
		slen = bpf_filter(d->bd_rfilter, (u_char *)m, pktlen, 0);
d1215 2
a1216 1
bpf_mtap_hdr(caddr_t arg, caddr_t data, u_int dlen, struct mbuf *m)
d1225 1
a1225 1
	bpf_mtap(arg, (struct mbuf *) &mh);
d1239 1
a1239 1
bpf_mtap_af(caddr_t arg, u_int32_t af, struct mbuf *m)
d1248 1
a1248 1
	bpf_mtap(arg, (struct mbuf *) &mh);
@


1.60
log
@re-implement the bpf "filter drop" option that it actually works. the
bpf FILDROP interface exists for about one year but the required
interface to the drivers was missing - so it was useless. this new
approach based on a design by henning@@ uses a new mbuf flag to mark
filtered packets and to drop them in the generic network stack input
routines (like ether_input).

for example; after some additional testing, this could be used by
dhclient to filter everything except DHCP packets (track tech@@
for a corresponding dhclient diff). the "filter dropped" packets won't
reach the network stack. so it's probably some kind of a very basic
application layer packet filter ;).

ok canacar@@, discussed with henning@@ and others
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.59 2005/07/31 03:52:18 pascoe Exp $	*/
d238 1
a238 1
 * Must be called at splimp.
d366 1
a366 1
	s = splimp();
d408 1
a408 1
	s = splimp();
d497 1
a497 1
	s = splimp();
d572 1
a572 1
 * receive and drop counts.  Should be called at splimp.
d652 1
a652 1
			s = splimp();
d704 1
a704 1
		s = splimp();
d720 1
a720 1
		s = splimp();
d913 1
a913 1
		s = splimp();
d932 1
a932 1
		s = splimp();
d987 1
a987 1
		s = splimp();
d1031 1
a1031 1
	s = splimp();
d1067 1
a1067 1
	s = splimp();
d1082 1
a1082 1
	s = splimp();
d1558 1
a1558 1
	s = splimp();
@


1.59
log
@Introduce bpf_mtap_af and bpf_mtap_hdr to be used when passing a mbuf chain
to bpf with either an address family or other header added.

These helpers only allocate a much smaller struct m_hdr on the stack when
needed, rather than leaving 256 byte struct mbufs on the stack in deep
call paths.  Also removes a fair bit of duplicated code.

commit now, tune after deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.58 2005/04/20 19:52:42 reyk Exp $	*/
d1160 1
a1160 1
int
a1166 1
	int drop = 0;
d1169 1
a1169 1
		return (0);
d1184 1
a1184 1
			drop++;
a1185 2

	return (drop);
d1197 1
a1197 1
int
d1207 2
a1208 1
	return bpf_mtap(arg, (struct mbuf *) &mh);
d1220 1
a1220 1
int
d1230 2
a1231 1
	return bpf_mtap(arg, (struct mbuf *) &mh);
@


1.58
log
@send raw 802.11 frames with bpf(4) using the IEEE802_11 or
IEEE802_11_RADIO data link types.

ok canacar@@ damien@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.57 2005/04/20 17:03:22 reyk Exp $	*/
d1189 44
@


1.57
log
@the linktype (DLT) should always be of type u_int.

fine deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.56 2005/01/07 16:28:38 reyk Exp $	*/
d110 1
d154 6
d220 9
@


1.56
log
@add support for BIOCGDLTLIST and BIOCSDLT, see bpf(4)

ok canacar@@, fgsch@@, tested by some other people
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.55 2004/12/17 15:56:58 reyk Exp $	*/
d84 1
a84 1
int	bpf_movein(struct uio *, int, struct mbuf **,
d106 1
a106 1
bpf_movein(struct uio *uio, int linktype, struct mbuf **mp,
d531 1
a531 1
	error = bpf_movein(uio, (int)d->bd_bif->bif_dlt, &m,
@


1.55
log
@knf cleanup, convert old k&r-style functions to ansi-style for a
consistent style in sys/net/bpf.c.

ok henning@@, "looks fine" canacar@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.54 2004/10/09 19:55:28 brad Exp $	*/
d95 2
d578 1
d580 1
d605 1
d714 10
d734 10
d1447 58
@


1.54
log
@sizeof(struct ether_header) -> ETHER_HDR_LEN

ok mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.53 2004/09/23 03:31:08 brad Exp $	*/
d104 2
a105 6
bpf_movein(uio, linktype, mp, sockp, filter)
	struct uio *uio;
	int linktype;
	struct mbuf **mp;
	struct sockaddr *sockp;
	struct bpf_insn *filter;
d223 1
a223 3
bpf_attachd(d, bp)
	struct bpf_d *d;
	struct bpf_if *bp;
d241 1
a241 2
bpf_detachd(d)
	struct bpf_d *d;
d302 1
a302 2
bpfilterattach(n)
	int n;
d313 1
a313 5
bpfopen(dev, flag, mode, p)
	dev_t dev;
	int flag;
	int mode;
	struct proc *p;
d342 1
a342 5
bpfclose(dev, flag, mode, p)
	dev_t dev;
	int flag;
	int mode;
	struct proc *p;
d373 1
a373 4
bpfread(dev, uio, ioflag)
	dev_t dev;
	struct uio *uio;
	int ioflag;
d393 1
a393 1
	
d428 2
a429 1
		if ((d->bd_rtout != -1) || (d->bd_rdStart + d->bd_rtout) < ticks) {
d495 1
a495 2
bpf_wakeup(d)
	struct bpf_d *d;
d509 1
a509 4
bpfwrite(dev, uio, ioflag)
	dev_t dev;
	struct uio *uio;
	int ioflag;
d557 1
a557 2
bpf_reset_d(d)
	struct bpf_d *d;
d589 1
a589 6
bpfioctl(dev, cmd, addr, flag, p)
	dev_t dev;
	u_long cmd;
	caddr_t addr;
	int flag;
	struct proc *p;
d840 1
a840 1
		 	u_int sig;
d862 1
a862 4
bpf_setf(d, fp, wf)
	struct bpf_d *d;
	struct bpf_program *fp;
	int wf;
d913 1
a913 3
bpf_setif(d, ifr)
	struct bpf_d *d;
	struct ifreq *ifr;
d927 1
d968 1
a968 3
bpf_ifname(ifp, ifr)
	struct ifnet *ifp;
	struct ifreq *ifr;
d977 1
a977 4
bpfpoll(dev, events, p)
	dev_t dev;
	int events;
	struct proc *p;
d1008 1
a1008 1
bpfkqfilter(dev_t dev,struct knote *kn)
d1066 1
a1066 4
bpf_tap(arg, pkt, pktlen)
	caddr_t arg;
	u_char *pkt;
	u_int pktlen;
d1097 1
a1097 4
bpf_mcopy(src_arg, dst_arg, len)
	const void *src_arg;
	void *dst_arg;
	size_t len;
d1120 1
a1120 3
bpf_mtap(arg, m)
	caddr_t arg;
	struct mbuf *m;
d1138 7
a1144 5
		if (slen != 0) {
			bpf_catchpacket(d, (u_char *)m, pktlen, slen, bpf_mcopy);
			if (d->bd_fildrop)
				drop++;
		}
d1159 2
a1160 5
bpf_catchpacket(d, pkt, pktlen, snaplen, cpfn)
	struct bpf_d *d;
	u_char *pkt;
	size_t pktlen, snaplen;
	void (*cpfn)(const void *, void *, size_t);
d1242 1
a1242 2
bpf_allocbufs(d)
	struct bpf_d *d;
d1262 1
a1262 2
bpf_freed(d)
	struct bpf_d *d;
d1288 1
a1288 4
bpfattach(driverp, ifp, dlt, hdrlen)
	caddr_t *driverp;
	struct ifnet *ifp;
	u_int dlt, hdrlen;
d1317 1
a1317 2
bpfdetach(ifp)
	struct ifnet *ifp;
@


1.53
log
@- remove EVFILT_WRITE in bpfkqfilter() switch case, handled
by default label.
- fill in kn_data with the number of bytes available, same
behavior as FreeBSD/NetBSD.

ok tedu@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.52 2004/09/12 09:35:50 claudio Exp $	*/
d141 1
a141 1
		hlen = sizeof(struct ether_header);
@


1.52
log
@Return the most common data link type instead of the first match for an
interface. Where the most common DLT is the one with the smallest id.
This fixes tcpdump for atw(4) that attaches multiple bpf hooks.
Tested: millert@@, Sigfred Haversen, otto@@, mcbride@@, sturm@@, krw@@,
Steve Shockley
OK millert@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.51 2004/06/22 04:58:27 canacar Exp $	*/
a1056 1
	case EVFILT_WRITE:
d1075 1
a1075 1
	int s = splimp();
d1078 1
a1087 3
	int res, s;

	kn->kn_data = 0;
d1090 4
a1093 4
	s = splimp();
	res = d->bd_hlen != 0 || (d->bd_immediate && d->bd_slen != 0);
	splx(s);
	return (res);
@


1.51
log
@Unbreak previous commit ok markus@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.50 2004/06/22 04:04:19 canacar Exp $	*/
d948 1
a948 1
	struct bpf_if *bp;
d962 7
d979 1
a979 1
		if (bp != d->bd_bif) {
d986 1
a986 1
			bpf_attachd(d, bp);
@


1.50
log
@Add a new "filter drop" flag to bpf and related ioclts.
When enabled, it notifies the calling interface that the packet
matches a bpf filter and should be dropped.
ok henning@@ markus@@ frantzen@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.49 2004/06/21 23:05:10 markus Exp $	*/
d1107 1
a1107 1
	int match = 0;
d1120 2
a1121 1
			match ++;
d1125 1
a1125 1
	return (d->bd_fildrop && match);
d1167 1
a1167 1
	int match = 0;
d1181 2
a1182 1
			match++;
d1186 1
a1186 1
	return (d->bd_fildrop && match);
@


1.49
log
@move the IFF_UP check to bpfwrite; ok canacar@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.48 2004/05/31 13:04:13 markus Exp $	*/
d829 8
d1098 1
a1098 1
void
d1107 2
d1118 1
a1118 1
		if (slen != 0)
d1120 2
d1123 2
d1157 1
a1157 1
void
d1166 1
d1169 1
a1169 1
		return;
d1178 1
a1178 1
		if (slen != 0)
d1180 2
d1183 2
@


1.48
log
@remove the broken auto-append-'0' code; ok canacar, deraadt, thierry
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.47 2004/05/28 08:16:23 grange Exp $	*/
d545 3
a953 1
		 * If it's not up, return an error.
a957 3
		if ((ifp->if_flags & IFF_UP) == 0)
			return (ENETDOWN);

@


1.47
log
@bpf device cloning.
Now to have more bpf devices just add device nodes in /dev,
no need to recompile kernel anymore.

Code from form@@pdp-11.org.ru, some help from markus@@.
ok markus@@ canacar@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.46 2004/05/25 17:36:49 canacar Exp $	*/
d938 1
a938 25
	char *cp;
	int unit_seen, i, s, error;

	/*
	 * Make sure the provided name has a unit number, and default
	 * it to '0' if not specified.
	 * XXX This is ugly ... do this differently?
	 */
	unit_seen = 0;
	cp = ifr->ifr_name;
	cp[sizeof(ifr->ifr_name) - 1] = '\0';	/* sanity */
	while (*cp++)
		if (*cp >= '0' && *cp <= '9')
			unit_seen = 1;
	if (!unit_seen) {
		/* Make sure to leave room for the '\0'. */
		for (i = 0; i < (IFNAMSIZ - 1); ++i) {
			if ((ifr->ifr_name[i] >= 'a' &&
			     ifr->ifr_name[i] <= 'z') ||
			    (ifr->ifr_name[i] >= 'A' &&
			     ifr->ifr_name[i] <= 'Z'))
				continue;
			ifr->ifr_name[i] = '0';
		}
	}
@


1.46
log
@Return buffered packets when reading from a bpf descriptor and the
interface is detached, and wakeup any  polling processes when the
bpf descriptor is closed. ok henning@@, tedu@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.45 2004/05/08 20:54:13 canacar Exp $	*/
d75 1
a75 1
 *  bpf_dtab holds the descriptors, indexed by minor device #
d78 1
a78 2
struct bpf_d	*bpf_dtab;
int nbpfilter;
d99 4
d312 1
a312 13
	int i;

	bpf_dtab = malloc(n * sizeof(*bpf_dtab), M_DEVBUF, M_NOWAIT);
	if (!bpf_dtab)
		return;
	nbpfilter = n;
	bzero(bpf_dtab, n * sizeof(*bpf_dtab));
	/*
	 * Mark all the descriptors free if this hasn't been done.
	 */
	if (!D_ISFREE(&bpf_dtab[0]))
		for (i = 0; i < nbpfilter; ++i)
			D_MARKFREE(&bpf_dtab[i]);
d329 2
a330 1
	if (minor(dev) >= nbpfilter)
a335 1
	d = &bpf_dtab[minor(dev)];
a339 1
	bzero((char *)d, sizeof(*d));
d360 1
a360 1
	struct bpf_d *d = &bpf_dtab[minor(dev)];
d363 1
d394 1
a394 1
	struct bpf_d *d = &bpf_dtab[minor(dev)];
d398 1
d533 1
a533 1
	struct bpf_d *d = &bpf_dtab[minor(dev)];
d539 1
d616 1
a616 1
	struct bpf_d *d = &bpf_dtab[minor(dev)];
d619 1
d1036 1
a1036 1
	d = &bpf_dtab[minor(dev)];
d1057 1
a1057 1
	struct bpf_d *d = &bpf_dtab[minor(dev)];
d1061 1
d1085 1
a1085 1
	struct bpf_d *d = &bpf_dtab[minor(dev)];
d1088 1
d1097 1
a1097 1
	struct bpf_d *d = &bpf_dtab[minor(dev)];
d1102 1
d1327 1
a1327 1
	D_MARKFREE(d);
d1373 1
a1373 1
	int maj, mn;
d1385 3
a1387 1
			for (bd = bp->bif_dlist; bd; bd = bp->bif_dlist)
d1392 4
a1395 3
				for (mn = 0; mn < nbpfilter; mn++)
					if (&bpf_dtab[mn] == bd) {
						vdevgone(maj, mn, mn, VCHR);
d1398 1
d1440 34
@


1.45
log
@reference count bpf descriptors to protect against disappearing interfaces
while asleep in read. ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.44 2004/02/24 21:43:55 tedu Exp $	*/
d376 1
d436 10
d1315 1
a1315 3
	d->bd_ref--;
	if (d->bd_ref > 0) {
		bpf_wakeup(d);
a1316 1
	}
@


1.44
log
@sysctl knob for bpf tunables.  some tips from canacar@@
ok canacar@@ deraadt@@ mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.43 2004/02/06 22:38:58 tedu Exp $	*/
d295 6
d353 2
d376 1
a377 1
	bpf_freed(d);
d418 2
d455 1
d474 1
d498 2
d1297 2
a1298 2
 * Free buffers currently in use by a descriptor.
 * Called on close.
d1304 6
a1309 5
	/*
	 * We don't need to lock out interrupts since this descriptor has
	 * been detached from its interface and it yet hasn't been marked
	 * free.
	 */
@


1.43
log
@as seen in netbsd.  crank bpf sizes to adapt to faster networks.
max size goes to 2MB, default goes to 32k.  ok canacar@@ mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.42 2003/12/10 07:22:42 itojun Exp $	*/
d53 1
d1381 35
@


1.42
log
@de-register.  deraadt ok
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.41 2003/10/24 04:26:16 canacar Exp $	*/
d62 1
a62 1
#define BPF_BUFSIZE 9216	/* 8192 too small for ATM frames */
d70 1
d662 2
a663 2
			if (size > BPF_MAXBUFSIZE)
				*(u_int *)addr = size = BPF_MAXBUFSIZE;
@


1.41
log
@Fix write filter blocking when no filter was set. Fixes
problems with dhcp.

ok frantzen@@ krw@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.40 2003/10/22 18:42:40 canacar Exp $	*/
d100 1
a100 1
	register struct uio *uio;
d102 2
a103 2
	register struct mbuf **mp;
	register struct sockaddr *sockp;
d328 1
a328 1
	register struct bpf_d *d;
d360 2
a361 2
	register struct bpf_d *d = &bpf_dtab[minor(dev)];
	register int s;
d389 1
a389 1
	register struct uio *uio;
d392 1
a392 1
	register struct bpf_d *d = &bpf_dtab[minor(dev)];
d495 1
a495 1
	register struct bpf_d *d;
d514 1
a514 1
	register struct bpf_d *d = &bpf_dtab[minor(dev)];
d596 1
a596 1
	register struct bpf_d *d = &bpf_dtab[minor(dev)];
d659 1
a659 1
			register u_int size = *(u_int *)addr;
d1001 1
a1001 1
	register dev_t dev;
d1005 2
a1006 2
	register struct bpf_d *d;
	register int s, revents;
d1094 2
a1095 2
	register u_char *pkt;
	register u_int pktlen;
d1098 2
a1099 2
	register struct bpf_d *d;
	register size_t slen;
d1122 1
a1122 1
	register size_t len;
d1124 2
a1125 2
	register const struct mbuf *m;
	register u_int count;
d1179 8
a1186 8
	register struct bpf_d *d;
	register u_char *pkt;
	register size_t pktlen, snaplen;
	register void (*cpfn)(const void *, void *, size_t);
{
	register struct bpf_hdr *hp;
	register int totlen, curlen;
	register int hdrlen = d->bd_bif->bif_hdrlen;
d1265 1
a1265 1
	register struct bpf_d *d;
d1286 1
a1286 1
	register struct bpf_d *d;
@


1.40
log
@Add locking and write filtering to bpf descriptors.
Locking prevents dangerous ioctls such as changing the
interface and sending signals to be executed by an
unprivileged process. A filter can also be applied
to packets injected through a bpf descriptor.

These features allow programs using bpf descriptors to
safely drop/seperate privileges.

ok frantzen@@ henning@@ mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.39 2003/10/04 01:03:49 deraadt Exp $	*/
d108 3
a110 3
	int len;
	int hlen;
	int slen; /* XXX  u_int ? */
d171 1
a171 1
	if ((unsigned)len > MCLBYTES)
d193 1
a193 1
	if (slen == 0 || slen < len) {
@


1.39
log
@bpf support for atm cards; from jason@@ackley.net
none of us can test this, but that does not mean it has to sit in the pr
database
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.38 2003/09/23 16:51:13 millert Exp $	*/
d83 2
a84 1
int	bpf_movein(struct uio *, int, struct mbuf **, struct sockaddr *);
d99 1
a99 1
bpf_movein(uio, linktype, mp, sockp)
d104 1
d110 1
d187 15
d203 1
a203 1
	 * Make room for link header.
d206 1
a208 3
		error = uiomove((caddr_t)sockp->sa_data, hlen, uio);
		if (error)
			goto bad;
d210 2
a211 3
	error = uiomove(mtod(m, caddr_t), len - hlen, uio);
	if (!error)
		return (0);
d529 1
a529 1
	    (struct sockaddr *)&dst);
d599 23
d673 8
a680 1
		error = bpf_setf(d, (struct bpf_program *)addr);
d801 3
d858 1
a858 1
bpf_setf(d, fp)
d861 1
d867 1
a867 1
	old = d->bd_filter;
d872 4
a875 1
		d->bd_filter = 0;
d891 4
a894 1
		d->bd_filter = fcode;
d1108 1
a1108 1
		slen = bpf_filter(d->bd_filter, pkt, pktlen, pktlen);
d1163 1
a1163 1
		slen = bpf_filter(d->bd_filter, (u_char *)m, pktlen, 0);
d1300 4
a1303 2
	if (d->bd_filter)
		free((caddr_t)d->bd_filter, M_DEVBUF);
@


1.38
log
@Replace select backends with poll backends.  selscan() and pollscan()
now call the poll backend.  With this change we implement greater
poll(2) functionality instead of emulating it via the select backend.
Adapted from NetBSD and including some changes from FreeBSD.
Tested by many, deraadt@@ OK
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.37 2003/07/29 23:02:52 itojun Exp $	*/
d62 1
a62 1
#define BPF_BUFSIZE 8192	/* 4096 too small for FDDI frames */
d151 10
@


1.37
log
@avoid stack smash on FDDI case.  found by kernel propolice.
markus ok.  miod/paul confirmed
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.36 2003/06/18 22:47:54 henning Exp $	*/
d51 1
d87 1
a87 1
int	bpfselect(dev_t, int, struct proc *);
d932 1
a932 4
 * Support for select() system call
 *
 * Return true iff the specific operation will not block indefinitely.
 * Otherwise, return false but make a note that a selwakeup() must be done.
d935 1
a935 1
bpfselect(dev, rw, p)
d937 1
a937 1
	int rw;
d941 5
a945 1
	register int s;
a946 2
	if (rw != FREAD)
		return (0);
a950 1

d952 2
a953 1
	if (d->bd_hlen != 0 || (d->bd_immediate && d->bd_slen != 0)) {
d955 1
a955 1
		 * There is data waiting.
d957 3
a959 2
		splx(s);
		return (1);
a960 9

	/*
	 * if there isn't data waiting, and there's a timeout,
	 * mark the time we started waiting.
	 */
	if (d->bd_rtout != -1 && d->bd_rdStart == 0)
		d->bd_rdStart = ticks;
			    
	selrecord(p, &d->bd_sel);
d962 1
a962 1
	return (0);
@


1.36
log
@Do not panic on no memory available when allocating bufs, pass ENOBUFS
to userland instead.

fixes PRs 2235, 2236 and 2640
from Otto Moerbeek <otto@@drijf.net>

ok frantzen@@, tedu@@, deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.35 2003/06/02 23:28:11 millert Exp $	*/
d492 1
a492 1
	struct sockaddr dst;
d502 2
a503 1
	error = bpf_movein(uio, (int)d->bd_bif->bif_dlt, &m, &dst);
d513 1
a513 1
		dst.sa_family = pseudo_AF_HDRCMPLT;
d516 2
a517 1
	error = (*ifp->if_output)(ifp, m, &dst, (struct rtentry *)0);
@


1.35
log
@Remove the advertising clause in the UCB license which Berkeley
rescinded 22 July 1999.  Proofed by myself and Theo.
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.34 2003/04/01 23:42:24 art Exp $	*/
d1208 8
a1215 2
	d->bd_fbuf = (caddr_t)malloc(d->bd_bufsize, M_DEVBUF, M_WAITOK);
	d->bd_sbuf = (caddr_t)malloc(d->bd_bufsize, M_DEVBUF, M_WAITOK);
@


1.34
log
@When using bpf(4) in immediate mode, and using kevent(2) to receive
notification of packet arrival, the usermode application isn't notified
until a second packet arrives.

This is because KNOTE() calls filt_bpfread() before bd_slen has been
updated with the newly arrived packet length, so it looks like there
is no data there.

Moving the bpf_wakeup() call for immediate mode to after bd_slen is set
fixes it.

From: wayne@@epipe.com.au in pr 3175
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.33 2002/06/06 21:34:16 provos Exp $	*/
d21 1
a21 5
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by the University of
 *	California, Berkeley and its contributors.
 * 4. Neither the name of the University nor the names of its contributors
@


1.33
log
@kqueue support for bpf; okay markus@@
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.32 2002/03/14 03:16:10 millert Exp $	*/
a1165 7
	else if (d->bd_immediate) {
		/*
		 * Immediate mode is set.  A packet arrived so any
		 * reads should be woken up.
		 */
		bpf_wakeup(d);
	}
d1181 8
@


1.32
log
@Final __P removal plus some cosmetic fixups
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.31 2002/03/14 01:27:09 millert Exp $	*/
d91 1
d97 3
d483 1
d973 55
@


1.31
log
@First round of __P removal in sys
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.30 2001/10/02 18:04:35 deraadt Exp $	*/
d92 2
a93 2
void	bpf_catchpacket __P((struct bpf_d *, u_char *, size_t, size_t,
	    void (*)(const void *, void *, size_t)));
@


1.30
log
@change timeval to bpf_timeval; 32 bit in size, permitting much greater portability
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.29 2001/09/15 20:40:46 frantzen Exp $	*/
d82 10
a91 10
int	bpf_allocbufs __P((struct bpf_d *));
void	bpf_freed __P((struct bpf_d *));
void	bpf_ifname __P((struct ifnet *, struct ifreq *));
void	bpf_mcopy __P((const void *, void *, size_t));
int	bpf_movein __P((struct uio *, int, struct mbuf **, struct sockaddr *));
void	bpf_attachd __P((struct bpf_d *, struct bpf_if *));
void	bpf_detachd __P((struct bpf_d *));
int	bpf_setif __P((struct bpf_d *, struct ifreq *));
int	bpfselect __P((dev_t, int, struct proc *));
static __inline void bpf_wakeup __P((struct bpf_d *));
d94 1
a94 1
void	bpf_reset_d __P((struct bpf_d *));
d1067 1
a1067 1
	register void (*cpfn) __P((const void *, void *, size_t));
@


1.30.4.1
log
@Sync UBC branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.30 2001/10/02 18:04:35 deraadt Exp $	*/
d82 13
a94 17
int	bpf_allocbufs(struct bpf_d *);
void	bpf_freed(struct bpf_d *);
void	bpf_ifname(struct ifnet *, struct ifreq *);
void	bpf_mcopy(const void *, void *, size_t);
int	bpf_movein(struct uio *, int, struct mbuf **, struct sockaddr *);
void	bpf_attachd(struct bpf_d *, struct bpf_if *);
void	bpf_detachd(struct bpf_d *);
int	bpf_setif(struct bpf_d *, struct ifreq *);
int	bpfselect(dev_t, int, struct proc *);
int	bpfkqfilter(dev_t, struct knote *);
static __inline void bpf_wakeup(struct bpf_d *);
void	bpf_catchpacket(struct bpf_d *, u_char *, size_t, size_t,
	    void (*)(const void *, void *, size_t));
void	bpf_reset_d(struct bpf_d *);

void	filt_bpfrdetach(struct knote *);
int	filt_bpfread(struct knote *, long);
a478 1
	KNOTE(&d->bd_sel.si_note, 0);
a969 55
struct filterops bpfread_filtops =
	{ 1, NULL, filt_bpfrdetach, filt_bpfread };

int
bpfkqfilter(dev_t dev,struct knote *kn)
{
	struct bpf_d *d = &bpf_dtab[minor(dev)];
	struct klist *klist;
	int s;

	switch (kn->kn_filter) {
	case EVFILT_READ:
		klist = &d->bd_sel.si_note;
		kn->kn_fop = &bpfread_filtops;
		break;
	case EVFILT_WRITE:
	default:
		return (1);
	}

	kn->kn_hook = (caddr_t)((u_long)dev);

	s = splimp();
	SLIST_INSERT_HEAD(klist, kn, kn_selnext);
	splx(s);

	return (0);
}

void
filt_bpfrdetach(struct knote *kn)
{
	dev_t dev = (dev_t)((u_long)kn->kn_hook);
	struct bpf_d *d = &bpf_dtab[minor(dev)];
	int s = splimp();

	SLIST_REMOVE(&d->bd_sel.si_note, kn, knote, kn_selnext);
	splx(s);
}

int
filt_bpfread(struct knote *kn, long hint)
{
	dev_t dev = (dev_t)((u_long)kn->kn_hook);
	struct bpf_d *d = &bpf_dtab[minor(dev)];
	int res, s;

	kn->kn_data = 0;

	s = splimp();
	res = d->bd_hlen != 0 || (d->bd_immediate && d->bd_slen != 0);
	splx(s);
	return (res);
}

d1067 1
a1067 1
	register void (*cpfn)(const void *, void *, size_t);
@


1.30.4.2
log
@sync
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d1166 7
a1187 8

	if (d->bd_immediate) {
		/*
		 * Immediate mode is set.  A packet arrived so any
		 * reads should be woken up.
		 */
		bpf_wakeup(d);
	}
@


1.29
log
@Revert the sleep priority to something more sane
(the previous priority didn't help performance in tests on a hacked
up BPF and it weighed down the load average)
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.28 2001/06/08 04:19:24 angelos Exp $	*/
d1072 2
d1118 3
a1120 1
	microtime(&hp->bh_tstamp);
@


1.28
log
@Move ifpromisc() from bpf.c to if.c, include cleanup.
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.27 2001/05/28 19:51:06 dugsong Exp $	*/
d67 1
a67 1
#define PRINET  6			/* interruptible */
@


1.27
log
@add BIOC[GS]HDRCMPLT ioctl for BPF, to disable overwriting of link level source address in forged frames. from NetBSD. art@@ok
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.26 2001/05/16 12:53:34 ho Exp $	*/
a46 1
#include <sys/systm.h>
a47 1
#include <sys/time.h>
a49 1
#include <sys/user.h>
a50 1
#include <sys/map.h>
a52 1

a53 4
#include <sys/tty.h>
#include <sys/uio.h>

#include <sys/protosw.h>
a54 1
#include <sys/errno.h>
a57 1

a1250 41
}

/* XXX This routine belongs in net/if.c. */
/*
 * Set/clear promiscuous mode on interface ifp based on the truth value
 * of pswitch.  The calls are reference counted so that only the first
 * "on" request actually has an effect, as does the final "off" request.
 * Results are undefined if the "off" and "on" requests are not matched.
 */
int
ifpromisc(ifp, pswitch)
	struct ifnet *ifp;
	int pswitch;
{
	struct ifreq ifr;

	if (pswitch) {
		/*
		 * If the device is not configured up, we cannot put it in
		 * promiscuous mode.
		 */
		if ((ifp->if_flags & IFF_UP) == 0)
			return (ENETDOWN);
		if (ifp->if_pcount++ != 0)
			return (0);
		ifp->if_flags |= IFF_PROMISC;
	} else {
		if (--ifp->if_pcount > 0)
			return (0);
		ifp->if_flags &= ~IFF_PROMISC;
		/*
		 * If the device is not configured up, we should not need to
		 * turn off promiscuous mode (device should have turned it
		 * off when interface went down; and will look at IFF_PROMISC
		 * again next time interface comes up).
		 */
		if ((ifp->if_flags & IFF_UP) == 0)
			return (0);
	}
	ifr.ifr_flags = ifp->if_flags;
	return ((*ifp->if_ioctl)(ifp, SIOCSIFFLAGS, (caddr_t)&ifr));
@


1.26
log
@No need to check M_WAIT/M_WAITOK malloc return values. (art@@ ok)
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.25 2001/04/04 02:39:17 jason Exp $	*/
d521 3
d566 2
d744 8
@


1.25
log
@check for return value of ENODEV from ifpromisc().  This will happen
at detach time when if_detach_ioctl() has been installed for an outgoing
interface and does not represent an error.
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.24 2001/03/25 02:44:42 csapuntz Exp $	*/
a171 2
	if (m == 0)
		return (ENOBUFS);
a1145 3
	if (d->bd_fbuf == 0)
		return (ENOBUFS);

a1146 4
	if (d->bd_sbuf == 0) {
		free(d->bd_fbuf, M_DEVBUF);
		return (ENOBUFS);
	}
@


1.24
log
@Don't set pbp to point to free memory. Thanks to Dawson Engler and team
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.23 2001/03/13 05:09:51 mickey Exp $	*/
d245 1
a245 1
		if (error && error != EINVAL)
@


1.23
log
@allow configuring number of these in ukc
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.22 2000/06/19 03:00:51 jason Exp $	*/
d1254 2
a1255 2
		}
		pbp = &bp->bif_next;
@


1.22
log
@de-#ifdef-ize
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.21 2000/06/08 22:25:24 niklas Exp $	*/
d90 2
a91 1
struct bpf_d	bpf_dtab[NBPFILTER];
d290 5
d299 1
a299 1
		for (i = 0; i < NBPFILTER; ++i)
d317 1
a317 1
	if (minor(dev) >= NBPFILTER)
d1247 1
a1247 1
				for (mn = 0; mn < NBPFILTER; mn++)
@


1.21
log
@Add explicit inclusions of signalvar.h to files actually using syms defined
there but relying on an indirect inclusion
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.21 2000/06/08 21:12:12 niklas Exp $	*/
a58 3
#if defined(sparc) && BSD < 199103
#include <sys/stream.h>
#endif
a75 10
/*
 * Older BSDs don't have kernel malloc.
 */
#if BSD < 199103
extern bcopy();
caddr_t bpf_alloc();
#include <net/bpf_compat.h>
#define BPF_BUFSIZE (MCLBYTES-8)
#define UIOMOVE(cp, len, code, uio) uiomove(cp, len, code, uio)
#else
a76 2
#define UIOMOVE(cp, len, code, uio) uiomove(cp, len, uio)
#endif
a99 1
#if BSD >= 199103
a100 1
#endif
a176 1
#if BSD >= 199103
a178 4
#else
		MCLGET(m);
		if (m->m_len != MCLBYTES) {
#endif
a189 1
#if BSD >= 199103
d191 1
a191 4
#else
		m->m_off += hlen;
#endif
		error = UIOMOVE((caddr_t)sockp->sa_data, hlen, UIO_WRITE, uio);
d195 1
a195 1
	error = UIOMOVE(mtod(m, caddr_t), len - hlen, UIO_WRITE, uio);
a277 1
#if BSD >= 199207 || NetBSD0_9 >= 2
a295 1
#endif
d459 1
a459 1
	error = UIOMOVE(d->bd_hbuf, d->bd_hlen, UIO_READ, uio);
a482 1
#if BSD >= 199103
a485 7
#else
	if (d->bd_selproc) {
		selwakeup(d->bd_selproc, (int)d->bd_selcoll);
		d->bd_selcoll = 0;
		d->bd_selproc = 0;
	}
#endif
a517 1
#if BSD >= 199103
a518 3
#else
	error = (*ifp->if_output)(ifp, m, &dst);
#endif
a605 3
#if BSD < 199103
		error = EINVAL;
#else
a616 1
#endif
a921 23
 * The new select interface passes down the proc pointer; the old select
 * stubs had to grab it out of the user struct.  This glue allows either case.
 */
#if BSD >= 199103
#define bpf_select bpfselect
#else
int
bpfselect(dev, rw)
	register dev_t dev;
	int rw;
{
	/*
	 * if there isn't data waiting, and there's a timeout,
	 * mark the time we started waiting.
	 */
	if (b->db_rtout != -1 && (d->bd_rdStart == 0))
		d->bd_rdStart = ticks;
			    
	return (bpf_select(dev, rw, u.u_procp));
}
#endif

/*
d928 1
a928 1
bpf_select(dev, rw, p)
a958 1
#if BSD >= 199103
a959 13
#else
	/*
	 * No data ready.  If there's already a select() waiting on this
	 * minor device then this is a collision.  This shouldn't happen
	 * because minors really should not be shared, but if a process
	 * forks while one of these is open, it is possible that both
	 * processes could select on the same descriptor.
	 */
	if (d->bd_selproc && d->bd_selproc->p_wchan == (caddr_t)&selwait)
		d->bd_selcoll = 1;
	else
		d->bd_selproc = p;
#endif
a1109 1
#if BSD >= 199103
a1110 5
#elif defined(sun)
	uniqtime(&hp->bh_tstamp);
#else
	hp->bh_tstamp = time;
#endif
d1193 1
a1193 3
#if BSD < 199103
	static struct bpf_if bpf_ifs[NBPFILTER];
	static int bpfifno;
a1194 4
	bp = (bpfifno < NBPFILTER) ? &bpf_ifs[bpfifno++] : 0;
#else
	bp = (struct bpf_if *)malloc(sizeof(*bp), M_DEVBUF, M_DONTWAIT);
#endif
a1214 4

#if 0
	printf("bpf: %s attached\n", ifp->if_xname);
#endif
a1246 6
#if BSD < 199103
			if (bp == &bpf_ifs[bpfifno - 1])
				bpfifno--;
			else
				printf("bpfdetach: leaked one bpf\n");
#else
a1247 1
#endif
a1253 1
#if BSD >= 199103
a1293 32
#endif

#if BSD < 199103
/*
 * Allocate some memory for bpf.  This is temporary SunOS support, and
 * is admittedly a hack.
 * If resources unavaiable, return 0.
 */
caddr_t
bpf_alloc(size, canwait)
	register int size;
	register int canwait;
{
	register struct mbuf *m;

	if ((unsigned)size > (MCLBYTES-8))
		return 0;

	MGET(m, canwait, MT_DATA);
	if (m == 0)
		return 0;
	if ((unsigned)size > (MLEN-8)) {
		MCLGET(m);
		if (m->m_len != MCLBYTES) {
			m_freem(m);
			return 0;
		}
	}
	*mtod(m, struct mbuf **) = m;
	return mtod(m, caddr_t) + 8;
}
#endif
@


1.20
log
@Remove code from the stone age.
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.19 2000/02/19 08:59:04 niklas Exp $	*/
d51 1
@


1.19
log
@set interface fields to null when detaching substructures
in preparation for softc retainment.
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.18 1999/08/10 02:42:30 deraadt Exp $	*/
a380 39
 * Support for SunOS, which does not have tsleep.
 */
#if BSD < 199103
int
bpf_timeout(arg)
	caddr_t arg;
{
	struct bpf_d *d = (struct bpf_d *)arg;
	d->bd_timedout = 1;
	wakeup(arg);
}

#define BPF_SLEEP(chan, pri, s, t) bpf_sleep((struct bpf_d *)chan)

int
bpf_sleep(d)
	register struct bpf_d *d;
{
	register int rto = d->bd_rtout;
	register int st;

	if (rto != 0) {
		d->bd_timedout = 0;
		timeout(bpf_timeout, (caddr_t)d, rto);
	}
	st = sleep((caddr_t)d, PRINET|PCATCH);
	if (rto != 0) {
		if (d->bd_timedout == 0)
			untimeout(bpf_timeout, (caddr_t)d);
		else if (st == 0)
			return EWOULDBLOCK;
	}
	return (st != 0) ? EINTR : 0;
}
#else
#define BPF_SLEEP tsleep
#endif

/*
d441 1
a441 1
			error = BPF_SLEEP((caddr_t)d, PRINET|PCATCH, "bpf",
@


1.18
log
@code we do not use, had a typo; sirsyko@@temp.ishiboo.com
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.17 1999/08/08 00:43:00 niklas Exp $	*/
d1393 1
@


1.18.4.1
log
@Merge in recent code from the trunk
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.19 2000/02/19 08:59:04 niklas Exp $	*/
a1392 1
	ifp->if_bpf = NULL;
@


1.18.4.2
log
@Sync with -current
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d381 39
d480 1
a480 1
			error = tsleep((caddr_t)d, PRINET|PCATCH, "bpf",
@


1.18.4.3
log
@merge in approximately 2.9 into SMP branch
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.25 2001/04/04 02:39:17 jason Exp $	*/
a50 1
#include <sys/signalvar.h>
d58 3
d78 10
d89 2
d104 1
a104 2
struct bpf_d	*bpf_dtab;
int nbpfilter;
d114 1
d116 1
d193 1
d196 4
d211 1
d213 4
a216 1
		error = uiomove((caddr_t)sockp->sa_data, hlen, uio);
d220 1
a220 1
	error = uiomove(mtod(m, caddr_t), len - hlen, uio);
d269 1
a269 1
		if (error && !(error == EINVAL || error == ENODEV))
d303 1
a314 5
	bpf_dtab = malloc(n * sizeof(*bpf_dtab), M_DEVBUF, M_NOWAIT);
	if (!bpf_dtab)
		return;
	nbpfilter = n;
	bzero(bpf_dtab, n * sizeof(*bpf_dtab));
d319 1
a319 1
		for (i = 0; i < nbpfilter; ++i)
d322 1
d338 1
a338 1
	if (minor(dev) >= nbpfilter)
d486 1
a486 1
	error = uiomove(d->bd_hbuf, d->bd_hlen, uio);
d510 1
d514 7
d553 1
d555 3
d645 3
d659 1
d965 23
d994 1
a994 1
bpfselect(dev, rw, p)
d1025 1
d1027 13
d1190 1
d1192 5
d1279 6
d1286 1
a1286 1

d1307 4
d1337 1
a1337 1
				for (mn = 0; mn < nbpfilter; mn++)
d1343 6
d1350 3
a1352 2
		} else
			pbp = &bp->bif_next;
d1357 1
d1398 32
@


1.18.4.4
log
@Merge in -current from two days ago in the SMP branch.
As usual with merges, they do not indicate progress, so do not hold
your breath for working SMP, and do not mail me and ask about the
state of it.  It has not changed.  There is work ongoing, but very, very
slowly.  The commit is done in parts as to not lock up the tree in too
big chunks at a time.
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.18.4.3 2001/05/14 22:39:58 niklas Exp $	*/
d47 1
d49 1
d52 1
d54 1
d57 1
d59 4
d64 1
d68 1
d172 2
a522 3
	if (d->bd_hdrcmplt)
		dst.sa_family = pseudo_AF_HDRCMPLT;

a564 2
 *  BIOCGHDRCMPLT	Get "header already complete" flag
 *  BIOCSHDRCMPLT	Set "header already complete" flag
a741 8
	case BIOCGHDRCMPLT:	/* get "header already complete" flag */
		*(u_int *)addr = d->bd_hdrcmplt;
		break;

	case BIOCSHDRCMPLT:	/* set "header already complete" flag */
		d->bd_hdrcmplt = *(u_int *)addr ? 1 : 0;
		break;

d1148 3
d1152 4
d1258 41
@


1.18.4.5
log
@Sync the SMP branch to something just after 3.0
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.18.4.4 2001/07/04 10:53:50 niklas Exp $	*/
d67 1
a67 1
#define PRINET  26			/* interruptible */
a1071 2
	struct timeval tv;

d1116 1
a1116 3
	microtime(&tv);
	hp->bh_tstamp.tv_sec = tv.tv_sec;
	hp->bh_tstamp.tv_usec = tv.tv_usec;
@


1.18.4.6
log
@Merge in -current from roughly a week ago
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
d82 13
a94 13
int	bpf_allocbufs(struct bpf_d *);
void	bpf_freed(struct bpf_d *);
void	bpf_ifname(struct ifnet *, struct ifreq *);
void	bpf_mcopy(const void *, void *, size_t);
int	bpf_movein(struct uio *, int, struct mbuf **, struct sockaddr *);
void	bpf_attachd(struct bpf_d *, struct bpf_if *);
void	bpf_detachd(struct bpf_d *);
int	bpf_setif(struct bpf_d *, struct ifreq *);
int	bpfselect(dev_t, int, struct proc *);
static __inline void bpf_wakeup(struct bpf_d *);
void	bpf_catchpacket(struct bpf_d *, u_char *, size_t, size_t,
	    void (*)(const void *, void *, size_t));
void	bpf_reset_d(struct bpf_d *);
d1067 1
a1067 1
	register void (*cpfn)(const void *, void *, size_t);
@


1.18.4.7
log
@Sync the SMP branch with 3.3
@
text
@a90 1
int	bpfkqfilter(dev_t, struct knote *);
a95 3
void	filt_bpfrdetach(struct knote *);
int	filt_bpfread(struct knote *, long);

a478 1
	KNOTE(&d->bd_sel.si_note, 0);
a967 55
}

struct filterops bpfread_filtops =
	{ 1, NULL, filt_bpfrdetach, filt_bpfread };

int
bpfkqfilter(dev_t dev,struct knote *kn)
{
	struct bpf_d *d = &bpf_dtab[minor(dev)];
	struct klist *klist;
	int s;

	switch (kn->kn_filter) {
	case EVFILT_READ:
		klist = &d->bd_sel.si_note;
		kn->kn_fop = &bpfread_filtops;
		break;
	case EVFILT_WRITE:
	default:
		return (1);
	}

	kn->kn_hook = (caddr_t)((u_long)dev);

	s = splimp();
	SLIST_INSERT_HEAD(klist, kn, kn_selnext);
	splx(s);

	return (0);
}

void
filt_bpfrdetach(struct knote *kn)
{
	dev_t dev = (dev_t)((u_long)kn->kn_hook);
	struct bpf_d *d = &bpf_dtab[minor(dev)];
	int s = splimp();

	SLIST_REMOVE(&d->bd_sel.si_note, kn, knote, kn_selnext);
	splx(s);
}

int
filt_bpfread(struct knote *kn, long hint)
{
	dev_t dev = (dev_t)((u_long)kn->kn_hook);
	struct bpf_d *d = &bpf_dtab[minor(dev)];
	int res, s;

	kn->kn_data = 0;

	s = splimp();
	res = d->bd_hlen != 0 || (d->bd_immediate && d->bd_slen != 0);
	splx(s);
	return (res);
@


1.18.4.8
log
@Sync the SMP branch to -current. This includes moving to ELF.
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.18.4.7 2003/03/28 00:41:28 niklas Exp $	*/
d1166 7
a1187 8

	if (d->bd_immediate) {
		/*
		 * Immediate mode is set.  A packet arrived so any
		 * reads should be woken up.
		 */
		bpf_wakeup(d);
	}
@


1.18.4.9
log
@Sync SMP branch to -current
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.18.4.8 2003/05/13 19:36:14 ho Exp $	*/
d21 5
a25 1
 * 3. Neither the name of the University nor the names of its contributors
@


1.18.4.10
log
@Merge of current from two weeks agointo the SMP branch
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
a50 1
#include <sys/poll.h>
d61 1
a61 1
#define BPF_BUFSIZE 9216	/* 8192 too small for ATM frames */
d82 1
a82 2
int	bpf_movein(struct uio *, int, struct mbuf **,
	    struct sockaddr *, struct bpf_insn *);
d86 1
a86 1
int	bpfpoll(dev_t, int, struct proc *);
d97 2
a98 2
bpf_movein(uio, linktype, mp, sockp, filter)
	struct uio *uio;
d100 2
a101 3
	struct mbuf **mp;
	struct sockaddr *sockp;
	struct bpf_insn *filter;
d105 2
a106 3
	u_int hlen;
	u_int len;
	u_int slen;
a151 10
	case DLT_ATM_RFC1483:
		/*
		 * en atm driver requires 4-byte atm pseudo header.
		 * though it isn't standard, vpi:vci needs to be
		 * specified anyway.
		 */
		sockp->sa_family = AF_UNSPEC;
		hlen = 12; 	/* XXX 4(ATM_PH) + 3(LLC) + 5(SNAP) */
		break;

d157 1
a157 1
	if (len > MCLBYTES)
a172 15

	error = uiomove(mtod(m, caddr_t), len, uio);
	if (error)
		goto bad;

	slen = bpf_filter(filter, mtod(m, u_char *), len, len);
	if (slen < len) {
		error = EPERM;
		goto bad;
	}

	if (m->m_len < hlen) {
		error = EPERM;
		goto bad;
	}
d174 1
a174 1
	 * Make room for link header, and copy it to sockaddr
a176 1
		bcopy(m->m_data, sockp->sa_data, hlen);
d179 3
d183 3
a185 2

	return (0);
d302 1
a302 1
	struct bpf_d *d;
d334 2
a335 2
	struct bpf_d *d = &bpf_dtab[minor(dev)];
	int s;
d363 1
a363 1
	struct uio *uio;
d366 1
a366 1
	struct bpf_d *d = &bpf_dtab[minor(dev)];
d469 1
a469 1
	struct bpf_d *d;
d488 1
a488 1
	struct bpf_d *d = &bpf_dtab[minor(dev)];
d492 1
a492 1
	struct sockaddr_storage dst;
d502 1
a502 2
	error = bpf_movein(uio, (int)d->bd_bif->bif_dlt, &m,
	    (struct sockaddr *)&dst, d->bd_wfilter);
d512 1
a512 1
		dst.ss_family = pseudo_AF_HDRCMPLT;
d515 1
a515 2
	error = (*ifp->if_output)(ifp, m, (struct sockaddr *)&dst,
	    (struct rtentry *)0);
d568 1
a568 1
	struct bpf_d *d = &bpf_dtab[minor(dev)];
a570 23
	if (d->bd_locked && suser(p, 0) != 0) {
		/* list of allowed ioctls when locked and not root */
		switch (cmd) {
		case BIOCGBLEN:
		case BIOCFLUSH:
		case BIOCGDLT:
		case BIOCGETIF:
		case BIOCGRTIMEOUT:
		case BIOCGSTATS:
		case BIOCVERSION:
		case BIOCGRSIG:
		case BIOCGHDRCMPLT:
		case FIONREAD:
		case BIOCLOCK:
		case BIOCSRTIMEOUT:
		case BIOCIMMEDIATE:
		case TIOCGPGRP:
			break;
		default:
			return (EPERM);
		}
	}

d608 1
a608 1
			u_int size = *(u_int *)addr;
d622 1
a622 8
		error = bpf_setf(d, (struct bpf_program *)addr, 0);
		break;

	/*
	 * Set link layer write filter.
	 */
	case BIOCSETWF:
		error = bpf_setf(d, (struct bpf_program *)addr, 1);
a742 3
	case BIOCLOCK:		/* set "locked" flag (no reset) */
		d->bd_locked = 1;
		break;
d797 1
a797 1
bpf_setf(d, fp, wf)
a799 1
	int wf;
d805 1
a805 1
	old = wf ? d->bd_wfilter : d->bd_rfilter;
d810 1
a810 4
		if (wf)
			d->bd_wfilter = 0;
		else
			d->bd_rfilter = 0;
d826 1
a826 4
		if (wf)
			d->bd_wfilter = fcode;
		else
			d->bd_rfilter = fcode;
d929 4
a932 1
 * Support for poll() system call
d935 3
a937 3
bpfpoll(dev, events, p)
	dev_t dev;
	int events;
d940 2
a941 6
	struct bpf_d *d;
	int s, revents;

	revents = events & (POLLIN | POLLRDNORM);
	if (revents == 0)
		return (0);		/* only support reading */
d943 2
d949 1
d951 1
a951 2
	if (d->bd_hlen == 0 && (!d->bd_immediate || d->bd_slen == 0)) {
		revents = 0;		/* no data waiting */
d953 1
a953 1
		 * if there's a timeout, mark the time we started waiting.
d955 2
a956 3
		if (d->bd_rtout != -1 && d->bd_rdStart == 0)
			d->bd_rdStart = ticks;
		selrecord(p, &d->bd_sel);
d958 9
d968 1
a968 1
	return (revents);
d1035 2
a1036 2
	u_char *pkt;
	u_int pktlen;
d1039 2
a1040 2
	struct bpf_d *d;
	size_t slen;
d1049 1
a1049 1
		slen = bpf_filter(d->bd_rfilter, pkt, pktlen, pktlen);
d1063 1
a1063 1
	size_t len;
d1065 2
a1066 2
	const struct mbuf *m;
	u_int count;
d1104 1
a1104 1
		slen = bpf_filter(d->bd_rfilter, (u_char *)m, pktlen, 0);
d1120 8
a1127 8
	struct bpf_d *d;
	u_char *pkt;
	size_t pktlen, snaplen;
	void (*cpfn)(const void *, void *, size_t);
{
	struct bpf_hdr *hp;
	int totlen, curlen;
	int hdrlen = d->bd_bif->bif_hdrlen;
d1206 1
a1206 1
	struct bpf_d *d;
d1208 2
a1209 8
	d->bd_fbuf = (caddr_t)malloc(d->bd_bufsize, M_DEVBUF, M_NOWAIT);
	if (d->bd_fbuf == NULL)
		return (ENOBUFS);
	d->bd_sbuf = (caddr_t)malloc(d->bd_bufsize, M_DEVBUF, M_NOWAIT);
	if (d->bd_sbuf == NULL) {
		free(d->bd_fbuf, M_DEVBUF);
		return (ENOBUFS);
	}
d1221 1
a1221 1
	struct bpf_d *d;
d1235 2
a1236 4
	if (d->bd_rfilter)
		free((caddr_t)d->bd_rfilter, M_DEVBUF);
	if (d->bd_wfilter)
		free((caddr_t)d->bd_wfilter, M_DEVBUF);
@


1.18.4.11
log
@Merge with the trunk
@
text
@a52 1
#include <sys/sysctl.h>
d62 1
a62 1
#define BPF_BUFSIZE 32768
a69 1
int bpf_maxbufsize = BPF_MAXBUFSIZE;
d73 1
a73 1
 *  bpf_d_list is the list of descriptors
d76 2
a77 1
LIST_HEAD(, bpf_d) bpf_d_list;
a97 4
struct bpf_d *bpfilter_lookup(int);
struct bpf_d *bpfilter_create(int);
void bpfilter_destroy(struct bpf_d *);

a292 6
 * Reference count access to descriptor buffers
 */
#define D_GET(d) ((d)->bd_ref++)
#define D_PUT(d) bpf_freed(d)

/*
d301 13
a313 1
	LIST_INIT(&bpf_d_list);
d330 1
a330 2
	/* create on demand */
	if ((d = bpfilter_create(minor(dev))) == NULL)
d336 1
d341 1
a344 2
	D_GET(d);

d360 1
a360 1
	struct bpf_d *d;
a362 1
	d = bpfilter_lookup(minor(dev));
a365 2
	bpf_wakeup(d);
	D_PUT(d);
d367 1
d392 1
a392 1
	struct bpf_d *d;
a395 1
	d = bpfilter_lookup(minor(dev));
a407 2
	D_GET(d);
	
a422 10
		if (d->bd_bif == NULL) {
			/* interface is gone */
			if (d->bd_slen == 0) {
				D_PUT(d);
				splx(s);
				return (EIO);
			}
			ROTATE_BUFFERS(d);
			break;
		}
a442 1
			D_PUT(d);
a460 1
				D_PUT(d);
a483 2

	D_PUT(d);
d514 1
a514 1
	struct bpf_d *d;
a519 1
	d = bpfilter_lookup(minor(dev));
d596 1
a596 1
	struct bpf_d *d;
a598 1
	d = bpfilter_lookup(minor(dev));
d661 2
a662 2
			if (size > bpf_maxbufsize)
				*(u_int *)addr = size = bpf_maxbufsize;
d917 25
a941 1
	int s, error;
d1015 1
a1015 1
	d = bpfilter_lookup(minor(dev));
d1036 1
a1036 1
	struct bpf_d *d;
a1039 1
	d = bpfilter_lookup(minor(dev));
d1063 1
a1063 1
	struct bpf_d *d;
a1065 1
	d = bpfilter_lookup(minor(dev));
d1074 1
a1074 1
	struct bpf_d *d;
a1078 1
	d = bpfilter_lookup(minor(dev));
d1281 2
a1282 2
 * Free buffers currently in use by a descriptor
 * when the reference count drops to zero.
d1288 5
a1292 3
	if (--d->bd_ref > 0)
		return;

d1305 1
a1305 1
	bpfilter_destroy(d);
d1351 1
a1351 1
	int maj;
d1363 1
a1363 3
			for (bd = bp->bif_dlist; bd; bd = bp->bif_dlist) {
				struct bpf_d *d;

d1368 3
a1370 4
				LIST_FOREACH(d, &bpf_d_list, bd_list)
					if (d == bd) {
						vdevgone(maj, d->bd_unit,
						    d->bd_unit, VCHR);
a1372 1
			}
a1378 69
}

int
bpf_sysctl(int *name, u_int namelen, void *oldp, size_t *oldlenp, void *newp,
    size_t newlen)
{
	int newval;
	int error;

	if (namelen != 1)
		return (ENOTDIR);

	switch (name[0]) {
	case NET_BPF_BUFSIZE:
		newval = bpf_bufsize;
		error = sysctl_int(oldp, oldlenp, newp, newlen, &newval);
		if (error)
			return (error);
		if (newval < BPF_MINBUFSIZE || newval > bpf_maxbufsize)
			return (EINVAL);
		bpf_bufsize = newval;
		break;
	case NET_BPF_MAXBUFSIZE:
		newval = bpf_maxbufsize;
		error = sysctl_int(oldp, oldlenp, newp, newlen, &newval);
		if (error)
			return (error);
		if (newval < BPF_MINBUFSIZE)
			return (EINVAL);
		bpf_maxbufsize = newval;
		break;
	default:
		return (EOPNOTSUPP);
	}
	return (0);
}

struct bpf_d *
bpfilter_lookup(int unit)
{
	struct bpf_d *bd;

	LIST_FOREACH(bd, &bpf_d_list, bd_list)
		if (bd->bd_unit == unit)
			return (bd);
	return (NULL);
}

struct bpf_d *
bpfilter_create(int unit)
{
	struct bpf_d *bd;

	if ((bd = bpfilter_lookup(unit)) != NULL)
		return (bd);
	if ((bd = malloc(sizeof(*bd), M_DEVBUF, M_NOWAIT)) != NULL) {
		bzero(bd, sizeof(*bd));
		bd->bd_unit = unit;
		D_MARKFREE(bd);
		LIST_INSERT_HEAD(&bpf_d_list, bd, bd_list);
	}
	return (bd);
}

void
bpfilter_destroy(struct bpf_d *bd)
{
	LIST_REMOVE(bd, bd_list);
	free(bd, M_DEVBUF);
@


1.17
log
@Support detaching of network interfaces.  Still work to do in ipf, and
other families than inet.
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.16 1999/05/26 19:26:11 brad Exp $	*/
d1019 1
a1019 1
	if (b->db_rtout != -1 && (d->bd_rdStart == 0)
@


1.16
log
@Implement DLT_RAW, DLT_{SLIP,PPP}_BSDOS from libpcap 0.4
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.15 1999/04/22 20:02:42 art Exp $	*/
d55 1
d1350 43
@


1.15
log
@we don't need to include buf.h
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.14 1998/11/12 16:35:02 deraadt Exp $	*/
d171 1
@


1.14
log
@crank BPF_BUFSIZE so that fddi frames fit
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.13 1998/06/26 09:13:10 deraadt Exp $	*/
a48 1
#include <sys/buf.h>
@


1.13
log
@fix bpf select(); from mts@@rare.net
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.12 1997/09/30 02:31:04 millert Exp $	*/
d88 1
a88 1
#define BPF_BUFSIZE 4096
@


1.12
log
@Check for NULL argument in bpf_mtap().  Some ethernet drivers
can call this with a NULL pointer, resulting in a panic.
Matthias Scheler <tron@@lyssa.owl.de>
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.11 1997/09/05 20:17:30 deraadt Exp $	*/
d92 1
a92 1
#define PRINET  26			/* interruptible */
d453 10
d478 1
a478 1
		if (d->bd_rtout != -1)
d480 8
a487 3
					  d->bd_rtout);
		else
			error = EWOULDBLOCK; /* User requested non-blocking I/O */
d1014 7
d1055 8
d1216 1
a1216 1
	else if (d->bd_immediate)
d1222 1
d1242 14
@


1.11
log
@make bpfread return ENXIO if a read is attempted on an uninitialized
descriptor; newsham@@secnet.com
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.10 1997/08/31 20:42:29 deraadt Exp $	*/
d1120 3
@


1.10
log
@for non-tty TIOCSPGRP/F_SETOWN/FIOSETOWN pgid setting calls, store uid
and euid as well, then deliver them using new csignal() interface
which ensures that pgid setting process is permitted to signal the
pgid process(es). Thanks to newsham@@aloha.net for extensive help and
discussion.
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.9 1997/03/17 16:29:37 niklas Exp $	*/
d441 3
@


1.9
log
@Removed static specifiers.  Align bpf headers on sizeof(long) boundaries
as it begins with a timeval struct.  This fixes the alpha bpf panics.
Removed double prototypes.  Reordered includes.  The last change came from
NetBSD.  Updated $NetBSD$ tags.  Slight KNF too.
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.8 1997/02/12 03:35:11 deraadt Exp $	*/
a524 2
	struct proc *p;

d527 2
a528 4
		if (d->bd_pgid > 0)
			gsignal (d->bd_pgid, d->bd_sig);
		else if ((p = pfind (-d->bd_pgid)) != NULL)
			psignal (p, d->bd_sig);
d821 2
@


1.8
log
@mark descriptors free in bpfilterattach() instead of bpfattach(); clearly
must not re-marking them when new interfaces are added while one or more
bpf channels are in use; my fix to netbsd pr#3189, Jean-Luc.Richier@@imag.fr
@
text
@d1 2
a2 2
/*	$OpenBSD: bpf.c,v 1.7 1997/01/27 23:21:18 deraadt Exp $	*/
/*	$NetBSD: bpf.c,v 1.27 1996/05/07 05:26:02 thorpej Exp $	*/
d66 3
a73 2
#include <sys/errno.h>

a76 1
#include <sys/kernel.h>
d83 1
a83 1
static caddr_t bpf_alloc();
d106 8
a113 13
static int	bpf_allocbufs __P((struct bpf_d *));
static int	bpf_allocbufs __P((struct bpf_d *));
static void	bpf_freed __P((struct bpf_d *));
static void	bpf_freed __P((struct bpf_d *));
static void	bpf_ifname __P((struct ifnet *, struct ifreq *));
static void	bpf_ifname __P((struct ifnet *, struct ifreq *));
static void	bpf_mcopy __P((const void *, void *, size_t));
static int	bpf_movein __P((struct uio *, int,
			        struct mbuf **, struct sockaddr *));
static void	bpf_attachd __P((struct bpf_d *, struct bpf_if *));
static void	bpf_detachd __P((struct bpf_d *));
static int	bpf_setif __P((struct bpf_d *, struct ifreq *));
static int	bpf_setif __P((struct bpf_d *, struct ifreq *));
d115 1
a115 1
int		bpfselect __P((dev_t, int, struct proc *));
d117 4
a120 5
static __inline void
		bpf_wakeup __P((struct bpf_d *));
static void	catchpacket __P((struct bpf_d *, u_char *, size_t, size_t,
				 void (*)(const void *, void *, size_t)));
static void	reset_d __P((struct bpf_d *));
d122 1
a122 1
static int
d231 1
a231 1
static void
d251 1
a251 1
static void
d383 1
a383 1
static
d593 2
a594 2
static void
reset_d(d)
d698 1
a698 1
		reset_d(d);
d869 1
a869 1
		reset_d(d);
d885 1
a885 1
		reset_d(d);
d901 1
a901 1
static int
d967 1
a967 1
		reset_d(d);
d978 1
a978 1
static void
a982 1

d1076 1
a1076 1
			catchpacket(d, pkt, pktlen, slen, bcopy);
d1084 1
a1084 1
static void
d1128 1
a1128 1
			catchpacket(d, (u_char *)m, pktlen, slen, bpf_mcopy);
d1140 2
a1141 2
static void
catchpacket(d, pkt, pktlen, snaplen, cpfn)
d1212 1
a1212 1
static int
d1234 1
a1234 1
static void
d1351 1
a1351 1
static caddr_t
@


1.7
log
@select subsystem si_pid becomes si_selpid, to not conflict against user/kernel siginfo si_pid #define
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.6 1996/12/07 09:17:46 deraadt Exp $	*/
a105 13
#if BSD >= 199207 || NetBSD0_9 >= 2
/*
 * bpfilterattach() is called at boot time in new systems.  We do
 * nothing here since old systems will not call this.
 */
/* ARGSUSED */
void
bpfilterattach(n)
	int n;
{
}
#endif

d308 21
a1274 1
	int i;
a1302 7

	/*
	 * Mark all the descriptors free if this hasn't been done.
	 */
	if (!D_ISFREE(&bpf_dtab[0]))
		for (i = 0; i < NBPFILTER; ++i)
			D_MARKFREE(&bpf_dtab[i]);
@


1.6
log
@avoid race, avoid mbuf leak
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.5 1996/06/18 16:12:17 deraadt Exp $	*/
d535 1
a535 1
	d->bd_sel.si_pid = 0;
@


1.5
log
@bpf BIOCSRTIMEOUT can round tv_usec down to zero & block; netbsd pr#2531; jhawk@@mit.edu
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.4 1996/05/10 12:31:05 deraadt Exp $	*/
d555 1
a555 1
	static struct sockaddr dst;
d569 2
a570 1
	if (m->m_pkthdr.len > ifp->if_mtu)
d572 1
@


1.4
log
@if_name/if_unit -> if_xname/if_softc
@
text
@d1 1
a1 1
/*	$OpenBSD: bpf.c,v 1.2 1996/03/03 21:07:00 niklas Exp $	*/
d754 2
@


1.3
log
@partial sync with netbsd 960418, more to come
@
text
@d2 1
a2 1
/*	$NetBSD: bpf.c,v 1.25 1996/03/30 21:57:30 christos Exp $	*/
d902 1
a902 1
	int unit, s, error;
d905 3
a907 4
	 * Separate string into name part and unit number.  Put a null
	 * byte at the end of the name part, and compute the number.
	 * If the a unit number is unspecified, the default is 0,
	 * as initialized above.  XXX This should be common code.
d909 1
a909 1
	unit = 0;
d911 13
a923 8
	cp[sizeof(ifr->ifr_name) - 1] = '\0';
	while (*cp++) {
		if (*cp >= '0' && *cp <= '9') {
			unit = *cp - '0';
			*cp++ = '\0';
			while (*cp)
				unit = 10 * unit + *cp++ - '0';
			break;
d926 1
d933 2
a934 2
		if (ifp == 0 || unit != ifp->if_unit
		    || strcmp(ifp->if_name, ifr->ifr_name) != 0)
d970 1
a970 2
 * Convert an interface name plus unit number of an ifp to a single
 * name which is returned in the ifr.
a976 2
	char *s = ifp->if_name;
	char *d = ifr->ifr_name;
d978 1
a978 3
	while ((*d++ = *s++) != '\0')
		continue;
	sprintf(d, "%d", ifp->if_unit);
d1301 1
a1301 1
	printf("bpf: %s%d attached\n", ifp->if_name, ifp->if_unit);
@


1.2
log
@From NetBSD: 960217 merge
@
text
@d1 2
a2 2
/*	$OpenBSD$	*/
/*	$NetBSD: bpf.c,v 1.24 1996/02/13 21:59:53 christos Exp $	*/
d55 1
a69 1
#include <net/net_conf.h>
@


1.1
log
@Initial revision
@
text
@d1 2
a2 1
/*	$NetBSD: bpf.c,v 1.23 1995/09/27 18:30:37 thorpej Exp $	*/
d69 1
d127 3
a129 1
		    struct mbuf **, struct sockaddr *));
d132 3
d137 2
a138 2
static void	catchpacket __P((struct bpf_d *, u_char *, size_t,
		    size_t, void (*)(const void *, void *, size_t)));
d327 1
a327 1
bpfopen(dev, flag)
d330 2
d359 1
a359 1
bpfclose(dev, flag)
d362 2
d431 1
a431 1
bpfread(dev, uio)
d434 1
d529 1
a529 1
		else if (p = pfind (-d->bd_pgid))
d546 1
a546 1
bpfwrite(dev, uio)
d549 1
d621 1
a621 1
bpfioctl(dev, cmd, addr, flag)
d626 1
d976 1
a976 1
	while (*d++ = *s++)
d978 1
a978 3
	/* XXX Assume that unit number is less than 10. */
	*d++ = ifp->if_unit + '0';
	*d = '\0';
@


1.1.1.1
log
@initial import of NetBSD tree
@
text
@@
