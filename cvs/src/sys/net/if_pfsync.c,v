head	1.246;
access;
symbols
	OPENBSD_6_1:1.246.0.2
	OPENBSD_6_1_BASE:1.246
	OPENBSD_6_0:1.229.0.4
	OPENBSD_6_0_BASE:1.229
	OPENBSD_5_9:1.227.0.2
	OPENBSD_5_9_BASE:1.227
	OPENBSD_5_8:1.219.0.4
	OPENBSD_5_8_BASE:1.219
	OPENBSD_5_7:1.217.0.2
	OPENBSD_5_7_BASE:1.217
	OPENBSD_5_6:1.208.0.4
	OPENBSD_5_6_BASE:1.208
	OPENBSD_5_5:1.204.0.4
	OPENBSD_5_5_BASE:1.204
	OPENBSD_5_4:1.200.0.2
	OPENBSD_5_4_BASE:1.200
	OPENBSD_5_3:1.195.0.2
	OPENBSD_5_3_BASE:1.195
	OPENBSD_5_2:1.188.0.2
	OPENBSD_5_2_BASE:1.188
	OPENBSD_5_1_BASE:1.181
	OPENBSD_5_1:1.181.0.2
	OPENBSD_5_0:1.167.0.2
	OPENBSD_5_0_BASE:1.167
	OPENBSD_4_9:1.161.0.2
	OPENBSD_4_9_BASE:1.161
	OPENBSD_4_8:1.154.0.2
	OPENBSD_4_8_BASE:1.154
	OPENBSD_4_7:1.143.0.2
	OPENBSD_4_7_BASE:1.143
	OPENBSD_4_6:1.127.0.4
	OPENBSD_4_6_BASE:1.127
	OPENBSD_4_5:1.112.0.2
	OPENBSD_4_5_BASE:1.112
	OPENBSD_4_4:1.98.0.2
	OPENBSD_4_4_BASE:1.98
	OPENBSD_4_3:1.89.0.2
	OPENBSD_4_3_BASE:1.89
	OPENBSD_4_2:1.83.0.2
	OPENBSD_4_2_BASE:1.83
	OPENBSD_4_1:1.73.0.2
	OPENBSD_4_1_BASE:1.73
	OPENBSD_4_0:1.66.0.2
	OPENBSD_4_0_BASE:1.66
	OPENBSD_3_9:1.60.0.2
	OPENBSD_3_9_BASE:1.60
	OPENBSD_3_8:1.54.0.2
	OPENBSD_3_8_BASE:1.54
	OPENBSD_3_7:1.46.0.2
	OPENBSD_3_7_BASE:1.46
	OPENBSD_3_6:1.37.0.2
	OPENBSD_3_6_BASE:1.37
	SMP_SYNC_A:1.34
	SMP_SYNC_B:1.34
	OPENBSD_3_5:1.26.0.2
	OPENBSD_3_5_BASE:1.26
	OPENBSD_3_4:1.6.0.2
	OPENBSD_3_4_BASE:1.6
	UBC:1.5.0.2
	UBC_SYNC_A:1.5
	SMP:1.4.0.4
	OPENBSD_3_3:1.4.0.2
	OPENBSD_3_3_BASE:1.4;
locks; strict;
comment	@ * @;


1.246
date	2017.03.11.13.21.16;	author stsp;	state Exp;
branches;
next	1.245;
commitid	JCKUbx4bqMLhCfSO;

1.245
date	2017.02.20.06.30.39;	author jca;	state Exp;
branches;
next	1.244;
commitid	kEYANVo5IvTssoQm;

1.244
date	2017.01.29.19.58.47;	author bluhm;	state Exp;
branches;
next	1.243;
commitid	3e3CkrbYekyVOcxy;

1.243
date	2017.01.25.17.34.31;	author bluhm;	state Exp;
branches;
next	1.242;
commitid	pVtptbHA3yk4jSpN;

1.242
date	2017.01.23.11.37.29;	author mpi;	state Exp;
branches;
next	1.241;
commitid	F6oNrr9LCLUSAxgA;

1.241
date	2017.01.20.03.56.46;	author mpi;	state Exp;
branches;
next	1.240;
commitid	GrrFK5deVzhlmoXf;

1.240
date	2017.01.20.00.51.56;	author mpi;	state Exp;
branches;
next	1.239;
commitid	ASQosbhukUA3DGlR;

1.239
date	2016.12.19.15.46.28;	author mpi;	state Exp;
branches;
next	1.238;
commitid	emgEFc6CjatxFt63;

1.238
date	2016.11.22.19.29.54;	author procter;	state Exp;
branches;
next	1.237;
commitid	Wwno1dT3ILCyVgb1;

1.237
date	2016.11.14.13.25.00;	author bluhm;	state Exp;
branches;
next	1.236;
commitid	B8d5g57KBGx1yYQP;

1.236
date	2016.10.27.21.41.20;	author bluhm;	state Exp;
branches;
next	1.235;
commitid	RZerTDpaYI8sgJZ6;

1.235
date	2016.10.04.13.54.32;	author mpi;	state Exp;
branches;
next	1.234;
commitid	QtKIaSOt6xUiLgI5;

1.234
date	2016.09.27.04.57.17;	author dlg;	state Exp;
branches;
next	1.233;
commitid	irzdR7hwk1GHVaEu;

1.233
date	2016.09.27.02.51.12;	author dlg;	state Exp;
branches;
next	1.232;
commitid	bZuzILta8BoFCDiT;

1.232
date	2016.09.21.07.41.49;	author mpi;	state Exp;
branches;
next	1.231;
commitid	W19auu7eqXTbl8XK;

1.231
date	2016.09.15.02.00.18;	author dlg;	state Exp;
branches;
next	1.230;
commitid	RlO92XR575sygHqm;

1.230
date	2016.08.23.12.37.44;	author dlg;	state Exp;
branches;
next	1.229;
commitid	bclyIfk7Kd0stY7Z;

1.229
date	2016.04.29.08.55.03;	author krw;	state Exp;
branches;
next	1.228;
commitid	OXPWeCN3XhMKFRzT;

1.228
date	2016.03.29.10.34.42;	author sashan;	state Exp;
branches;
next	1.227;
commitid	3oT5Q5z024mhykOL;

1.227
date	2016.01.31.00.18.07;	author sashan;	state Exp;
branches;
next	1.226;
commitid	XnM42P9Sq7TQR88T;

1.226
date	2016.01.27.04.35.56;	author dlg;	state Exp;
branches;
next	1.225;
commitid	ngoZtFIrOYXkO5NJ;

1.225
date	2016.01.26.22.23.15;	author sashan;	state Exp;
branches;
next	1.224;
commitid	Mw7GWcajnNQN76jp;

1.224
date	2015.12.05.10.07.55;	author tedu;	state Exp;
branches;
next	1.223;
commitid	ILbVM1M3uPNjwswz;

1.223
date	2015.12.03.09.49.15;	author bluhm;	state Exp;
branches;
next	1.222;
commitid	6HkfIaw2ROsrfw1Q;

1.222
date	2015.11.10.06.36.14;	author dlg;	state Exp;
branches;
next	1.221;
commitid	K5Jqf1WdzOhU2OVC;

1.221
date	2015.10.30.11.33.55;	author mikeb;	state Exp;
branches;
next	1.220;
commitid	b90TPnSXmdusuD88;

1.220
date	2015.09.11.08.17.06;	author claudio;	state Exp;
branches;
next	1.219;
commitid	Cr0DVA7exR1t2zXg;

1.219
date	2015.06.16.11.09.39;	author mpi;	state Exp;
branches;
next	1.218;
commitid	h7z8lokZ0dFyuWpg;

1.218
date	2015.03.14.03.38.51;	author jsg;	state Exp;
branches;
next	1.217;
commitid	p4LJxGKbi0BU2cG6;

1.217
date	2015.02.10.09.28.40;	author henning;	state Exp;
branches;
next	1.216;
commitid	UCQxCe3lrdmzEpqK;

1.216
date	2015.01.24.00.29.06;	author deraadt;	state Exp;
branches;
next	1.215;
commitid	VK3ncyiP3NS1N4Sy;

1.215
date	2014.12.19.17.14.39;	author tedu;	state Exp;
branches;
next	1.214;
commitid	zhW8jJrfVCoAthrR;

1.214
date	2014.12.17.09.57.13;	author mpi;	state Exp;
branches;
next	1.213;
commitid	cYQY7jiay4SydLhD;

1.213
date	2014.12.17.09.45.59;	author mpi;	state Exp;
branches;
next	1.212;
commitid	Vq8oSnWLkf7dyy0N;

1.212
date	2014.11.23.07.39.02;	author deraadt;	state Exp;
branches;
next	1.211;
commitid	mdGXHklUZmESVFlY;

1.211
date	2014.11.06.05.29.35;	author lteo;	state Exp;
branches;
next	1.210;
commitid	MdPVMYfvAnWXeaXf;

1.210
date	2014.10.17.00.47.48;	author dlg;	state Exp;
branches;
next	1.209;
commitid	Sf5V66QzGiwR2QbY;

1.209
date	2014.09.08.06.24.13;	author jsg;	state Exp;
branches;
next	1.208;
commitid	ZqXwxwmeo3l29NOg;

1.208
date	2014.07.22.11.06.09;	author mpi;	state Exp;
branches;
next	1.207;
commitid	DQakU8LLWV6Iwx84;

1.207
date	2014.07.12.18.44.22;	author tedu;	state Exp;
branches;
next	1.206;
commitid	B4dZSbxas1X1IpXI;

1.206
date	2014.04.21.12.22.25;	author henning;	state Exp;
branches;
next	1.205;

1.205
date	2014.04.14.09.06.42;	author mpi;	state Exp;
branches;
next	1.204;

1.204
date	2013.11.18.21.16.55;	author chl;	state Exp;
branches;
next	1.203;

1.203
date	2013.11.15.12.18.02;	author henning;	state Exp;
branches;
next	1.202;

1.202
date	2013.10.17.16.27.41;	author bluhm;	state Exp;
branches;
next	1.201;

1.201
date	2013.08.07.05.39.05;	author dlg;	state Exp;
branches;
next	1.200;

1.200
date	2013.06.20.12.03.40;	author mpi;	state Exp;
branches;
next	1.199;

1.199
date	2013.06.20.09.38.24;	author mpi;	state Exp;
branches;
next	1.198;

1.198
date	2013.05.10.11.36.24;	author mikeb;	state Exp;
branches;
next	1.197;

1.197
date	2013.03.28.16.45.16;	author tedu;	state Exp;
branches;
next	1.196;

1.196
date	2013.03.26.13.19.26;	author mpi;	state Exp;
branches;
next	1.195;

1.195
date	2012.10.30.12.09.05;	author florian;	state Exp;
branches;
next	1.194;

1.194
date	2012.10.09.11.16.28;	author markus;	state Exp;
branches;
next	1.193;

1.193
date	2012.10.08.18.33.23;	author markus;	state Exp;
branches;
next	1.192;

1.192
date	2012.09.20.17.37.47;	author mikeb;	state Exp;
branches;
next	1.191;

1.191
date	2012.09.20.10.25.03;	author blambert;	state Exp;
branches;
next	1.190;

1.190
date	2012.09.19.13.47.17;	author mikeb;	state Exp;
branches;
next	1.189;

1.189
date	2012.07.26.12.25.31;	author mikeb;	state Exp;
branches;
next	1.188;

1.188
date	2012.06.30.00.16.15;	author mikeb;	state Exp;
branches;
next	1.187;

1.187
date	2012.06.30.00.14.23;	author mikeb;	state Exp;
branches;
next	1.186;

1.186
date	2012.06.29.15.12.21;	author mikeb;	state Exp;
branches;
next	1.185;

1.185
date	2012.06.28.13.59.21;	author mikeb;	state Exp;
branches;
next	1.184;

1.184
date	2012.04.11.17.42.53;	author mikeb;	state Exp;
branches;
next	1.183;

1.183
date	2012.04.07.14.28.45;	author camield;	state Exp;
branches;
next	1.182;

1.182
date	2012.04.03.15.09.03;	author mikeb;	state Exp;
branches;
next	1.181;

1.181
date	2012.02.03.01.57.50;	author bluhm;	state Exp;
branches;
next	1.180;

1.180
date	2012.01.16.10.28.02;	author mikeb;	state Exp;
branches;
next	1.179;

1.179
date	2011.12.01.20.43.03;	author mcbride;	state Exp;
branches;
next	1.178;

1.178
date	2011.11.29.10.17.52;	author dlg;	state Exp;
branches;
next	1.177;

1.177
date	2011.11.27.16.06.30;	author mikeb;	state Exp;
branches;
next	1.176;

1.176
date	2011.11.26.03.28.46;	author mcbride;	state Exp;
branches;
next	1.175;

1.175
date	2011.11.25.12.52.10;	author dlg;	state Exp;
branches;
next	1.174;

1.174
date	2011.11.16.11.59.28;	author mikeb;	state Exp;
branches;
next	1.173;

1.173
date	2011.11.09.12.36.03;	author camield;	state Exp;
branches;
next	1.172;

1.172
date	2011.11.04.22.11.11;	author mikeb;	state Exp;
branches;
next	1.171;

1.171
date	2011.10.31.22.02.52;	author mikeb;	state Exp;
branches;
next	1.170;

1.170
date	2011.10.30.23.04.38;	author mikeb;	state Exp;
branches;
next	1.169;

1.169
date	2011.10.20.08.57.26;	author mikeb;	state Exp;
branches;
next	1.168;

1.168
date	2011.10.13.18.23.39;	author claudio;	state Exp;
branches;
next	1.167;

1.167
date	2011.08.03.00.01.30;	author dlg;	state Exp;
branches;
next	1.166;

1.166
date	2011.08.02.13.13.57;	author mcbride;	state Exp;
branches;
next	1.165;

1.165
date	2011.07.06.02.42.28;	author henning;	state Exp;
branches;
next	1.164;

1.164
date	2011.07.04.20.40.58;	author dhill;	state Exp;
branches;
next	1.163;

1.163
date	2011.05.10.01.10.08;	author dlg;	state Exp;
branches;
next	1.162;

1.162
date	2011.04.02.17.16.34;	author dlg;	state Exp;
branches;
next	1.161;

1.161
date	2011.03.02.12.02.26;	author dlg;	state Exp;
branches;
next	1.160;

1.160
date	2011.01.11.08.33.27;	author dlg;	state Exp;
branches;
next	1.159;

1.159
date	2010.11.29.06.48.09;	author dlg;	state Exp;
branches;
next	1.158;

1.158
date	2010.11.29.05.31.38;	author dlg;	state Exp;
branches;
next	1.157;

1.157
date	2010.11.28.11.43.41;	author dlg;	state Exp;
branches;
next	1.156;

1.156
date	2010.09.27.23.45.48;	author dlg;	state Exp;
branches;
next	1.155;

1.155
date	2010.09.08.08.53.57;	author blambert;	state Exp;
branches;
next	1.154;

1.154
date	2010.07.28.06.52.05;	author dlg;	state Exp;
branches;
next	1.153;

1.153
date	2010.07.25.23.36.31;	author jsg;	state Exp;
branches;
next	1.152;

1.152
date	2010.07.09.16.58.06;	author reyk;	state Exp;
branches;
next	1.151;

1.151
date	2010.07.09.13.09.34;	author dlg;	state Exp;
branches;
next	1.150;

1.150
date	2010.07.09.12.07.21;	author dlg;	state Exp;
branches;
next	1.149;

1.149
date	2010.07.09.11.16.45;	author dlg;	state Exp;
branches;
next	1.148;

1.148
date	2010.07.09.09.01.32;	author dlg;	state Exp;
branches;
next	1.147;

1.147
date	2010.05.24.02.11.04;	author dlg;	state Exp;
branches;
next	1.146;

1.146
date	2010.05.12.08.11.11;	author claudio;	state Exp;
branches;
next	1.145;

1.145
date	2010.04.25.17.38.53;	author mpf;	state Exp;
branches;
next	1.144;

1.144
date	2010.03.23.22.34.49;	author pyr;	state Exp;
branches;
next	1.143;

1.143
date	2010.03.01.12.29.35;	author dlg;	state Exp;
branches
	1.143.2.1;
next	1.142;

1.142
date	2010.02.17.00.00.04;	author dlg;	state Exp;
branches;
next	1.141;

1.141
date	2010.01.18.23.52.46;	author mcbride;	state Exp;
branches;
next	1.140;

1.140
date	2010.01.12.23.38.02;	author dlg;	state Exp;
branches;
next	1.139;

1.139
date	2010.01.12.10.21.38;	author dlg;	state Exp;
branches;
next	1.138;

1.138
date	2010.01.12.02.47.07;	author claudio;	state Exp;
branches;
next	1.137;

1.137
date	2010.01.11.00.19.11;	author dlg;	state Exp;
branches;
next	1.136;

1.136
date	2010.01.10.23.54.21;	author dlg;	state Exp;
branches;
next	1.135;

1.135
date	2009.12.14.12.31.45;	author henning;	state Exp;
branches;
next	1.134;

1.134
date	2009.12.03.12.23.52;	author otto;	state Exp;
branches;
next	1.133;

1.133
date	2009.11.23.16.03.10;	author henning;	state Exp;
branches;
next	1.132;

1.132
date	2009.11.22.22.34.50;	author henning;	state Exp;
branches;
next	1.131;

1.131
date	2009.11.12.06.53.24;	author deraadt;	state Exp;
branches;
next	1.130;

1.130
date	2009.11.03.10.59.04;	author claudio;	state Exp;
branches;
next	1.129;

1.129
date	2009.09.28.03.01.23;	author dlg;	state Exp;
branches;
next	1.128;

1.128
date	2009.08.16.13.01.57;	author jsg;	state Exp;
branches;
next	1.127;

1.127
date	2009.06.17.04.24.02;	author dlg;	state Exp;
branches
	1.127.4.1;
next	1.126;

1.126
date	2009.06.14.00.16.50;	author dlg;	state Exp;
branches;
next	1.125;

1.125
date	2009.06.12.02.03.51;	author dlg;	state Exp;
branches;
next	1.124;

1.124
date	2009.06.10.00.03.55;	author dlg;	state Exp;
branches;
next	1.123;

1.123
date	2009.05.13.01.09.05;	author dlg;	state Exp;
branches;
next	1.122;

1.122
date	2009.05.13.01.01.34;	author dlg;	state Exp;
branches;
next	1.121;

1.121
date	2009.04.15.05.11.49;	author david;	state Exp;
branches;
next	1.120;

1.120
date	2009.04.04.13.09.29;	author dlg;	state Exp;
branches;
next	1.119;

1.119
date	2009.03.31.01.21.29;	author dlg;	state Exp;
branches;
next	1.118;

1.118
date	2009.03.23.06.19.59;	author dlg;	state Exp;
branches;
next	1.117;

1.117
date	2009.03.17.05.06.54;	author dlg;	state Exp;
branches;
next	1.116;

1.116
date	2009.03.15.19.40.41;	author miod;	state Exp;
branches;
next	1.115;

1.115
date	2009.03.01.12.02.39;	author dlg;	state Exp;
branches;
next	1.114;

1.114
date	2009.03.01.11.24.36;	author dlg;	state Exp;
branches;
next	1.113;

1.113
date	2009.03.01.10.34.38;	author dlg;	state Exp;
branches;
next	1.112;

1.112
date	2009.02.26.07.29.46;	author dlg;	state Exp;
branches;
next	1.111;

1.111
date	2009.02.24.21.47.28;	author dlg;	state Exp;
branches;
next	1.110;

1.110
date	2009.02.24.05.39.19;	author dlg;	state Exp;
branches;
next	1.109;

1.109
date	2009.02.23.21.16.35;	author dlg;	state Exp;
branches;
next	1.108;

1.108
date	2009.02.18.10.07.24;	author dlg;	state Exp;
branches;
next	1.107;

1.107
date	2009.02.17.23.46.25;	author dlg;	state Exp;
branches;
next	1.106;

1.106
date	2009.02.17.23.45.43;	author dlg;	state Exp;
branches;
next	1.105;

1.105
date	2009.02.17.23.43.47;	author dlg;	state Exp;
branches;
next	1.104;

1.104
date	2009.02.17.20.59.29;	author chl;	state Exp;
branches;
next	1.103;

1.103
date	2009.02.16.00.31.25;	author dlg;	state Exp;
branches;
next	1.102;

1.102
date	2008.12.21.23.41.26;	author dlg;	state Exp;
branches;
next	1.101;

1.101
date	2008.09.17.20.10.37;	author chl;	state Exp;
branches;
next	1.100;

1.100
date	2008.09.10.14.01.23;	author blambert;	state Exp;
branches;
next	1.99;

1.99
date	2008.09.02.17.35.16;	author chl;	state Exp;
branches;
next	1.98;

1.98
date	2008.06.29.08.42.15;	author mcbride;	state Exp;
branches;
next	1.97;

1.97
date	2008.06.19.04.53.21;	author mcbride;	state Exp;
branches;
next	1.96;

1.96
date	2008.06.10.22.39.31;	author mcbride;	state Exp;
branches;
next	1.95;

1.95
date	2008.06.10.19.32.13;	author henning;	state Exp;
branches;
next	1.94;

1.94
date	2008.06.10.04.24.17;	author henning;	state Exp;
branches;
next	1.93;

1.93
date	2008.05.29.01.00.53;	author mcbride;	state Exp;
branches;
next	1.92;

1.92
date	2008.05.29.00.28.07;	author henning;	state Exp;
branches;
next	1.91;

1.91
date	2008.05.18.11.54.04;	author mcbride;	state Exp;
branches;
next	1.90;

1.90
date	2008.05.06.03.45.21;	author mpf;	state Exp;
branches;
next	1.89;

1.89
date	2008.01.12.17.08.33;	author mpf;	state Exp;
branches;
next	1.88;

1.88
date	2007.12.14.18.33.37;	author deraadt;	state Exp;
branches;
next	1.87;

1.87
date	2007.09.18.18.56.02;	author markus;	state Exp;
branches;
next	1.86;

1.86
date	2007.09.15.16.43.51;	author henning;	state Exp;
branches;
next	1.85;

1.85
date	2007.09.03.06.15.06;	author joel;	state Exp;
branches;
next	1.84;

1.84
date	2007.09.01.18.49.27;	author henning;	state Exp;
branches;
next	1.83;

1.83
date	2007.06.26.14.44.12;	author mcbride;	state Exp;
branches;
next	1.82;

1.82
date	2007.06.25.13.57.18;	author henning;	state Exp;
branches;
next	1.81;

1.81
date	2007.06.24.11.17.13;	author mcbride;	state Exp;
branches;
next	1.80;

1.80
date	2007.06.21.11.55.54;	author henning;	state Exp;
branches;
next	1.79;

1.79
date	2007.06.14.13.38.27;	author henning;	state Exp;
branches;
next	1.78;

1.78
date	2007.06.01.18.44.22;	author henning;	state Exp;
branches;
next	1.77;

1.77
date	2007.05.31.20.38.12;	author henning;	state Exp;
branches;
next	1.76;

1.76
date	2007.05.31.18.48.05;	author mcbride;	state Exp;
branches;
next	1.75;

1.75
date	2007.05.31.04.11.42;	author mcbride;	state Exp;
branches;
next	1.74;

1.74
date	2007.05.26.17.13.31;	author jason;	state Exp;
branches;
next	1.73;

1.73
date	2006.11.16.13.13.38;	author henning;	state Exp;
branches;
next	1.72;

1.72
date	2006.11.01.23.39.34;	author mcbride;	state Exp;
branches;
next	1.71;

1.71
date	2006.11.01.00.02.14;	author henning;	state Exp;
branches;
next	1.70;

1.70
date	2006.10.31.22.01.56;	author henning;	state Exp;
branches;
next	1.69;

1.69
date	2006.10.31.22.00.38;	author henning;	state Exp;
branches;
next	1.68;

1.68
date	2006.10.31.17.37.11;	author deraadt;	state Exp;
branches;
next	1.67;

1.67
date	2006.10.31.14.49.01;	author henning;	state Exp;
branches;
next	1.66;

1.66
date	2006.06.02.19.53.12;	author mpf;	state Exp;
branches;
next	1.65;

1.65
date	2006.05.28.02.04.15;	author mcbride;	state Exp;
branches;
next	1.64;

1.64
date	2006.05.13.05.23.45;	author mcbride;	state Exp;
branches;
next	1.63;

1.63
date	2006.05.06.18.31.00;	author mcbride;	state Exp;
branches;
next	1.62;

1.62
date	2006.03.25.22.41.47;	author djm;	state Exp;
branches;
next	1.61;

1.61
date	2006.03.04.22.40.15;	author brad;	state Exp;
branches;
next	1.60;

1.60
date	2006.02.20.20.12.14;	author damien;	state Exp;
branches;
next	1.59;

1.59
date	2005.11.04.08.24.14;	author mcbride;	state Exp;
branches;
next	1.58;

1.58
date	2005.11.01.06.26.52;	author pascoe;	state Exp;
branches;
next	1.57;

1.57
date	2005.10.28.03.20.41;	author mcbride;	state Exp;
branches;
next	1.56;

1.56
date	2005.10.27.12.34.40;	author mcbride;	state Exp;
branches;
next	1.55;

1.55
date	2005.09.28.01.46.32;	author pascoe;	state Exp;
branches;
next	1.54;

1.54
date	2005.08.18.10.28.13;	author pascoe;	state Exp;
branches;
next	1.53;

1.53
date	2005.08.16.11.22.43;	author pascoe;	state Exp;
branches;
next	1.52;

1.52
date	2005.08.11.17.58.58;	author mcbride;	state Exp;
branches;
next	1.51;

1.51
date	2005.08.03.00.55.07;	author pascoe;	state Exp;
branches;
next	1.50;

1.50
date	2005.08.01.11.14.47;	author pascoe;	state Exp;
branches;
next	1.49;

1.49
date	2005.07.12.17.40.51;	author mickey;	state Exp;
branches;
next	1.48;

1.48
date	2005.05.28.15.10.07;	author ho;	state Exp;
branches;
next	1.47;

1.47
date	2005.05.21.21.03.57;	author henning;	state Exp;
branches;
next	1.46;

1.46
date	2005.02.20.15.58.38;	author mcbride;	state Exp;
branches
	1.46.2.1;
next	1.45;

1.45
date	2005.02.15.21.31.22;	author aaron;	state Exp;
branches;
next	1.44;

1.44
date	2005.01.20.17.54.26;	author mcbride;	state Exp;
branches;
next	1.43;

1.43
date	2005.01.20.17.47.38;	author mcbride;	state Exp;
branches;
next	1.42;

1.42
date	2004.12.16.00.45.34;	author mcbride;	state Exp;
branches;
next	1.41;

1.41
date	2004.12.13.01.47.26;	author pascoe;	state Exp;
branches;
next	1.40;

1.40
date	2004.12.06.10.27.53;	author mpf;	state Exp;
branches;
next	1.39;

1.39
date	2004.11.16.20.07.56;	author mcbride;	state Exp;
branches;
next	1.38;

1.38
date	2004.09.17.21.49.15;	author mcbride;	state Exp;
branches;
next	1.37;

1.37
date	2004.08.30.07.44.28;	author mcbride;	state Exp;
branches;
next	1.36;

1.36
date	2004.08.03.05.32.28;	author mcbride;	state Exp;
branches;
next	1.35;

1.35
date	2004.06.21.23.50.36;	author tholo;	state Exp;
branches;
next	1.34;

1.34
date	2004.06.04.22.25.09;	author mcbride;	state Exp;
branches;
next	1.33;

1.33
date	2004.05.17.17.15.07;	author mickey;	state Exp;
branches;
next	1.32;

1.32
date	2004.04.30.22.08.18;	author mcbride;	state Exp;
branches;
next	1.31;

1.31
date	2004.04.28.00.28.43;	author mcbride;	state Exp;
branches;
next	1.30;

1.30
date	2004.04.28.00.20.47;	author pb;	state Exp;
branches;
next	1.29;

1.29
date	2004.04.25.18.09.30;	author pb;	state Exp;
branches;
next	1.28;

1.28
date	2004.04.25.17.52.37;	author pb;	state Exp;
branches;
next	1.27;

1.27
date	2004.04.05.00.21.39;	author mcbride;	state Exp;
branches;
next	1.26;

1.26
date	2004.03.28.18.14.20;	author mcbride;	state Exp;
branches;
next	1.25;

1.25
date	2004.03.23.09.57.44;	author mcbride;	state Exp;
branches;
next	1.24;

1.24
date	2004.03.22.04.54.17;	author mcbride;	state Exp;
branches;
next	1.23;

1.23
date	2004.02.20.19.22.03;	author mcbride;	state Exp;
branches;
next	1.22;

1.22
date	2004.02.10.09.21.54;	author mcbride;	state Exp;
branches;
next	1.21;

1.21
date	2004.02.08.09.18.45;	author mcbride;	state Exp;
branches;
next	1.20;

1.20
date	2004.02.07.05.26.21;	author mcbride;	state Exp;
branches;
next	1.19;

1.19
date	2004.01.22.09.25.25;	author mcbride;	state Exp;
branches;
next	1.18;

1.18
date	2004.01.20.17.40.31;	author henning;	state Exp;
branches;
next	1.17;

1.17
date	2004.01.20.03.36.19;	author mcbride;	state Exp;
branches;
next	1.16;

1.16
date	2004.01.19.19.46.33;	author mcbride;	state Exp;
branches;
next	1.15;

1.15
date	2004.01.19.07.24.07;	author mcbride;	state Exp;
branches;
next	1.14;

1.14
date	2003.12.31.11.18.25;	author cedric;	state Exp;
branches;
next	1.13;

1.13
date	2003.12.28.17.18.58;	author mcbride;	state Exp;
branches;
next	1.12;

1.12
date	2003.12.18.16.07.38;	author dhartmei;	state Exp;
branches;
next	1.11;

1.11
date	2003.12.16.08.17.56;	author mcbride;	state Exp;
branches;
next	1.10;

1.10
date	2003.12.15.21.49.38;	author deraadt;	state Exp;
branches;
next	1.9;

1.9
date	2003.12.15.07.28.25;	author mcbride;	state Exp;
branches;
next	1.8;

1.8
date	2003.12.15.07.11.30;	author mcbride;	state Exp;
branches;
next	1.7;

1.7
date	2003.11.08.19.51.38;	author dhartmei;	state Exp;
branches;
next	1.6;

1.6
date	2003.06.21.09.07.01;	author djm;	state Exp;
branches;
next	1.5;

1.5
date	2003.05.03.21.15.11;	author deraadt;	state Exp;
branches;
next	1.4;

1.4
date	2002.12.23.18.53.59;	author mickey;	state Exp;
branches
	1.4.4.1;
next	1.3;

1.3
date	2002.12.20.22.13.27;	author mickey;	state Exp;
branches;
next	1.2;

1.2
date	2002.12.03.15.52.34;	author mickey;	state Exp;
branches;
next	1.1;

1.1
date	2002.11.29.18.25.22;	author mickey;	state Exp;
branches;
next	;

1.4.4.1
date	2003.05.13.19.36.15;	author ho;	state Exp;
branches;
next	1.4.4.2;

1.4.4.2
date	2004.02.19.10.57.21;	author niklas;	state Exp;
branches;
next	1.4.4.3;

1.4.4.3
date	2004.06.05.23.11.23;	author niklas;	state Exp;
branches;
next	;

1.46.2.1
date	2005.10.20.02.05.31;	author brad;	state Exp;
branches;
next	;

1.127.4.1
date	2010.05.14.09.08.34;	author stephan;	state Exp;
branches;
next	;

1.143.2.1
date	2010.03.24.20.52.09;	author pyr;	state Exp;
branches;
next	1.143.2.2;

1.143.2.2
date	2010.05.14.09.02.41;	author stephan;	state Exp;
branches;
next	;


desc
@@


1.246
log
@Add a detachhook to pfsync(4) which deals with the syncdev going away.
Fixes a panic observed by douple-p (aka pb@@) when destroying the syncdev.
tweak & ok mpi@@
@
text
@/*	$OpenBSD: if_pfsync.c,v 1.245 2017/02/20 06:30:39 jca Exp $	*/

/*
 * Copyright (c) 2002 Michael Shalayeff
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR
 * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
 * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
 * IN NO EVENT SHALL THE AUTHOR OR HIS RELATIVES BE LIABLE FOR ANY DIRECT,
 * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 * SERVICES; LOSS OF MIND, USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
 * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING
 * IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
 * THE POSSIBILITY OF SUCH DAMAGE.
 */

/*
 * Copyright (c) 2009 David Gwynne <dlg@@openbsd.org>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/time.h>
#include <sys/malloc.h>
#include <sys/mbuf.h>
#include <sys/socket.h>
#include <sys/ioctl.h>
#include <sys/timeout.h>
#include <sys/kernel.h>
#include <sys/sysctl.h>
#include <sys/pool.h>
#include <sys/syslog.h>

#include <net/if.h>
#include <net/if_types.h>
#include <net/bpf.h>
#include <net/netisr.h>

#include <netinet/in.h>
#include <netinet/if_ether.h>
#include <netinet/ip.h>
#include <netinet/in_var.h>
#include <netinet/ip_var.h>
#include <netinet/ip_ipsp.h>
#include <netinet/ip_icmp.h>
#include <netinet/icmp6.h>
#include <netinet/tcp.h>
#include <netinet/tcp_seq.h>
#include <netinet/tcp_fsm.h>
#include <netinet/udp.h>

#ifdef INET6
#include <netinet6/in6_var.h>
#include <netinet/ip6.h>
#include <netinet6/ip6_var.h>
#include <netinet6/nd6.h>
#endif /* INET6 */

#include "carp.h"
#if NCARP > 0
#include <netinet/ip_carp.h>
#endif

#define PF_DEBUGNAME	"pfsync: "
#include <net/pfvar.h>
#include <net/pfvar_priv.h>
#include <net/if_pfsync.h>

#include "bpfilter.h"
#include "pfsync.h"

#define PFSYNC_MINPKT ( \
	sizeof(struct ip) + \
	sizeof(struct pfsync_header))

int	pfsync_upd_tcp(struct pf_state *, struct pfsync_state_peer *,
	    struct pfsync_state_peer *);

int	pfsync_in_clr(caddr_t, int, int, int);
int	pfsync_in_iack(caddr_t, int, int, int);
int	pfsync_in_upd_c(caddr_t, int, int, int);
int	pfsync_in_ureq(caddr_t, int, int, int);
int	pfsync_in_del(caddr_t, int, int, int);
int	pfsync_in_del_c(caddr_t, int, int, int);
int	pfsync_in_bus(caddr_t, int, int, int);
int	pfsync_in_tdb(caddr_t, int, int, int);
int	pfsync_in_ins(caddr_t, int, int, int);
int	pfsync_in_upd(caddr_t, int, int, int);
int	pfsync_in_eof(caddr_t, int, int, int);

int	pfsync_in_error(caddr_t, int, int, int);

struct {
	int	(*in)(caddr_t, int, int, int);
	size_t	len;
} pfsync_acts[] = {
	/* PFSYNC_ACT_CLR */
	{ pfsync_in_clr,	sizeof(struct pfsync_clr) },
	 /* PFSYNC_ACT_OINS */
	{ pfsync_in_error,	0 },
	/* PFSYNC_ACT_INS_ACK */
	{ pfsync_in_iack,	sizeof(struct pfsync_ins_ack) },
	/* PFSYNC_ACT_OUPD */
	{ pfsync_in_error,	0 },
	/* PFSYNC_ACT_UPD_C */
	{ pfsync_in_upd_c,	sizeof(struct pfsync_upd_c) },
	/* PFSYNC_ACT_UPD_REQ */
	{ pfsync_in_ureq,	sizeof(struct pfsync_upd_req) },
	/* PFSYNC_ACT_DEL */
	{ pfsync_in_del,	sizeof(struct pfsync_state) },
	/* PFSYNC_ACT_DEL_C */
	{ pfsync_in_del_c,	sizeof(struct pfsync_del_c) },
	/* PFSYNC_ACT_INS_F */
	{ pfsync_in_error,	0 },
	/* PFSYNC_ACT_DEL_F */
	{ pfsync_in_error,	0 },
	/* PFSYNC_ACT_BUS */
	{ pfsync_in_bus,	sizeof(struct pfsync_bus) },
	/* PFSYNC_ACT_OTDB */
	{ pfsync_in_error,	0 },
	/* PFSYNC_ACT_EOF */
	{ pfsync_in_error,	0 },
	/* PFSYNC_ACT_INS */
	{ pfsync_in_ins,	sizeof(struct pfsync_state) },
	/* PFSYNC_ACT_UPD */
	{ pfsync_in_upd,	sizeof(struct pfsync_state) },
	/* PFSYNC_ACT_TDB */
	{ pfsync_in_tdb,	sizeof(struct pfsync_tdb) },
};

struct pfsync_q {
	void		(*write)(struct pf_state *, void *);
	size_t		len;
	u_int8_t	action;
};

/* we have one of these for every PFSYNC_S_ */
void	pfsync_out_state(struct pf_state *, void *);
void	pfsync_out_iack(struct pf_state *, void *);
void	pfsync_out_upd_c(struct pf_state *, void *);
void	pfsync_out_del(struct pf_state *, void *);

struct pfsync_q pfsync_qs[] = {
	{ pfsync_out_iack,  sizeof(struct pfsync_ins_ack), PFSYNC_ACT_INS_ACK },
	{ pfsync_out_upd_c, sizeof(struct pfsync_upd_c),   PFSYNC_ACT_UPD_C },
	{ pfsync_out_del,   sizeof(struct pfsync_del_c),   PFSYNC_ACT_DEL_C },
	{ pfsync_out_state, sizeof(struct pfsync_state),   PFSYNC_ACT_INS },
	{ pfsync_out_state, sizeof(struct pfsync_state),   PFSYNC_ACT_UPD }
};

void	pfsync_q_ins(struct pf_state *, int);
void	pfsync_q_del(struct pf_state *);

struct pfsync_upd_req_item {
	TAILQ_ENTRY(pfsync_upd_req_item)	ur_entry;
	struct pfsync_upd_req			ur_msg;
};
TAILQ_HEAD(pfsync_upd_reqs, pfsync_upd_req_item);

struct pfsync_deferral {
	TAILQ_ENTRY(pfsync_deferral)		 pd_entry;
	struct pf_state				*pd_st;
	struct mbuf				*pd_m;
	struct timeout				 pd_tmo;
};
TAILQ_HEAD(pfsync_deferrals, pfsync_deferral);

#define PFSYNC_PLSIZE	MAX(sizeof(struct pfsync_upd_req_item), \
			    sizeof(struct pfsync_deferral))

void	pfsync_out_tdb(struct tdb *, void *);

struct pfsync_softc {
	struct ifnet		 sc_if;
	struct ifnet		*sc_sync_if;

	struct pool		 sc_pool;

	struct ip_moptions	 sc_imo;

	struct in_addr		 sc_sync_peer;
	u_int8_t		 sc_maxupdates;

	struct ip		 sc_template;

	struct pf_state_queue	 sc_qs[PFSYNC_S_COUNT];
	size_t			 sc_len;

	struct pfsync_upd_reqs	 sc_upd_req_list;

	int			 sc_initial_bulk;
	int			 sc_link_demoted;

	int			 sc_defer;
	struct pfsync_deferrals	 sc_deferrals;
	u_int			 sc_deferred;

	void			*sc_plus;
	size_t			 sc_pluslen;

	u_int32_t		 sc_ureq_sent;
	int			 sc_bulk_tries;
	struct timeout		 sc_bulkfail_tmo;

	u_int32_t		 sc_ureq_received;
	struct pf_state		*sc_bulk_next;
	struct pf_state		*sc_bulk_last;
	struct timeout		 sc_bulk_tmo;

	TAILQ_HEAD(, tdb)	 sc_tdb_q;

	void			*sc_lhcookie;
	void			*sc_dhcookie;

	struct timeout		 sc_tmo;
};

struct pfsync_softc	*pfsyncif = NULL;
struct cpumem		*pfsynccounters;

void	pfsyncattach(int);
int	pfsync_clone_create(struct if_clone *, int);
int	pfsync_clone_destroy(struct ifnet *);
int	pfsync_alloc_scrub_memory(struct pfsync_state_peer *,
	    struct pf_state_peer *);
void	pfsync_update_net_tdb(struct pfsync_tdb *);
int	pfsyncoutput(struct ifnet *, struct mbuf *, struct sockaddr *,
	    struct rtentry *);
int	pfsyncioctl(struct ifnet *, u_long, caddr_t);
void	pfsyncstart(struct ifnet *);
void	pfsync_syncdev_state(void *);
void	pfsync_ifdetach(void *);

void	pfsync_deferred(struct pf_state *, int);
void	pfsync_undefer(struct pfsync_deferral *, int);
void	pfsync_defer_tmo(void *);

void	pfsync_cancel_full_update(struct pfsync_softc *);
void	pfsync_request_full_update(struct pfsync_softc *);
void	pfsync_request_update(u_int32_t, u_int64_t);
void	pfsync_update_state_req(struct pf_state *);

void	pfsync_drop(struct pfsync_softc *);
void	pfsync_sendout(void);
void	pfsync_send_plus(void *, size_t);
void	pfsync_timeout(void *);
void	pfsync_tdb_timeout(void *);

void	pfsync_bulk_start(void);
void	pfsync_bulk_status(u_int8_t);
void	pfsync_bulk_update(void *);
void	pfsync_bulk_fail(void *);

#define PFSYNC_MAX_BULKTRIES	12
int	pfsync_sync_ok;

struct if_clone	pfsync_cloner =
    IF_CLONE_INITIALIZER("pfsync", pfsync_clone_create, pfsync_clone_destroy);

void
pfsyncattach(int npfsync)
{
	if_clone_attach(&pfsync_cloner);
	pfsynccounters = counters_alloc(pfsyncs_ncounters);
}

int
pfsync_clone_create(struct if_clone *ifc, int unit)
{
	struct pfsync_softc *sc;
	struct ifnet *ifp;
	int q;

	if (unit != 0)
		return (EINVAL);

	pfsync_sync_ok = 1;

	sc = malloc(sizeof(*pfsyncif), M_DEVBUF, M_WAITOK | M_ZERO);

	for (q = 0; q < PFSYNC_S_COUNT; q++)
		TAILQ_INIT(&sc->sc_qs[q]);

	pool_init(&sc->sc_pool, PFSYNC_PLSIZE, 0, IPL_SOFTNET, 0, "pfsync",
	    NULL);
	TAILQ_INIT(&sc->sc_upd_req_list);
	TAILQ_INIT(&sc->sc_deferrals);
	sc->sc_deferred = 0;

	TAILQ_INIT(&sc->sc_tdb_q);

	sc->sc_len = PFSYNC_MINPKT;
	sc->sc_maxupdates = 128;

	sc->sc_imo.imo_membership = (struct in_multi **)malloc(
	    (sizeof(struct in_multi *) * IP_MIN_MEMBERSHIPS), M_IPMOPTS,
	    M_WAITOK | M_ZERO);
	sc->sc_imo.imo_max_memberships = IP_MIN_MEMBERSHIPS;

	ifp = &sc->sc_if;
	snprintf(ifp->if_xname, sizeof ifp->if_xname, "pfsync%d", unit);
	ifp->if_softc = sc;
	ifp->if_ioctl = pfsyncioctl;
	ifp->if_output = pfsyncoutput;
	ifp->if_start = pfsyncstart;
	ifp->if_type = IFT_PFSYNC;
	IFQ_SET_MAXLEN(&ifp->if_snd, IFQ_MAXLEN);
	ifp->if_hdrlen = sizeof(struct pfsync_header);
	ifp->if_mtu = ETHERMTU;
	ifp->if_xflags = IFXF_CLONED;
	timeout_set_proc(&sc->sc_tmo, pfsync_timeout, sc);
	timeout_set_proc(&sc->sc_bulk_tmo, pfsync_bulk_update, sc);
	timeout_set_proc(&sc->sc_bulkfail_tmo, pfsync_bulk_fail, sc);

	if_attach(ifp);
	if_alloc_sadl(ifp);

#if NCARP > 0
	if_addgroup(ifp, "carp");
#endif

#if NBPFILTER > 0
	bpfattach(&sc->sc_if.if_bpf, ifp, DLT_PFSYNC, PFSYNC_HDRLEN);
#endif

	pfsyncif = sc;

	return (0);
}

int
pfsync_clone_destroy(struct ifnet *ifp)
{
	struct pfsync_softc *sc = ifp->if_softc;
	struct pfsync_deferral *pd;

	timeout_del(&sc->sc_bulkfail_tmo);
	timeout_del(&sc->sc_bulk_tmo);
	timeout_del(&sc->sc_tmo);
#if NCARP > 0
	if (!pfsync_sync_ok)
		carp_group_demote_adj(&sc->sc_if, -1, "pfsync destroy");
	if (sc->sc_link_demoted)
		carp_group_demote_adj(&sc->sc_if, -1, "pfsync destroy");
#endif
	if (sc->sc_sync_if) {
		hook_disestablish(
		    sc->sc_sync_if->if_linkstatehooks,
		    sc->sc_lhcookie);
		hook_disestablish(sc->sc_sync_if->if_detachhooks,
		    sc->sc_dhcookie);
	}
	if_detach(ifp);

	pfsync_drop(sc);

	while (sc->sc_deferred > 0) {
		pd = TAILQ_FIRST(&sc->sc_deferrals);
		timeout_del(&pd->pd_tmo);
		pfsync_undefer(pd, 0);
	}

	pool_destroy(&sc->sc_pool);
	free(sc->sc_imo.imo_membership, M_IPMOPTS, 0);
	free(sc, M_DEVBUF, sizeof(*sc));

	pfsyncif = NULL;

	return (0);
}

/*
 * Start output on the pfsync interface.
 */
void
pfsyncstart(struct ifnet *ifp)
{
	IFQ_PURGE(&ifp->if_snd);
}

void
pfsync_syncdev_state(void *arg)
{
	struct pfsync_softc *sc = arg;

	if (!sc->sc_sync_if || !(sc->sc_if.if_flags & IFF_UP))
		return;

	if (sc->sc_sync_if->if_link_state == LINK_STATE_DOWN) {
		sc->sc_if.if_flags &= ~IFF_RUNNING;
		if (!sc->sc_link_demoted) {
#if NCARP > 0
			carp_group_demote_adj(&sc->sc_if, 1,
			    "pfsync link state down");
#endif
			sc->sc_link_demoted = 1;
		}

		/* drop everything */
		timeout_del(&sc->sc_tmo);
		pfsync_drop(sc);

		pfsync_cancel_full_update(sc);
	} else if (sc->sc_link_demoted) {
		sc->sc_if.if_flags |= IFF_RUNNING;

		pfsync_request_full_update(sc);
	}
}

void
pfsync_ifdetach(void *arg)
{
	struct pfsync_softc *sc = arg;

	sc->sc_sync_if = NULL;
}

int
pfsync_alloc_scrub_memory(struct pfsync_state_peer *s,
    struct pf_state_peer *d)
{
	if (s->scrub.scrub_flag && d->scrub == NULL) {
		d->scrub = pool_get(&pf_state_scrub_pl, PR_NOWAIT | PR_ZERO);
		if (d->scrub == NULL)
			return (ENOMEM);
	}

	return (0);
}

void
pfsync_state_export(struct pfsync_state *sp, struct pf_state *st)
{
	pf_state_export(sp, st);
}

int
pfsync_state_import(struct pfsync_state *sp, int flags)
{
	struct pf_state	*st = NULL;
	struct pf_state_key *skw = NULL, *sks = NULL;
	struct pf_rule *r = NULL;
	struct pfi_kif	*kif;
	int pool_flags;
	int error;

	if (sp->creatorid == 0) {
		DPFPRINTF(LOG_NOTICE, "pfsync_state_import: "
		    "invalid creator id: %08x", ntohl(sp->creatorid));
		return (EINVAL);
	}

	if ((kif = pfi_kif_get(sp->ifname)) == NULL) {
		DPFPRINTF(LOG_NOTICE, "pfsync_state_import: "
		    "unknown interface: %s", sp->ifname);
		if (flags & PFSYNC_SI_IOCTL)
			return (EINVAL);
		return (0);	/* skip this state */
	}

	if (sp->af == 0)
		return (0);	/* skip this state */

	/*
	 * If the ruleset checksums match or the state is coming from the ioctl,
	 * it's safe to associate the state with the rule of that number.
	 */
	if (sp->rule != htonl(-1) && sp->anchor == htonl(-1) &&
	    (flags & (PFSYNC_SI_IOCTL | PFSYNC_SI_CKSUM)) && ntohl(sp->rule) <
	    pf_main_ruleset.rules.active.rcount)
		r = pf_main_ruleset.rules.active.ptr_array[ntohl(sp->rule)];
	else
		r = &pf_default_rule;

	if ((r->max_states && r->states_cur >= r->max_states))
		goto cleanup;

	if (flags & PFSYNC_SI_IOCTL)
		pool_flags = PR_WAITOK | PR_LIMITFAIL | PR_ZERO;
	else
		pool_flags = PR_NOWAIT | PR_LIMITFAIL | PR_ZERO;

	if ((st = pool_get(&pf_state_pl, pool_flags)) == NULL)
		goto cleanup;

	if ((skw = pf_alloc_state_key(pool_flags)) == NULL)
		goto cleanup;

	if ((sp->key[PF_SK_WIRE].af &&
	    (sp->key[PF_SK_WIRE].af != sp->key[PF_SK_STACK].af)) ||
	    PF_ANEQ(&sp->key[PF_SK_WIRE].addr[0],
	    &sp->key[PF_SK_STACK].addr[0], sp->af) ||
	    PF_ANEQ(&sp->key[PF_SK_WIRE].addr[1],
	    &sp->key[PF_SK_STACK].addr[1], sp->af) ||
	    sp->key[PF_SK_WIRE].port[0] != sp->key[PF_SK_STACK].port[0] ||
	    sp->key[PF_SK_WIRE].port[1] != sp->key[PF_SK_STACK].port[1] ||
	    sp->key[PF_SK_WIRE].rdomain != sp->key[PF_SK_STACK].rdomain) {
		if ((sks = pf_alloc_state_key(pool_flags)) == NULL)
			goto cleanup;
	} else
		sks = skw;

	/* allocate memory for scrub info */
	if (pfsync_alloc_scrub_memory(&sp->src, &st->src) ||
	    pfsync_alloc_scrub_memory(&sp->dst, &st->dst))
		goto cleanup;

	/* copy to state key(s) */
	skw->addr[0] = sp->key[PF_SK_WIRE].addr[0];
	skw->addr[1] = sp->key[PF_SK_WIRE].addr[1];
	skw->port[0] = sp->key[PF_SK_WIRE].port[0];
	skw->port[1] = sp->key[PF_SK_WIRE].port[1];
	skw->rdomain = ntohs(sp->key[PF_SK_WIRE].rdomain);
	PF_REF_INIT(skw->refcnt);
	skw->proto = sp->proto;
	if (!(skw->af = sp->key[PF_SK_WIRE].af))
		skw->af = sp->af;
	if (sks != skw) {
		sks->addr[0] = sp->key[PF_SK_STACK].addr[0];
		sks->addr[1] = sp->key[PF_SK_STACK].addr[1];
		sks->port[0] = sp->key[PF_SK_STACK].port[0];
		sks->port[1] = sp->key[PF_SK_STACK].port[1];
		sks->rdomain = ntohs(sp->key[PF_SK_STACK].rdomain);
		PF_REF_INIT(sks->refcnt);
		if (!(sks->af = sp->key[PF_SK_STACK].af))
			sks->af = sp->af;
		if (sks->af != skw->af) {
			switch (sp->proto) {
			case IPPROTO_ICMP:
				sks->proto = IPPROTO_ICMPV6;
				break;
			case IPPROTO_ICMPV6:
				sks->proto = IPPROTO_ICMP;
				break;
			default:
				sks->proto = sp->proto;
			}
		} else
			sks->proto = sp->proto;
	}
	st->rtableid[PF_SK_WIRE] = ntohl(sp->rtableid[PF_SK_WIRE]);
	st->rtableid[PF_SK_STACK] = ntohl(sp->rtableid[PF_SK_STACK]);

	/* copy to state */
	bcopy(&sp->rt_addr, &st->rt_addr, sizeof(st->rt_addr));
	st->creation = time_uptime - ntohl(sp->creation);
	st->expire = time_uptime;
	if (ntohl(sp->expire)) {
		u_int32_t timeout;

		timeout = r->timeout[sp->timeout];
		if (!timeout)
			timeout = pf_default_rule.timeout[sp->timeout];

		/* sp->expire may have been adaptively scaled by export. */
		st->expire -= timeout - ntohl(sp->expire);
	}

	st->direction = sp->direction;
	st->log = sp->log;
	st->timeout = sp->timeout;
	st->state_flags = ntohs(sp->state_flags);
	st->max_mss = ntohs(sp->max_mss);
	st->min_ttl = sp->min_ttl;
	st->set_tos = sp->set_tos;
	st->set_prio[0] = sp->set_prio[0];
	st->set_prio[1] = sp->set_prio[1];

	st->id = sp->id;
	st->creatorid = sp->creatorid;
	pf_state_peer_ntoh(&sp->src, &st->src);
	pf_state_peer_ntoh(&sp->dst, &st->dst);

	st->rule.ptr = r;
	st->anchor.ptr = NULL;
	st->rt_kif = NULL;

	st->pfsync_time = time_uptime;
	st->sync_state = PFSYNC_S_NONE;

	/* XXX when we have anchors, use STATE_INC_COUNTERS */
	r->states_cur++;
	r->states_tot++;

	if (!ISSET(flags, PFSYNC_SI_IOCTL))
		SET(st->state_flags, PFSTATE_NOSYNC);

	if (pf_state_insert(kif, &skw, &sks, st) != 0) {
		/* XXX when we have anchors, use STATE_DEC_COUNTERS */
		r->states_cur--;
		error = EEXIST;
		goto cleanup_state;
	}

	if (!ISSET(flags, PFSYNC_SI_IOCTL)) {
		CLR(st->state_flags, PFSTATE_NOSYNC);
		if (ISSET(st->state_flags, PFSTATE_ACK)) {
			pfsync_q_ins(st, PFSYNC_S_IACK);
			schednetisr(NETISR_PFSYNC);
		}
	}
	CLR(st->state_flags, PFSTATE_ACK);

	return (0);

 cleanup:
	error = ENOMEM;
	if (skw == sks)
		sks = NULL;
	if (skw != NULL)
		pool_put(&pf_state_key_pl, skw);
	if (sks != NULL)
		pool_put(&pf_state_key_pl, sks);

 cleanup_state:	/* pf_state_insert frees the state keys */
	if (st) {
		if (st->dst.scrub)
			pool_put(&pf_state_scrub_pl, st->dst.scrub);
		if (st->src.scrub)
			pool_put(&pf_state_scrub_pl, st->src.scrub);
		pool_put(&pf_state_pl, st);
	}
	return (error);
}

int
pfsync_input(struct mbuf **mp, int *offp, int proto)
{
	struct mbuf *n, *m = *mp;
	struct pfsync_softc *sc = pfsyncif;
	struct ip *ip = mtod(m, struct ip *);
	struct pfsync_header *ph;
	struct pfsync_subheader subh;
	int offset, noff, len, count, mlen, flags = 0;

	pfsyncstat_inc(pfsyncs_ipackets);

	/* verify that we have a sync interface configured */
	if (sc == NULL || !ISSET(sc->sc_if.if_flags, IFF_RUNNING) ||
	    sc->sc_sync_if == NULL || !pf_status.running)
		goto done;

	/* verify that the packet came in on the right interface */
	if (sc->sc_sync_if->if_index != m->m_pkthdr.ph_ifidx) {
		pfsyncstat_inc(pfsyncs_badif);
		goto done;
	}

	sc->sc_if.if_ipackets++;
	sc->sc_if.if_ibytes += m->m_pkthdr.len;

	/* verify that the IP TTL is 255. */
	if (ip->ip_ttl != PFSYNC_DFLTTL) {
		pfsyncstat_inc(pfsyncs_badttl);
		goto done;
	}

	offset = ip->ip_hl << 2;
	n = m_pulldown(m, offset, sizeof(*ph), &noff);
	if (n == NULL) {
		pfsyncstat_inc(pfsyncs_hdrops);
		return IPPROTO_DONE;
	}
	ph = (struct pfsync_header *)(n->m_data + noff);

	/* verify the version */
	if (ph->version != PFSYNC_VERSION) {
		pfsyncstat_inc(pfsyncs_badver);
		goto done;
	}
	len = ntohs(ph->len) + offset;
	if (m->m_pkthdr.len < len) {
		pfsyncstat_inc(pfsyncs_badlen);
		goto done;
	}

	if (!bcmp(&ph->pfcksum, &pf_status.pf_chksum, PF_MD5_DIGEST_LENGTH))
		flags = PFSYNC_SI_CKSUM;

	offset += sizeof(*ph);
	while (offset <= len - sizeof(subh)) {
		m_copydata(m, offset, sizeof(subh), (caddr_t)&subh);
		offset += sizeof(subh);

		mlen = subh.len << 2;
		count = ntohs(subh.count);

		if (subh.action >= PFSYNC_ACT_MAX ||
		    subh.action >= nitems(pfsync_acts) ||
		    mlen < pfsync_acts[subh.action].len) {
			/*
			 * subheaders are always followed by at least one
			 * message, so if the peer is new
			 * enough to tell us how big its messages are then we
			 * know enough to skip them.
			 */
			if (count > 0 && mlen > 0) {
				offset += count * mlen;
				continue;
			}
			pfsyncstat_inc(pfsyncs_badact);
			goto done;
		}

		n = m_pulldown(m, offset, mlen * count, &noff);
		if (n == NULL) {
			pfsyncstat_inc(pfsyncs_badlen);
			return IPPROTO_DONE;
		}

		if (pfsync_acts[subh.action].in(n->m_data + noff,
		    mlen, count, flags) != 0)
			goto done;

		offset += mlen * count;
	}

done:
	m_freem(m);
	return IPPROTO_DONE;
}

int
pfsync_in_clr(caddr_t buf, int len, int count, int flags)
{
	struct pfsync_clr *clr;
	struct pf_state *st, *nexts;
	struct pfi_kif *kif;
	u_int32_t creatorid;
	int i;

	for (i = 0; i < count; i++) {
		clr = (struct pfsync_clr *)buf + len * i;
		kif = NULL;
		creatorid = clr->creatorid;
		if (strlen(clr->ifname) &&
		    (kif = pfi_kif_find(clr->ifname)) == NULL)
			continue;

		for (st = RB_MIN(pf_state_tree_id, &tree_id); st; st = nexts) {
			nexts = RB_NEXT(pf_state_tree_id, &tree_id, st);
			if (st->creatorid == creatorid &&
			    ((kif && st->kif == kif) || !kif)) {
				SET(st->state_flags, PFSTATE_NOSYNC);
				pf_remove_state(st);
			}
		}
	}

	return (0);
}

int
pfsync_in_ins(caddr_t buf, int len, int count, int flags)
{
	struct pfsync_state *sp;
	sa_family_t af1, af2;
	int i;

	for (i = 0; i < count; i++) {
		sp = (struct pfsync_state *)(buf + len * i);
		af1 = sp->key[0].af;
		af2 = sp->key[1].af;

		/* check for invalid values */
		if (sp->timeout >= PFTM_MAX ||
		    sp->src.state > PF_TCPS_PROXY_DST ||
		    sp->dst.state > PF_TCPS_PROXY_DST ||
		    sp->direction > PF_OUT ||
		    (((af1 || af2) &&
		     ((af1 != AF_INET && af1 != AF_INET6) ||
		      (af2 != AF_INET && af2 != AF_INET6))) ||
		    (sp->af != AF_INET && sp->af != AF_INET6))) {
			DPFPRINTF(LOG_NOTICE,
			    "pfsync_input: PFSYNC5_ACT_INS: invalid value");
			pfsyncstat_inc(pfsyncs_badval);
			continue;
		}

		if (pfsync_state_import(sp, flags) == ENOMEM) {
			/* drop out, but process the rest of the actions */
			break;
		}
	}

	return (0);
}

int
pfsync_in_iack(caddr_t buf, int len, int count, int flags)
{
	struct pfsync_ins_ack *ia;
	struct pf_state_cmp id_key;
	struct pf_state *st;
	int i;

	for (i = 0; i < count; i++) {
		ia = (struct pfsync_ins_ack *)(buf + len * i);

		id_key.id = ia->id;
		id_key.creatorid = ia->creatorid;

		st = pf_find_state_byid(&id_key);
		if (st == NULL)
			continue;

		if (ISSET(st->state_flags, PFSTATE_ACK))
			pfsync_deferred(st, 0);
	}

	return (0);
}

int
pfsync_upd_tcp(struct pf_state *st, struct pfsync_state_peer *src,
    struct pfsync_state_peer *dst)
{
	int sync = 0;

	/*
	 * The state should never go backwards except
	 * for syn-proxy states.  Neither should the
	 * sequence window slide backwards.
	 */
	if ((st->src.state > src->state &&
	    (st->src.state < PF_TCPS_PROXY_SRC ||
	    src->state >= PF_TCPS_PROXY_SRC)) ||

	    (st->src.state == src->state &&
	    SEQ_GT(st->src.seqlo, ntohl(src->seqlo))))
		sync++;
	else
		pf_state_peer_ntoh(src, &st->src);

	if ((st->dst.state > dst->state) ||

	    (st->dst.state >= TCPS_SYN_SENT &&
	    SEQ_GT(st->dst.seqlo, ntohl(dst->seqlo))))
		sync++;
	else
		pf_state_peer_ntoh(dst, &st->dst);

	return (sync);
}

int
pfsync_in_upd(caddr_t buf, int len, int count, int flags)
{
	struct pfsync_state *sp;
	struct pf_state_cmp id_key;
	struct pf_state *st;
	int sync;

	int i;

	for (i = 0; i < count; i++) {
		sp = (struct pfsync_state *)(buf + len * i);

		/* check for invalid values */
		if (sp->timeout >= PFTM_MAX ||
		    sp->src.state > PF_TCPS_PROXY_DST ||
		    sp->dst.state > PF_TCPS_PROXY_DST) {
			DPFPRINTF(LOG_NOTICE,
			    "pfsync_input: PFSYNC_ACT_UPD: invalid value");
			pfsyncstat_inc(pfsyncs_badval);
			continue;
		}

		id_key.id = sp->id;
		id_key.creatorid = sp->creatorid;

		st = pf_find_state_byid(&id_key);
		if (st == NULL) {
			/* insert the update */
			if (pfsync_state_import(sp, flags))
				pfsyncstat_inc(pfsyncs_badstate);
			continue;
		}

		if (ISSET(st->state_flags, PFSTATE_ACK))
			pfsync_deferred(st, 1);

		if (st->key[PF_SK_WIRE]->proto == IPPROTO_TCP)
			sync = pfsync_upd_tcp(st, &sp->src, &sp->dst);
		else {
			sync = 0;

			/*
			 * Non-TCP protocol state machine always go
			 * forwards
			 */
			if (st->src.state > sp->src.state)
				sync++;
			else
				pf_state_peer_ntoh(&sp->src, &st->src);

			if (st->dst.state > sp->dst.state)
				sync++;
			else
				pf_state_peer_ntoh(&sp->dst, &st->dst);
		}

		if (sync < 2) {
			pfsync_alloc_scrub_memory(&sp->dst, &st->dst);
			pf_state_peer_ntoh(&sp->dst, &st->dst);
			st->expire = time_uptime;
			st->timeout = sp->timeout;
		}
		st->pfsync_time = time_uptime;

		if (sync) {
			pfsyncstat_inc(pfsyncs_stale);

			pfsync_update_state(st);
			schednetisr(NETISR_PFSYNC);
		}
	}

	return (0);
}

int
pfsync_in_upd_c(caddr_t buf, int len, int count, int flags)
{
	struct pfsync_upd_c *up;
	struct pf_state_cmp id_key;
	struct pf_state *st;

	int sync;

	int i;

	for (i = 0; i < count; i++) {
		up = (struct pfsync_upd_c *)(buf + len * i);

		/* check for invalid values */
		if (up->timeout >= PFTM_MAX ||
		    up->src.state > PF_TCPS_PROXY_DST ||
		    up->dst.state > PF_TCPS_PROXY_DST) {
			DPFPRINTF(LOG_NOTICE,
			    "pfsync_input: PFSYNC_ACT_UPD_C: invalid value");
			pfsyncstat_inc(pfsyncs_badval);
			continue;
		}

		id_key.id = up->id;
		id_key.creatorid = up->creatorid;

		st = pf_find_state_byid(&id_key);
		if (st == NULL) {
			/* We don't have this state. Ask for it. */
			pfsync_request_update(id_key.creatorid, id_key.id);
			continue;
		}

		if (ISSET(st->state_flags, PFSTATE_ACK))
			pfsync_deferred(st, 1);

		if (st->key[PF_SK_WIRE]->proto == IPPROTO_TCP)
			sync = pfsync_upd_tcp(st, &up->src, &up->dst);
		else {
			sync = 0;
			/*
			 * Non-TCP protocol state machine always go
			 * forwards
			 */
			if (st->src.state > up->src.state)
				sync++;
			else
				pf_state_peer_ntoh(&up->src, &st->src);

			if (st->dst.state > up->dst.state)
				sync++;
			else
				pf_state_peer_ntoh(&up->dst, &st->dst);
		}
		if (sync < 2) {
			pfsync_alloc_scrub_memory(&up->dst, &st->dst);
			pf_state_peer_ntoh(&up->dst, &st->dst);
			st->expire = time_uptime;
			st->timeout = up->timeout;
		}
		st->pfsync_time = time_uptime;

		if (sync) {
			pfsyncstat_inc(pfsyncs_stale);

			pfsync_update_state(st);
			schednetisr(NETISR_PFSYNC);
		}
	}

	return (0);
}

int
pfsync_in_ureq(caddr_t buf, int len, int count, int flags)
{
	struct pfsync_upd_req *ur;
	int i;

	struct pf_state_cmp id_key;
	struct pf_state *st;

	for (i = 0; i < count; i++) {
		ur = (struct pfsync_upd_req *)(buf + len * i);

		id_key.id = ur->id;
		id_key.creatorid = ur->creatorid;

		if (id_key.id == 0 && id_key.creatorid == 0)
			pfsync_bulk_start();
		else {
			st = pf_find_state_byid(&id_key);
			if (st == NULL) {
				pfsyncstat_inc(pfsyncs_badstate);
				continue;
			}
			if (ISSET(st->state_flags, PFSTATE_NOSYNC))
				continue;

			pfsync_update_state_req(st);
		}
	}

	return (0);
}

int
pfsync_in_del(caddr_t buf, int len, int count, int flags)
{
	struct pfsync_state *sp;
	struct pf_state_cmp id_key;
	struct pf_state *st;
	int i;

	for (i = 0; i < count; i++) {
		sp = (struct pfsync_state *)(buf + len * i);

		id_key.id = sp->id;
		id_key.creatorid = sp->creatorid;

		st = pf_find_state_byid(&id_key);
		if (st == NULL) {
			pfsyncstat_inc(pfsyncs_badstate);
			continue;
		}
		SET(st->state_flags, PFSTATE_NOSYNC);
		pf_remove_state(st);
	}

	return (0);
}

int
pfsync_in_del_c(caddr_t buf, int len, int count, int flags)
{
	struct pfsync_del_c *sp;
	struct pf_state_cmp id_key;
	struct pf_state *st;
	int i;

	for (i = 0; i < count; i++) {
		sp = (struct pfsync_del_c *)(buf + len * i);

		id_key.id = sp->id;
		id_key.creatorid = sp->creatorid;

		st = pf_find_state_byid(&id_key);
		if (st == NULL) {
			pfsyncstat_inc(pfsyncs_badstate);
			continue;
		}

		SET(st->state_flags, PFSTATE_NOSYNC);
		pf_remove_state(st);
	}

	return (0);
}

int
pfsync_in_bus(caddr_t buf, int len, int count, int flags)
{
	struct pfsync_softc *sc = pfsyncif;
	struct pfsync_bus *bus;

	/* If we're not waiting for a bulk update, who cares. */
	if (sc->sc_ureq_sent == 0)
		return (0);

	bus = (struct pfsync_bus *)buf;

	switch (bus->status) {
	case PFSYNC_BUS_START:
		timeout_add(&sc->sc_bulkfail_tmo, 4 * hz +
		    pf_pool_limits[PF_LIMIT_STATES].limit /
		    ((sc->sc_if.if_mtu - PFSYNC_MINPKT) /
		    sizeof(struct pfsync_state)));
		DPFPRINTF(LOG_INFO, "received bulk update start");
		break;

	case PFSYNC_BUS_END:
		if (time_uptime - ntohl(bus->endtime) >=
		    sc->sc_ureq_sent) {
			/* that's it, we're happy */
			sc->sc_ureq_sent = 0;
			sc->sc_bulk_tries = 0;
			timeout_del(&sc->sc_bulkfail_tmo);
#if NCARP > 0
			if (!pfsync_sync_ok)
				carp_group_demote_adj(&sc->sc_if, -1,
				    sc->sc_link_demoted ?
				    "pfsync link state up" :
				    "pfsync bulk done");
			if (sc->sc_initial_bulk) {
				carp_group_demote_adj(&sc->sc_if, -32,
				    "pfsync init");
				sc->sc_initial_bulk = 0;
			}
#endif
			pfsync_sync_ok = 1;
			sc->sc_link_demoted = 0;
			DPFPRINTF(LOG_INFO, "received valid bulk update end");
		} else {
			DPFPRINTF(LOG_WARNING, "received invalid "
			    "bulk update end: bad timestamp");
		}
		break;
	}

	return (0);
}

int
pfsync_in_tdb(caddr_t buf, int len, int count, int flags)
{
#if defined(IPSEC)
	struct pfsync_tdb *tp;
	int i;

	for (i = 0; i < count; i++) {
		tp = (struct pfsync_tdb *)(buf + len * i);
		pfsync_update_net_tdb(tp);
	}
#endif

	return (0);
}

#if defined(IPSEC)
/* Update an in-kernel tdb. Silently fail if no tdb is found. */
void
pfsync_update_net_tdb(struct pfsync_tdb *pt)
{
	struct tdb		*tdb;

	splsoftassert(IPL_SOFTNET);

	/* check for invalid values */
	if (ntohl(pt->spi) <= SPI_RESERVED_MAX ||
	    (pt->dst.sa.sa_family != AF_INET &&
	     pt->dst.sa.sa_family != AF_INET6))
		goto bad;

	tdb = gettdb(ntohs(pt->rdomain), pt->spi,
	    (union sockaddr_union *)&pt->dst, pt->sproto);
	if (tdb) {
		pt->rpl = betoh64(pt->rpl);
		pt->cur_bytes = betoh64(pt->cur_bytes);

		/* Neither replay nor byte counter should ever decrease. */
		if (pt->rpl < tdb->tdb_rpl ||
		    pt->cur_bytes < tdb->tdb_cur_bytes) {
			goto bad;
		}

		tdb->tdb_rpl = pt->rpl;
		tdb->tdb_cur_bytes = pt->cur_bytes;
	}
	return;

 bad:
	DPFPRINTF(LOG_WARNING, "pfsync_insert: PFSYNC_ACT_TDB_UPD: "
	    "invalid value");
	pfsyncstat_inc(pfsyncs_badstate);
	return;
}
#endif


int
pfsync_in_eof(caddr_t buf, int len, int count, int flags)
{
	if (len > 0 || count > 0)
		pfsyncstat_inc(pfsyncs_badact);

	/* we're done. let the caller return */
	return (1);
}

int
pfsync_in_error(caddr_t buf, int len, int count, int flags)
{
	pfsyncstat_inc(pfsyncs_badact);
	return (-1);
}

int
pfsyncoutput(struct ifnet *ifp, struct mbuf *m, struct sockaddr *dst,
	struct rtentry *rt)
{
	m_freem(m);	/* drop packet */
	return (EAFNOSUPPORT);
}

int
pfsyncioctl(struct ifnet *ifp, u_long cmd, caddr_t data)
{
	struct proc *p = curproc;
	struct pfsync_softc *sc = ifp->if_softc;
	struct ifreq *ifr = (struct ifreq *)data;
	struct ip_moptions *imo = &sc->sc_imo;
	struct pfsyncreq pfsyncr;
	struct ifnet    *sifp;
	struct ip *ip;
	int s, error;

	switch (cmd) {
#if 0
	case SIOCSIFADDR:
	case SIOCSIFDSTADDR:
#endif
	case SIOCSIFFLAGS:
		s = splnet();
		if ((ifp->if_flags & IFF_RUNNING) == 0 &&
		    (ifp->if_flags & IFF_UP)) {
			ifp->if_flags |= IFF_RUNNING;

#if NCARP > 0
			sc->sc_initial_bulk = 1;
			carp_group_demote_adj(&sc->sc_if, 32, "pfsync init");
#endif

			pfsync_request_full_update(sc);
		}
		if ((ifp->if_flags & IFF_RUNNING) &&
		    (ifp->if_flags & IFF_UP) == 0) {
			ifp->if_flags &= ~IFF_RUNNING;

			/* drop everything */
			timeout_del(&sc->sc_tmo);
			pfsync_drop(sc);

			pfsync_cancel_full_update(sc);
		}
		splx(s);
		break;
	case SIOCSIFMTU:
		if (!sc->sc_sync_if ||
		    ifr->ifr_mtu <= PFSYNC_MINPKT ||
		    ifr->ifr_mtu > sc->sc_sync_if->if_mtu)
			return (EINVAL);
		s = splnet();
		if (ifr->ifr_mtu < ifp->if_mtu)
			pfsync_sendout();
		ifp->if_mtu = ifr->ifr_mtu;
		splx(s);
		break;
	case SIOCGETPFSYNC:
		bzero(&pfsyncr, sizeof(pfsyncr));
		if (sc->sc_sync_if) {
			strlcpy(pfsyncr.pfsyncr_syncdev,
			    sc->sc_sync_if->if_xname, IFNAMSIZ);
		}
		pfsyncr.pfsyncr_syncpeer = sc->sc_sync_peer;
		pfsyncr.pfsyncr_maxupdates = sc->sc_maxupdates;
		pfsyncr.pfsyncr_defer = sc->sc_defer;
		return (copyout(&pfsyncr, ifr->ifr_data, sizeof(pfsyncr)));

	case SIOCSETPFSYNC:
		if ((error = suser(p, 0)) != 0)
			return (error);
		if ((error = copyin(ifr->ifr_data, &pfsyncr, sizeof(pfsyncr))))
			return (error);

		s = splnet();

		if (pfsyncr.pfsyncr_syncpeer.s_addr == 0)
			sc->sc_sync_peer.s_addr = INADDR_PFSYNC_GROUP;
		else
			sc->sc_sync_peer.s_addr =
			    pfsyncr.pfsyncr_syncpeer.s_addr;

		if (pfsyncr.pfsyncr_maxupdates > 255) {
			splx(s);
			return (EINVAL);
		}
		sc->sc_maxupdates = pfsyncr.pfsyncr_maxupdates;

		sc->sc_defer = pfsyncr.pfsyncr_defer;

		if (pfsyncr.pfsyncr_syncdev[0] == 0) {
			if (sc->sc_sync_if) {
				hook_disestablish(
				    sc->sc_sync_if->if_linkstatehooks,
				    sc->sc_lhcookie);
				hook_disestablish(
				    sc->sc_sync_if->if_detachhooks,
				    sc->sc_dhcookie);
			}
			sc->sc_sync_if = NULL;
			if (imo->imo_num_memberships > 0) {
				in_delmulti(imo->imo_membership[
				    --imo->imo_num_memberships]);
				imo->imo_ifidx = 0;
			}
			splx(s);
			break;
		}

		if ((sifp = ifunit(pfsyncr.pfsyncr_syncdev)) == NULL) {
			splx(s);
			return (EINVAL);
		}

		if (sifp->if_mtu < sc->sc_if.if_mtu ||
		    (sc->sc_sync_if != NULL &&
		    sifp->if_mtu < sc->sc_sync_if->if_mtu) ||
		    sifp->if_mtu < MCLBYTES - sizeof(struct ip))
			pfsync_sendout();

		if (sc->sc_sync_if) {
			hook_disestablish(
			    sc->sc_sync_if->if_linkstatehooks,
			    sc->sc_lhcookie);
			hook_disestablish(
			    sc->sc_sync_if->if_detachhooks,
			    sc->sc_dhcookie);
		}
		sc->sc_sync_if = sifp;

		if (imo->imo_num_memberships > 0) {
			in_delmulti(imo->imo_membership[--imo->imo_num_memberships]);
			imo->imo_ifidx = 0;
		}

		if (sc->sc_sync_if &&
		    sc->sc_sync_peer.s_addr == INADDR_PFSYNC_GROUP) {
			struct in_addr addr;

			if (!(sc->sc_sync_if->if_flags & IFF_MULTICAST)) {
				sc->sc_sync_if = NULL;
				splx(s);
				return (EADDRNOTAVAIL);
			}

			addr.s_addr = INADDR_PFSYNC_GROUP;

			if ((imo->imo_membership[0] =
			    in_addmulti(&addr, sc->sc_sync_if)) == NULL) {
				sc->sc_sync_if = NULL;
				splx(s);
				return (ENOBUFS);
			}
			imo->imo_num_memberships++;
			imo->imo_ifidx = sc->sc_sync_if->if_index;
			imo->imo_ttl = PFSYNC_DFLTTL;
			imo->imo_loop = 0;
		}

		ip = &sc->sc_template;
		bzero(ip, sizeof(*ip));
		ip->ip_v = IPVERSION;
		ip->ip_hl = sizeof(sc->sc_template) >> 2;
		ip->ip_tos = IPTOS_LOWDELAY;
		/* len and id are set later */
		ip->ip_off = htons(IP_DF);
		ip->ip_ttl = PFSYNC_DFLTTL;
		ip->ip_p = IPPROTO_PFSYNC;
		ip->ip_src.s_addr = INADDR_ANY;
		ip->ip_dst.s_addr = sc->sc_sync_peer.s_addr;

		sc->sc_lhcookie =
		    hook_establish(sc->sc_sync_if->if_linkstatehooks, 1,
		    pfsync_syncdev_state, sc);
		sc->sc_dhcookie = hook_establish(sc->sc_sync_if->if_detachhooks,
		    0, pfsync_ifdetach, sc);

		pfsync_request_full_update(sc);
		splx(s);

		break;

	default:
		return (ENOTTY);
	}

	return (0);
}

void
pfsync_out_state(struct pf_state *st, void *buf)
{
	struct pfsync_state *sp = buf;

	pfsync_state_export(sp, st);
}

void
pfsync_out_iack(struct pf_state *st, void *buf)
{
	struct pfsync_ins_ack *iack = buf;

	iack->id = st->id;
	iack->creatorid = st->creatorid;
}

void
pfsync_out_upd_c(struct pf_state *st, void *buf)
{
	struct pfsync_upd_c *up = buf;

	bzero(up, sizeof(*up));
	up->id = st->id;
	pf_state_peer_hton(&st->src, &up->src);
	pf_state_peer_hton(&st->dst, &up->dst);
	up->creatorid = st->creatorid;
	up->timeout = st->timeout;
}

void
pfsync_out_del(struct pf_state *st, void *buf)
{
	struct pfsync_del_c *dp = buf;

	dp->id = st->id;
	dp->creatorid = st->creatorid;

	SET(st->state_flags, PFSTATE_NOSYNC);
}

void
pfsync_drop(struct pfsync_softc *sc)
{
	struct pf_state *st;
	struct pfsync_upd_req_item *ur;
	struct tdb *t;
	int q;

	for (q = 0; q < PFSYNC_S_COUNT; q++) {
		if (TAILQ_EMPTY(&sc->sc_qs[q]))
			continue;

		TAILQ_FOREACH(st, &sc->sc_qs[q], sync_list) {
#ifdef PFSYNC_DEBUG
			KASSERT(st->sync_state == q);
#endif
			st->sync_state = PFSYNC_S_NONE;
		}
		TAILQ_INIT(&sc->sc_qs[q]);
	}

	while ((ur = TAILQ_FIRST(&sc->sc_upd_req_list)) != NULL) {
		TAILQ_REMOVE(&sc->sc_upd_req_list, ur, ur_entry);
		pool_put(&sc->sc_pool, ur);
	}

	sc->sc_plus = NULL;

	if (!TAILQ_EMPTY(&sc->sc_tdb_q)) {
		TAILQ_FOREACH(t, &sc->sc_tdb_q, tdb_sync_entry)
			CLR(t->tdb_flags, TDBF_PFSYNC);

		TAILQ_INIT(&sc->sc_tdb_q);
	}

	sc->sc_len = PFSYNC_MINPKT;
}

void
pfsync_sendout(void)
{
	struct pfsync_softc *sc = pfsyncif;
#if NBPFILTER > 0
	struct ifnet *ifp = &sc->sc_if;
#endif
	struct mbuf *m;
	struct ip *ip;
	struct pfsync_header *ph;
	struct pfsync_subheader *subh;
	struct pf_state *st;
	struct pfsync_upd_req_item *ur;
	struct tdb *t;

	int offset;
	int q, count = 0;

	if (sc == NULL || sc->sc_len == PFSYNC_MINPKT)
		return;

	if (!ISSET(sc->sc_if.if_flags, IFF_RUNNING) ||
#if NBPFILTER > 0
	    (ifp->if_bpf == NULL && sc->sc_sync_if == NULL)) {
#else
	    sc->sc_sync_if == NULL) {
#endif
		pfsync_drop(sc);
		return;
	}

	MGETHDR(m, M_DONTWAIT, MT_DATA);
	if (m == NULL) {
		sc->sc_if.if_oerrors++;
		pfsyncstat_inc(pfsyncs_onomem);
		pfsync_drop(sc);
		return;
	}

	if (max_linkhdr + sc->sc_len > MHLEN) {
		MCLGETI(m, M_DONTWAIT, NULL, max_linkhdr + sc->sc_len);
		if (!ISSET(m->m_flags, M_EXT)) {
			m_free(m);
			sc->sc_if.if_oerrors++;
			pfsyncstat_inc(pfsyncs_onomem);
			pfsync_drop(sc);
			return;
		}
	}
	m->m_data += max_linkhdr;
	m->m_len = m->m_pkthdr.len = sc->sc_len;

	/* build the ip header */
	ip = mtod(m, struct ip *);
	bcopy(&sc->sc_template, ip, sizeof(*ip));
	offset = sizeof(*ip);

	ip->ip_len = htons(m->m_pkthdr.len);
	ip->ip_id = htons(ip_randomid());

	/* build the pfsync header */
	ph = (struct pfsync_header *)(m->m_data + offset);
	bzero(ph, sizeof(*ph));
	offset += sizeof(*ph);

	ph->version = PFSYNC_VERSION;
	ph->len = htons(sc->sc_len - sizeof(*ip));
	bcopy(pf_status.pf_chksum, ph->pfcksum, PF_MD5_DIGEST_LENGTH);

	if (!TAILQ_EMPTY(&sc->sc_upd_req_list)) {
		subh = (struct pfsync_subheader *)(m->m_data + offset);
		offset += sizeof(*subh);

		count = 0;
		while ((ur = TAILQ_FIRST(&sc->sc_upd_req_list)) != NULL) {
			TAILQ_REMOVE(&sc->sc_upd_req_list, ur, ur_entry);

			bcopy(&ur->ur_msg, m->m_data + offset,
			    sizeof(ur->ur_msg));
			offset += sizeof(ur->ur_msg);

			pool_put(&sc->sc_pool, ur);

			count++;
		}

		bzero(subh, sizeof(*subh));
		subh->len = sizeof(ur->ur_msg) >> 2;
		subh->action = PFSYNC_ACT_UPD_REQ;
		subh->count = htons(count);
	}

	/* has someone built a custom region for us to add? */
	if (sc->sc_plus != NULL) {
		bcopy(sc->sc_plus, m->m_data + offset, sc->sc_pluslen);
		offset += sc->sc_pluslen;

		sc->sc_plus = NULL;
	}

	if (!TAILQ_EMPTY(&sc->sc_tdb_q)) {
		subh = (struct pfsync_subheader *)(m->m_data + offset);
		offset += sizeof(*subh);

		count = 0;
		TAILQ_FOREACH(t, &sc->sc_tdb_q, tdb_sync_entry) {
			pfsync_out_tdb(t, m->m_data + offset);
			offset += sizeof(struct pfsync_tdb);
			CLR(t->tdb_flags, TDBF_PFSYNC);

			count++;
		}
		TAILQ_INIT(&sc->sc_tdb_q);

		bzero(subh, sizeof(*subh));
		subh->action = PFSYNC_ACT_TDB;
		subh->len = sizeof(struct pfsync_tdb) >> 2;
		subh->count = htons(count);
	}

	/* walk the queues */
	for (q = 0; q < PFSYNC_S_COUNT; q++) {
		if (TAILQ_EMPTY(&sc->sc_qs[q]))
			continue;

		subh = (struct pfsync_subheader *)(m->m_data + offset);
		offset += sizeof(*subh);

		count = 0;
		TAILQ_FOREACH(st, &sc->sc_qs[q], sync_list) {
#ifdef PFSYNC_DEBUG
			KASSERT(st->sync_state == q);
#endif
			pfsync_qs[q].write(st, m->m_data + offset);
			offset += pfsync_qs[q].len;

			st->sync_state = PFSYNC_S_NONE;
			count++;
		}
		TAILQ_INIT(&sc->sc_qs[q]);

		bzero(subh, sizeof(*subh));
		subh->action = pfsync_qs[q].action;
		subh->len = pfsync_qs[q].len >> 2;
		subh->count = htons(count);
	}

	/* we're done, let's put it on the wire */
#if NBPFILTER > 0
	if (ifp->if_bpf) {
		m->m_data += sizeof(*ip);
		m->m_len = m->m_pkthdr.len = sc->sc_len - sizeof(*ip);
		bpf_mtap(ifp->if_bpf, m, BPF_DIRECTION_OUT);
		m->m_data -= sizeof(*ip);
		m->m_len = m->m_pkthdr.len = sc->sc_len;
	}

	if (sc->sc_sync_if == NULL) {
		sc->sc_len = PFSYNC_MINPKT;
		m_freem(m);
		return;
	}
#endif

	/* start again */
	sc->sc_len = PFSYNC_MINPKT;

	sc->sc_if.if_opackets++;
	sc->sc_if.if_obytes += m->m_pkthdr.len;

	m->m_pkthdr.ph_rtableid = sc->sc_if.if_rdomain;

	if (ip_output(m, NULL, NULL, IP_RAWOUTPUT, &sc->sc_imo, NULL, 0) == 0)
		pfsyncstat_inc(pfsyncs_opackets);
	else
		pfsyncstat_inc(pfsyncs_oerrors);
}

void
pfsync_insert_state(struct pf_state *st)
{
	struct pfsync_softc *sc = pfsyncif;

	splsoftassert(IPL_SOFTNET);

	if (ISSET(st->rule.ptr->rule_flag, PFRULE_NOSYNC) ||
	    st->key[PF_SK_WIRE]->proto == IPPROTO_PFSYNC) {
		SET(st->state_flags, PFSTATE_NOSYNC);
		return;
	}

	if (sc == NULL || !ISSET(sc->sc_if.if_flags, IFF_RUNNING) ||
	    ISSET(st->state_flags, PFSTATE_NOSYNC))
		return;

#ifdef PFSYNC_DEBUG
	KASSERT(st->sync_state == PFSYNC_S_NONE);
#endif

	if (sc->sc_len == PFSYNC_MINPKT)
		timeout_add_sec(&sc->sc_tmo, 1);

	pfsync_q_ins(st, PFSYNC_S_INS);

	st->sync_updates = 0;
}

int
pfsync_defer(struct pf_state *st, struct mbuf *m)
{
	struct pfsync_softc *sc = pfsyncif;
	struct pfsync_deferral *pd;

	splsoftassert(IPL_SOFTNET);

	if (!sc->sc_defer ||
	    ISSET(st->state_flags, PFSTATE_NOSYNC) ||
	    m->m_flags & (M_BCAST|M_MCAST))
		return (0);

	if (sc->sc_deferred >= 128) {
		pd = TAILQ_FIRST(&sc->sc_deferrals);
		if (timeout_del(&pd->pd_tmo))
			pfsync_undefer(pd, 0);
	}

	pd = pool_get(&sc->sc_pool, M_NOWAIT);
	if (pd == NULL)
		return (0);

	m->m_pkthdr.pf.flags |= PF_TAG_GENERATED;
	SET(st->state_flags, PFSTATE_ACK);

	pd->pd_st = st;
	pd->pd_m = m;

	sc->sc_deferred++;
	TAILQ_INSERT_TAIL(&sc->sc_deferrals, pd, pd_entry);

	timeout_set_proc(&pd->pd_tmo, pfsync_defer_tmo, pd);
	timeout_add_msec(&pd->pd_tmo, 20);

	schednetisr(NETISR_PFSYNC);

	return (1);
}

void
pfsync_undefer(struct pfsync_deferral *pd, int drop)
{
	struct pfsync_softc *sc = pfsyncif;
	struct pf_pdesc pdesc;

	splsoftassert(IPL_SOFTNET);

	TAILQ_REMOVE(&sc->sc_deferrals, pd, pd_entry);
	sc->sc_deferred--;

	CLR(pd->pd_st->state_flags, PFSTATE_ACK);
	if (drop)
		m_freem(pd->pd_m);
	else {
		if (pd->pd_st->rule.ptr->rt == PF_ROUTETO) {
			if (pf_setup_pdesc(&pdesc,
			    pd->pd_st->key[PF_SK_WIRE]->af,
			    pd->pd_st->direction, pd->pd_st->rt_kif,
			    pd->pd_m, NULL) != PF_PASS) {
				m_freem(pd->pd_m);
				goto out;
			}
			switch (pd->pd_st->key[PF_SK_WIRE]->af) {
			case AF_INET:
				pf_route(&pdesc,
				    pd->pd_st->rule.ptr, pd->pd_st);
				break;
#ifdef INET6
			case AF_INET6:
				pf_route6(&pdesc,
				    pd->pd_st->rule.ptr, pd->pd_st);
				break;
#endif /* INET6 */
			}
			pd->pd_m = pdesc.m;
		} else {
			switch (pd->pd_st->key[PF_SK_WIRE]->af) {
			case AF_INET:
				ip_output(pd->pd_m, NULL, NULL, 0, NULL, NULL,
				    0);
				break;
#ifdef INET6
			case AF_INET6:
				ip6_output(pd->pd_m, NULL, NULL, 0,
				    NULL, NULL);
				break;
#endif /* INET6 */
			}
		}
	}
 out:
	pool_put(&sc->sc_pool, pd);
}

void
pfsync_defer_tmo(void *arg)
{
	int s;

	NET_LOCK(s);
	pfsync_undefer(arg, 0);
	NET_UNLOCK(s);
}

void
pfsync_deferred(struct pf_state *st, int drop)
{
	struct pfsync_softc *sc = pfsyncif;
	struct pfsync_deferral *pd;

	splsoftassert(IPL_SOFTNET);

	TAILQ_FOREACH(pd, &sc->sc_deferrals, pd_entry) {
		 if (pd->pd_st == st) {
			if (timeout_del(&pd->pd_tmo))
				pfsync_undefer(pd, drop);
			return;
		}
	}

	panic("pfsync_deferred: unable to find deferred state");
}

void
pfsync_update_state(struct pf_state *st)
{
	struct pfsync_softc *sc = pfsyncif;
	int sync = 0;

	splsoftassert(IPL_SOFTNET);

	if (sc == NULL || !ISSET(sc->sc_if.if_flags, IFF_RUNNING))
		return;

	if (ISSET(st->state_flags, PFSTATE_ACK))
		pfsync_deferred(st, 0);
	if (ISSET(st->state_flags, PFSTATE_NOSYNC)) {
		if (st->sync_state != PFSYNC_S_NONE)
			pfsync_q_del(st);
		return;
	}

	if (sc->sc_len == PFSYNC_MINPKT)
		timeout_add_sec(&sc->sc_tmo, 1);

	switch (st->sync_state) {
	case PFSYNC_S_UPD_C:
	case PFSYNC_S_UPD:
	case PFSYNC_S_INS:
		/* we're already handling it */

		if (st->key[PF_SK_WIRE]->proto == IPPROTO_TCP) {
			st->sync_updates++;
			if (st->sync_updates >= sc->sc_maxupdates)
				sync = 1;
		}
		break;

	case PFSYNC_S_IACK:
		pfsync_q_del(st);
	case PFSYNC_S_NONE:
		pfsync_q_ins(st, PFSYNC_S_UPD_C);
		st->sync_updates = 0;
		break;

	default:
		panic("pfsync_update_state: unexpected sync state %d",
		    st->sync_state);
	}

	if (sync || (time_uptime - st->pfsync_time) < 2)
		schednetisr(NETISR_PFSYNC);
}

void
pfsync_cancel_full_update(struct pfsync_softc *sc)
{
	if (timeout_pending(&sc->sc_bulkfail_tmo) ||
	    timeout_pending(&sc->sc_bulk_tmo)) {
#if NCARP > 0
		if (!pfsync_sync_ok)
			carp_group_demote_adj(&sc->sc_if, -1,
			    "pfsync bulk cancelled");
		if (sc->sc_initial_bulk) {
			carp_group_demote_adj(&sc->sc_if, -32,
			    "pfsync init");
			sc->sc_initial_bulk = 0;
		}
#endif
		pfsync_sync_ok = 1;
		DPFPRINTF(LOG_INFO, "cancelling bulk update");
	}
	timeout_del(&sc->sc_bulkfail_tmo);
	timeout_del(&sc->sc_bulk_tmo);
	sc->sc_bulk_next = NULL;
	sc->sc_bulk_last = NULL;
	sc->sc_ureq_sent = 0;
	sc->sc_bulk_tries = 0;
}

void
pfsync_request_full_update(struct pfsync_softc *sc)
{
	if (sc->sc_sync_if && ISSET(sc->sc_if.if_flags, IFF_RUNNING)) {
		/* Request a full state table update. */
		sc->sc_ureq_sent = time_uptime;
#if NCARP > 0
		if (!sc->sc_link_demoted && pfsync_sync_ok)
			carp_group_demote_adj(&sc->sc_if, 1,
			    "pfsync bulk start");
#endif
		pfsync_sync_ok = 0;
		DPFPRINTF(LOG_INFO, "requesting bulk update");
		timeout_add(&sc->sc_bulkfail_tmo, 4 * hz +
		    pf_pool_limits[PF_LIMIT_STATES].limit /
		    ((sc->sc_if.if_mtu - PFSYNC_MINPKT) /
		    sizeof(struct pfsync_state)));
		pfsync_request_update(0, 0);
	}
}

void
pfsync_request_update(u_int32_t creatorid, u_int64_t id)
{
	struct pfsync_softc *sc = pfsyncif;
	struct pfsync_upd_req_item *item;
	size_t nlen = sizeof(struct pfsync_upd_req);

	/*
	 * this code does nothing to prevent multiple update requests for the
	 * same state being generated.
	 */

	item = pool_get(&sc->sc_pool, PR_NOWAIT);
	if (item == NULL) {
		/* XXX stats */
		return;
	}

	item->ur_msg.id = id;
	item->ur_msg.creatorid = creatorid;

	if (TAILQ_EMPTY(&sc->sc_upd_req_list))
		nlen += sizeof(struct pfsync_subheader);

	if (sc->sc_len + nlen > sc->sc_if.if_mtu) {
		pfsync_sendout();

		nlen = sizeof(struct pfsync_subheader) +
		    sizeof(struct pfsync_upd_req);
	}

	TAILQ_INSERT_TAIL(&sc->sc_upd_req_list, item, ur_entry);
	sc->sc_len += nlen;

	schednetisr(NETISR_PFSYNC);
}

void
pfsync_update_state_req(struct pf_state *st)
{
	struct pfsync_softc *sc = pfsyncif;

	if (sc == NULL)
		panic("pfsync_update_state_req: nonexistant instance");

	if (ISSET(st->state_flags, PFSTATE_NOSYNC)) {
		if (st->sync_state != PFSYNC_S_NONE)
			pfsync_q_del(st);
		return;
	}

	switch (st->sync_state) {
	case PFSYNC_S_UPD_C:
	case PFSYNC_S_IACK:
		pfsync_q_del(st);
	case PFSYNC_S_NONE:
		pfsync_q_ins(st, PFSYNC_S_UPD);
		schednetisr(NETISR_PFSYNC);
		return;

	case PFSYNC_S_INS:
	case PFSYNC_S_UPD:
	case PFSYNC_S_DEL:
		/* we're already handling it */
		return;

	default:
		panic("pfsync_update_state_req: unexpected sync state %d",
		    st->sync_state);
	}
}

void
pfsync_delete_state(struct pf_state *st)
{
	struct pfsync_softc *sc = pfsyncif;

	splsoftassert(IPL_SOFTNET);

	if (sc == NULL || !ISSET(sc->sc_if.if_flags, IFF_RUNNING))
		return;

	if (ISSET(st->state_flags, PFSTATE_ACK))
		pfsync_deferred(st, 1);
	if (ISSET(st->state_flags, PFSTATE_NOSYNC)) {
		if (st->sync_state != PFSYNC_S_NONE)
			pfsync_q_del(st);
		return;
	}

	if (sc->sc_len == PFSYNC_MINPKT)
		timeout_add_sec(&sc->sc_tmo, 1);

	switch (st->sync_state) {
	case PFSYNC_S_INS:
		/* we never got to tell the world so just forget about it */
		pfsync_q_del(st);
		return;

	case PFSYNC_S_UPD_C:
	case PFSYNC_S_UPD:
	case PFSYNC_S_IACK:
		pfsync_q_del(st);
		/* FALLTHROUGH to putting it on the del list */

	case PFSYNC_S_NONE:
		pfsync_q_ins(st, PFSYNC_S_DEL);
		return;

	default:
		panic("pfsync_delete_state: unexpected sync state %d",
		    st->sync_state);
	}
}

void
pfsync_clear_states(u_int32_t creatorid, const char *ifname)
{
	struct pfsync_softc *sc = pfsyncif;
	struct {
		struct pfsync_subheader subh;
		struct pfsync_clr clr;
	} __packed r;

	splsoftassert(IPL_SOFTNET);

	if (sc == NULL || !ISSET(sc->sc_if.if_flags, IFF_RUNNING))
		return;

	bzero(&r, sizeof(r));

	r.subh.action = PFSYNC_ACT_CLR;
	r.subh.len = sizeof(struct pfsync_clr) >> 2;
	r.subh.count = htons(1);

	strlcpy(r.clr.ifname, ifname, sizeof(r.clr.ifname));
	r.clr.creatorid = creatorid;

	pfsync_send_plus(&r, sizeof(r));
}

void
pfsync_q_ins(struct pf_state *st, int q)
{
	struct pfsync_softc *sc = pfsyncif;
	size_t nlen = pfsync_qs[q].len;

	KASSERT(st->sync_state == PFSYNC_S_NONE);

#if defined(PFSYNC_DEBUG)
	if (sc->sc_len < PFSYNC_MINPKT)
		panic("pfsync pkt len is too low %d", sc->sc_len);
#endif
	if (TAILQ_EMPTY(&sc->sc_qs[q]))
		nlen += sizeof(struct pfsync_subheader);

	if (sc->sc_len + nlen > sc->sc_if.if_mtu) {
		pfsync_sendout();

		nlen = sizeof(struct pfsync_subheader) + pfsync_qs[q].len;
	}

	sc->sc_len += nlen;
	TAILQ_INSERT_TAIL(&sc->sc_qs[q], st, sync_list);
	st->sync_state = q;
}

void
pfsync_q_del(struct pf_state *st)
{
	struct pfsync_softc *sc = pfsyncif;
	int q = st->sync_state;

	KASSERT(st->sync_state != PFSYNC_S_NONE);

	sc->sc_len -= pfsync_qs[q].len;
	TAILQ_REMOVE(&sc->sc_qs[q], st, sync_list);
	st->sync_state = PFSYNC_S_NONE;

	if (TAILQ_EMPTY(&sc->sc_qs[q]))
		sc->sc_len -= sizeof(struct pfsync_subheader);
}

void
pfsync_update_tdb(struct tdb *t, int output)
{
	struct pfsync_softc *sc = pfsyncif;
	size_t nlen = sizeof(struct pfsync_tdb);

	if (sc == NULL)
		return;

	if (!ISSET(t->tdb_flags, TDBF_PFSYNC)) {
		if (TAILQ_EMPTY(&sc->sc_tdb_q))
			nlen += sizeof(struct pfsync_subheader);

		if (sc->sc_len + nlen > sc->sc_if.if_mtu) {
			pfsync_sendout();

			nlen = sizeof(struct pfsync_subheader) +
			    sizeof(struct pfsync_tdb);
		}

		sc->sc_len += nlen;
		TAILQ_INSERT_TAIL(&sc->sc_tdb_q, t, tdb_sync_entry);
		SET(t->tdb_flags, TDBF_PFSYNC);
		t->tdb_updates = 0;
	} else {
		if (++t->tdb_updates >= sc->sc_maxupdates)
			schednetisr(NETISR_PFSYNC);
	}

	if (output)
		SET(t->tdb_flags, TDBF_PFSYNC_RPL);
	else
		CLR(t->tdb_flags, TDBF_PFSYNC_RPL);
}

void
pfsync_delete_tdb(struct tdb *t)
{
	struct pfsync_softc *sc = pfsyncif;

	if (sc == NULL || !ISSET(t->tdb_flags, TDBF_PFSYNC))
		return;

	sc->sc_len -= sizeof(struct pfsync_tdb);
	TAILQ_REMOVE(&sc->sc_tdb_q, t, tdb_sync_entry);
	CLR(t->tdb_flags, TDBF_PFSYNC);

	if (TAILQ_EMPTY(&sc->sc_tdb_q))
		sc->sc_len -= sizeof(struct pfsync_subheader);
}

void
pfsync_out_tdb(struct tdb *t, void *buf)
{
	struct pfsync_tdb *ut = buf;

	bzero(ut, sizeof(*ut));
	ut->spi = t->tdb_spi;
	bcopy(&t->tdb_dst, &ut->dst, sizeof(ut->dst));
	/*
	 * When a failover happens, the master's rpl is probably above
	 * what we see here (we may be up to a second late), so
	 * increase it a bit for outbound tdbs to manage most such
	 * situations.
	 *
	 * For now, just add an offset that is likely to be larger
	 * than the number of packets we can see in one second. The RFC
	 * just says the next packet must have a higher seq value.
	 *
	 * XXX What is a good algorithm for this? We could use
	 * a rate-determined increase, but to know it, we would have
	 * to extend struct tdb.
	 * XXX pt->rpl can wrap over MAXINT, but if so the real tdb
	 * will soon be replaced anyway. For now, just don't handle
	 * this edge case.
	 */
#define RPL_INCR 16384
	ut->rpl = htobe64(t->tdb_rpl + (ISSET(t->tdb_flags, TDBF_PFSYNC_RPL) ?
	    RPL_INCR : 0));
	ut->cur_bytes = htobe64(t->tdb_cur_bytes);
	ut->sproto = t->tdb_sproto;
	ut->rdomain = htons(t->tdb_rdomain);
}

void
pfsync_bulk_start(void)
{
	struct pfsync_softc *sc = pfsyncif;

	DPFPRINTF(LOG_INFO, "received bulk update request");

	if (TAILQ_EMPTY(&state_list))
		pfsync_bulk_status(PFSYNC_BUS_END);
	else {
		sc->sc_ureq_received = time_uptime;

		if (sc->sc_bulk_next == NULL)
			sc->sc_bulk_next = TAILQ_FIRST(&state_list);
		sc->sc_bulk_last = sc->sc_bulk_next;

		pfsync_bulk_status(PFSYNC_BUS_START);
		timeout_add(&sc->sc_bulk_tmo, 0);
	}
}

void
pfsync_bulk_update(void *arg)
{
	struct pfsync_softc *sc = arg;
	struct pf_state *st;
	int i = 0;
	int s;

	NET_LOCK(s);
	st = sc->sc_bulk_next;

	for (;;) {
		if (st->sync_state == PFSYNC_S_NONE &&
		    st->timeout < PFTM_MAX &&
		    st->pfsync_time <= sc->sc_ureq_received) {
			pfsync_update_state_req(st);
			i++;
		}

		st = TAILQ_NEXT(st, entry_list);
		if (st == NULL)
			st = TAILQ_FIRST(&state_list);

		if (st == sc->sc_bulk_last) {
			/* we're done */
			sc->sc_bulk_next = NULL;
			sc->sc_bulk_last = NULL;
			pfsync_bulk_status(PFSYNC_BUS_END);
			break;
		}

		if (i > 1 && (sc->sc_if.if_mtu - sc->sc_len) <
		    sizeof(struct pfsync_state)) {
			/* we've filled a packet */
			sc->sc_bulk_next = st;
			timeout_add(&sc->sc_bulk_tmo, 1);
			break;
		}
	}
	NET_UNLOCK(s);
}

void
pfsync_bulk_status(u_int8_t status)
{
	struct {
		struct pfsync_subheader subh;
		struct pfsync_bus bus;
	} __packed r;

	struct pfsync_softc *sc = pfsyncif;

	bzero(&r, sizeof(r));

	r.subh.action = PFSYNC_ACT_BUS;
	r.subh.len = sizeof(struct pfsync_bus) >> 2;
	r.subh.count = htons(1);

	r.bus.creatorid = pf_status.hostid;
	r.bus.endtime = htonl(time_uptime - sc->sc_ureq_received);
	r.bus.status = status;

	pfsync_send_plus(&r, sizeof(r));
}

void
pfsync_bulk_fail(void *arg)
{
	struct pfsync_softc *sc = arg;
	int s;

	NET_LOCK(s);

	if (sc->sc_bulk_tries++ < PFSYNC_MAX_BULKTRIES) {
		/* Try again */
		timeout_add_sec(&sc->sc_bulkfail_tmo, 5);
		pfsync_request_update(0, 0);
	} else {
		/* Pretend like the transfer was ok */
		sc->sc_ureq_sent = 0;
		sc->sc_bulk_tries = 0;
#if NCARP > 0
		if (!pfsync_sync_ok)
			carp_group_demote_adj(&sc->sc_if, -1,
			    sc->sc_link_demoted ?
			    "pfsync link state up" :
			    "pfsync bulk fail");
		if (sc->sc_initial_bulk) {
			carp_group_demote_adj(&sc->sc_if, -32,
			    "pfsync init");
			sc->sc_initial_bulk = 0;
		}
#endif
		pfsync_sync_ok = 1;
		sc->sc_link_demoted = 0;
		DPFPRINTF(LOG_ERR, "failed to receive bulk update");
	}
	NET_UNLOCK(s);
}

void
pfsync_send_plus(void *plus, size_t pluslen)
{
	struct pfsync_softc *sc = pfsyncif;

	if (sc->sc_len + pluslen > sc->sc_if.if_mtu)
		pfsync_sendout();

	sc->sc_plus = plus;
	sc->sc_len += (sc->sc_pluslen = pluslen);

	pfsync_sendout();
}

int
pfsync_up(void)
{
	struct pfsync_softc *sc = pfsyncif;

	if (sc == NULL || !ISSET(sc->sc_if.if_flags, IFF_RUNNING))
		return (0);

	return (1);
}

int
pfsync_state_in_use(struct pf_state *st)
{
	struct pfsync_softc *sc = pfsyncif;

	if (sc == NULL)
		return (0);

	if (st->sync_state != PFSYNC_S_NONE ||
	    st == sc->sc_bulk_next ||
	    st == sc->sc_bulk_last)
		return (1);

	return (0);
}

void
pfsync_timeout(void *arg)
{
	int s;

	NET_LOCK(s);
	pfsync_sendout();
	NET_UNLOCK(s);
}

/* this is a softnet/netisr handler */
void
pfsyncintr(void)
{
	pfsync_sendout();
}

int
pfsync_sysctl_pfsyncstat(void *oldp, size_t *oldlenp, void *newp)
{
	struct pfsyncstats pfsyncstat;

	CTASSERT(sizeof(pfsyncstat) == (pfsyncs_ncounters * sizeof(uint64_t)));
	counters_read(pfsynccounters, (uint64_t *)&pfsyncstat,
	    pfsyncs_ncounters);
	return (sysctl_rdstruct(oldp, oldlenp, newp,
	    &pfsyncstat, sizeof(pfsyncstat)));
}

int
pfsync_sysctl(int *name, u_int namelen, void *oldp, size_t *oldlenp, void *newp,
    size_t newlen)
{
	/* All sysctl names at this level are terminal. */
	if (namelen != 1)
		return (ENOTDIR);

	switch (name[0]) {
	case PFSYNCCTL_STATS:
		return (pfsync_sysctl_pfsyncstat(oldp, oldlenp, newp));
	default:
		return (ENOPROTOOPT);
	}
}
@


1.245
log
@pfsync(4) percpu counters

ok florian@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.244 2017/01/29 19:58:47 bluhm Exp $	*/
d237 1
d256 1
d370 1
a370 1
	if (sc->sc_sync_if)
d374 3
d435 8
d1329 1
a1329 1
			if (sc->sc_sync_if)
d1333 4
d1358 1
a1358 1
		if (sc->sc_sync_if)
d1362 4
d1412 2
@


1.244
log
@Change the IPv4 pr_input function to the way IPv6 is implemented,
to get rid of struct ip6protosw and some wrapper functions.  It is
more consistent to have less different structures.  The divert_input
functions cannot be called anyway, so remove them.
OK visa@@ mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.243 2017/01/25 17:34:31 bluhm Exp $	*/
d242 1
a242 1
struct pfsyncstats	 pfsyncstats;
d286 1
d648 1
a648 1
	pfsyncstats.pfsyncs_ipackets++;
d657 1
a657 1
		pfsyncstats.pfsyncs_badif++;
d666 1
a666 1
		pfsyncstats.pfsyncs_badttl++;
d673 1
a673 1
		pfsyncstats.pfsyncs_hdrops++;
d680 1
a680 1
		pfsyncstats.pfsyncs_badver++;
d685 1
a685 1
		pfsyncstats.pfsyncs_badlen++;
d713 1
a713 1
			pfsyncstats.pfsyncs_badact++;
d719 1
a719 1
			pfsyncstats.pfsyncs_badlen++;
d788 1
a788 1
			pfsyncstats.pfsyncs_badval++;
d877 1
a877 1
			pfsyncstats.pfsyncs_badval++;
d888 1
a888 1
				pfsyncstats.pfsyncs_badstate++;
d924 1
a924 1
			pfsyncstats.pfsyncs_stale++;
d954 1
a954 1
			pfsyncstats.pfsyncs_badval++;
d998 1
a998 1
			pfsyncstats.pfsyncs_stale++;
d1028 1
a1028 1
				pfsyncstats.pfsyncs_badstate++;
d1057 1
a1057 1
			pfsyncstats.pfsyncs_badstate++;
d1083 1
a1083 1
			pfsyncstats.pfsyncs_badstate++;
d1198 1
a1198 1
	pfsyncstats.pfsyncs_badstate++;
d1208 1
a1208 1
		pfsyncstats.pfsyncs_badact++;
d1217 1
a1217 1
	pfsyncstats.pfsyncs_badact++;
d1517 1
a1517 1
		pfsyncstats.pfsyncs_onomem++;
d1527 1
a1527 1
			pfsyncstats.pfsyncs_onomem++;
d1656 1
a1656 1
		pfsyncstats.pfsyncs_opackets++;
d1658 1
a1658 1
		pfsyncstats.pfsyncs_oerrors++;
d2359 12
d2380 1
a2380 4
		if (newp != NULL)
			return (EPERM);
		return (sysctl_struct(oldp, oldlenp, newp, newlen,
		    &pfsyncstats, sizeof(pfsyncstats)));
@


1.243
log
@Since raw_input() and route_input() are gone from pr_input, we can
make the variable parameters of the protocol input functions fixed.
Also add the proto to make it similar to IPv6.
OK mpi@@ guenther@@ millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.242 2017/01/23 11:37:29 mpi Exp $	*/
d637 2
a638 2
void
pfsync_input(struct mbuf *m, int iphlen, int proto)
d640 1
a642 1
	struct mbuf *mp;
d645 1
a645 2

	int offset, offp, len, count, mlen, flags = 0;
d670 2
a671 2
	mp = m_pulldown(m, offset, sizeof(*ph), &offp);
	if (mp == NULL) {
d673 1
a673 1
		return;
d675 1
a675 1
	ph = (struct pfsync_header *)(mp->m_data + offp);
d716 2
a717 2
		mp = m_pulldown(m, offset, mlen * count, &offp);
		if (mp == NULL) {
d719 1
a719 1
			return;
d722 1
a722 1
		if (pfsync_acts[subh.action].in(mp->m_data + offp,
d731 1
@


1.242
log
@Flag pseudo-interfaces as such in order to call add_net_randomness()
only once per packet.

Fix a regression introduced when if_input() started to be called by
every pseudo-driver.

ok claudio@@, dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.241 2017/01/20 03:56:46 mpi Exp $	*/
d638 1
a638 1
pfsync_input(struct mbuf *m, ...)
@


1.241
log
@pfsync_update_net_tdb() is only called at IPL_SOFTNET, no need for a
splsofnet()/splx() dance.

Tested by Hrvoje Popovski, ok visa@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.240 2017/01/20 00:51:56 mpi Exp $	*/
d331 1
@


1.240
log
@No need to handle SIOCAIFADDR in drivers, it's never passed down to
them.

ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.239 2016/12/19 15:46:28 mpi Exp $	*/
d1167 2
a1168 1
	int			 s;
a1175 1
	s = splsoftnet();
a1184 1
			splx(s);
a1190 1
	splx(s);
@


1.239
log
@Timer sending packets need to grab the NET_LOCK().

ok bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.238 2016/11/22 19:29:54 procter Exp $	*/
a1243 1
	case SIOCAIFADDR:
@


1.238
log
@Fold union pf_headers buffer into struct pf_pdesc (enabled by pfvar_priv.h).
Prevent pf_socket_lookup() reading uninitialised header buffers on fragments.
OK blum@@ sashan@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.237 2016/11/14 13:25:00 bluhm Exp $	*/
d1791 1
a1791 1
	s = splsoftnet();
d1793 1
a1793 1
	splx(s);
d2209 1
a2209 2
	s = splsoftnet();

d2240 1
a2240 2

	splx(s);
d2272 1
a2272 1
	s = splsoftnet();
d2298 1
a2298 2

	splx(s);
d2347 1
a2347 1
	s = splsoftnet();
d2349 1
a2349 1
	splx(s);
@


1.237
log
@Instead of passing an extra mbuf pointer to pf_route(), it should
just use pd->m.  Then pf_test() can also operate on pd.m and set
the *m0 value in the caller just before it returns.
OK sashan@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.236 2016/10/27 21:41:20 bluhm Exp $	*/
a1735 1
	union pf_headers pdhdrs;
d1747 1
a1747 1
			if (pf_setup_pdesc(&pdesc, &pdhdrs,
@


1.236
log
@Pass a struct pf_pdesc to pf_route() like it is done in the other
pf functions.  That means less parameters, more consistency and
later we can call functions that need a pd from pf_route().
OK sashan@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.235 2016/10/04 13:54:32 mpi Exp $	*/
d1757 1
a1757 1
				pf_route(&pd->pd_m, &pdesc,
d1762 1
a1762 1
				pf_route6(&pd->pd_m, &pdesc,
d1767 1
@


1.235
log
@Convert timeouts that need a process context to timeout_set_proc(9).

The current reason is that rtalloc_mpath(9) inside ip_output() might
end up inserting a RTF_CLONED route and that require a write lock.

ok kettenis@@, bluhm@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.234 2016/09/27 04:57:17 dlg Exp $	*/
d62 1
d65 6
d74 1
a74 8

#include <netinet/in_var.h>
#include <netinet/ip.h>
#include <netinet/ip_var.h>

#ifdef IPSEC
#include <netinet/ip_ipsp.h>
#endif /* IPSEC */
d90 1
a90 1
#include <netinet/ip_ipsp.h>
d1735 2
d1748 7
d1757 2
a1758 3
				pf_route(&pd->pd_m, pd->pd_st->rule.ptr,
				    pd->pd_st->direction,
				    pd->pd_st->rt_kif->pfik_ifp, pd->pd_st);
d1762 2
a1763 3
				pf_route6(&pd->pd_m, pd->pd_st->rule.ptr,
				    pd->pd_st->direction,
				    pd->pd_st->rt_kif->pfik_ifp, pd->pd_st);
d1782 1
a1782 1

@


1.234
log
@roll back turning RB into RBT until i get better at this process.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.233 2016/09/27 02:51:12 dlg Exp $	*/
d331 3
a333 3
	timeout_set(&sc->sc_tmo, pfsync_timeout, sc);
	timeout_set(&sc->sc_bulk_tmo, pfsync_bulk_update, sc);
	timeout_set(&sc->sc_bulkfail_tmo, pfsync_bulk_fail, sc);
d1723 1
a1723 1
	timeout_set(&pd->pd_tmo, pfsync_defer_tmo, pd);
@


1.233
log
@move pf from the RB macros to the RBT functions.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.232 2016/09/21 07:41:49 mpi Exp $	*/
d750 2
a751 2
		for (st = RBT_MIN(pf_state_tree_id, &tree_id); st; st = nexts) {
			nexts = RBT_NEXT(pf_state_tree_id, st);
@


1.232
log
@Remove recursive splsoftnet() calls, from David Hill.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.231 2016/09/15 02:00:18 dlg Exp $	*/
d750 2
a751 2
		for (st = RB_MIN(pf_state_tree_id, &tree_id); st; st = nexts) {
			nexts = RB_NEXT(pf_state_tree_id, &tree_id, st);
@


1.231
log
@all pools have their ipl set via pool_setipl, so fold it into pool_init.

the ioff argument to pool_init() is unused and has been for many
years, so this replaces it with an ipl argument. because the ipl
will be set on init we no longer need pool_setipl.

most of these changes have been done with coccinelle using the spatch
below. cocci sucks at formatting code though, so i fixed that by hand.

the manpage and subr_pool.c bits i did myself.

ok tedu@@ jmatthew@@

@@ipl@@
expression pp;
expression ipl;
expression s, a, o, f, m, p;
@@@@
-pool_init(pp, s, a, o, f, m, p);
-pool_setipl(pp, ipl);
+pool_init(pp, s, a, ipl, f, m, p);
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.230 2016/08/23 12:37:44 dlg Exp $	*/
a355 1
	int s;
a356 1
	s = splsoftnet();
a384 1
	splx(s);
@


1.230
log
@pool_setipl
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.229 2016/04/29 08:55:03 krw Exp $	*/
d305 2
a306 2
	pool_init(&sc->sc_pool, PFSYNC_PLSIZE, 0, 0, 0, "pfsync", NULL);
	pool_setipl(&sc->sc_pool, IPL_SOFTNET);
@


1.229
log
@Make if_output() return EAFNOSUPPORT instead of just dropping packets
and pretending the output succeeded. Packets are still dropped!

Idea from jsg@@ following same change to bridge(4). ok mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.228 2016/03/29 10:34:42 sashan Exp $	*/
d306 1
@


1.228
log
@- packet must keep reference to statekey
  this is the second attempt to get it in, the first
  attempt got backed out on Jan 31 2016

  the change also contains fixes contributed by Stefan Kempf
  in earlier iteration.

OK srhen@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.227 2016/01/31 00:18:07 sashan Exp $	*/
d1227 2
a1228 2
	m_freem(m);
	return (0);
@


1.227
log
@- m_pkthdr.pf.statekey changes are not ready for 5.9, I must back them out

OK sthen@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.226 2016/01/27 04:35:56 dlg Exp $	*/
d526 1
d536 1
@


1.226
log
@white space tweaks. no functional change.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.225 2016/01/26 22:23:15 sashan Exp $	*/
a525 1
	PF_REF_INIT(skw->refcnt);
a534 1
		PF_REF_INIT(sks->refcnt);
@


1.225
log
@- state keys imported by if_pfsync trip refcnt != ~0 Assert

OK mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.224 2015/12/05 10:07:55 tedu Exp $	*/
d1751 1
a1751 1
				    pd->pd_st->direction, 
d1769 2
a1770 2
	                case AF_INET6:
		                ip6_output(pd->pd_m, NULL, NULL, 0,
d1775 1
a1775 1
                }
@


1.224
log
@remove old lint annotations
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.223 2015/12/03 09:49:15 bluhm Exp $	*/
d526 1
d536 1
@


1.223
log
@Rename pf_unlink_state() to pf_remove_state() so the name does not
collide with the statekey to inp unlinking.
OK sashan@@ mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.222 2015/11/10 06:36:14 dlg Exp $	*/
a1228 1
/* ARGSUSED */
@


1.222
log
@flush the send queue in start routines with IFQ_PURGE.

ok mpi@@ uebayasi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.221 2015/10/30 11:33:55 mikeb Exp $	*/
d755 1
a755 1
				pf_unlink_state(st);
d1059 1
a1059 1
		pf_unlink_state(st);
d1086 1
a1086 1
		pf_unlink_state(st);
@


1.221
log
@Clean up handling of 'clear states' pfsync packets.

If interface was specified in the packet only if-bound states
attached to this interface must be purged.

ok mpi, looked at by sasha@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.220 2015/09/11 08:17:06 claudio Exp $	*/
a255 2
struct mbuf *pfsync_if_dequeue(struct ifnet *);

a390 10
struct mbuf *
pfsync_if_dequeue(struct ifnet *ifp)
{
	struct mbuf *m;

	IF_DEQUEUE(&ifp->if_snd, m);

	return (m);
}

d397 1
a397 9
	struct mbuf *m;
	int s;

	s = splnet();
	while ((m = pfsync_if_dequeue(ifp)) != NULL) {
		IF_DROP(&ifp->if_snd);
		m_freem(m);
	}
	splx(s);
@


1.220
log
@Kill yet another argument to functions in IPv6. This time ip6_output's
ifpp - XXX: just for statistics
ifpp is always NULL in all callers so that statistic confirms ifpp is
dying
OK mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.219 2015/06/16 11:09:39 mpi Exp $	*/
a756 2
	int i;

d758 1
a758 2
	struct pf_state_key *sk, *nextsk;
	struct pf_state_item *si;
d760 1
d764 1
d766 10
a775 26

		if (clr->ifname[0] == '\0') {
			for (st = RB_MIN(pf_state_tree_id, &tree_id);
			    st; st = nexts) {
				nexts = RB_NEXT(pf_state_tree_id, &tree_id, st);
				if (st->creatorid == creatorid) {
					SET(st->state_flags, PFSTATE_NOSYNC);
					pf_unlink_state(st);
				}
			}
		} else {
			if (pfi_kif_get(clr->ifname) == NULL)
				continue;

			/* XXX correct? */
			for (sk = RB_MIN(pf_state_tree, &pf_statetbl);
			    sk; sk = nextsk) {
				nextsk = RB_NEXT(pf_state_tree,
				    &pf_statetbl, sk);
				TAILQ_FOREACH(si, &sk->states, entry) {
					if (si->s->creatorid == creatorid) {
						SET(si->s->state_flags,
						    PFSTATE_NOSYNC);
						pf_unlink_state(si->s);
					}
				}
@


1.219
log
@Store a unique ID, an interface index, rather than a pointer to the
receiving interface in the packet header of every mbuf.

The interface pointer should now be retrieved when necessary with
if_get().  If a NULL pointer is returned by if_get(), the interface
has probably been destroy/removed and the mbuf should be freed.

Such mechanism will simplify garbage collection of mbufs and limit
problems with dangling ifp pointers.

Tested by jmatthew@@ and krw@@, discussed with many.

ok mikeb@@, bluhm@@, dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.218 2015/03/14 03:38:51 jsg Exp $	*/
d1807 1
a1807 1
				    NULL, NULL, NULL);
@


1.218
log
@Remove some includes include-what-you-use claims don't
have any direct symbols used.  Tested for indirect use by compiling
amd64/i386/sparc64 kernels.

ok tedu@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.217 2015/02/10 09:28:40 henning Exp $	*/
d675 1
a675 1
	if (sc->sc_sync_if != m->m_pkthdr.rcvif) {
@


1.217
log
@include the "set prio" values.
no real compat issue since we're using spare bytes.
old -> new ends up with set prio (0, 0) equivalent
new -> old is entirely harmless, old ignores the prios.
requested by Alexey Suslikov <alexey.suslikov at gmail>
ok phessler pelikan dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.215 2014/12/19 17:14:39 tedu Exp $	*/
a79 1
#include <netinet/icmp6.h>
@


1.216
log
@Userland (base & ports) was adapted to always include <netinet/in.h>
before <net/pfvar.h> or <net/if_pflog.h>.  The kernel files can be
cleaned up next.  Some sockaddr_union steps make it into here as well.
ok naddy
@
text
@d597 2
@


1.215
log
@unifdef INET in net code as a precursor to removing the pretend option.
long live the one true internet.
ok henning mikeb
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.214 2014/12/17 09:57:13 mpi Exp $	*/
d66 1
d72 4
d91 1
d1212 2
a1213 1
	tdb = gettdb(ntohs(pt->rdomain), pt->spi, &pt->dst, pt->sproto);
@


1.214
log
@Remove the "multicast_" prefix from the fields a multicast-only struct.

Prodded by claudio@@ and mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.213 2014/12/17 09:45:59 mpi Exp $	*/
a66 1
#ifdef	INET
a69 1
#endif
a1776 1
#ifdef INET
a1781 1
#endif /* INET */
a1791 1
#ifdef INET
a1795 1
#endif /* INET */
@


1.213
log
@Use an interface index instead of a pointer for multicast options.

Output interface (port) selection for multicast traffic is not done via
route lookups.  Instead the output ifp is registred when setsockopt(2)
is called with the IP{V6,}_MULTICAST_IF option.  But since there is no
mechanism to invalidate such pointer stored in a pcb when an interface
is destroyed/removed, it might lead your kernel to fault.

Prevent a fault upon resume reported by frantisek holop, thanks!

ok mikeb@@, claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.212 2014/11/23 07:39:02 deraadt Exp $	*/
d1405 2
a1406 2
			imo->imo_multicast_ttl = PFSYNC_DFLTTL;
			imo->imo_multicast_loop = 0;
@


1.212
log
@length argument for some free() calls; ok doug
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.211 2014/11/06 05:29:35 lteo Exp $	*/
d1357 1
a1357 1
				imo->imo_multicast_ifp = NULL;
d1382 1
a1382 1
			imo->imo_multicast_ifp = NULL;
d1404 1
a1404 1
			imo->imo_multicast_ifp = sc->sc_sync_if;
@


1.211
log
@Remove unneeded netinet6/ip6_divert.h include.

ok bluhm@@ dlg@@ florian@@ mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.210 2014/10/17 00:47:48 dlg Exp $	*/
d382 1
a382 1
	free(sc, M_DEVBUF, 0);
@


1.210
log
@reset all the pfsync packet state before calling ip_output in
pfsync_sendout. more specifically, move the reset of sc->sc_len to
PFSYNC_MINPKT above ip_output.

this prevents a situation where ipsec via ip_output calls
pfsync_update_tdb for syncing the ipsec flow to a peer, which
accounts for the tdb in the next pfsync packet, before unwinding
back to pfsync_output which resets the accounting we just did.

the next pfsync packet to be sent out will be allocated with a short
length because sc_len is wrong, and the long lists of things (eg,
the tdb) can overwrite memory after the mbuf. this manifests as
incorrect poisoning or xsimpleq entry corruption in mbufs still in
a pool, or random corruption of m->m_next on other mbufs in the
system.

bug found, fix tested, and ok stsp@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.209 2014/09/08 06:24:13 jsg Exp $	*/
a78 1
#include <netinet6/ip6_divert.h>
@


1.209
log
@remove uneeded route.h includes
ok miod@@ mpi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.208 2014/07/22 11:06:09 mpi Exp $	*/
d1681 3
a1692 3

	/* start again */
	sc->sc_len = PFSYNC_MINPKT;
@


1.208
log
@Fewer <netinet/in_systm.h> !
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.207 2014/07/12 18:44:22 tedu Exp $	*/
a59 1
#include <net/route.h>
d76 1
a76 1
#include <netinet/in_pcb.h>
@


1.207
log
@add a size argument to free. will be used soon, but for now default to 0.
after discussions with beck deraadt kettenis.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.206 2014/04/21 12:22:25 henning Exp $	*/
a68 1
#include <netinet/in_systm.h>
@


1.206
log
@ip_output() using varargs always struck me as bizarre, esp since it's only
ever used to pass on uint32 (for ipsec). stop that madness and just pass
the uint32, 0 in all cases but the two that pass the ipsec flowinfo.
ok deraadt reyk guenther
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.204 2013/11/18 21:16:55 chl Exp $	*/
d384 2
a385 2
	free(sc->sc_imo.imo_membership, M_IPMOPTS);
	free(sc, M_DEVBUF);
@


1.205
log
@"struct pkthdr" holds a routing table ID, not a routing domain one.
Avoid the confusion by using an appropriate name for the variable.

Note that since routing domain IDs are a subset of the set of routing
table IDs, the following idiom is correct:

	rtableid = rdomain

But to get the routing domain ID corresponding to a given routing table
ID, you must call rtable_l2(9).

claudio@@ likes it, ok mikeb@@
@
text
@d1688 1
a1688 1
	if (ip_output(m, NULL, NULL, IP_RAWOUTPUT, &sc->sc_imo, NULL) == 0)
d1801 2
a1802 2
				ip_output(pd->pd_m, NULL, NULL, 0,
				    NULL, NULL);
@


1.204
log
@Fix potential null dereference.

Found by LLVM/Clang Static Analyzer.

ok benno@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.203 2013/11/15 12:18:02 henning Exp $	*/
d1686 1
a1686 1
	m->m_pkthdr.rdomain = sc->sc_if.if_rdomain;
@


1.203
log
@inherit the rdomain sc to pkthdr
from erik at halon dot se, ok benno phessler benno
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.202 2013/10/17 16:27:41 bluhm Exp $	*/
d425 1
a425 1
	if (!sc->sc_sync_if && !(sc->sc_if.if_flags & IFF_UP))
@


1.202
log
@The header file netinet/in_var.h included netinet6/in6_var.h.  This
created a bunch of useless dependencies.  Remove this implicit
inclusion and do an explicit #include <netinet6/in6_var.h> when it
is needed.
OK mpi@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.201 2013/08/07 05:39:05 dlg Exp $	*/
d1685 2
@


1.201
log
@states learnt via pfsync from a peer with the same ruleset checksum were
not getting assigned to rules like they should cos pfsync_in_upd() wasnt
passing the PFSYNC_SI_CKSUM flag along to pfsync_state_import.

found and fixed by pedro
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.200 2013/06/20 12:03:40 mpi Exp $	*/
d76 1
@


1.200
log
@Revert previous and unbreak asr, the new include should be protected.

Reported by naddy@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.199 2013/06/20 09:38:24 mpi Exp $	*/
d919 1
a919 1
			if (pfsync_state_import(sp, 0))
@


1.199
log
@Allocate the various hook head descriptors as part of the ifnet
structure rather than doing various M_WAITOK allocations during
the *attach() functions, we always rely on them anyway.

ok mikeb@@, uebayasi@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.198 2013/05/10 11:36:24 mikeb Exp $	*/
d370 1
a370 1
		    &sc->sc_sync_if->if_linkstatehooks,
d1353 1
a1353 1
				    &sc->sc_sync_if->if_linkstatehooks,
d1378 1
a1378 1
			    &sc->sc_sync_if->if_linkstatehooks,
d1424 1
a1424 1
		    hook_establish(&sc->sc_sync_if->if_linkstatehooks, 1,
@


1.198
log
@Since pf_state_key_attach can decide to free the provided state
key we need to sync our state key pointers with whatever values
the function will pick.  Not doing so will produce wrong results
if address translation must be applied afterwards and we happen
to have a state key collision.  Then pf_translate will follow an
old pointer and punch in garbage addresses into the packet.

Noticed, initial patch and tests by Vitaly Sinilin <vs @@ kp4 ! ru>
ok tedu, henning
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.197 2013/03/28 16:45:16 tedu Exp $	*/
d370 1
a370 1
		    sc->sc_sync_if->if_linkstatehooks,
d1353 1
a1353 1
				    sc->sc_sync_if->if_linkstatehooks,
d1378 1
a1378 1
			    sc->sc_sync_if->if_linkstatehooks,
d1424 1
a1424 1
		    hook_establish(sc->sc_sync_if->if_linkstatehooks, 1,
@


1.197
log
@no need for a lot of code to include proc.h
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.196 2013/03/26 13:19:26 mpi Exp $	*/
d615 1
a615 1
	if (pf_state_insert(kif, skw, sks, st) != 0) {
@


1.196
log
@Remove various read-only *maxlen variables and use IFQ_MAXLEN directly.

ok beck@@, mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.195 2012/10/30 12:09:05 florian Exp $	*/
a45 1
#include <sys/proc.h>
@


1.195
log
@Use time_uptime for expiration values as time_second can be skewed at
runtime while time_uptime is monotonic. Prevent underflows in
pfsync(4) and pflow(4) by using signed variables.  pfsync(4) problem
pointed out by camield.

Diff originally by dlg, frag and pflow bits by me.

feedback dlg
man page tweak jmc

Various versions of the pflow bits tested by Hrvoje Popovski
(hrvoje AT srce DOT hr), thanks!

ok benno, henning, dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.194 2012/10/09 11:16:28 markus Exp $	*/
d329 1
a329 1
	IFQ_SET_MAXLEN(&ifp->if_snd, ifqmaxlen);
@


1.194
log
@simplify hook_disestablish() handling by always resetting the hook when
the syncdev gets set. this also makes sure we no longer leak hooks on
repeatet 'ifconfig syncdev' invocations.
ok mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.193 2012/10/08 18:33:23 markus Exp $	*/
d577 2
a578 2
	st->expire = time_second;
	if (sp->expire) {
d951 1
a951 1
			st->expire = time_second;
d1025 1
a1025 1
			st->expire = time_second;
@


1.193
log
@make sure we don't call hook_disestablish() twice e.g. ifconfig -syncdev
followed by ifconfig destroy; ok mikeb
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.192 2012/09/20 17:37:47 mikeb Exp $	*/
d369 1
a369 1
	if (sc->sc_lhcookie != NULL) {
a372 2
		sc->sc_lhcookie = NULL;
	}
d1352 1
a1352 1
			if (sc->sc_lhcookie != NULL) {
a1355 2
				sc->sc_lhcookie = NULL;
			}
d1376 5
a1392 6
				if (sc->sc_lhcookie != NULL) {
					hook_disestablish(
					    sc->sc_sync_if->if_linkstatehooks,
					    sc->sc_lhcookie);
					sc->sc_lhcookie = NULL;
				}
a1401 6
				if (sc->sc_lhcookie != NULL) {
					hook_disestablish(
					    sc->sc_sync_if->if_linkstatehooks,
					    sc->sc_lhcookie);
					sc->sc_lhcookie = NULL;
				}
@


1.192
log
@pfsync_cancel_full_update needs to restore carp demotions since
it's cancelling the bulk update and can leave the machine in a
demoted state.

bug was noticed by benno, who was kind enough to verify that the
fix is working fine.  ok mpf, benno
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.191 2012/09/20 10:25:03 blambert Exp $	*/
d369 1
a369 1
	if (sc->sc_lhcookie != NULL)
d373 2
d1354 1
a1354 1
			if (sc->sc_lhcookie != NULL)
d1358 2
d1392 1
a1392 1
				if (sc->sc_lhcookie != NULL)
d1396 2
d1407 1
a1407 1
				if (sc->sc_lhcookie != NULL)
d1411 2
@


1.191
log
@spltdb() was really just #define'd to be splsoftnet(); replace the former
with the latter

no change in md5 checksum of generated files

ok claudio@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.190 2012/09/19 13:47:17 mikeb Exp $	*/
a1298 8
#if NCARP > 0
			if (sc->sc_initial_bulk) {
				carp_group_demote_adj(&sc->sc_if, -32,
				    "pfsync init");
				sc->sc_initial_bulk = 0;
			}
#endif

d1903 12
a1914 1
	    timeout_pending(&sc->sc_bulk_tmo))
d1916 1
@


1.190
log
@update the tdb replay counter endian conversion to 64 bits;
ok camield mpf
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.189 2012/07/26 12:25:31 mikeb Exp $	*/
d1210 1
a1210 1
	s = spltdb();
@


1.189
log
@rename all_state_flags to state_flags to finish the transition
to the 16 bit flags;  reminded by claudio, ok henning
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.188 2012/06/30 00:16:15 mikeb Exp $	*/
d1213 1
a1213 1
		pt->rpl = ntohl(pt->rpl);
d2202 1
a2202 1
	ut->rpl = htonl(t->tdb_rpl + (ISSET(t->tdb_flags, TDBF_PFSYNC_RPL) ?
@


1.188
log
@Fix a number of problems introduced by the link state handling commit:

1) demote by 32 on the first bulk update to prevent failovers w/o having
   a full state table;

2) don't do any demotion adjustments on the link up event and undemote
   when bulk update finishes (or times out) preventing a race between
   nodes getting a link state update asynchronously.

With phessler; tested by phessler and Kapetanakis Giannis.  Thanks!

Looked through by henning and dlg.  Now the correct version.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.187 2012/06/30 00:14:23 mikeb Exp $	*/
d592 1
a592 2
	/* XXX replace state_flags post 5.0 */
	st->state_flags = sp->state_flags | ntohs(sp->all_state_flags);
@


1.187
log
@backout rev1.185 as it's not what i have intended to commit
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.186 2012/06/29 15:12:21 mikeb Exp $	*/
d215 3
d262 1
d366 2
d425 1
a425 1
	if (!sc->sc_sync_if)
d428 1
a428 2
	if (sc->sc_sync_if->if_link_state == LINK_STATE_DOWN ||
	    !(sc->sc_sync_if->if_flags & IFF_UP)) {
d430 1
d432 2
a433 1
		carp_group_demote_adj(&sc->sc_if, 1, "pfsyncdev");
d435 3
d442 2
a443 5
		/* cancel bulk update */
		timeout_del(&sc->sc_bulk_tmo);
		sc->sc_bulk_next = NULL;
		sc->sc_bulk_last = NULL;
	} else {
d445 1
a446 3
#if NCARP > 0
		carp_group_demote_adj(&sc->sc_if, -1, "pfsyncdev");
#endif
d1159 2
d1162 5
d1169 1
d1288 6
d1300 8
d1312 1
a1312 4
			/* cancel bulk update */
			timeout_del(&sc->sc_bulk_tmo);
			sc->sc_bulk_next = NULL;
			sc->sc_bulk_last = NULL;
d1909 14
d1929 1
a1929 1
		if (pfsync_sync_ok)
d2317 2
d2320 5
d2327 1
@


1.186
log
@add ESN-related bits missed in the previous commit
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.185 2012/06/28 13:59:21 mikeb Exp $	*/
a214 2
	int			 sc_link_demote;

d422 2
a423 1
	if (sc->sc_sync_if->if_link_state == LINK_STATE_DOWN) {
d426 1
a426 4
		if (!sc->sc_link_demote) {
			carp_group_demote_adj(&sc->sc_if, 1, "pfsyncdev");
			sc->sc_link_demote = 1;
		}
a437 1

d439 3
a1154 5
			if (sc->sc_link_demote) {
				carp_group_demote_adj(&sc->sc_if, -1,
				    "pfsyncdev");
				sc->sc_link_demote = 0;
			}
a2279 4
		if (sc->sc_link_demote) {
			carp_group_demote_adj(&sc->sc_if, -1, "pfsyncdev");
			sc->sc_link_demote = 0;
		}
@


1.185
log
@Fix a number of problems introduced by the link state handling commit:

1) demote by 32 on the first bulk update to prevent failovers w/o having
   a full state table;

2) don't do any demotion adjustments on the link up event and undemote
   when bulk update finishes (or times out) preventing a race between
   nodes getting a link state update asynchronously.

With phessler; tested by phessler and Kapetanakis Giannis.  Thanks!

Looked through by henning and dlg.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.184 2012/04/11 17:42:53 mikeb Exp $	*/
d143 2
a144 2
	/* PFSYNC_ACT_TDB */
	{ pfsync_in_tdb,	sizeof(struct pfsync_tdb) },
d150 3
a152 1
	{ pfsync_in_upd,	sizeof(struct pfsync_state) }
@


1.184
log
@fix all the suser calls which pass an incorrect p_acflag argument;
figured out by and ok guenther
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.183 2012/04/07 14:28:45 camield Exp $	*/
d213 2
d422 1
a422 2
	if (sc->sc_sync_if->if_link_state == LINK_STATE_DOWN ||
	    !(sc->sc_sync_if->if_flags & IFF_UP)) {
d425 4
a428 1
		carp_group_demote_adj(&sc->sc_if, 1, "pfsyncdev");
d440 1
a441 3
#if NCARP > 0
		carp_group_demote_adj(&sc->sc_if, -1, "pfsyncdev");
#endif
d1155 5
d2285 4
@


1.183
log
@remove superfluous return, ok mikeb
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.182 2012/04/03 15:09:03 mikeb Exp $	*/
d1313 1
a1313 1
		if ((error = suser(p, p->p_acflag)) != 0)
@


1.182
log
@Fix kernel compilation with pf but without pfsync pseudo-device by
moving the state export functionality from pfsync code into pf.
Based on the initial diff diff by guenther, ok henning.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.181 2012/02/03 01:57:50 bluhm Exp $	*/
d459 1
a459 1
	return (pf_state_export(sp, st));
@


1.181
log
@The kernel did not compile without INET6.  Put some #ifdefs into
pf to fix that.
- add #ifdef INET6 in obvious places
- af translation is only possible with both INET and INET6
- interleave #endif /* INET6 */ and closing brace correctly
- it is not necessary to #ifdef function prototypes
- do not compile af translate functions at all instead of empty stub,
  then the linker will report inconsistencies
- pf_poolmask() actually takes an sa_family_t not an u_int8_t argument
No binary change for GENERIC compiled with -O2 and -UDIAGNOSTIC.
reported by Olivier Cochard-Labbe; ok mikeb@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.180 2012/01/16 10:28:02 mikeb Exp $	*/
d459 1
a459 62
	bzero(sp, sizeof(struct pfsync_state));

	/* copy from state key */
	sp->key[PF_SK_WIRE].addr[0] = st->key[PF_SK_WIRE]->addr[0];
	sp->key[PF_SK_WIRE].addr[1] = st->key[PF_SK_WIRE]->addr[1];
	sp->key[PF_SK_WIRE].port[0] = st->key[PF_SK_WIRE]->port[0];
	sp->key[PF_SK_WIRE].port[1] = st->key[PF_SK_WIRE]->port[1];
	sp->key[PF_SK_WIRE].rdomain = htons(st->key[PF_SK_WIRE]->rdomain);
	sp->key[PF_SK_WIRE].af = st->key[PF_SK_WIRE]->af;
	sp->key[PF_SK_STACK].addr[0] = st->key[PF_SK_STACK]->addr[0];
	sp->key[PF_SK_STACK].addr[1] = st->key[PF_SK_STACK]->addr[1];
	sp->key[PF_SK_STACK].port[0] = st->key[PF_SK_STACK]->port[0];
	sp->key[PF_SK_STACK].port[1] = st->key[PF_SK_STACK]->port[1];
	sp->key[PF_SK_STACK].rdomain = htons(st->key[PF_SK_STACK]->rdomain);
	sp->key[PF_SK_STACK].af = st->key[PF_SK_STACK]->af;
	sp->rtableid[PF_SK_WIRE] = htonl(st->rtableid[PF_SK_WIRE]);
	sp->rtableid[PF_SK_STACK] = htonl(st->rtableid[PF_SK_STACK]);
	sp->proto = st->key[PF_SK_WIRE]->proto;
	sp->af = st->key[PF_SK_WIRE]->af;

	/* copy from state */
	strlcpy(sp->ifname, st->kif->pfik_name, sizeof(sp->ifname));
	bcopy(&st->rt_addr, &sp->rt_addr, sizeof(sp->rt_addr));
	sp->creation = htonl(time_uptime - st->creation);
	sp->expire = pf_state_expires(st);
	if (sp->expire <= time_second)
		sp->expire = htonl(0);
	else
		sp->expire = htonl(sp->expire - time_second);

	sp->direction = st->direction;
	sp->log = st->log;
	sp->timeout = st->timeout;
	/* XXX replace state_flags post 5.0 */
	sp->state_flags = st->state_flags;
	sp->all_state_flags = htons(st->state_flags);
	if (!SLIST_EMPTY(&st->src_nodes))
		sp->sync_flags |= PFSYNC_FLAG_SRCNODE;

	sp->id = st->id;
	sp->creatorid = st->creatorid;
	pf_state_peer_hton(&st->src, &sp->src);
	pf_state_peer_hton(&st->dst, &sp->dst);

	if (st->rule.ptr == NULL)
		sp->rule = htonl(-1);
	else
		sp->rule = htonl(st->rule.ptr->nr);
	if (st->anchor.ptr == NULL)
		sp->anchor = htonl(-1);
	else
		sp->anchor = htonl(st->anchor.ptr->nr);
	sp->nat_rule = htonl(-1);	/* left for compat, nat_rule is gone */

	pf_state_counter_hton(st->packets[0], sp->packets[0]);
	pf_state_counter_hton(st->packets[1], sp->packets[1]);
	pf_state_counter_hton(st->bytes[0], sp->bytes[0]);
	pf_state_counter_hton(st->bytes[1], sp->bytes[1]);

	sp->max_mss = htons(st->max_mss);
	sp->min_ttl = st->min_ttl;
	sp->set_tos = st->set_tos;
@


1.180
log
@do carp demotion adjustments on syncdev link state change.
this prevents backup to failover back to master immediately
after getting link back on carpdev interface if underlying
pfsync interface went down as well.  instead pfsync will
request a bulk update to get new states from the master.

sthen and mpf like the idea, ok dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.179 2011/12/01 20:43:03 mcbride Exp $	*/
d1855 1
a1856 1
#endif /* INET6 */
@


1.179
log
@Make sure we only enter pf_route() when undefering in the PF_ROUTETO case.

ok dlg claudio
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.178 2011/11/29 10:17:52 dlg Exp $	*/
d231 2
d249 1
d361 4
d412 31
d1396 4
d1432 4
d1445 4
d1470 4
@


1.178
log
@use a u_int64_t for the state id in pfsync_state. this makes it consistent
with every other thing that stores the state id (including other pfsync
messages).

includes improvements to the systat code to consider the creatorid as well
as the state id in its cache to avoid collisions between states created on
different hosts.

tested by me in production and on amd64 talking to sparc64.
ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.177 2011/11/27 16:06:30 mikeb Exp $	*/
d1771 1
a1771 1
		if (pd->pd_st->rule.ptr->rt) {
@


1.177
log
@Protect more operations in the pfsync_clone_destroy to prevent
accidental race conditions.  From Erik Lax, thanks!  ok dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.176 2011/11/26 03:28:46 mcbride Exp $	*/
d460 1
a460 1
	bcopy(&st->id, &sp->id, sizeof(sp->id));
d614 1
a614 1
	bcopy(sp->id, &st->id, sizeof(st->id));
d862 1
a862 1
		bcopy(&ia->id, &id_key.id, sizeof(id_key.id));
d931 1
a931 1
		bcopy(sp->id, &id_key.id, sizeof(id_key.id));
d1008 1
a1008 1
		bcopy(&up->id, &id_key.id, sizeof(id_key.id));
d1070 1
a1070 1
		bcopy(&ur->id, &id_key.id, sizeof(id_key.id));
d1102 1
a1102 1
		bcopy(sp->id, &id_key.id, sizeof(id_key.id));
d1128 1
a1128 1
		bcopy(&sp->id, &id_key.id, sizeof(id_key.id));
@


1.176
log
@Apply route-to to deferred packet; without this the first packet of a
connection does not observe the route-to option.

ok dlg mikeb
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.175 2011/11/25 12:52:10 dlg Exp $	*/
d350 1
a361 1
	s = splsoftnet();
a366 1
	splx(s);
d373 1
@


1.175
log
@use time_uptime to set state creation values as time_second can be
skewed at runtime by things like date(1) and ntpd. time_uptime is
monotonic and therefore more useful to compare against.

ok deraadt@@ mikeb@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.174 2011/11/16 11:59:28 mikeb Exp $	*/
d1771 2
a1772 1
		switch (pd->pd_st->key[PF_SK_WIRE]->af) {
d1774 21
a1794 3
		case AF_INET:
			ip_output(pd->pd_m, NULL, NULL, 0, NULL, NULL);
			break;
d1797 5
a1801 3
                case AF_INET6:
	                ip6_output(pd->pd_m, NULL, NULL, 0, NULL, NULL, NULL);
			break;
@


1.174
log
@Improve flag setting ioctl so that bulk updates are requested
only when we're going up, not when we set PROMISC or any other
flag.  Fixes spontaneous CARP failovers when running tcpdump
on pfsync.

ok henning, mcbride, camield
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.173 2011/11/09 12:36:03 camield Exp $	*/
d444 1
a444 1
	sp->creation = htonl(time_second - st->creation);
d592 1
a592 1
	st->creation = time_second - ntohl(sp->creation);
@


1.173
log
@State expire time is a baseline time ("last active") for expiry
calculations, and does _not_ denote the time when to expire.  So
it should never be added to (set into the future).

Try to reconstruct it with an educated guess on state import and
just set it to the current time on state updates.

This fixes a problem on pfsync listeners where the expiry time
could be double the expected value and cause a lot more states
to linger.

Timeout code from mikeb.

Found and testing by Maxim Bourmistrov.

ok mikeb dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.172 2011/11/04 22:11:11 mikeb Exp $	*/
d1293 2
a1294 1
		if (ifp->if_flags & IFF_UP) {
d1297 3
a1299 1
		} else {
@


1.172
log
@Select a correct protocol for a stack side state key when importing
an icmp<->icmp6 state (nat64);  ok henning, mcbride, dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.171 2011/10/31 22:02:52 mikeb Exp $	*/
d595 8
a602 2
		/* XXX No adaptive scaling. */
		st->expire -= r->timeout[sp->timeout] - ntohl(sp->expire);
a604 1
	st->expire = ntohl(sp->expire) + time_second;
d968 1
a968 1
			st->expire = ntohl(sp->expire) + time_second;
d1042 1
a1042 1
			st->expire = ntohl(up->expire) + time_second;
a1456 6

	up->expire = pf_state_expires(st);
	if (up->expire <= time_second)
		up->expire = htonl(0);
	else
		up->expire = htonl(up->expire - time_second);
@


1.171
log
@Don't forget to cancel bulk update failure timeout when destroying an
interface.  Problem report and fix from Erik Lax, thanks!
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.170 2011/10/30 23:04:38 mikeb Exp $	*/
a570 1
		sks->proto = sp->proto;
d573 13
@


1.170
log
@Allow setting big MTU values on the pfsync interface but not larger
than the syncdev MTU.  Prompted by the discussion with and tested
by Maxim Bourmistrov;  ok dlg, mpf
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.169 2011/10/20 08:57:26 mikeb Exp $	*/
d350 1
@


1.169
log
@remove a bogus chunk accidentally introduced by mcbride in rev1.141;
mcbride agrees, ok mpf, dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.168 2011/10/13 18:23:39 claudio Exp $	*/
d322 1
a322 2
	ifp->if_mtu = 1500; /* XXX */
	ifp->if_hardmtu = MCLBYTES; /* XXX */
d1293 4
a1297 4
		if (ifr->ifr_mtu <= PFSYNC_MINPKT)
			return (EINVAL);
		if (ifr->ifr_mtu > MCLBYTES) /* XXX could be bigger */
			ifr->ifr_mtu = MCLBYTES;
@


1.168
log
@Since the IPv6 madness is not enough introduce NAT64 -- which is actually
"af-to" a generic IP version translator for pf(4).
Not everything perfect yet but lets fix these things in the tree.
Insane amount of work done by sperreault@@, mikeb@@ and reyk@@.
Looked over by mcbride@@ henning@@ and myself at eurobsdcon.
OK mcbride@@ and general put it in from deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.167 2011/08/03 00:01:30 dlg Exp $	*/
a907 21
			DPFPRINTF(LOG_NOTICE,
			    "pfsync_input: PFSYNC_ACT_UPD: invalid value");
			pfsyncstats.pfsyncs_badval++;
			continue;
		}

		bcopy(sp->id, &id_key.id, sizeof(id_key.id));
		id_key.creatorid = sp->creatorid;

		st = pf_find_state_byid(&id_key);
		if (st == NULL) {
			/* insert the update */
			if (pfsync_state_import(sp, 0))
				pfsyncstats.pfsyncs_badstate++;
			continue;
		}

		if (ISSET(st->state_flags, PFSTATE_ACK))
			pfsync_deferred(st, 1);

		if (st->key[PF_SK_WIRE]->proto == IPPROTO_TCP) {
@


1.167
log
@someone (*cough*henning*cough*) made pf_state.state_flags a u_int16_t
without growing it in pfsync_state too.

to keep the wire format compat this uses some of the pad bytes to send
all the state flags on the wire as well as maintaining the old state_flags
field. after 5.0 we'll deprecate the original field and only use the new
one.

discussed with mcbride and deraadt and based on a diff from deraadt.
tested against an "old" pfsync locally.
ok mcbride@@ henning@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.166 2011/08/02 13:13:57 mcbride Exp $	*/
d429 1
d435 1
d537 3
a539 1
	if (PF_ANEQ(&sp->key[PF_SK_WIRE].addr[0],
d563 2
a564 1
	skw->af = sp->af;
d572 2
a573 1
		sks->af = sp->af;
d802 1
d807 2
d815 4
a818 1
		    (sp->af != AF_INET && sp->af != AF_INET6)) {
@


1.166
log
@Replace one byte of padding with sa_family_t af in pfsync_state_key;
Reject states with pfsync_state->af == 0 in pfsync_state_import(), in
preparation for states which specify an address family in each state key
instead (change will take place post-5.0).

ok dlg henning mikeb
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.165 2011/07/06 02:42:28 henning Exp $	*/
d452 1
d454 1
d585 2
a586 1
	st->state_flags = sp->state_flags;
@


1.165
log
@cosnistently use IFQ_SET_MAXLEN, surfaced in a discussion with + ok bluhm
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.164 2011/07/04 20:40:58 dhill Exp $	*/
d504 3
@


1.164
log
@use mtod.

no change in binary

"Sure" claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.163 2011/05/10 01:10:08 dlg Exp $	*/
d320 1
a320 1
	ifp->if_snd.ifq_maxlen = ifqmaxlen;
@


1.163
log
@when undeferring a packet, try to timeout_del first to check if you
actually removed it from the timeout wheel before releasing it. if
timeout_del returns 0 then you know the timeout is about to run or
is already running, meaning it will free itself so you dont have
to.

this handling is only done for the undefer paths at SOFTNET since
it is higher than SOFTCLOCK which timeouts run from. it is possible
for a timeout to start running at softclock and get interrupted by
softnet. the undefer in process context blocks both these interrupts
while it undefers, so it is impossible for the timeout to run and
cause the list to be in this inconsistent state.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.162 2011/04/02 17:16:34 dlg Exp $	*/
d1554 1
a1554 1
	ip = (struct ip *)m->m_data;
@


1.162
log
@dont let pfsync defer packets for states with NOSYNC set.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.161 2011/03/02 12:02:26 dlg Exp $	*/
d348 1
d362 5
a366 2
	while (sc->sc_deferred > 0)
		pfsync_undefer(TAILQ_FIRST(&sc->sc_deferrals), 0);
d1719 5
a1723 2
	if (sc->sc_deferred >= 128)
		pfsync_undefer(TAILQ_FIRST(&sc->sc_deferrals), 0);
a1752 1
	timeout_del(&pd->pd_tmo); /* bah */
d1797 2
a1798 1
			pfsync_undefer(pd, drop);
@


1.161
log
@when sending deferred packets use ip6_output for v6 frames instead of
blindly assuming everything is v4 to be sent with ip_output.

problem originally reported by Marco Fretz.
fix verified locally.
ok henning@@ mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.160 2011/01/11 08:33:27 dlg Exp $	*/
d1710 3
a1712 1
	if (!sc->sc_defer || m->m_flags & (M_BCAST|M_MCAST))
@


1.160
log
@delay deferred packets for a maximum of 20ms instead of 100 ticks (which
varies by arch). the 20ms is still up for discussion.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.159 2010/11/29 06:48:09 dlg Exp $	*/
d77 3
d81 1
d1752 12
a1763 2
		ip_output(pd->pd_m, (void *)NULL, (void *)NULL, 0,
		    (void *)NULL, (void *)NULL);
@


1.159
log
@use m_pulldown to get a contig view of the pfsync_header instead of
m_pullup.

not really a significant change since most rx bufs (which we read pfsync
packets from) are a single contig cluster coming off the network, so we
rarely hit the case m_pullup was called in.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.158 2010/11/29 05:31:38 dlg Exp $	*/
a1697 2
int defer = 10;

d1726 1
a1726 1
	timeout_add(&pd->pd_tmo, defer);
@


1.158
log
@get rid of struct pfsync_pkt. it was used to store data on the stack to
pass to all the submessage handlers, but only the flags part of it was
ever used. just pass the flags directly instead.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.157 2010/11/28 11:43:41 dlg Exp $	*/
d668 2
a669 1
	if (m->m_pkthdr.len < offset + sizeof(*ph)) {
d671 1
a671 9
		goto done;
	}

	if (offset + sizeof(*ph) > m->m_len) {
		if (m_pullup(m, offset + sizeof(*ph)) == NULL) {
			pfsyncstats.pfsyncs_hdrops++;
			return;
		}
		ip = mtod(m, struct ip *);
d673 1
a673 1
	ph = (struct pfsync_header *)((char *)ip + offset);
@


1.157
log
@there's no need to take splsoftnet in the input packet action handlers
since theyre only ever called from pfsync_input, which is only called
from ipintr, which is only called by softnet.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.156 2010/09/27 23:45:48 dlg Exp $	*/
a95 6
struct pfsync_pkt {
	struct ip *ip;
	struct in_addr src;
	u_int8_t flags;
};

d99 11
a109 11
int	pfsync_in_clr(struct pfsync_pkt *, caddr_t, int, int);
int	pfsync_in_iack(struct pfsync_pkt *, caddr_t, int, int);
int	pfsync_in_upd_c(struct pfsync_pkt *, caddr_t, int, int);
int	pfsync_in_ureq(struct pfsync_pkt *, caddr_t, int, int);
int	pfsync_in_del(struct pfsync_pkt *, caddr_t, int, int);
int	pfsync_in_del_c(struct pfsync_pkt *, caddr_t, int, int);
int	pfsync_in_bus(struct pfsync_pkt *, caddr_t, int, int);
int	pfsync_in_tdb(struct pfsync_pkt *, caddr_t, int, int);
int	pfsync_in_ins(struct pfsync_pkt *, caddr_t, int, int);
int	pfsync_in_upd(struct pfsync_pkt *, caddr_t, int, int);
int	pfsync_in_eof(struct pfsync_pkt *, caddr_t, int, int);
d111 1
a111 1
int	pfsync_in_error(struct pfsync_pkt *, caddr_t, int, int);
d114 1
a114 1
	int	(*in)(struct pfsync_pkt *, caddr_t, int, int);
d474 1
a474 1
pfsync_state_import(struct pfsync_state *sp, u_int8_t flags)
a637 1
	struct pfsync_pkt pkt;
d643 1
a643 1
	int offset, offp, len, count, mlen;
a692 5
	/* Cheaper to grab this now than having to mess with mbufs later */
	pkt.ip = ip;
	pkt.src = ip->ip_src;
	pkt.flags = 0;

d694 1
a694 1
		pkt.flags |= PFSYNC_SI_CKSUM;
d727 2
a728 2
		if (pfsync_acts[subh.action].in(&pkt, mp->m_data + offp,
		    mlen, count) != 0)
d739 1
a739 1
pfsync_in_clr(struct pfsync_pkt *pkt, caddr_t buf, int len, int count)
d786 1
a786 1
pfsync_in_ins(struct pfsync_pkt *pkt, caddr_t buf, int len, int count)
d806 1
a806 1
		if (pfsync_state_import(sp, pkt->flags) == ENOMEM) {
d816 1
a816 1
pfsync_in_iack(struct pfsync_pkt *pkt, caddr_t buf, int len, int count)
d873 1
a873 1
pfsync_in_upd(struct pfsync_pkt *pkt, caddr_t buf, int len, int count)
d970 1
a970 1
pfsync_in_upd_c(struct pfsync_pkt *pkt, caddr_t buf, int len, int count)
d1044 1
a1044 1
pfsync_in_ureq(struct pfsync_pkt *pkt, caddr_t buf, int len, int count)
d1077 1
a1077 1
pfsync_in_del(struct pfsync_pkt *pkt, caddr_t buf, int len, int count)
d1103 1
a1103 1
pfsync_in_del_c(struct pfsync_pkt *pkt, caddr_t buf, int len, int count)
d1130 1
a1130 1
pfsync_in_bus(struct pfsync_pkt *pkt, caddr_t buf, int len, int count)
d1175 1
a1175 1
pfsync_in_tdb(struct pfsync_pkt *pkt, caddr_t buf, int len, int count)
d1233 1
a1233 1
pfsync_in_eof(struct pfsync_pkt *pkt, caddr_t buf, int len, int count)
d1243 1
a1243 1
pfsync_in_error(struct pfsync_pkt *pkt, caddr_t buf, int len, int count)
@


1.156
log
@must have either PR_WAITOK or PR_NOWAIT set.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.155 2010/09/08 08:53:57 blambert Exp $	*/
a759 1
	int s;
a760 1
	s = splsoftnet();
a792 1
	splx(s);
a802 3
	int s;

	s = splsoftnet();
a822 1
	splx(s);
a833 1
	int s;
a834 1
	s = splsoftnet();
a847 1
	splx(s);
a892 2
	int s;

a893 1
	s = splsoftnet();
a976 1
	splx(s);
a990 1
	int s;
a991 1
	s = splsoftnet();
a1050 1
	splx(s);
a1094 1
	int s;
a1095 1
	s = splsoftnet();
a1109 1
	splx(s);
a1120 1
	int s;
a1121 1
	s = splsoftnet();
a1136 1
	splx(s);
a1191 1
	int s;
a1192 1
	s = splsoftnet();
a1196 1
	splx(s);
@


1.155
log
@creating a pfsync interface is always done from process context, so
we can pass M_WAITOK to malloc(9) (which was already done a few lines
down, which set off my aesthetic alarm).

While here, include malloc.h, since we're calling malloc.

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.154 2010/07/28 06:52:05 dlg Exp $	*/
d520 1
a520 1
		pool_flags = PR_LIMITFAIL | PR_ZERO;
@


1.154
log
@pfsync_bulk_fail was mucking around with pfsync_softc and sending packets
without holding splsoftnet. this adds the necessary protection.

reported by patrick coleman
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.153 2010/07/25 23:36:31 jsg Exp $	*/
d49 1
d282 1
d295 1
a295 3
	sc = malloc(sizeof(*pfsyncif), M_DEVBUF, M_NOWAIT | M_ZERO);
	if (sc == NULL)
		return (ENOMEM);
@


1.153
log
@Add missing braces so a loop will function as intended.
ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.152 2010/07/09 16:58:06 reyk Exp $	*/
d2261 3
d2281 2
@


1.152
log
@Add support for using IPsec in multiple rdomains.

This allows to run isakmpd/iked/ipsecctl in multiple rdomains
independently (with "route exec"); the kernel will pickup the rdomain
from the process context of the pfkey socket and load the flows and
SAs into the matching rdomain encap routing table.  The network stack
also needs to pass the rdomain to the ipsec stack to lookup the
correct rdomain that belongs to an interface/mbuf/... You can now run
individual IPsec configs per rdomain or create IPsec VPNs between
multiple rdomains on the same machine ;).  Note that a primary enc(4)
in addition to enc0 interface is required per rdomain, eg. enc1 rdomain 1.

Test by some people, mostly on existing "rdomain 0" setups.  Was in
snaps for some days and people didn't complain.

ok claudio@@ naddy@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.151 2010/07/09 13:09:34 dlg Exp $	*/
d1218 1
a1218 1
	for (i = 0; i < count; i++)
d1221 1
@


1.151
log
@instead of saying we're using the all the states in the table when
sending a bulk update, only say we're using the states referenced
by the next and last pointers into the table. this means the pf
timeout thread can keep trimming states during a bulk update.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.148 2010/07/09 09:01:32 dlg Exp $	*/
d1242 1
a1242 1
	tdb = gettdb(pt->spi, &pt->dst, pt->sproto);
d2165 1
@


1.150
log
@-#if 1 || defined(PFSYNC_DEBUG)
+#if defined(PFSYNC_DEBUG)
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.149 2010/07/09 11:16:45 dlg Exp $	*/
d2311 3
a2313 1
	if (st->sync_state != PFSYNC_S_NONE)
d2316 1
a2316 4
	if (sc->sc_bulk_next == NULL && sc->sc_bulk_last == NULL)
		return (0);

	return (1);
@


1.149
log
@the current code doesnt detect when its filled a bulk packet so it
keeps on building them, which means that it floods the tx ring on
the pfsync interface rather than actually sending many packets.

this change correctly calculates when we've filled a bulk update
packet.

many thanks to david@@ for making me go chase this. ive been wondering
why the state count on my firewalls has had such a discrepency for
a long time now.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.148 2010/07/09 09:01:32 dlg Exp $	*/
d2050 1
a2050 1
#if 1 || defined(PFSYNC_DEBUG)
@


1.148
log
@sending of bulk updates has been very broken since r1.124.
pfsync_bulk_start sets up a bulk transfer by doing this:

	sc->sc_bulk_next = TAILQ_FIRST(&state_list);
	sc->sc_bulk_last = sc->sc_bulk_next;

and then calls pfsync_bulk_update which loops over state_list like
this:

        st = sc->sc_bulk_next;
        while (st != sc->sc_bulk_last) {

basically bulk updates never got sent.

this diff handles jjs problem by not attempting to send a bulk
update when the state table is empty and fixed the loop to break
at the right times.

reported by david@@ who's initial tests are positive.
reviewed by mcbride@@
tested in production at work.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.147 2010/05/24 02:11:04 dlg Exp $	*/
d2220 3
a2222 1
		if (i > 0 && TAILQ_EMPTY(&sc->sc_qs[PFSYNC_S_UPD])) {
@


1.147
log
@remove bpfdetach() here, because it is called correctly in if_detach()
afterwards

diff from gleydson soares
ok claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.146 2010/05/12 08:11:11 claudio Exp $	*/
d2172 1
a2172 1
	sc->sc_ureq_received = time_uptime;
d2174 4
a2177 3
	if (sc->sc_bulk_next == NULL)
		sc->sc_bulk_next = TAILQ_FIRST(&state_list);
	sc->sc_bulk_last = sc->sc_bulk_next;
d2179 3
a2181 1
	DPFPRINTF(LOG_INFO, "received bulk update request");
d2183 3
a2185 2
	pfsync_bulk_status(PFSYNC_BUS_START);
	timeout_add(&sc->sc_bulk_tmo, 0);
d2200 1
a2200 1
	while (st != sc->sc_bulk_last) {
d2212 8
d2223 1
a2223 1
			goto out;
a2226 6
	/* we're done */
	sc->sc_bulk_next = NULL;
	sc->sc_bulk_last = NULL;
	pfsync_bulk_status(PFSYNC_BUS_END);

out:
@


1.146
log
@bzero() the full compressed update struct before setting the values.
This is needed because pf_state_peer_hton() skips some fields in certain
situations which could result in garbage beeing sent to the other peer.
This seems to fix the pfsync storms seen by stephan@@ and so dlg owes me
a whiskey.
OK dlg@@, stephan@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.145 2010/04/25 17:38:53 mpf Exp $	*/
a356 3
#endif
#if NBPFILTER > 0
	bpfdetach(ifp);
@


1.145
log
@Properly adjust group demotion counters when groups are added or
removed.  Extend carp demote logging to also show the reason for
the demote.  Return EINVAL instead of ERANGE if a carpdemote request
is out range.  Requested from otto.
OK mcbride, henning.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.144 2010/03/23 22:34:49 pyr Exp $	*/
d1477 1
a1488 2

	bzero(up->_pad, sizeof(up->_pad)); /* XXX */
@


1.144
log
@Fix a crash in pfsync when running IPSEC.
Found out the hard way by Laurent ``bucky'' Lavaud and myself.

Input by claudio@@, ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.143 2010/03/01 12:29:35 dlg Exp $	*/
d356 1
a356 1
		carp_group_demote_adj(&sc->sc_if, -1);
d1197 2
a1198 1
				carp_group_demote_adj(&sc->sc_if, -1);
d1892 2
a1893 1
			carp_group_demote_adj(&sc->sc_if, 1);
d2266 2
a2267 1
			carp_group_demote_adj(&sc->sc_if, -1);
@


1.143
log
@shuffle slightly and add more splassert.

also protect the flushing of the deferred packet queue in clone_destroy
with the right spls. noticed by claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.142 2010/02/17 00:00:04 dlg Exp $	*/
d1222 1
a1222 1
		pfsync_update_net_tdb(&tp[i]);
@


1.143.2.1
log
@Sync with head as prompted by deraadt@@,
Original commit message: "Fix a crash in pfsync when running IPSEC."
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.144 2010/03/23 22:34:49 pyr Exp $	*/
d1222 1
a1222 1
		pfsync_update_net_tdb(tp);
@


1.143.2.2
log
@MFC, original commit by claudio@@:
------------------------------------------------------------------------
bzero() the full compressed update struct before setting the values.
This is needed because pf_state_peer_hton() skips some fields in certain
situations which could result in garbage beeing sent to the other peer.
This seems to fix the pfsync storms seen by stephan@@ and so dlg owes me
a whiskey.
OK dlg@@, stephan@@
------------------------------------------------------------------------

ok claudio@@ and sthen@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.143.2.1 2010/03/24 20:52:09 pyr Exp $	*/
a1475 1
	bzero(up, sizeof(*up));
d1487 2
@


1.142
log
@dont defer broadcast or multicast packets.

ok sthen@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.141 2010/01/18 23:52:46 mcbride Exp $	*/
d350 1
d365 1
d368 1
a1763 1
	sc->sc_deferred++;
d1771 1
d1773 1
d1789 1
a1793 1
	timeout_del(&pd->pd_tmo); /* bah */
d1820 2
d1829 1
a1829 1
	panic("pfsync_send_deferred: unable to find deferred state");
@


1.141
log
@Convert pf debug logging to using log()/addlog(), a single standardised
definition of DPFPRINTF(), and log priorities from syslog.h. Old debug
levels will still work for now, but will eventually be phased out.

discussed with henning, ok dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.140 2010/01/12 23:38:02 dlg Exp $	*/
d1752 1
a1752 1
	if (!sc->sc_defer)
@


1.140
log
@factor m_pulldown out of the message handlers up into pfsync_input now
that it knows how big the messages are.

rework the message handlers to use the pfsync_subheader.len value to
iterate over the message regions.

deprecate the EOF subheader since trying to pulldown a 0 byte buffer is
fail.

ok mcbride@@ sperreault@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.139 2010/01/12 10:21:38 dlg Exp $	*/
d56 1
d84 1
d489 3
a491 3
	if (sp->creatorid == 0 && pf_status.debug >= PF_DEBUG_MISC) {
		printf("pfsync_state_import: invalid creator id:"
		    " %08x\n", ntohl(sp->creatorid));
d496 2
a497 3
		if (pf_status.debug >= PF_DEBUG_MISC)
			printf("pfsync_state_import: "
			    "unknown interface: %s\n", sp->ifname);
d818 2
a819 4
			if (pf_status.debug >= PF_DEBUG_MISC) {
				printf("pfsync_input: PFSYNC5_ACT_INS: "
				    "invalid value\n");
			}
d914 23
a936 4
			if (pf_status.debug >= PF_DEBUG_MISC) {
				printf("pfsync_input: PFSYNC_ACT_UPD: "
				    "invalid value\n");
			}
d1015 2
a1016 5
			if (pf_status.debug >= PF_DEBUG_MISC) {
				printf("pfsync_input: "
				    "PFSYNC_ACT_UPD_C: "
				    "invalid value\n");
			}
d1182 1
a1182 2
		if (pf_status.debug >= PF_DEBUG_MISC)
			printf("pfsync: received bulk update start\n");
d1197 1
a1197 3
			if (pf_status.debug >= PF_DEBUG_MISC)
				printf("pfsync: received valid "
				    "bulk update end\n");
d1199 2
a1200 3
			if (pf_status.debug >= PF_DEBUG_MISC)
				printf("pfsync: received invalid "
				    "bulk update end: bad timestamp\n");
d1260 2
a1261 3
	if (pf_status.debug >= PF_DEBUG_MISC)
		printf("pfsync_insert: PFSYNC_ACT_TDB_UPD: "
		    "invalid value\n");
d1888 1
a1888 2
		if (pf_status.debug >= PF_DEBUG_MISC)
			printf("pfsync: requesting bulk update\n");
d2174 1
a2174 2
	if (pf_status.debug >= PF_DEBUG_MISC)
		printf("pfsync: received bulk update request\n");
d2261 1
a2261 2
		if (pf_status.debug >= PF_DEBUG_MISC)
			printf("pfsync: failed to receive bulk update\n");
@


1.139
log
@check the new pfsync_subheader len field on input.

this makes sure there is enough of the message to try and parse it, and
allows implementations to skip past regions prefixed by unknown subheaders.

based on discussion with mcbride@@ deraadt@@ and simon perreault
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.137 2010/01/11 00:19:11 dlg Exp $	*/
d91 1
a91 2
	sizeof(struct pfsync_header) + \
	sizeof(struct pfsync_subheader))
d102 11
a112 11
int	pfsync_in_clr(struct pfsync_pkt *, struct mbuf *, int, int);
int	pfsync_in_iack(struct pfsync_pkt *, struct mbuf *, int, int);
int	pfsync_in_upd_c(struct pfsync_pkt *, struct mbuf *, int, int);
int	pfsync_in_ureq(struct pfsync_pkt *, struct mbuf *, int, int);
int	pfsync_in_del(struct pfsync_pkt *, struct mbuf *, int, int);
int	pfsync_in_del_c(struct pfsync_pkt *, struct mbuf *, int, int);
int	pfsync_in_bus(struct pfsync_pkt *, struct mbuf *, int, int);
int	pfsync_in_tdb(struct pfsync_pkt *, struct mbuf *, int, int);
int	pfsync_in_ins(struct pfsync_pkt *, struct mbuf *, int, int);
int	pfsync_in_upd(struct pfsync_pkt *, struct mbuf *, int, int);
int	pfsync_in_eof(struct pfsync_pkt *, struct mbuf *, int, int);
d114 1
a114 1
int	pfsync_in_error(struct pfsync_pkt *, struct mbuf *, int, int);
d117 1
a117 1
	int	(*in)(struct pfsync_pkt *, struct mbuf *, int, int);
d145 1
a145 1
	{ pfsync_in_eof,	0 },
d645 1
d649 1
a649 1
	int offset, len, count, mlen;
d720 1
a720 1
			 * message (except for EOF), so if the peer is new
d732 3
a734 1
		if (pfsync_acts[subh.action].in(&pkt, m, offset, count) == -1)
d736 5
d750 1
a750 1
pfsync_in_clr(struct pfsync_pkt *pkt, struct mbuf *m, int offset, int count)
d753 1
a753 2
	struct mbuf *mp;
	int i, offp;
a760 7
	mp = m_pulldown(m, offset, sizeof(*clr) * count, &offp);
	if (mp == NULL) {
		pfsyncstats.pfsyncs_badlen++;
		return (-1);
	}
	clr = (struct pfsync_clr *)(mp->m_data + offp);

d763 2
a764 1
		creatorid = clr[i].creatorid;
d766 1
a766 1
		if (clr[i].ifname[0] == '\0') {
d776 1
a776 1
			if (pfi_kif_get(clr[i].ifname) == NULL)
d800 1
a800 1
pfsync_in_ins(struct pfsync_pkt *pkt, struct mbuf *m, int offset, int count)
d802 2
a803 3
	struct mbuf *mp;
	struct pfsync_state *sa, *sp;
	int i, offp;
a806 7
	mp = m_pulldown(m, offset, sizeof(*sp) * count, &offp);
	if (mp == NULL) {
		pfsyncstats.pfsyncs_badlen++;
		return (-1);
	}
	sa = (struct pfsync_state *)(mp->m_data + offp);

d809 1
a809 1
		sp = &sa[i];
d836 1
a836 1
pfsync_in_iack(struct pfsync_pkt *pkt, struct mbuf *m, int offset, int count)
d838 1
a838 1
	struct pfsync_ins_ack *ia, *iaa;
d841 1
a841 3

	struct mbuf *mp;
	int offp, i;
a843 7
	mp = m_pulldown(m, offset, count * sizeof(*ia), &offp);
	if (mp == NULL) {
		pfsyncstats.pfsyncs_badlen++;
		return (-1);
	}
	iaa = (struct pfsync_ins_ack *)(mp->m_data + offp);

d846 1
a846 1
		ia = &iaa[i];
d896 1
a896 1
pfsync_in_upd(struct pfsync_pkt *pkt, struct mbuf *m, int offset, int count)
d898 1
a898 1
	struct pfsync_state *sa, *sp;
d903 1
a903 2
	struct mbuf *mp;
	int offp, i;
a905 6
	mp = m_pulldown(m, offset, count * sizeof(*sp), &offp);
	if (mp == NULL) {
		pfsyncstats.pfsyncs_badlen++;
		return (-1);
	}
	sa = (struct pfsync_state *)(mp->m_data + offp);
d909 1
a909 1
		sp = &sa[i];
d978 1
a978 1
pfsync_in_upd_c(struct pfsync_pkt *pkt, struct mbuf *m, int offset, int count)
d980 1
a980 1
	struct pfsync_upd_c *ua, *up;
d986 1
a986 2
	struct mbuf *mp;
	int offp, i;
a988 7
	mp = m_pulldown(m, offset, count * sizeof(*up), &offp);
	if (mp == NULL) {
		pfsyncstats.pfsyncs_badlen++;
		return (-1);
	}
	ua = (struct pfsync_upd_c *)(mp->m_data + offp);

d991 1
a991 1
		up = &ua[i];
d1058 1
a1058 1
pfsync_in_ureq(struct pfsync_pkt *pkt, struct mbuf *m, int offset, int count)
d1060 2
a1061 3
	struct pfsync_upd_req *ur, *ura;
	struct mbuf *mp;
	int i, offp;
a1065 7
	mp = m_pulldown(m, offset, count * sizeof(*ur), &offp);
	if (mp == NULL) {
		pfsyncstats.pfsyncs_badlen++;
		return (-1);
	}
	ura = (struct pfsync_upd_req *)(mp->m_data + offp);

d1067 1
a1067 1
		ur = &ura[i];
d1091 1
a1091 1
pfsync_in_del(struct pfsync_pkt *pkt, struct mbuf *m, int offset, int count)
d1093 1
a1093 2
	struct mbuf *mp;
	struct pfsync_state *sa, *sp;
d1096 1
a1096 1
	int offp, i;
a1098 7
	mp = m_pulldown(m, offset, count * sizeof(*sp), &offp);
	if (mp == NULL) {
		pfsyncstats.pfsyncs_badlen++;
		return (-1);
	}
	sa = (struct pfsync_state *)(mp->m_data + offp);

d1101 1
a1101 1
		sp = &sa[i];
d1120 1
a1120 1
pfsync_in_del_c(struct pfsync_pkt *pkt, struct mbuf *m, int offset, int count)
d1122 1
a1122 2
	struct mbuf *mp;
	struct pfsync_del_c *sa, *sp;
d1125 1
a1125 1
	int offp, i;
a1127 7
	mp = m_pulldown(m, offset, count * sizeof(*sp), &offp);
	if (mp == NULL) {
		pfsyncstats.pfsyncs_badlen++;
		return (-1);
	}
	sa = (struct pfsync_del_c *)(mp->m_data + offp);

d1130 1
a1130 1
		sp = &sa[i];
d1150 1
a1150 1
pfsync_in_bus(struct pfsync_pkt *pkt, struct mbuf *m, int offset, int count)
a1153 2
	struct mbuf *mp;
	int offp;
d1159 1
a1159 6
	mp = m_pulldown(m, offset, count * sizeof(*bus), &offp);
	if (mp == NULL) {
		pfsyncstats.pfsyncs_badlen++;
		return (-1);
	}
	bus = (struct pfsync_bus *)(mp->m_data + offp);
d1198 1
a1198 1
pfsync_in_tdb(struct pfsync_pkt *pkt, struct mbuf *m, int offset, int count)
a1201 2
	struct mbuf *mp;
	int offp;
a1204 7
	mp = m_pulldown(m, offset, count * sizeof(struct pfsync_tdb), &offp);
	if (mp == NULL) {
		pfsyncstats.pfsyncs_badlen++;
		return (-1);
	}
	tp = (struct pfsync_tdb *)(mp->m_data + offp);

d1207 1
d1259 1
a1259 1
pfsync_in_eof(struct pfsync_pkt *pkt, struct mbuf *m, int offset, int count)
d1261 2
a1262 3
	/* check if we are at the right place in the packet */
	if (offset != m->m_pkthdr.len)
		pfsyncstats.pfsyncs_badlen++;
d1265 1
a1265 1
	return (0);
d1269 1
a1269 1
pfsync_in_error(struct pfsync_pkt *pkt, struct mbuf *m, int offset, int count)
a1271 2

	m_freem(m);
a1672 8

	subh = (struct pfsync_subheader *)(m->m_data + offset);
	offset += sizeof(*subh);

	bzero(subh, sizeof(*subh));
	subh->action = PFSYNC_ACT_EOF;
	subh->len = 0 >> 2;
	subh->count = htons(0);
@


1.138
log
@Remove bpfdetach() call right in front of the if_detach() call since
bpfdetach() will be called in if_detach(). Diff by Gleydson Soares
@
text
@d117 34
a150 16
int	(*pfsync_acts[])(struct pfsync_pkt *, struct mbuf *, int, int) = {
	pfsync_in_clr,			/* PFSYNC_ACT_CLR */
	pfsync_in_error,		/* PFSYNC_ACT_OINS */
	pfsync_in_iack,			/* PFSYNC_ACT_INS_ACK */
	pfsync_in_error,		/* PFSYNC_ACT_OUPD */
	pfsync_in_upd_c,		/* PFSYNC_ACT_UPD_C */
	pfsync_in_ureq,			/* PFSYNC_ACT_UPD_REQ */
	pfsync_in_del,			/* PFSYNC_ACT_DEL */
	pfsync_in_del_c,		/* PFSYNC_ACT_DEL_C */
	pfsync_in_error,		/* PFSYNC_ACT_INS_F */
	pfsync_in_error,		/* PFSYNC_ACT_DEL_F */
	pfsync_in_bus,			/* PFSYNC_ACT_BUS */
	pfsync_in_tdb,			/* PFSYNC_ACT_TDB */
	pfsync_in_eof,			/* PFSYNC_ACT_EOF */
	pfsync_in_ins,			/* PFSYNC_ACT_INS */
	pfsync_in_upd			/* PFSYNC_ACT_UPD */
d356 3
d649 1
a649 2
	int offset, len;
	int rv;
d712 3
d716 12
a727 1
		    subh.action >= nitems(pfsync_acts)) {
d732 1
a732 3
		rv = (*pfsync_acts[subh.action])(&pkt, m, offset,
		    ntohs(subh.count));
		if (rv == -1)
d735 1
a735 1
		offset += rv;
a746 1
	int len = sizeof(*clr) * count;
d755 1
a755 1
	mp = m_pulldown(m, offset, len, &offp);
d796 1
a796 1
	return (len);
a803 1
	int len = sizeof(*sp) * count;
d808 1
a808 1
	mp = m_pulldown(m, offset, len, &offp);
d840 1
a840 1
	return (len);
a850 1
	int len = count * sizeof(*ia);
d854 1
a854 1
	mp = m_pulldown(m, offset, len, &offp);
d877 1
a877 1
	return (len);
a920 1
	int len = count * sizeof(*sp);
d924 1
a924 1
	mp = m_pulldown(m, offset, len, &offp);
d998 1
a998 1
	return (len);
a1007 1
	int len = count * sizeof(*up);
d1014 1
a1014 1
	mp = m_pulldown(m, offset, len, &offp);
d1086 1
a1086 1
	return (len);
a1093 1
	int len = count * sizeof(*ur);
d1099 1
a1099 1
	mp = m_pulldown(m, offset, len, &offp);
d1127 1
a1127 1
	return (len);
a1136 1
	int len = count * sizeof(*sp);
d1140 1
a1140 1
	mp = m_pulldown(m, offset, len, &offp);
d1164 1
a1164 1
	return (len);
a1173 1
	int len = count * sizeof(*sp);
d1177 1
a1177 1
	mp = m_pulldown(m, offset, len, &offp);
d1202 1
a1202 1
	return (len);
a1210 1
	int len = count * sizeof(*bus);
d1215 1
a1215 1
		return (len);
d1217 1
a1217 1
	mp = m_pulldown(m, offset, len, &offp);
d1257 1
a1257 1
	return (len);
a1262 2
	int len = count * sizeof(struct pfsync_tdb);

d1270 1
a1270 1
	mp = m_pulldown(m, offset, len, &offp);
d1283 1
a1283 1
	return (len);
d1336 2
a1337 3
	/* we're done. free and let the caller return */
	m_freem(m);
	return (-1);
d1754 1
a1754 1
	subh->count = htons(1);
@


1.137
log
@remove some debug code that snuck in somehow.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.136 2010/01/10 23:54:21 dlg Exp $	*/
a336 3
#endif
#if NBPFILTER > 0
	bpfdetach(ifp);
@


1.136
log
@replace a pad in the pfsync subheader with a length field. it stores the
length of its message in dwords. multiply that by the count of the messages
to figure out how to skip to the next subheader.

"old" code still thinks the len field is a pad, which it doesnt look at, so
new messages with a filled in len are still parsed correctly by "old" code.

input and ok mcbride@@
sounds good! Simon Perreault
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.135 2009/12/14 12:31:45 henning Exp $	*/
a1880 2
u_int pfsync_upds = 0;

d1928 1
a1928 2
	if (sync || (time_uptime - st->pfsync_time) < 2) {
		pfsync_upds++;
a1929 1
	}
@


1.135
log
@fix sticky-address - by pretty much re-implementing it. still following
the original approach using a source tracking node.
the reimplementation i smore flexible than the original one, we now have an
slist of source tracking nodes per state. that is cheap because more than
one entry will be an absolute exception.
ok beck and jsg, also stress tested by Sebastian Benoit <benoit-lists at fb12.de>
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.134 2009/12/03 12:23:52 otto Exp $	*/
d1671 1
d1700 1
d1727 1
d1736 1
d2089 1
d2294 1
@


1.134
log
@fix order dependency of pfsync interface setup, with claudio;
ok claudio@@ dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.133 2009/11/23 16:03:10 henning Exp $	*/
d432 1
a432 1
	if (st->src_node)
@


1.133
log
@remove the nat_rule pointer on pf_state and pf_pdesc, obsolete after
the NAT rewrite and ever since then only checked in a couple of plaes
but never set. same for nat_src_node on pf_state.
with this the NAT rewrite made pf over 1000 lines shorter.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.132 2009/11/22 22:34:50 henning Exp $	*/
d236 1
d1361 1
a1361 1
		if (ifp->if_flags & IFF_UP)
d1363 2
a1364 1
		else {
d1486 1
a1486 16
		if (sc->sc_sync_if) {
			/* Request a full state table update. */
			sc->sc_ureq_sent = time_uptime;
#if NCARP > 0
			if (pfsync_sync_ok)
				carp_group_demote_adj(&sc->sc_if, 1);
#endif
			pfsync_sync_ok = 0;
			if (pf_status.debug >= PF_DEBUG_MISC)
				printf("pfsync: requesting bulk update\n");
			timeout_add(&sc->sc_bulkfail_tmo, 4 * hz +
			    pf_pool_limits[PF_LIMIT_STATES].limit /
			    ((sc->sc_if.if_mtu - PFSYNC_MINPKT) /
			    sizeof(struct pfsync_state)));
			pfsync_request_update(0, 0);
		}
d1929 21
@


1.132
log
@cleanup after the NAT changes. we used to have multiple rulesets (scrub,
NAT, filter). now we only have one. no need for an array any more. simplifies
the code quite a bit.
in the process fix the abuse of PF_RULESET_* by (surprise, isn't it) the
table code.
written at the filesystem hackathon in stockholm, committed from the
hardware hackathon in portugal. ok gcc and jsing
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.131 2009/11/12 06:53:24 deraadt Exp $	*/
a432 2
	if (st->nat_src_node)
		sp->sync_flags |= PFSYNC_FLAG_NATSRCNODE;
d447 1
a447 4
	if (st->nat_rule.ptr == NULL)
		sp->nat_rule = htonl(-1);
	else
		sp->nat_rule = htonl(st->nat_rule.ptr->nr);
a569 1
	st->nat_rule.ptr = NULL;
d576 1
a576 1
	/* XXX when we have nat_rule/anchors, use STATE_INC_COUNTERS */
d584 1
a584 1
		/* XXX when we have nat_rule/anchors, use STATE_DEC_COUNTERS */
@


1.131
log
@be paranoid in case the action array changes size (again, grr)
ok dlg
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.130 2009/11/03 10:59:04 claudio Exp $	*/
d495 2
a496 3
	    pf_main_ruleset.rules[PF_RULESET_FILTER].active.rcount)
		r = pf_main_ruleset.rules[
		    PF_RULESET_FILTER].active.ptr_array[ntohl(sp->rule)];
@


1.130
log
@rtables are stacked on rdomains (it is possible to have multiple routing
tables on top of a rdomain) but until now our code was a crazy mix so that
it was impossible to correctly use rtables in that case. Additionally pf(4)
only knows about rtables and not about rdomains. This is especially bad when
tracking (possibly conflicting) states in various domains.
This diff fixes all or most of these issues. It adds a lookup function to
get the rdomain id based on a rtable id. Makes pf understand rdomains and
allows pf to move packets between rdomains (it is similar to NAT).
Because pf states now track the rdomain id as well it is necessary to modify
the pfsync wire format. So old and new systems will not sync up.
A lot of help by dlg@@, tested by sthen@@, jsg@@ and probably more
OK dlg@@, mpf@@, deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.129 2009/09/28 03:01:23 dlg Exp $	*/
d701 2
a702 1
		if (subh.action >= PFSYNC_ACT_MAX) {
@


1.129
log
@when inserting a state, turn the error that pf_state_insert returns
into something usable by ioctl. makes DIOCADDSTATE on /dev/pf cope
when inserting an already existing state.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.128 2009/08/16 13:01:57 jsg Exp $	*/
a103 1
int	pfsync_in_ins(struct pfsync_pkt *, struct mbuf *, int, int);
a104 1
int	pfsync_in_upd(struct pfsync_pkt *, struct mbuf *, int, int);
d111 2
d119 1
a119 1
	pfsync_in_ins,			/* PFSYNC_ACT_INS */
d121 1
a121 1
	pfsync_in_upd,			/* PFSYNC_ACT_UPD */
d130 3
a132 1
	pfsync_in_eof			/* PFSYNC_ACT_EOF */
a147 1
	{ pfsync_out_state, sizeof(struct pfsync_state),   PFSYNC_ACT_INS },
a148 1
	{ pfsync_out_state, sizeof(struct pfsync_state),   PFSYNC_ACT_UPD },
d150 3
a152 1
	{ pfsync_out_del,   sizeof(struct pfsync_del_c),   PFSYNC_ACT_DEL_C }
d406 1
d411 3
d459 3
d520 2
a521 1
	    sp->key[PF_SK_WIRE].port[1] != sp->key[PF_SK_STACK].port[1]) {
d537 1
d545 1
d549 2
d566 3
a1671 26
	/* walk the queues */
	for (q = 0; q < PFSYNC_S_COUNT; q++) {
		if (TAILQ_EMPTY(&sc->sc_qs[q]))
			continue;

		subh = (struct pfsync_subheader *)(m->m_data + offset);
		offset += sizeof(*subh);

		count = 0;
		TAILQ_FOREACH(st, &sc->sc_qs[q], sync_list) {
#ifdef PFSYNC_DEBUG
			KASSERT(st->sync_state == q);
#endif
			pfsync_qs[q].write(st, m->m_data + offset);
			offset += pfsync_qs[q].len;

			st->sync_state = PFSYNC_S_NONE;
			count++;
		}
		TAILQ_INIT(&sc->sc_qs[q]);

		bzero(subh, sizeof(*subh));
		subh->action = pfsync_qs[q].action;
		subh->count = htons(count);
	}

d1718 26
@


1.128
log
@remove prototypes of a bunch of functions that had their implementations
removed in pfsync v5.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.127 2009/06/17 04:24:02 dlg Exp $	*/
d573 1
a573 1
	if ((error = pf_state_insert(kif, skw, sks, st)) != 0) {
d576 1
@


1.127
log
@do better detection of when we have a better version of the tcp sequence
windows than our peer.

this resolves the last of the pfsync traffic storm issues ive been able to
produce, and therefore makes it possible to do usable active-active
statuful firewalls with pf.

lots of testing locally on the production firewalls, also tested by sthen@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.126 2009/06/14 00:16:50 dlg Exp $	*/
a228 1
struct mbuf *pfsync_get_mbuf(struct pfsync_softc *);
a239 2
int	pfsync_tdb_sendout(struct pfsync_softc *);
int	pfsync_sendout_mbuf(struct pfsync_softc *, struct mbuf *);
a241 1
void	pfsync_send_bus(struct pfsync_softc *, u_int8_t);
@


1.127.4.1
log
@MFC, original commit by claudio@@:
------------------------------------------------------------------------
bzero() the full compressed update struct before setting the values.
This is needed because pf_state_peer_hton() skips some fields in certain
situations which could result in garbage beeing sent to the other peer.
This seems to fix the pfsync storms seen by stephan@@ and so dlg owes me
a whiskey.
OK dlg@@, stephan@@
------------------------------------------------------------------------

ok claudio@@ and sthen@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.127 2009/06/17 04:24:02 dlg Exp $	*/
a1524 1
	bzero(up, sizeof(*up));
d1536 2
@


1.126
log
@enable support for deferring the packet that creates a state so that your
sync peers are able to get the states before the replies. previously there
was a race where the reply could hit a partner firewall before it had the
state for it, which caused the reply to get processed by the ruleset which
probably would drop it.

this behaviour is off by default because it does delay packets, which is
only wanted in active-active firewalls or when an upstream router is slow
to learn that you're moved the active member of the pfsync cluster. it also
uses memory keeping the packets in the kernel.

use "ifconfig pfsync0 defer" to enable it, "ifconfig pfsync0 -defer" to
disable.

tested by sthen@@ who loves it. he's got manpage changes coming up for me.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.125 2009/06/12 02:03:51 dlg Exp $	*/
d859 3
a861 1
	    SEQ_GT(st->src.seqlo, ntohl(src->seqlo)))
d866 2
a867 1
	if (st->dst.state > dst->state ||
@


1.125
log
@rewrite the way states from pfsync are merged into the local state tree
and the conditions on which pfsync will notify its peers on a stale update.

each side (ie, the sending and receiving side) of the state update is
compared separately. any side that is further along than the local state
tree is merged. if any side is further along in the local state table, an
update is sent out telling the peers about it.

this has been flogged to death on my firewalls.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.124 2009/06/10 00:03:55 dlg Exp $	*/
d193 1
d1384 1
d1407 2
d1792 1
a1792 4
	if (ISSET(st->state_flags, PFSTATE_ACK))
		schednetisr(NETISR_PFSYNC);
	else
		st->sync_updates = 0;
a1799 2
	return (0);
#ifdef notyet
d1805 3
d1826 2
a1828 1
#endif
@


1.124
log
@jj reported a panic in bulk updates to me. this is my attempt to fix the
most obvious problem.

if the state table is empty, we'd deref a null pointer.

tested on my firewalls with big state tables, so existing use cases still
work.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.123 2009/05/13 01:09:05 dlg Exp $	*/
d848 1
a848 1
	int sfail = 0;
d855 1
a855 1
	if (st->src.state > src->state &&
d857 4
a860 11
	    src->state >= PF_TCPS_PROXY_SRC))
		sfail = 1;
	else if (SEQ_GT(st->src.seqlo, ntohl(src->seqlo)))
		sfail = 3;
	else if (st->dst.state > dst->state) {
		/* There might still be useful
		 * information about the src state here,
		 * so import that part of the update,
		 * then "fail" so we send the updated
		 * state back to the peer who is missing
		 * our what we know. */
a861 5
		/* XXX do anything with timeouts? */
		sfail = 7;
	} else if (st->dst.state >= TCPS_SYN_SENT &&
	    SEQ_GT(st->dst.seqlo, ntohl(dst->seqlo)))
		sfail = 4;
d863 8
a870 1
	return (sfail);
a877 1
	struct pf_state_key *sk;
d879 1
a879 1
	int sfail;
d923 2
a924 4
		sk = st->key[PF_SK_WIRE];	/* XXX right one? */
		sfail = 0;
		if (sk->proto == IPPROTO_TCP)
			sfail = pfsync_upd_tcp(st, &sp->src, &sp->dst);
d926 2
d933 8
a940 3
				sfail = 5;
			else if (st->dst.state > sp->dst.state)
				sfail = 6;
d943 9
a951 8
		if (sfail) {
			if (pf_status.debug >= PF_DEBUG_NOISY) {
				printf("pfsync: %s stale update (%d)"
				    " id: %016llx creatorid: %08x\n",
				    (sfail < 7 ?  "ignoring" : "partial"),
				    sfail, betoh64(st->id),
				    ntohl(st->creatorid));
			}
a955 1
			continue;
a956 6
		pfsync_alloc_scrub_memory(&sp->dst, &st->dst);
		pf_state_peer_ntoh(&sp->src, &st->src);
		pf_state_peer_ntoh(&sp->dst, &st->dst);
		st->expire = ntohl(sp->expire) + time_second;
		st->timeout = sp->timeout;
		st->pfsync_time = time_uptime;
a966 1
	struct pf_state_key *sk;
d971 1
a971 1
	int sfail;
d1014 2
a1015 4
		sk = st->key[PF_SK_WIRE]; /* XXX right one? */
		sfail = 0;
		if (sk->proto == IPPROTO_TCP)
			sfail = pfsync_upd_tcp(st, &up->src, &up->dst);
d1017 1
d1019 2
a1020 1
			 * Non-TCP protocol state machine always go forwards
d1023 14
a1036 3
				sfail = 5;
			else if (st->dst.state > up->dst.state)
				sfail = 6;
d1038 1
d1040 1
a1040 8
		if (sfail) {
			if (pf_status.debug >= PF_DEBUG_NOISY) {
				printf("pfsync: ignoring stale update "
				    "(%d) id: %016llx "
				    "creatorid: %08x\n", sfail,
				    betoh64(st->id),
				    ntohl(st->creatorid));
			}
a1044 1
			continue;
a1045 6
		pfsync_alloc_scrub_memory(&up->dst, &st->dst);
		pf_state_peer_ntoh(&up->src, &st->src);
		pf_state_peer_ntoh(&up->dst, &st->dst);
		st->expire = ntohl(up->expire) + time_second;
		st->timeout = up->timeout;
		st->pfsync_time = time_uptime;
@


1.123
log
@dont go splx(s) in the ioctl handler if we havent done splnet(). this adds
the splnet calls and the extra splx(s)s necessary for it to be safe.

bug found by sthen@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.122 2009/05/13 01:01:34 dlg Exp $	*/
d2221 1
a2221 1
	pfsync_bulk_update(sc);
d2228 1
a2228 1
	struct pf_state *st = sc->sc_bulk_next;
d2233 4
a2236 1
	do {
d2253 1
a2253 1
	} while (st != sc->sc_bulk_last);
@


1.122
log
@only keep track of the number of updates on tcp connections. state sync on
all the other protocols is simply pushing the timeouts along which has a
resolution of 1 second, so it isnt going to be hurt by pfsync taking up
to a second to send it over.

keep track of updates on tcp still though, their windows need constant
attention.

tested by sthen@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.121 2009/04/15 05:11:49 david Exp $	*/
d1357 1
d1372 1
d1375 1
d1383 1
d1401 2
d1409 2
a1410 1
		if (pfsyncr.pfsyncr_maxupdates > 255)
d1412 1
d1422 1
d1426 2
a1427 1
		if ((sifp = ifunit(pfsyncr.pfsyncr_syncdev)) == NULL)
d1429 1
d1495 1
@


1.121
log
@move pfsync stale update messages to NOISY level; ok dlg@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.120 2009/04/04 13:09:29 dlg Exp $	*/
d1904 5
a1908 3
		st->sync_updates++;
		if (st->sync_updates >= sc->sc_maxupdates)
			sync = 1;
@


1.120
log
@use time_uptime instead of time_second internally. time_uptime isnt
affected by adjusting the clock.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.119 2009/03/31 01:21:29 dlg Exp $	*/
d945 1
a945 1
			if (pf_status.debug >= PF_DEBUG_MISC) {
d1037 1
a1037 1
			if (pf_status.debug >= PF_DEBUG_MISC) {
@


1.119
log
@do not include space in the end of the from for a hmac. after discussion
with deraadt@@, mcbride@@, and mpf@@ it is obvious that a hmac doesnt make
sense for pfsync.

this also firms up some of the input parsing so it handles short frames a
bit better.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.118 2009/03/23 06:19:59 dlg Exp $	*/
d566 1
a566 1
	st->pfsync_time = time_second;
d963 1
a963 1
		st->pfsync_time = time_second;
d1055 1
a1055 1
		st->pfsync_time = time_second;
d1921 1
a1921 1
	if (sync || (time_second - st->pfsync_time) < 2) {
@


1.118
log
@wait an appropriate amount of time before giving up on a bulk update,
rather than giving up after a hardcoded 5 seconds (which is generally much
too short an interval for a bulk update).

pointed out by david@@, eyeballed by mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.117 2009/03/17 05:06:54 dlg Exp $	*/
d92 1
a92 2
	sizeof(struct pfsync_subheader) + \
	sizeof(struct pfsync_eof))
a99 2
int	pfsync_input_hmac(struct mbuf *, int);

d622 1
a622 1
	int offset;
d667 3
a669 4

#if 0
	if (pfsync_input_hmac(m, offset) != 0) {
		/* XXX stats */
a671 1
#endif
d682 1
a682 1
	for (;;) {
d1312 2
a1313 2
	if (offset != m->m_pkthdr.len - sizeof(struct pfsync_eof))
		pfsyncstats.pfsyncs_badact++;
a1729 2

	/* XXX write checksum in EOF here */
@


1.117
log
@we do know how to handle iack. in the rx path at least.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.116 2009/03/15 19:40:41 miod Exp $	*/
d1208 1
a1208 2
		timeout_add_sec(&sc->sc_bulkfail_tmo, 5); /* XXX magic */
#if XXX
d1210 2
a1211 2
		    (PFSYNC_BULKPACKETS * sc->sc_maxcount));
#endif
d1483 4
a1486 1
			timeout_add_sec(&sc->sc_bulkfail_tmo, 5);
@


1.116
log
@Introduce splsoftassert(), similar to splassert() but for soft interrupt
levels. This will allow for platforms where soft interrupt levels do not
map to real hardware interrupt levels to have soft ipl values overlapping
hard ipl values without breaking spl asserts.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.115 2009/03/01 12:02:39 dlg Exp $	*/
a844 4
	/*
	 * XXX this is not yet implemented, but we know the size of the
	 * message so we can skip it.
	 */
d846 1
a846 1
	return (count * sizeof(struct pfsync_ins_ack));
@


1.115
log
@rework serialisation of messages slightly.
- pass a void *, rather than an mbuf and an offset into m_data, the callers
can do the math for it.
- we need to store the size of the messages these functions will serialise
into, so dont get the funcs to return it, just add it on in the caller.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.114 2009/03/01 11:24:36 dlg Exp $	*/
d1774 1
a1774 1
	splassert(IPL_SOFTNET);
d1811 1
a1811 1
	splassert(IPL_SOFTNET);
d1840 1
a1840 1
	splassert(IPL_SOFTNET);
d1891 1
a1891 1
	splassert(IPL_SOFTNET);
d2013 1
a2013 1
	splassert(IPL_SOFTNET);
d2060 1
a2060 1
	splassert(IPL_SOFTNET);
@


1.114
log
@check pfsyncs IFF_RUNNING flag before doing stuff. should save time for
people who hate^Wdont use pfsync.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.113 2009/03/01 10:34:38 dlg Exp $	*/
d137 1
a137 1
	int		(*write)(struct pf_state *, struct mbuf *, int);
d143 4
a146 4
int	pfsync_out_state(struct pf_state *, struct mbuf *, int);
int	pfsync_out_iack(struct pf_state *, struct mbuf *, int);
int	pfsync_out_upd_c(struct pf_state *, struct mbuf *, int);
int	pfsync_out_del(struct pf_state *, struct mbuf *, int);
d176 1
a176 1
int	pfsync_out_tdb(struct tdb *, struct mbuf *, int);
d1501 2
a1502 2
int
pfsync_out_state(struct pf_state *st, struct mbuf *m, int offset)
d1504 1
a1504 1
	struct pfsync_state *sp = (struct pfsync_state *)(m->m_data + offset);
a1506 2

	return (sizeof(*sp));
d1509 2
a1510 2
int
pfsync_out_iack(struct pf_state *st, struct mbuf *m, int offset)
d1512 1
a1512 2
	struct pfsync_ins_ack *iack =
	    (struct pfsync_ins_ack *)(m->m_data + offset);
a1515 2

	return (sizeof(*iack));
d1518 2
a1519 2
int
pfsync_out_upd_c(struct pf_state *st, struct mbuf *m, int offset)
d1521 1
a1521 1
	struct pfsync_upd_c *up = (struct pfsync_upd_c *)(m->m_data + offset);
a1535 2

	return (sizeof(*up));
d1538 2
a1539 2
int
pfsync_out_del(struct pf_state *st, struct mbuf *m, int offset)
d1541 1
a1541 1
	struct pfsync_del_c *dp = (struct pfsync_del_c *)(m->m_data + offset);
a1546 2

	return (sizeof(*dp));
d1669 2
a1671 1
			offset += pfsync_qs[q].write(st, m, offset);
d1718 2
a1719 1
			offset += pfsync_out_tdb(t, m, offset);
d2169 2
a2170 2
int
pfsync_out_tdb(struct tdb *t, struct mbuf *m, int offset)
d2172 1
a2172 1
	struct pfsync_tdb *ut = (struct pfsync_tdb *)(m->m_data + offset);
a2198 2

	return (sizeof(*ut));
@


1.113
log
@i can't see a reason that we'd need to go to splnet to call ip_output.
this cleans up use of splnet.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.112 2009/02/26 07:29:46 dlg Exp $	*/
d631 2
a632 1
	if (!sc || !sc->sc_sync_if || !pf_status.running)
d1369 1
a1369 1
		else
d1371 10
d1617 1
d1619 1
a1619 1
	if (ifp->if_bpf == NULL && sc->sc_sync_if == NULL) {
d1621 1
a1621 1
	if (sc->sc_sync_if == NULL) {
d1789 2
a1790 1
	if (sc == NULL || ISSET(st->state_flags, PFSTATE_NOSYNC))
d1900 1
a1900 1
	if (sc == NULL)
d2022 1
a2022 1
	if (sc == NULL)
d2061 1
a2066 2
	struct pfsync_softc *sc = pfsyncif;

d2069 1
a2069 1
	if (sc == NULL)
@


1.112
log
@bulk updates are sent from a timeout which walks over the state tree and
modifies the pfsync state queues, however, it didnt prevent interrupts from
whacking the same structures.

this diff makes the bulk update code take splsoftnet() to prevent the
panics ive been suffering all day when a firewall peer was booted.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.110 2009/02/24 05:39:19 dlg Exp $	*/
a363 1
	int s;
a364 1
	s = splnet();
a365 1
	splx(s);
d377 1
d379 1
d384 1
d1376 1
a1376 2
		if (ifr->ifr_mtu < ifp->if_mtu) {
			s = splnet();
a1377 2
			splx(s);
		}
a1418 1
		s = splnet();
a1479 1
		splx(s);
a1602 2
	splassert(IPL_NET);

a1832 1
	int s;
a1843 1
		s = splnet();
a1845 1
		splx(s);
a1935 1
	int s;
a1954 1
		s = splnet();
a1955 1
		splx(s);
a2075 1
	int s;
a2086 1
		s = splnet();
a2087 1
		splx(s);
a2117 1
	int s;
a2126 1
			s = splnet();
a2127 1
			splx(s);
a2301 1
	int s;
d2303 1
a2303 2
	if (sc->sc_len + pluslen > sc->sc_if.if_mtu) {
		s = splnet();
a2304 2
		splx(s);
	}
a2308 1
	s = splnet();
a2309 1
	splx(s);
a2339 3
u_int pfsync_ints;
u_int pfsync_tmos;

d2345 1
a2345 3
	pfsync_tmos++;

	s = splnet();
a2353 5
	int s;

	pfsync_ints++;

	s = splnet();
a2354 1
	splx(s);
@


1.111
log
@restore the parsing of incoming tdb update messages. this was disabled
while i was replacing the guts of pfsync, but i forgot to put it back
again. this will make ipsec gateway failover work again.

tested by sthen@@ and david@@
ok deraadt@@
@
text
@d2241 1
d2243 1
d2259 1
a2259 1
			return;
d2267 3
@


1.110
log
@request a bulk update when the pfsync if configuration is changed via an
ioctl. without this peers would not request a bulk update when they come
up, and therefore will not have the full state tree available for use in
failover.

ok mcbride@@ "go for it" deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.109 2009/02/23 21:16:35 dlg Exp $	*/
d1251 1
a1251 1
#if 0 && defined(IPSEC)
d1267 1
a1267 1
		pfsync_update_net_tdb(&tp[i]); /* XXX */
d1273 43
@


1.109
log
@dont put pfsync packets on the wire if no syncdev is specified. issues
reported by david@@

an earlier version of this was ok mcbride@@
ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.108 2009/02/18 10:07:24 dlg Exp $	*/
a1428 1
#if 0
a1438 1
			/* XXX bulks done this way? */
a1439 1
#endif
@


1.108
log
@if a peer requests a state that is marked as NOSYNC, then skip it.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.107 2009/02/17 23:46:25 dlg Exp $	*/
d1573 9
d1711 6
d1718 1
@


1.107
log
@// style comments shouldnt be in the tree.

reminded by deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.106 2009/02/17 23:45:43 dlg Exp $	*/
a1069 2
int pfsync_req_del;

d1102 2
a1103 3

			if (st->timeout == PFTM_UNLINKED)
				pfsync_req_del++;
@


1.106
log
@assert copyright over the changes i made.

reminded by deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.105 2009/02/17 23:43:47 dlg Exp $	*/
a888 1
//	struct pfsync_softc *sc = pfsyncif;
a980 1
//	struct pfsync_softc *sc = pfsyncif;
@


1.105
log
@init the tdb tailq. hopefully this fixes sthens crash.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.104 2009/02/17 20:59:29 chl Exp $	*/
d29 15
@


1.104
log
@fix uninitialized variable.

found by LLVM/Clang Static Analyzer.

ok dlg@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.103 2009/02/16 00:31:25 dlg Exp $	*/
d273 2
@


1.103
log
@pfsync v5, mostly written at n2k9, but based on work done at n2k8.

WARNING: THIS BREAKS COMPATIBILITY WITH THE PREVIOUS VERSION OF PFSYNC

this is a new variant of the protocol and a large reworking of the
pfsync code to address some performance issues. the single largest
benefit comes from having multiple pfsync messages of different
types handled in a single packet. pfsyncs handling of pf states is
highly optimised now, along with packet parsing and construction.

huggz for beck@@ for testing.
huge thanks to mcbride@@ for his help during development and for
finding all the bugs during the initial tests.
thanks to peter sutton for letting me get credit for this work.

ok beck@@ mcbride@@ "good." deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.102 2008/12/21 23:41:26 dlg Exp $	*/
d1120 2
@


1.102
log
@split the pfsync input routine up so that each action has its own function
to handle it. this is to modularise it in preparation for further changes.

in my opinion it also makes the code a lot easier to read and to maintain.

tested by sthen@@ johan@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.100 2008/09/10 14:01:23 blambert Exp $	*/
d40 1
d46 1
a50 1
#include <sys/pool.h>
d74 112
a185 2
#define PFSYNC_MINMTU	\
    (sizeof(struct pfsync_header) + sizeof(struct pf_state))
d187 13
a199 6
#ifdef PFSYNCDEBUG
#define DPRINTF(x)    do { if (pfsyncdebug) printf x ; } while (0)
int pfsyncdebug;
#else
#define DPRINTF(x)
#endif
a206 1
void	pfsync_setmtu(struct pfsync_softc *, int);
d215 13
a227 3
struct mbuf *pfsync_get_mbuf(struct pfsync_softc *, u_int8_t, void **);
int	pfsync_request_update(struct pfsync_state_upd *, struct in_addr *);
int	pfsync_sendout(struct pfsync_softc *);
d233 3
d237 1
a237 35
void	pfsync_bulkfail(void *);

struct pfsync_pkt {
	struct ip *ip;
	struct in_addr src;
	u_int8_t flags;
};

void	pfsync4_input(struct pfsync_pkt *, struct mbuf *);

int	pfsync4_in_clr(struct pfsync_pkt *, struct mbuf *, int, int);
int	pfsync4_in_ins(struct pfsync_pkt *, struct mbuf *, int, int);
int	pfsync4_in_upd(struct pfsync_pkt *, struct mbuf *, int, int);
int	pfsync4_in_del(struct pfsync_pkt *, struct mbuf *, int, int);
int	pfsync4_in_upd_c(struct pfsync_pkt *, struct mbuf *, int, int);
int	pfsync4_in_del_c(struct pfsync_pkt *, struct mbuf *, int, int);
int	pfsync4_in_ureq(struct pfsync_pkt *, struct mbuf *, int, int);
int	pfsync4_in_bus(struct pfsync_pkt *, struct mbuf *, int, int);
int	pfsync4_in_tdb_upd(struct pfsync_pkt *, struct mbuf *, int, int);

int	pfsync4_in_error(struct pfsync_pkt *, struct mbuf *, int, int);

int	(*pfsync4_acts[])(struct pfsync_pkt *, struct mbuf *, int, int) = {
	pfsync4_in_clr,			/* PFSYNC_ACT_CLR */
	pfsync4_in_ins,			/* PFSYNC_ACT_INS */
	pfsync4_in_upd,			/* PFSYNC_ACT_UPD */
	pfsync4_in_del,			/* PFSYNC_ACT_DEL */
	pfsync4_in_upd_c,		/* PFSYNC_ACT_UPD_C */
	pfsync4_in_del_c,		/* PFSYNC_ACT_DEL_C */
	pfsync4_in_error,		/* PFSYNC_ACT_INS_F */
	pfsync4_in_error,		/* PFSYNC_ACT_DEL_F */
	pfsync4_in_ureq,		/* PFSYNC_ACT_UREQ */
	pfsync4_in_bus,			/* PFSYNC_ACT_BUS */
	pfsync4_in_tdb_upd		/* PFSYNC_ACT_TDB_UPD */
};
d239 1
d253 1
d255 1
d261 3
a263 2
	if ((pfsyncif = malloc(sizeof(*pfsyncif), M_DEVBUF,
	    M_NOWAIT|M_ZERO)) == NULL)
d265 13
a277 14
	pfsyncif->sc_mbuf = NULL;
	pfsyncif->sc_mbuf_net = NULL;
	pfsyncif->sc_mbuf_tdb = NULL;
	pfsyncif->sc_statep.s = NULL;
	pfsyncif->sc_statep_net.s = NULL;
	pfsyncif->sc_statep_tdb.t = NULL;
	pfsyncif->sc_maxupdates = 128;
	pfsyncif->sc_sync_peer.s_addr = INADDR_PFSYNC_GROUP;
	pfsyncif->sc_sendaddr.s_addr = INADDR_PFSYNC_GROUP;
	pfsyncif->sc_ureq_received = 0;
	pfsyncif->sc_ureq_sent = 0;
	pfsyncif->sc_bulk_send_next = NULL;
	pfsyncif->sc_bulk_terminator = NULL;
	pfsyncif->sc_imo.imo_membership = (struct in_multi **)malloc(
d279 4
a282 3
	    M_WAITOK|M_ZERO);
	pfsyncif->sc_imo.imo_max_memberships = IP_MIN_MEMBERSHIPS;
	ifp = &pfsyncif->sc_if;
d284 1
a284 1
	ifp->if_softc = pfsyncif;
d290 7
a296 6
	ifp->if_hdrlen = PFSYNC_HDRLEN;
	pfsync_setmtu(pfsyncif, ETHERMTU);
	timeout_set(&pfsyncif->sc_tmo, pfsync_timeout, pfsyncif);
	timeout_set(&pfsyncif->sc_tdb_tmo, pfsync_tdb_timeout, pfsyncif);
	timeout_set(&pfsyncif->sc_bulk_tmo, pfsync_bulk_update, pfsyncif);
	timeout_set(&pfsyncif->sc_bulkfail_tmo, pfsync_bulkfail, pfsyncif);
d305 1
a305 1
	bpfattach(&pfsyncif->sc_if.if_bpf, ifp, DLT_PFSYNC, PFSYNC_HDRLEN);
d308 2
d318 1
a319 3
	timeout_del(&sc->sc_tdb_tmo);
	timeout_del(&sc->sc_bulk_tmo);
	timeout_del(&sc->sc_bulkfail_tmo);
d328 10
a337 2
	free(pfsyncif->sc_imo.imo_membership, M_IPMOPTS);
	free(pfsyncif, M_DEVBUF);
d339 1
d343 13
a362 1
	int s;
d364 1
a364 2
	for (;;) {
		s = splnet();
d366 1
a366 7
		IF_DEQUEUE(&ifp->if_snd, m);
		splx(s);

		if (m == NULL)
			return;
		else
			m_freem(m);
a540 2
	if (!(flags & PFSYNC_SI_IOCTL))
		st->sync_flags = PFSTATE_FROMSYNC;
d552 2
a553 2
	st->pfsync_time = 0;

d559 3
d568 9
d606 1
a608 1
	int action, count;
d614 1
a614 1
	if (!sc || !sc->sc_sync_ifp || !pf_status.running)
d618 1
a618 1
	if (sc->sc_sync_ifp != m->m_pkthdr.rcvif) {
d623 4
a626 1
	/* verify that the IP TTL is 255.  */
a632 1

d653 3
a655 6
	action = ph->action;
	count = ph->count;

	/* make sure it's a valid action code */
	if (action >= PFSYNC_ACT_MAX) {
		pfsyncstats.pfsyncs_badact++;
d658 1
d665 1
a665 1
	if (!bcmp(&ph->pf_chksum, &pf_status.pf_chksum, PF_MD5_DIGEST_LENGTH))
d669 16
a684 3
	rv = (*pfsync4_acts[action])(&pkt, m, offset, count);
	if (rv == -1)
		return;
d691 1
a691 1
pfsync4_in_clr(struct pfsync_pkt *pkt, struct mbuf *m, int offset, int count)
d693 1
d695 2
a696 1
	int offp;
d698 1
a698 2
	struct pfsync_state_clr *cp;
	struct pf_state *nexts;
d700 1
a700 3
        struct pf_state_item *si;
	struct pf_state *st;
	struct pfi_kif *kif;
d704 1
a704 1
	mp = m_pulldown(m, offset, sizeof(*cp), &offp);
d709 1
a709 1
	cp = (struct pfsync_state_clr *)(mp->m_data + offp);
d712 11
a722 6
	if (cp->ifname[0] == '\0') {
		for (st = RB_MIN(pf_state_tree_id, &tree_id); st; st = nexts) {
			nexts = RB_NEXT(pf_state_tree_id, &tree_id, st);
			if (st->creatorid == creatorid) {
				st->sync_flags |= PFSTATE_FROMSYNC;
				pf_unlink_state(st);
d724 15
a738 11
		}
	} else if ((kif = pfi_kif_get(cp->ifname)) != NULL) {
		/* XXX correct? */
		for (sk = RB_MIN(pf_state_tree, &pf_statetbl);
		    sk; sk = nextsk) {
			nextsk = RB_NEXT(pf_state_tree, &pf_statetbl, sk);
			TAILQ_FOREACH(si, &sk->states, entry) {
				if (si->s->creatorid == creatorid &&
				    si->s->kif == kif) {
					si->s->sync_flags |= PFSTATE_FROMSYNC;
					pf_unlink_state(si->s);
d745 1
a745 1
	return (sizeof(*cp));
d749 1
a749 1
pfsync4_in_ins(struct pfsync_pkt *pkt, struct mbuf *m, int offset, int count)
d751 5
a755 1
	struct pfsync_state *sp, *spa;
a757 5
	struct mbuf *mp;
	int len = count * sizeof(*sp);
	int offp;
	int i;

d763 1
a763 1
	spa = (struct pfsync_state *)(mp->m_data + offp);
d767 1
a767 1
		sp = &spa[i];
d776 1
a776 1
				printf("pfsync_input: PFSYNC_ACT_INS: "
d784 1
a784 1
			/* drop out */
d794 77
a870 1
pfsync4_in_upd(struct pfsync_pkt *pkt, struct mbuf *m, int offset, int count)
d872 2
a873 2
	struct pfsync_softc *sc = pfsyncif;
	struct pfsync_state *sp, *spa;
d877 1
a877 3
	int stale, sfail;
	int flags;
	int s;
d881 2
a882 2
	int offp;
	int i;
d889 1
a889 1
	spa = (struct pfsync_state *)(mp->m_data + offp);
d893 1
a893 3
		sp = &spa[i];

		flags = PFSYNC_FLAG_STALE;
d913 1
a913 1
			if (pfsync_state_import(sp, flags))
d917 4
a921 1

d923 3
a925 27
		if (sk->proto == IPPROTO_TCP) {
			/*
			 * The state should never go backwards except
			 * for syn-proxy states.  Neither should the
			 * sequence window slide backwards.
			 */
			if (st->src.state > sp->src.state &&
			    (st->src.state < PF_TCPS_PROXY_SRC ||
			    sp->src.state >= PF_TCPS_PROXY_SRC))
				sfail = 1;
			else if (SEQ_GT(st->src.seqlo, ntohl(sp->src.seqlo)))
				sfail = 3;
			else if (st->dst.state > sp->dst.state) {
				/* There might still be useful
				 * information about the src state here,
				 * so import that part of the update,
				 * then "fail" so we send the updated
				 * state back to the peer who is missing
				 * our what we know. */
				pf_state_peer_ntoh(&sp->src, &st->src);
				/* XXX do anything with timeouts? */
				sfail = 7;
				flags = 0;
			} else if (st->dst.state >= TCPS_SYN_SENT &&
			    SEQ_GT(st->dst.seqlo, ntohl(sp->dst.seqlo)))
				sfail = 4;
		} else {
d935 1
d937 5
a941 7
			if (pf_status.debug >= PF_DEBUG_MISC)
				printf("pfsync: %s stale update "
				    "(%d) id: %016llx "
				    "creatorid: %08x\n",
				    (sfail < 7 ?  "ignoring"
				     : "partial"), sfail,
				    betoh64(st->id),
d943 1
d946 2
a947 9
			if (!(sp->sync_flags & PFSTATE_STALE)) {
				/* we have a better state, send it */
				if (sc->sc_mbuf != NULL && !stale)
					pfsync_sendout(sc);
				stale++;
				if (!st->sync_flags)
					pfsync_pack_state( PFSYNC_ACT_UPD,
					    st, flags);
			}
d955 1
a956 2
	if (stale && sc->sc_mbuf != NULL)
		pfsync_sendout(sc);
d963 1
a963 1
pfsync4_in_del(struct pfsync_pkt *pkt, struct mbuf *m, int offset, int count)
d965 3
a967 1
	struct pfsync_state *sp, *spa;
d970 3
a972 1
	int s;
d975 2
a976 3
	int len = count * sizeof(*sp);
	int offp;
	int i;
d983 1
a983 1
	spa = (struct pfsync_state *)(mp->m_data + offp);
d987 1
a987 45
		sp = &spa[i];

		bcopy(sp->id, &id_key.id, sizeof(id_key.id));
		id_key.creatorid = sp->creatorid;

		st = pf_find_state_byid(&id_key);
		if (st == NULL) {
			pfsyncstats.pfsyncs_badstate++;
			continue;
		}
		st->sync_flags |= PFSTATE_FROMSYNC;
		pf_unlink_state(st);
	}
	splx(s);

	return (len);
}

int
pfsync4_in_upd_c(struct pfsync_pkt *pkt, struct mbuf *m, int offset, int count)
{
	struct pfsync_softc *sc = pfsyncif;
	struct pfsync_state_upd *up, *upa;
	struct pf_state_cmp id_key;
	struct pf_state_key *sk;
	struct pf_state *st;
	int stale, sfail;
	int update_requested;
	int s;

	struct mbuf *mp;
	int len = count * sizeof(*up);
	int offp;
	int i;

	mp = m_pulldown(m, offset, len, &offp);
	if (mp == NULL) {
		pfsyncstats.pfsyncs_badlen++;
		return (-1);
	}
	upa = (struct pfsync_state_upd *)(mp->m_data + offp);

	s = splnet();
	for (i = 0; i < count; i++) {
		up = &upa[i];
d993 1
a993 1
			if (pf_status.debug >= PF_DEBUG_MISC)
d997 1
d1002 1
a1002 1
		bcopy(up->id, &id_key.id, sizeof(id_key.id));
d1008 1
a1008 10
			switch (pfsync_request_update(up, &pkt->src)) {
			case 0:
				update_requested = 1;
				break;
			case ENOMEM:
				break;
			default:
				pfsyncstats.pfsyncs_badstate++;
				break;
			}
d1012 3
d1017 3
a1019 18
		if (sk->proto == IPPROTO_TCP) {
			/*
			 * The state should never go backwards except
			 * for syn-proxy states.  Neither should the
			 * sequence window slide backwards.
			 */
			if (st->src.state > up->src.state &&
			    (st->src.state < PF_TCPS_PROXY_SRC ||
			    up->src.state >= PF_TCPS_PROXY_SRC))
				sfail = 1;
			else if (st->dst.state > up->dst.state)
				sfail = 2;
			else if (SEQ_GT(st->src.seqlo, ntohl(up->src.seqlo)))
				sfail = 3;
			else if (st->dst.state >= TCPS_SYN_SENT &&
			    SEQ_GT(st->dst.seqlo, ntohl(up->dst.seqlo)))
				sfail = 4;
		} else {
d1021 1
a1021 2
			 * Non-TCP protocol state machine always go
			 * forwards
d1028 1
d1030 1
a1030 1
			if (pf_status.debug >= PF_DEBUG_MISC)
d1036 1
d1039 2
a1040 10
			/* we have a better state, send it out */
			if ((!stale || update_requested) &&
			    sc->sc_mbuf != NULL) {
				pfsync_sendout(sc);
				update_requested = 0;
			}
			stale++;
			if (!st->sync_flags)
				pfsync_pack_state(PFSYNC_ACT_UPD, st,
				    PFSYNC_FLAG_STALE);
d1048 1
a1049 2
	if ((update_requested || stale) && sc->sc_mbuf)
		pfsync_sendout(sc);
d1055 2
d1058 1
a1058 1
pfsync4_in_del_c(struct pfsync_pkt *pkt, struct mbuf *m, int offset, int count)
d1060 5
a1064 1
	struct pfsync_state_del *dp, *dpa;
a1066 6
	int s;

	struct mbuf *mp;
	int len = count * sizeof(*dp);
	int offp;
	int i;
d1073 1
a1073 1
	dpa = (struct pfsync_state_del *)(mp->m_data + offp);
a1074 1
	s = splsoftnet();
d1076 4
a1079 1
		dp = &dpa[i];
d1081 41
a1121 2
		bcopy(dp->id, &id_key.id, sizeof(id_key.id));
		id_key.creatorid = dp->creatorid;
d1128 1
a1128 1
		st->sync_flags |= PFSTATE_FROMSYNC;
d1137 1
a1137 1
pfsync4_in_error(struct pfsync_pkt *pkt, struct mbuf *m, int offset, int count)
d1139 2
a1140 9
	m_freem(m);
	return (-1);
}

int
pfsync4_in_ureq(struct pfsync_pkt *pkt, struct mbuf *m, int offset, int count)
{
	struct pfsync_softc *sc = pfsyncif;
	struct pfsync_state_upd_req *rup, *rupa;
d1143 2
a1146 5
	struct mbuf *mp;
	int len = count * sizeof(*rup);
	int offp;
	int i;

d1152 1
a1152 1
	rupa = (struct pfsync_state_upd_req *)(mp->m_data + offp);
a1154 3
	if (sc->sc_mbuf != NULL)
		pfsync_sendout(sc);

d1156 1
a1156 1
		    rup = &rupa[i];
d1158 2
a1159 2
		bcopy(rup->id, &id_key.id, sizeof(id_key.id));
		id_key.creatorid = rup->creatorid;
d1161 4
a1164 19
		if (id_key.id == 0 && id_key.creatorid == 0) {
			sc->sc_ureq_received = time_uptime;
			if (sc->sc_bulk_send_next == NULL)
				sc->sc_bulk_send_next =
				    TAILQ_FIRST(&state_list);
			sc->sc_bulk_terminator = sc->sc_bulk_send_next;
			if (pf_status.debug >= PF_DEBUG_MISC)
				printf("pfsync: received "
				    "bulk update request\n");
			pfsync_send_bus(sc, PFSYNC_BUS_START);
			timeout_add_sec(&sc->sc_bulk_tmo, 1);
		} else {
			st = pf_find_state_byid(&id_key);
			if (st == NULL) {
				pfsyncstats.pfsyncs_badstate++;
				continue;
			}
			if (!st->sync_flags)
				pfsync_pack_state(PFSYNC_ACT_UPD, st, 0);
d1166 3
a1169 3

	if (sc->sc_mbuf != NULL)
		pfsync_sendout(sc);
d1176 1
a1176 1
pfsync4_in_bus(struct pfsync_pkt *pkt, struct mbuf *m, int offset, int count)
d1179 1
a1179 2
	struct pfsync_state_bus *bus;

d1181 1
d1186 1
a1186 1
		return (sizeof(*bus));
d1188 1
a1188 1
	mp = m_pulldown(m, offset, sizeof(*bus), &offp);
d1193 1
a1193 1
	bus = (struct pfsync_state_bus *)(mp->m_data + offp);
d1197 2
a1198 1
		timeout_add(&sc->sc_bulkfail_tmo,
d1201 1
d1203 1
a1203 2
			printf("pfsync: received bulk "
			    "update start\n");
d1205 1
d1229 1
a1229 1
	return (sizeof(*bus));
d1233 1
a1233 2
pfsync4_in_tdb_upd(struct pfsync_pkt *pkt, struct mbuf *m, int offset,
    int count)
d1235 1
a1235 5
	struct pfsync_tdb *pt;
	int len = count * sizeof(*pt);

#ifdef IPSEC
	int s;
d1237 2
d1242 1
d1249 1
a1249 1
	pt = (struct pfsync_tdb *)(mp->m_data + offp);
d1253 1
a1253 1
		pfsync_update_net_tdb(&pt[i]);
d1261 21
d1299 1
d1303 1
d1307 1
d1315 1
a1315 1
		if (ifr->ifr_mtu < PFSYNC_MINMTU)
d1317 1
a1317 1
		if (ifr->ifr_mtu > MCLBYTES)
d1319 6
a1324 5
		s = splnet();
		if (ifr->ifr_mtu < ifp->if_mtu)
			pfsync_sendout(sc);
		pfsync_setmtu(sc, ifr->ifr_mtu);
		splx(s);
d1328 1
a1328 1
		if (sc->sc_sync_ifp)
d1330 2
a1331 1
			    sc->sc_sync_ifp->if_xname, IFNAMSIZ);
d1334 2
a1335 3
		if ((error = copyout(&pfsyncr, ifr->ifr_data, sizeof(pfsyncr))))
			return (error);
		break;
d1353 1
a1353 9
			sc->sc_sync_ifp = NULL;
			if (sc->sc_mbuf_net != NULL) {
				/* Don't keep stale pfsync packets around. */
				s = splnet();
				m_freem(sc->sc_mbuf_net);
				sc->sc_mbuf_net = NULL;
				sc->sc_statep_net.s = NULL;
				splx(s);
			}
d1355 2
a1356 1
				in_delmulti(imo->imo_membership[--imo->imo_num_memberships]);
d1367 2
a1368 2
		    (sc->sc_sync_ifp != NULL &&
		    sifp->if_mtu < sc->sc_sync_ifp->if_mtu) ||
d1370 2
a1371 4
			pfsync_sendout(sc);
		sc->sc_sync_ifp = sifp;

		pfsync_setmtu(sc, sc->sc_if.if_mtu);
d1378 1
a1378 1
		if (sc->sc_sync_ifp &&
d1382 2
a1383 2
			if (!(sc->sc_sync_ifp->if_flags & IFF_MULTICAST)) {
				sc->sc_sync_ifp = NULL;
d1391 2
a1392 2
			    in_addmulti(&addr, sc->sc_sync_ifp)) == NULL) {
				sc->sc_sync_ifp = NULL;
d1397 1
a1397 1
			imo->imo_multicast_ifp = sc->sc_sync_ifp;
d1402 14
a1415 2
		if (sc->sc_sync_ifp ||
		    sc->sc_sendaddr.s_addr != INADDR_PFSYNC_GROUP) {
d1426 3
a1428 6
			error = pfsync_request_update(NULL, NULL);
			if (error == ENOMEM) {
				splx(s);
				return (ENOMEM);
			}
			pfsync_sendout(sc);
d1441 2
a1442 2
void
pfsync_setmtu(struct pfsync_softc *sc, int mtu_req)
d1444 1
a1444 1
	int mtu;
d1446 1
a1446 4
	if (sc->sc_sync_ifp && sc->sc_sync_ifp->if_mtu < mtu_req)
		mtu = sc->sc_sync_ifp->if_mtu;
	else
		mtu = mtu_req;
d1448 1
a1448 6
	sc->sc_maxcount = (mtu - sizeof(struct pfsync_header)) /
	    sizeof(struct pfsync_state);
	if (sc->sc_maxcount > 254)
	    sc->sc_maxcount = 254;
	sc->sc_if.if_mtu = sizeof(struct pfsync_header) +
	    sc->sc_maxcount * sizeof(struct pfsync_state);
d1451 2
a1452 2
struct mbuf *
pfsync_get_mbuf(struct pfsync_softc *sc, u_int8_t action, void **sp)
d1454 5
a1458 3
	struct pfsync_header *h;
	struct mbuf *m;
	int len;
d1460 2
a1461 5
	MGETHDR(m, M_DONTWAIT, MT_DATA);
	if (m == NULL) {
		sc->sc_if.if_oerrors++;
		return (NULL);
	}
d1463 4
a1466 30
	switch (action) {
	case PFSYNC_ACT_CLR:
		len = sizeof(struct pfsync_header) +
		    sizeof(struct pfsync_state_clr);
		break;
	case PFSYNC_ACT_UPD_C:
		len = (sc->sc_maxcount * sizeof(struct pfsync_state_upd)) +
		    sizeof(struct pfsync_header);
		break;
	case PFSYNC_ACT_DEL_C:
		len = (sc->sc_maxcount * sizeof(struct pfsync_state_del)) +
		    sizeof(struct pfsync_header);
		break;
	case PFSYNC_ACT_UREQ:
		len = (sc->sc_maxcount * sizeof(struct pfsync_state_upd_req)) +
		    sizeof(struct pfsync_header);
		break;
	case PFSYNC_ACT_BUS:
		len = sizeof(struct pfsync_header) +
		    sizeof(struct pfsync_state_bus);
		break;
	case PFSYNC_ACT_TDB_UPD:
		len = (sc->sc_maxcount * sizeof(struct pfsync_tdb)) +
		    sizeof(struct pfsync_header);
		break;
	default:
		len = (sc->sc_maxcount * sizeof(struct pfsync_state)) +
		    sizeof(struct pfsync_header);
		break;
	}
d1468 4
a1471 10
	if (len > MHLEN) {
		MCLGET(m, M_DONTWAIT);
		if ((m->m_flags & M_EXT) == 0) {
			m_free(m);
			sc->sc_if.if_oerrors++;
			return (NULL);
		}
		m->m_data += (MCLBYTES - len) &~ (sizeof(long) - 1);
	} else
		MH_ALIGN(m, len);
d1473 3
a1475 14
	m->m_pkthdr.rcvif = NULL;
	m->m_pkthdr.len = m->m_len = sizeof(struct pfsync_header);
	h = mtod(m, struct pfsync_header *);
	h->version = PFSYNC_VERSION;
	h->af = 0;
	h->count = 0;
	h->action = action;
	if (action != PFSYNC_ACT_TDB_UPD)
		bcopy(&pf_status.pf_chksum, &h->pf_chksum,
		    PF_MD5_DIGEST_LENGTH);

	*sp = (void *)((char *)h + PFSYNC_HDRLEN);
	if (action == PFSYNC_ACT_TDB_UPD)
		timeout_add_sec(&sc->sc_tdb_tmo, 1);
d1477 6
a1482 2
		timeout_add_sec(&sc->sc_tmo, 1);
	return (m);
d1486 14
a1499 1
pfsync_pack_state(u_int8_t action, struct pf_state *st, int flags)
d1501 4
a1504 8
	struct ifnet *ifp = NULL;
	struct pfsync_softc *sc = pfsyncif;
	struct pfsync_header *h, *h_net;
	struct pfsync_state *sp = NULL;
	struct pfsync_state_upd *up = NULL;
	struct pfsync_state_del *dp = NULL;
	int s, ret = 0;
	u_int8_t i = 255, newaction = 0;
d1506 3
a1508 3
	if (sc == NULL)
		return (0);
	ifp = &sc->sc_if;
d1510 5
a1514 11
	/*
	 * If a packet falls in the forest and there's nobody around to
	 * hear, does it make a sound?
	 */
	if (ifp->if_bpf == NULL && sc->sc_sync_ifp == NULL &&
	    sc->sc_sync_peer.s_addr == INADDR_PFSYNC_GROUP) {
		/* Don't leave any stale pfsync packets hanging around. */
		if (sc->sc_mbuf != NULL) {
			m_freem(sc->sc_mbuf);
			sc->sc_mbuf = NULL;
			sc->sc_statep.s = NULL;
d1516 6
a1521 1
		return (0);
d1524 5
a1528 2
	if (action >= PFSYNC_ACT_MAX)
		return (EINVAL);
d1530 1
a1530 39
	s = splnet();
	if (sc->sc_mbuf == NULL) {
		if ((sc->sc_mbuf = pfsync_get_mbuf(sc, action,
		    (void *)&sc->sc_statep.s)) == NULL) {
			splx(s);
			return (ENOMEM);
		}
		h = mtod(sc->sc_mbuf, struct pfsync_header *);
	} else {
		h = mtod(sc->sc_mbuf, struct pfsync_header *);
		if (h->action != action) {
			pfsync_sendout(sc);
			if ((sc->sc_mbuf = pfsync_get_mbuf(sc, action,
			    (void *)&sc->sc_statep.s)) == NULL) {
				splx(s);
				return (ENOMEM);
			}
			h = mtod(sc->sc_mbuf, struct pfsync_header *);
		} else {
			/*
			 * If it's an update, look in the packet to see if
			 * we already have an update for the state.
			 */
			if (action == PFSYNC_ACT_UPD && sc->sc_maxupdates) {
				struct pfsync_state *usp =
				    (void *)((char *)h + PFSYNC_HDRLEN);

				for (i = 0; i < h->count; i++) {
					if (!memcmp(usp->id, &st->id,
					    PFSYNC_ID_LEN) &&
					    usp->creatorid == st->creatorid) {
						sp = usp;
						sp->updates++;
						break;
					}
					usp++;
				}
			}
		}
d1533 17
a1549 1
	st->pfsync_time = time_uptime;
d1551 2
a1552 8
	if (sp == NULL) {
		/* not a "duplicate" update */
		i = 255;
		sp = sc->sc_statep.s++;
		sc->sc_mbuf->m_pkthdr.len =
		    sc->sc_mbuf->m_len += sizeof(struct pfsync_state);
		h->count++;
		bzero(sp, sizeof(*sp));
d1554 1
a1554 1
		pfsync_state_export(sp, st);
d1556 2
a1557 5
		if (flags & PFSYNC_FLAG_STALE)
			sp->sync_flags |= PFSTATE_STALE;
	} else {
		pf_state_peer_hton(&st->src, &sp->src);
		pf_state_peer_hton(&st->dst, &sp->dst);
d1559 6
a1564 4
		if (st->expire <= time_second)
			sp->expire = htonl(0);
		else
			sp->expire = htonl(st->expire - time_second);
d1567 8
a1574 12
	/* do we need to build "compressed" actions for network transfer? */
	if (sc->sc_sync_ifp && flags & PFSYNC_FLAG_COMPRESS) {
		switch (action) {
		case PFSYNC_ACT_UPD:
			newaction = PFSYNC_ACT_UPD_C;
			break;
		case PFSYNC_ACT_DEL:
			newaction = PFSYNC_ACT_DEL_C;
			break;
		default:
			/* by default we just send the uncompressed states */
			break;
d1577 27
d1605 9
a1613 7
	if (newaction) {
		if (sc->sc_mbuf_net == NULL) {
			if ((sc->sc_mbuf_net = pfsync_get_mbuf(sc, newaction,
			    (void *)&sc->sc_statep_net.s)) == NULL) {
				splx(s);
				return (ENOMEM);
			}
d1615 1
a1615 1
		h_net = mtod(sc->sc_mbuf_net, struct pfsync_header *);
d1617 3
a1619 32
		switch (newaction) {
		case PFSYNC_ACT_UPD_C:
			if (i != 255) {
				up = (void *)((char *)h_net +
				    PFSYNC_HDRLEN + (i * sizeof(*up)));
				up->updates++;
			} else {
				h_net->count++;
				sc->sc_mbuf_net->m_pkthdr.len =
				    sc->sc_mbuf_net->m_len += sizeof(*up);
				up = sc->sc_statep_net.u++;

				bzero(up, sizeof(*up));
				bcopy(&st->id, up->id, sizeof(up->id));
				up->creatorid = st->creatorid;
			}
			up->timeout = st->timeout;
			up->expire = sp->expire;
			up->src = sp->src;
			up->dst = sp->dst;
			break;
		case PFSYNC_ACT_DEL_C:
			sc->sc_mbuf_net->m_pkthdr.len =
			    sc->sc_mbuf_net->m_len += sizeof(*dp);
			dp = sc->sc_statep_net.d++;
			h_net->count++;

			bzero(dp, sizeof(*dp));
			bcopy(&st->id, dp->id, sizeof(dp->id));
			dp->creatorid = st->creatorid;
			break;
		}
d1622 3
a1624 3
	if (h->count == sc->sc_maxcount ||
	    (sc->sc_maxupdates && (sp->updates >= sc->sc_maxupdates)))
		ret = pfsync_sendout(sc);
d1626 3
a1628 3
	splx(s);
	return (ret);
}
d1630 3
a1632 8
/* This must be called in splnet() */
int
pfsync_request_update(struct pfsync_state_upd *up, struct in_addr *src)
{
	struct pfsync_header *h;
	struct pfsync_softc *sc = pfsyncif;
	struct pfsync_state_upd_req *rup;
	int ret = 0;
d1634 1
a1634 2
	if (sc == NULL)
		return (0);
d1636 1
a1636 13
	if (sc->sc_mbuf == NULL) {
		if ((sc->sc_mbuf = pfsync_get_mbuf(sc, PFSYNC_ACT_UREQ,
		    (void *)&sc->sc_statep.s)) == NULL)
			return (ENOMEM);
		h = mtod(sc->sc_mbuf, struct pfsync_header *);
	} else {
		h = mtod(sc->sc_mbuf, struct pfsync_header *);
		if (h->action != PFSYNC_ACT_UREQ) {
			pfsync_sendout(sc);
			if ((sc->sc_mbuf = pfsync_get_mbuf(sc, PFSYNC_ACT_UREQ,
			    (void *)&sc->sc_statep.s)) == NULL)
				return (ENOMEM);
			h = mtod(sc->sc_mbuf, struct pfsync_header *);
d1638 4
d1644 6
a1649 9
	if (src != NULL)
		sc->sc_sendaddr = *src;
	sc->sc_mbuf->m_pkthdr.len = sc->sc_mbuf->m_len += sizeof(*rup);
	h->count++;
	rup = sc->sc_statep.r++;
	bzero(rup, sizeof(*rup));
	if (up != NULL) {
		bcopy(up->id, rup->id, sizeof(rup->id));
		rup->creatorid = up->creatorid;
d1652 3
a1654 2
	if (h->count == sc->sc_maxcount)
		ret = pfsync_sendout(sc);
d1656 4
a1659 2
	return (ret);
}
d1661 3
a1663 6
int
pfsync_clear_states(u_int32_t creatorid, char *ifname)
{
	struct pfsync_softc *sc = pfsyncif;
	struct pfsync_state_clr *cp;
	int s, ret;
d1665 4
a1668 2
	if (sc == NULL)
		return (0);
d1670 2
a1671 13
	s = splnet();
	if (sc->sc_mbuf != NULL)
		pfsync_sendout(sc);
	if ((sc->sc_mbuf = pfsync_get_mbuf(sc, PFSYNC_ACT_CLR,
	    (void *)&sc->sc_statep.c)) == NULL) {
		splx(s);
		return (ENOMEM);
	}
	sc->sc_mbuf->m_pkthdr.len = sc->sc_mbuf->m_len += sizeof(*cp);
	cp = sc->sc_statep.c;
	cp->creatorid = creatorid;
	if (ifname != NULL)
		strlcpy(cp->ifname, ifname, IFNAMSIZ);
d1673 3
a1675 4
	ret = (pfsync_sendout(sc));
	splx(s);
	return (ret);
}
d1677 1
a1677 5
void
pfsync_timeout(void *v)
{
	struct pfsync_softc *sc = v;
	int s;
d1679 12
a1690 4
	s = splnet();
	pfsync_sendout(sc);
	splx(s);
}
d1692 4
a1695 5
void
pfsync_tdb_timeout(void *v)
{
	struct pfsync_softc *sc = v;
	int s;
d1697 2
a1698 3
	s = splnet();
	pfsync_tdb_sendout(sc);
	splx(s);
a1700 1
/* This must be called in splnet() */
d1702 1
a1702 1
pfsync_send_bus(struct pfsync_softc *sc, u_int8_t status)
d1704 1
a1704 1
	struct pfsync_state_bus *bus;
d1706 1
a1706 2
	if (sc->sc_mbuf != NULL)
		pfsync_sendout(sc);
d1708 4
a1711 9
	if (pfsync_sync_ok &&
	    (sc->sc_mbuf = pfsync_get_mbuf(sc, PFSYNC_ACT_BUS,
	    (void *)&sc->sc_statep.b)) != NULL) {
		sc->sc_mbuf->m_pkthdr.len = sc->sc_mbuf->m_len += sizeof(*bus);
		bus = sc->sc_statep.b;
		bus->creatorid = pf_status.hostid;
		bus->status = status;
		bus->endtime = htonl(time_uptime - sc->sc_ureq_received);
		pfsync_sendout(sc);
a1712 1
}
d1714 6
a1719 6
void
pfsync_bulk_update(void *v)
{
	struct pfsync_softc *sc = v;
	int s, i = 0;
	struct pf_state *state;
d1721 2
a1722 3
	s = splnet();
	if (sc->sc_mbuf != NULL)
		pfsync_sendout(sc);
d1724 49
a1772 14
	/*
	 * Grab at most PFSYNC_BULKPACKETS worth of states which have not
	 * been sent since the latest request was made.
	 */
	state = sc->sc_bulk_send_next;
	if (state)
		do {
			/* send state update if syncable and not already sent */
			if (!state->sync_flags
			    && state->timeout < PFTM_MAX
			    && state->pfsync_time <= sc->sc_ureq_received) {
				pfsync_pack_state(PFSYNC_ACT_UPD, state, 0);
				i++;
			}
d1774 2
a1775 2
			/* figure next state to send */
			state = TAILQ_NEXT(state, entry_list);
d1777 9
a1785 19
			/* wrap to start of list if we hit the end */
			if (!state)
				state = TAILQ_FIRST(&state_list);
		} while (i < sc->sc_maxcount * PFSYNC_BULKPACKETS &&
		    state != sc->sc_bulk_terminator);

	if (!state || state == sc->sc_bulk_terminator) {
		/* we're done */
		pfsync_send_bus(sc, PFSYNC_BUS_END);
		sc->sc_ureq_received = 0;
		sc->sc_bulk_send_next = NULL;
		sc->sc_bulk_terminator = NULL;
		timeout_del(&sc->sc_bulk_tmo);
		if (pf_status.debug >= PF_DEBUG_MISC)
			printf("pfsync: bulk update complete\n");
	} else {
		/* look again for more in a bit */
		timeout_add(&sc->sc_bulk_tmo, 1);
		sc->sc_bulk_send_next = state;
d1787 11
a1797 2
	if (sc->sc_mbuf != NULL)
		pfsync_sendout(sc);
d1802 1
a1802 1
pfsync_bulkfail(void *v)
d1804 90
a1893 2
	struct pfsync_softc *sc = v;
	int s, error;
d1895 1
a1895 3
	if (sc->sc_bulk_tries++ < PFSYNC_MAX_BULKTRIES) {
		/* Try again in a bit */
		timeout_add_sec(&sc->sc_bulkfail_tmo, 5);
d1897 1
a1897 7
		error = pfsync_request_update(NULL, NULL);
		if (error == ENOMEM) {
			if (pf_status.debug >= PF_DEBUG_MISC)
				printf("pfsync: cannot allocate mbufs for "
				    "bulk update\n");
		} else
			pfsync_sendout(sc);
d1899 3
a1901 13
	} else {
		/* Pretend like the transfer was ok */
		sc->sc_ureq_sent = 0;
		sc->sc_bulk_tries = 0;
#if NCARP > 0
		if (!pfsync_sync_ok)
			carp_group_demote_adj(&sc->sc_if, -1);
#endif
		pfsync_sync_ok = 1;
		if (pf_status.debug >= PF_DEBUG_MISC)
			printf("pfsync: failed to receive "
			    "bulk update status\n");
		timeout_del(&sc->sc_bulkfail_tmo);
d1903 5
d1910 2
a1911 3
/* This must be called in splnet() */
int
pfsync_sendout(struct pfsync_softc *sc)
d1913 4
a1916 4
#if NBPFILTER > 0
	struct ifnet *ifp = &sc->sc_if;
#endif
	struct mbuf *m;
d1918 5
a1922 1
	timeout_del(&sc->sc_tmo);
d1924 8
a1931 5
	if (sc->sc_mbuf == NULL)
		return (0);
	m = sc->sc_mbuf;
	sc->sc_mbuf = NULL;
	sc->sc_statep.s = NULL;
d1933 5
a1937 4
#if NBPFILTER > 0
	if (ifp->if_bpf)
		bpf_mtap(ifp->if_bpf, m, BPF_DIRECTION_OUT);
#endif
d1939 3
a1941 5
	if (sc->sc_mbuf_net) {
		m_freem(m);
		m = sc->sc_mbuf_net;
		sc->sc_mbuf_net = NULL;
		sc->sc_statep_net.s = NULL;
a1942 2

	return pfsync_sendout_mbuf(sc, m);
d1945 2
a1946 2
int
pfsync_tdb_sendout(struct pfsync_softc *sc)
d1948 17
a1964 4
#if NBPFILTER > 0
	struct ifnet *ifp = &sc->sc_if;
#endif
	struct mbuf *m;
d1966 5
a1970 1
	timeout_del(&sc->sc_tdb_tmo);
d1972 5
a1976 5
	if (sc->sc_mbuf_tdb == NULL)
		return (0);
	m = sc->sc_mbuf_tdb;
	sc->sc_mbuf_tdb = NULL;
	sc->sc_statep_tdb.t = NULL;
d1978 3
a1980 4
#if NBPFILTER > 0
	if (ifp->if_bpf)
		bpf_mtap(ifp->if_bpf, m, BPF_DIRECTION_OUT);
#endif
d1982 4
a1985 1
	return pfsync_sendout_mbuf(sc, m);
d1988 2
a1989 2
int
pfsync_sendout_mbuf(struct pfsync_softc *sc, struct mbuf *m)
d1991 6
a1996 2
	struct sockaddr sa;
	struct ip *ip;
d1998 1
a1998 17
	if (sc->sc_sync_ifp ||
	    sc->sc_sync_peer.s_addr != INADDR_PFSYNC_GROUP) {
		M_PREPEND(m, sizeof(struct ip), M_DONTWAIT);
		if (m == NULL) {
			pfsyncstats.pfsyncs_onomem++;
			return (0);
		}
		ip = mtod(m, struct ip *);
		ip->ip_v = IPVERSION;
		ip->ip_hl = sizeof(*ip) >> 2;
		ip->ip_tos = IPTOS_LOWDELAY;
		ip->ip_len = htons(m->m_pkthdr.len);
		ip->ip_id = htons(ip_randomid());
		ip->ip_off = htons(IP_DF);
		ip->ip_ttl = PFSYNC_DFLTTL;
		ip->ip_p = IPPROTO_PFSYNC;
		ip->ip_sum = 0;
d2000 2
a2001 2
		bzero(&sa, sizeof(sa));
		ip->ip_src.s_addr = INADDR_ANY;
d2003 1
a2003 4
		if (sc->sc_sendaddr.s_addr == INADDR_PFSYNC_GROUP)
			m->m_flags |= M_MCAST;
		ip->ip_dst = sc->sc_sendaddr;
		sc->sc_sendaddr.s_addr = sc->sc_sync_peer.s_addr;
d2005 2
a2006 1
		pfsyncstats.pfsyncs_opackets++;
d2008 2
a2009 4
		if (ip_output(m, NULL, NULL, IP_RAWOUTPUT, &sc->sc_imo, NULL))
			pfsyncstats.pfsyncs_oerrors++;
	} else
		m_freem(m);
d2011 1
a2011 1
	return (0);
a2013 2
#ifdef IPSEC
/* Update an in-kernel tdb. Silently fail if no tdb is found. */
d2015 1
a2015 1
pfsync_update_net_tdb(struct pfsync_tdb *pt)
d2017 12
a2028 2
	struct tdb		*tdb;
	int			 s;
d2030 4
a2033 18
	/* check for invalid values */
	if (ntohl(pt->spi) <= SPI_RESERVED_MAX ||
	    (pt->dst.sa.sa_family != AF_INET &&
	     pt->dst.sa.sa_family != AF_INET6))
		goto bad;

	s = spltdb();
	tdb = gettdb(pt->spi, &pt->dst, pt->sproto);
	if (tdb) {
		pt->rpl = ntohl(pt->rpl);
		pt->cur_bytes = betoh64(pt->cur_bytes);

		/* Neither replay nor byte counter should ever decrease. */
		if (pt->rpl < tdb->tdb_rpl ||
		    pt->cur_bytes < tdb->tdb_cur_bytes) {
			splx(s);
			goto bad;
		}
d2035 1
a2035 2
		tdb->tdb_rpl = pt->rpl;
		tdb->tdb_cur_bytes = pt->cur_bytes;
a2036 2
	splx(s);
	return;
d2038 19
a2056 6
 bad:
	if (pf_status.debug >= PF_DEBUG_MISC)
		printf("pfsync_insert: PFSYNC_ACT_TDB_UPD: "
		    "invalid value\n");
	pfsyncstats.pfsyncs_badstate++;
	return;
d2059 2
a2060 3
/* One of our local tdbs have been updated, need to sync rpl with others */
int
pfsync_update_tdb(struct tdb *tdb, int output)
a2061 1
	struct ifnet *ifp = NULL;
d2063 2
a2064 3
	struct pfsync_header *h;
	struct pfsync_tdb *pt = NULL;
	int s, i, ret;
d2067 10
a2076 1
		return (0);
d2078 2
a2079 8
	ifp = &sc->sc_if;
	if (ifp->if_bpf == NULL && sc->sc_sync_ifp == NULL &&
	    sc->sc_sync_peer.s_addr == INADDR_PFSYNC_GROUP) {
		/* Don't leave any stale pfsync packets hanging around. */
		if (sc->sc_mbuf_tdb != NULL) {
			m_freem(sc->sc_mbuf_tdb);
			sc->sc_mbuf_tdb = NULL;
			sc->sc_statep_tdb.t = NULL;
d2081 8
a2088 1
		return (0);
d2091 17
a2107 30
	s = splnet();
	if (sc->sc_mbuf_tdb == NULL) {
		if ((sc->sc_mbuf_tdb = pfsync_get_mbuf(sc, PFSYNC_ACT_TDB_UPD,
		    (void *)&sc->sc_statep_tdb.t)) == NULL) {
			splx(s);
			return (ENOMEM);
		}
		h = mtod(sc->sc_mbuf_tdb, struct pfsync_header *);
	} else {
		h = mtod(sc->sc_mbuf_tdb, struct pfsync_header *);
		if (h->action != PFSYNC_ACT_TDB_UPD) {
			/*
			 * XXX will never happen as long as there's
			 * only one "TDB action".
			 */
			pfsync_tdb_sendout(sc);
			sc->sc_mbuf_tdb = pfsync_get_mbuf(sc,
			    PFSYNC_ACT_TDB_UPD, (void *)&sc->sc_statep_tdb.t);
			if (sc->sc_mbuf_tdb == NULL) {
				splx(s);
				return (ENOMEM);
			}
			h = mtod(sc->sc_mbuf_tdb, struct pfsync_header *);
		} else if (sc->sc_maxupdates) {
			/*
			 * If it's an update, look in the packet to see if
			 * we already have an update for the state.
			 */
			struct pfsync_tdb *u =
			    (void *)((char *)h + PFSYNC_HDRLEN);
d2109 3
a2111 12
			for (i = 0; !pt && i < h->count; i++) {
				if (tdb->tdb_spi == u->spi &&
				    tdb->tdb_sproto == u->sproto &&
				    !bcmp(&tdb->tdb_dst, &u->dst,
				    SA_LEN(&u->dst.sa))) {
					pt = u;
					pt->updates++;
				}
				u++;
			}
		}
	}
d2113 4
a2116 12
	if (pt == NULL) {
		/* not a "duplicate" update */
		pt = sc->sc_statep_tdb.t++;
		sc->sc_mbuf_tdb->m_pkthdr.len =
		    sc->sc_mbuf_tdb->m_len += sizeof(struct pfsync_tdb);
		h->count++;
		bzero(pt, sizeof(*pt));

		pt->spi = tdb->tdb_spi;
		memcpy(&pt->dst, &tdb->tdb_dst, sizeof pt->dst);
		pt->sproto = tdb->tdb_sproto;
	}
d2118 3
d2139 51
a2189 2
	pt->rpl = htonl(tdb->tdb_rpl + (output ? RPL_INCR : 0));
	pt->cur_bytes = htobe64(tdb->tdb_cur_bytes);
d2191 121
a2311 3
	if (h->count == sc->sc_maxcount ||
	    (sc->sc_maxupdates && (pt->updates >= sc->sc_maxupdates)))
		ret = pfsync_tdb_sendout(sc);
d2313 2
a2315 1
	return (ret);
a2316 1
#endif
@


1.101
log
@remove dead stores and newly created unused variables.

fix potential use of uninitialized value in trunk_port_ioctl() function.

Found by LLVM/Clang Static Analyzer.

ok mpf@@ henning@@
@
text
@d109 34
d477 2
d481 4
a484 18
	struct pfsync_softc *sc = pfsyncif;
	struct pf_state *st;
	struct pf_state_key *sk;
	struct pf_state_item *si;
	struct pf_state_cmp id_key;
	struct pfsync_state *sp;
	struct pfsync_state_upd *up;
	struct pfsync_state_del *dp;
	struct pfsync_state_clr *cp;
	struct pfsync_state_upd_req *rup;
	struct pfsync_state_bus *bus;
#ifdef IPSEC
	struct pfsync_tdb *pt;
#endif
	struct in_addr src;
	struct mbuf *mp;
	int iplen, action, error, i, s, count, offp, sfail, stale = 0;
	u_int8_t flags = 0;
d504 1
a504 1
	iplen = ip->ip_hl << 2;
d506 1
a506 1
	if (m->m_pkthdr.len < iplen + sizeof(*ph)) {
d511 2
a512 2
	if (iplen + sizeof(*ph) > m->m_len) {
		if ((m = m_pullup(m, iplen + sizeof(*ph))) == NULL) {
d514 1
a514 1
			goto done;
d518 1
a518 1
	ph = (struct pfsync_header *)((char *)ip + iplen);
d536 3
a538 1
	src = ip->ip_src;
d541 1
a541 1
		flags |= PFSYNC_SI_CKSUM;
d543 4
a546 12
	switch (action) {
	case PFSYNC_ACT_CLR: {
		struct pf_state *nexts;
		struct pf_state_key *nextsk;
		u_int32_t creatorid;
		if ((mp = m_pulldown(m, iplen + sizeof(*ph),
		    sizeof(*cp), &offp)) == NULL) {
			pfsyncstats.pfsyncs_badlen++;
			return;
		}
		cp = (struct pfsync_state_clr *)(mp->m_data + offp);
		creatorid = cp->creatorid;
d548 3
a550 30
		s = splsoftnet();
		if (cp->ifname[0] == '\0') {
			for (st = RB_MIN(pf_state_tree_id, &tree_id);
			    st; st = nexts) {
				nexts = RB_NEXT(pf_state_tree_id, &tree_id, st);
				if (st->creatorid == creatorid) {
					st->sync_flags |= PFSTATE_FROMSYNC;
					pf_unlink_state(st);
				}
			}
		} else {
			if (pfi_kif_get(cp->ifname) == NULL) {
				splx(s);
				return;
			}
			/* XXX correct? */
			for (sk = RB_MIN(pf_state_tree,
			    &pf_statetbl); sk; sk = nextsk) {
				nextsk = RB_NEXT(pf_state_tree,
				    &pf_statetbl, sk);
				TAILQ_FOREACH(si, &sk->states, entry) {
					if (si->s->creatorid == creatorid) {
						si->s->sync_flags |=
						    PFSTATE_FROMSYNC;
						pf_unlink_state(si->s);
					}
				}
			}
		}
		splx(s);
d552 5
a556 8
		break;
	}
	case PFSYNC_ACT_INS:
		if ((mp = m_pulldown(m, iplen + sizeof(*ph),
		    count * sizeof(*sp), &offp)) == NULL) {
			pfsyncstats.pfsyncs_badlen++;
			return;
		}
d558 8
a565 15
		s = splsoftnet();
		for (i = 0, sp = (struct pfsync_state *)(mp->m_data + offp);
		    i < count; i++, sp++) {
			/* check for invalid values */
			if (sp->timeout >= PFTM_MAX ||
			    sp->src.state > PF_TCPS_PROXY_DST ||
			    sp->dst.state > PF_TCPS_PROXY_DST ||
			    sp->direction > PF_OUT ||
			    (sp->af != AF_INET && sp->af != AF_INET6)) {
				if (pf_status.debug >= PF_DEBUG_MISC)
					printf("pfsync_input: PFSYNC_ACT_INS: "
					    "invalid value\n");
				pfsyncstats.pfsyncs_badval++;
				continue;
			}
d567 26
a592 4
			if ((error = pfsync_state_import(sp, flags))) {
				if (error == ENOMEM) {
					splx(s);
					goto done;
a593 1
				continue;
d596 2
a597 8
		splx(s);
		break;
	case PFSYNC_ACT_UPD:
		if ((mp = m_pulldown(m, iplen + sizeof(*ph),
		    count * sizeof(*sp), &offp)) == NULL) {
			pfsyncstats.pfsyncs_badlen++;
			return;
		}
d599 2
a600 15
		s = splsoftnet();
		for (i = 0, sp = (struct pfsync_state *)(mp->m_data + offp);
		    i < count; i++, sp++) {
			int flags = PFSYNC_FLAG_STALE;

			/* check for invalid values */
			if (sp->timeout >= PFTM_MAX ||
			    sp->src.state > PF_TCPS_PROXY_DST ||
			    sp->dst.state > PF_TCPS_PROXY_DST) {
				if (pf_status.debug >= PF_DEBUG_MISC)
					printf("pfsync_input: PFSYNC_ACT_UPD: "
					    "invalid value\n");
				pfsyncstats.pfsyncs_badval++;
				continue;
			}
d602 5
a606 2
			bcopy(sp->id, &id_key.id, sizeof(id_key.id));
			id_key.creatorid = sp->creatorid;
d608 25
a632 6
			st = pf_find_state_byid(&id_key);
			if (st == NULL) {
				/* insert the update */
				if (pfsync_state_import(sp, flags))
					pfsyncstats.pfsyncs_badstate++;
				continue;
d634 2
a635 66
			sk = st->key[PF_SK_WIRE];	/* XXX right one? */
			sfail = 0;
			if (sk->proto == IPPROTO_TCP) {
				/*
				 * The state should never go backwards except
				 * for syn-proxy states.  Neither should the
				 * sequence window slide backwards.
				 */
				if (st->src.state > sp->src.state &&
				    (st->src.state < PF_TCPS_PROXY_SRC ||
				    sp->src.state >= PF_TCPS_PROXY_SRC))
					sfail = 1;
				else if (SEQ_GT(st->src.seqlo,
				    ntohl(sp->src.seqlo)))
					sfail = 3;
				else if (st->dst.state > sp->dst.state) {
					/* There might still be useful
					 * information about the src state here,
					 * so import that part of the update,
					 * then "fail" so we send the updated
					 * state back to the peer who is missing
					 * our what we know. */
					pf_state_peer_ntoh(&sp->src, &st->src);
					/* XXX do anything with timeouts? */
					sfail = 7;
					flags = 0;
				} else if (st->dst.state >= TCPS_SYN_SENT &&
				    SEQ_GT(st->dst.seqlo, ntohl(sp->dst.seqlo)))
					sfail = 4;
			} else {
				/*
				 * Non-TCP protocol state machine always go
				 * forwards
				 */
				if (st->src.state > sp->src.state)
					sfail = 5;
				else if (st->dst.state > sp->dst.state)
					sfail = 6;
			}
			if (sfail) {
				if (pf_status.debug >= PF_DEBUG_MISC)
					printf("pfsync: %s stale update "
					    "(%d) id: %016llx "
					    "creatorid: %08x\n",
					    (sfail < 7 ?  "ignoring"
					     : "partial"), sfail,
					    betoh64(st->id),
					    ntohl(st->creatorid));
				pfsyncstats.pfsyncs_stale++;

				if (!(sp->sync_flags & PFSTATE_STALE)) {
					/* we have a better state, send it */
					if (sc->sc_mbuf != NULL && !stale)
						pfsync_sendout(sc);
					stale++;
					if (!st->sync_flags)
						pfsync_pack_state(
						    PFSYNC_ACT_UPD, st, flags);
				}
				continue;
			}
			pfsync_alloc_scrub_memory(&sp->dst, &st->dst);
			pf_state_peer_ntoh(&sp->src, &st->src);
			pf_state_peer_ntoh(&sp->dst, &st->dst);
			st->expire = ntohl(sp->expire) + time_second;
			st->timeout = sp->timeout;
d637 4
a640 13
		if (stale && sc->sc_mbuf != NULL)
			pfsync_sendout(sc);
		splx(s);
		break;
	/*
	 * It's not strictly necessary for us to support the "uncompressed"
	 * delete action, but it's relatively simple and maintains consistency.
	 */
	case PFSYNC_ACT_DEL:
		if ((mp = m_pulldown(m, iplen + sizeof(*ph),
		    count * sizeof(*sp), &offp)) == NULL) {
			pfsyncstats.pfsyncs_badlen++;
			return;
d642 2
d645 14
a658 5
		s = splsoftnet();
		for (i = 0, sp = (struct pfsync_state *)(mp->m_data + offp);
		    i < count; i++, sp++) {
			bcopy(sp->id, &id_key.id, sizeof(id_key.id));
			id_key.creatorid = sp->creatorid;
d660 37
a696 2
			st = pf_find_state_byid(&id_key);
			if (st == NULL) {
d698 60
a757 1
				continue;
d759 1
a759 2
			st->sync_flags |= PFSTATE_FROMSYNC;
			pf_unlink_state(st);
d761 39
a799 4
		splx(s);
		break;
	case PFSYNC_ACT_UPD_C: {
		int update_requested = 0;
d801 4
a804 4
		if ((mp = m_pulldown(m, iplen + sizeof(*ph),
		    count * sizeof(*up), &offp)) == NULL) {
			pfsyncstats.pfsyncs_badlen++;
			return;
d806 7
d814 11
a824 14
		s = splsoftnet();
		for (i = 0, up = (struct pfsync_state_upd *)(mp->m_data + offp);
		    i < count; i++, up++) {
			/* check for invalid values */
			if (up->timeout >= PFTM_MAX ||
			    up->src.state > PF_TCPS_PROXY_DST ||
			    up->dst.state > PF_TCPS_PROXY_DST) {
				if (pf_status.debug >= PF_DEBUG_MISC)
					printf("pfsync_input: "
					    "PFSYNC_ACT_UPD_C: "
					    "invalid value\n");
				pfsyncstats.pfsyncs_badval++;
				continue;
			}
d826 27
a852 2
			bcopy(up->id, &id_key.id, sizeof(id_key.id));
			id_key.creatorid = up->creatorid;
d854 8
a861 8
			st = pf_find_state_byid(&id_key);
			if (st == NULL) {
				/* We don't have this state. Ask for it. */
				error = pfsync_request_update(up, &src);
				if (error == ENOMEM) {
					splx(s);
					goto done;
				}
d863 4
d868 1
a868 1
				continue;
d870 31
a900 56
			sk = st->key[PF_SK_WIRE]; /* XXX right one? */
			sfail = 0;
			if (sk->proto == IPPROTO_TCP) {
				/*
				 * The state should never go backwards except
				 * for syn-proxy states.  Neither should the
				 * sequence window slide backwards.
				 */
				if (st->src.state > up->src.state &&
				    (st->src.state < PF_TCPS_PROXY_SRC ||
				    up->src.state >= PF_TCPS_PROXY_SRC))
					sfail = 1;
				else if (st->dst.state > up->dst.state)
					sfail = 2;
				else if (SEQ_GT(st->src.seqlo,
				    ntohl(up->src.seqlo)))
					sfail = 3;
				else if (st->dst.state >= TCPS_SYN_SENT &&
				    SEQ_GT(st->dst.seqlo, ntohl(up->dst.seqlo)))
					sfail = 4;
			} else {
				/*
				 * Non-TCP protocol state machine always go
				 * forwards
				 */
				if (st->src.state > up->src.state)
					sfail = 5;
				else if (st->dst.state > up->dst.state)
					sfail = 6;
			}
			if (sfail) {
				if (pf_status.debug >= PF_DEBUG_MISC)
					printf("pfsync: ignoring stale update "
					    "(%d) id: %016llx "
					    "creatorid: %08x\n", sfail,
					    betoh64(st->id),
					    ntohl(st->creatorid));
				pfsyncstats.pfsyncs_stale++;

				/* we have a better state, send it out */
				if ((!stale || update_requested) &&
				    sc->sc_mbuf != NULL) {
					pfsync_sendout(sc);
					update_requested = 0;
				}
				stale++;
				if (!st->sync_flags)
					pfsync_pack_state(PFSYNC_ACT_UPD, st,
					    PFSYNC_FLAG_STALE);
				continue;
			}
			pfsync_alloc_scrub_memory(&up->dst, &st->dst);
			pf_state_peer_ntoh(&up->src, &st->src);
			pf_state_peer_ntoh(&up->dst, &st->dst);
			st->expire = ntohl(up->expire) + time_second;
			st->timeout = up->timeout;
d902 51
a952 4
		if ((update_requested || stale) && sc->sc_mbuf)
			pfsync_sendout(sc);
		splx(s);
		break;
d954 13
a966 5
	case PFSYNC_ACT_DEL_C:
		if ((mp = m_pulldown(m, iplen + sizeof(*ph),
		    count * sizeof(*dp), &offp)) == NULL) {
			pfsyncstats.pfsyncs_badlen++;
			return;
d968 4
d973 9
a981 5
		s = splsoftnet();
		for (i = 0, dp = (struct pfsync_state_del *)(mp->m_data + offp);
		    i < count; i++, dp++) {
			bcopy(dp->id, &id_key.id, sizeof(id_key.id));
			id_key.creatorid = dp->creatorid;
d983 43
d1031 2
a1032 14
			st->sync_flags |= PFSTATE_FROMSYNC;
			pf_unlink_state(st);
		}
		splx(s);
		break;
	case PFSYNC_ACT_INS_F:
	case PFSYNC_ACT_DEL_F:
		/* not implemented */
		break;
	case PFSYNC_ACT_UREQ:
		if ((mp = m_pulldown(m, iplen + sizeof(*ph),
		    count * sizeof(*rup), &offp)) == NULL) {
			pfsyncstats.pfsyncs_badlen++;
			return;
d1034 17
d1052 19
a1070 34
		s = splsoftnet();
		if (sc->sc_mbuf != NULL)
			pfsync_sendout(sc);
		for (i = 0,
		    rup = (struct pfsync_state_upd_req *)(mp->m_data + offp);
		    i < count; i++, rup++) {
			bcopy(rup->id, &id_key.id, sizeof(id_key.id));
			id_key.creatorid = rup->creatorid;

			if (id_key.id == 0 && id_key.creatorid == 0) {
				sc->sc_ureq_received = time_uptime;
				if (sc->sc_bulk_send_next == NULL)
					sc->sc_bulk_send_next =
					    TAILQ_FIRST(&state_list);
				sc->sc_bulk_terminator = sc->sc_bulk_send_next;
				if (pf_status.debug >= PF_DEBUG_MISC)
					printf("pfsync: received "
					    "bulk update request\n");
				pfsync_send_bus(sc, PFSYNC_BUS_START);
				timeout_add_sec(&sc->sc_bulk_tmo, 1);
			} else {
				st = pf_find_state_byid(&id_key);
				if (st == NULL) {
					pfsyncstats.pfsyncs_badstate++;
					continue;
				}
				if (!st->sync_flags)
					pfsync_pack_state(PFSYNC_ACT_UPD,
					    st, 0);
			}
		}
		if (sc->sc_mbuf != NULL)
			pfsync_sendout(sc);
		splx(s);
d1072 7
a1078 27
	case PFSYNC_ACT_BUS:
		/* If we're not waiting for a bulk update, who cares. */
		if (sc->sc_ureq_sent == 0)
			break;

		if ((mp = m_pulldown(m, iplen + sizeof(*ph),
		    sizeof(*bus), &offp)) == NULL) {
			pfsyncstats.pfsyncs_badlen++;
			return;
		}
		bus = (struct pfsync_state_bus *)(mp->m_data + offp);
		switch (bus->status) {
		case PFSYNC_BUS_START:
			timeout_add(&sc->sc_bulkfail_tmo,
			    pf_pool_limits[PF_LIMIT_STATES].limit /
			    (PFSYNC_BULKPACKETS * sc->sc_maxcount));
			if (pf_status.debug >= PF_DEBUG_MISC)
				printf("pfsync: received bulk "
				    "update start\n");
			break;
		case PFSYNC_BUS_END:
			if (time_uptime - ntohl(bus->endtime) >=
			    sc->sc_ureq_sent) {
				/* that's it, we're happy */
				sc->sc_ureq_sent = 0;
				sc->sc_bulk_tries = 0;
				timeout_del(&sc->sc_bulkfail_tmo);
d1080 2
a1081 2
				if (!pfsync_sync_ok)
					carp_group_demote_adj(&sc->sc_if, -1);
d1083 8
a1090 10
				pfsync_sync_ok = 1;
				if (pf_status.debug >= PF_DEBUG_MISC)
					printf("pfsync: received valid "
					    "bulk update end\n");
			} else {
				if (pf_status.debug >= PF_DEBUG_MISC)
					printf("pfsync: received invalid "
					    "bulk update end: bad timestamp\n");
			}
			break;
d1093 12
d1106 17
a1122 12
	case PFSYNC_ACT_TDB_UPD:
		if ((mp = m_pulldown(m, iplen + sizeof(*ph),
		    count * sizeof(*pt), &offp)) == NULL) {
			pfsyncstats.pfsyncs_badlen++;
			return;
		}
		s = splsoftnet();
		for (i = 0, pt = (struct pfsync_tdb *)(mp->m_data + offp);
		    i < count; i++, pt++)
			pfsync_update_net_tdb(pt);
		splx(s);
		break;
a1123 1
	}
d1125 1
a1125 3
done:
	if (m)
		m_freem(m);
@


1.100
log
@Convert timeout_add() calls using multiples of hz to timeout_add_sec()

Really just the low-hanging fruit of (hopefully) forthcoming timeout
conversions.

ok art@@, krw@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.99 2008/09/02 17:35:16 chl Exp $	*/
a522 1
		struct pfi_kif *kif;
d543 1
a543 1
			if ((kif = pfi_kif_get(cp->ifname)) == NULL) {
@


1.99
log
@remove dead stores and newly created unused variables.

Found by LLVM/Clang Static Analyzer.

ok henning@@ mpf@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.98 2008/06/29 08:42:15 mcbride Exp $	*/
d884 1
a884 1
				timeout_add(&sc->sc_bulk_tmo, 1 * hz);
d1101 1
a1101 1
			timeout_add(&sc->sc_bulkfail_tmo, 5 * hz);
d1206 1
a1206 1
		timeout_add(&sc->sc_tdb_tmo, hz);
d1208 1
a1208 1
		timeout_add(&sc->sc_tmo, hz);
d1558 1
a1558 1
		timeout_add(&sc->sc_bulkfail_tmo, 5 * hz);
@


1.98
log
@Simplify state creation code; merge state import/export code between pfsync
and the state-related pf(4) ioctls, and make functions in state creation and
destruction paths more robust in error conditions.

All values in struct pfsync_state now in network byte order, as with pfsync.

testing by david
ok henning, systat parts ok canacar
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.97 2008/06/19 04:53:21 mcbride Exp $	*/
a1382 1
	struct ifnet *ifp = NULL;
a1390 1
	ifp = &sc->sc_if;
a1426 1
	struct ifnet *ifp = NULL;
a1433 1
	ifp = &sc->sc_if;
@


1.97
log
@Fix handling check for NAT and creation of a second pf_state_key in pfsync.

Problem report and testing by david@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.96 2008/06/10 22:39:31 mcbride Exp $	*/
a91 1
int	pfsync_insert_net_state(struct pfsync_state *, u_int8_t);
d234 61
d296 1
a296 1
pfsync_insert_net_state(struct pfsync_state *sp, u_int8_t chksum_flag)
d302 2
d306 1
a306 1
		printf("pfsync_insert_net_state: invalid creator id:"
d311 1
a311 2
	kif = pfi_kif_get(sp->ifname);
	if (kif == NULL) {
d313 1
a313 1
			printf("pfsync_insert_net_state: "
d315 3
a317 2
		/* skip this state */
		return (0);
d321 2
a322 2
	 * If the ruleset checksums match, it's safe to associate the state
	 * with the rule of that number.
d324 2
a325 2
	if (sp->rule != htonl(-1) && sp->anchor == htonl(-1) && chksum_flag &&
	    ntohl(sp->rule) <
d332 13
a344 6
	if (!r->max_states || r->states_cur < r->max_states)
		st = pool_get(&pf_state_pl, PR_NOWAIT | PR_ZERO);
	if (st == NULL) {
		pfi_kif_unref(kif, PFI_KIF_REF_NONE);
		return (ENOMEM);
	}
a345 5
	if ((skw = pf_alloc_state_key()) == NULL) {
		pool_put(&pf_state_pl, st);
		pfi_kif_unref(kif, PFI_KIF_REF_NONE);
		return (ENOMEM);
	}
d352 2
a353 6
		if ((sks = pf_alloc_state_key()) == NULL) {
			pool_put(&pf_state_pl, st);
			pfi_kif_unref(kif, PFI_KIF_REF_NONE);
			pool_put(&pf_state_key_pl, skw);
			return (ENOMEM);
		}
d359 2
a360 20
	    pfsync_alloc_scrub_memory(&sp->dst, &st->dst)) {
		pfi_kif_unref(kif, PFI_KIF_REF_NONE);
		if (st->src.scrub)
			pool_put(&pf_state_scrub_pl, st->src.scrub);
		pool_put(&pf_state_pl, st);
		if (skw == sks)
			sks = NULL;
		if (skw != NULL)
			pool_put(&pf_state_key_pl, skw);
		if (sks != NULL)
			pool_put(&pf_state_key_pl, sks);
		return (ENOMEM);
	}

	st->rule.ptr = r;
	/* XXX get pointers to nat_rule and anchor */

	/* XXX when we have nat_rule/anchors, use STATE_INC_COUNTERS */
	r->states_cur++;
	r->states_tot++;
d362 1
a362 1
	/* fill in the rest of the state entry */
d378 1
a378 3
	pf_state_peer_ntoh(&sp->src, &st->src);
	pf_state_peer_ntoh(&sp->dst, &st->dst);

d381 6
d392 2
d397 14
a410 1
	st->sync_flags = PFSTATE_FROMSYNC;
d412 1
a412 2
	if (pf_state_insert(kif, skw, sks, st)) {
		pfi_kif_unref(kif, PFI_KIF_REF_NONE);
d415 16
a435 1
		return (EINVAL);
d437 1
a437 2

	return (0);
d462 1
a462 1
	u_int8_t chksum_flag = 0;
d517 1
a517 1
		chksum_flag++;
d589 1
a589 2
			if ((error = pfsync_insert_net_state(sp,
			    chksum_flag))) {
d628 1
a628 1
				if (pfsync_insert_net_state(sp, chksum_flag))
a1220 3
	struct pf_state_key *sk = st->key[PF_SK_WIRE];
	struct pf_rule *r;
	u_long secs;
a1286 2
	secs = time_second;

d1298 1
a1298 2
		bcopy(&st->id, sp->id, sizeof(sp->id));
		sp->creatorid = st->creatorid;
d1300 5
a1304 1
		strlcpy(sp->ifname, st->kif->pfik_name, sizeof(sp->ifname));
d1306 2
a1307 22
		sp->key[PF_SK_WIRE].addr[0] = st->key[PF_SK_WIRE]->addr[0];
		sp->key[PF_SK_WIRE].addr[1] = st->key[PF_SK_WIRE]->addr[1];
		sp->key[PF_SK_WIRE].port[0] = st->key[PF_SK_WIRE]->port[0];
		sp->key[PF_SK_WIRE].port[1] = st->key[PF_SK_WIRE]->port[1];
		sp->key[PF_SK_STACK].addr[0] = st->key[PF_SK_STACK]->addr[0];
		sp->key[PF_SK_STACK].addr[1] = st->key[PF_SK_STACK]->addr[1];
		sp->key[PF_SK_STACK].port[0] = st->key[PF_SK_STACK]->port[0];
		sp->key[PF_SK_STACK].port[1] = st->key[PF_SK_STACK]->port[1];

		bcopy(&st->rt_addr, &sp->rt_addr, sizeof(sp->rt_addr));

		sp->creation = htonl(secs - st->creation);
		pf_state_counter_hton(st->packets[0], sp->packets[0]);
		pf_state_counter_hton(st->packets[1], sp->packets[1]);
		pf_state_counter_hton(st->bytes[0], sp->bytes[0]);
		pf_state_counter_hton(st->bytes[1], sp->bytes[1]);
		if ((r = st->rule.ptr) == NULL)
			sp->rule = htonl(-1);
		else
			sp->rule = htonl(r->nr);
		if ((r = st->anchor.ptr) == NULL)
			sp->anchor = htonl(-1);
d1309 1
a1309 10
			sp->anchor = htonl(r->nr);
		sp->af = sk->af;
		sp->proto = sk->proto;
		sp->direction = st->direction;
		sp->log = st->log;
		sp->state_flags = st->state_flags;
		sp->timeout = st->timeout;

		if (flags & PFSYNC_FLAG_STALE)
			sp->sync_flags |= PFSTATE_STALE;
a1310 8

	pf_state_peer_hton(&st->src, &sp->src);
	pf_state_peer_hton(&st->dst, &sp->dst);

	if (st->expire <= secs)
		sp->expire = htonl(0);
	else
		sp->expire = htonl(st->expire - secs);
@


1.96
log
@Simplify code slightly; use PR_ZERO with pool_get() rather than bzero().

ok mpf henning
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.95 2008/06/10 19:32:13 henning Exp $	*/
d282 1
a282 1
	if ((PF_ANEQ(&sp->key[PF_SK_WIRE].addr[0],
d287 7
a293 6
	    sp->key[PF_SK_WIRE].port[1] != sp->key[PF_SK_STACK].port[1]) &&
	    (sks = pf_alloc_state_key()) == NULL) {
		pool_put(&pf_state_pl, st);
		pfi_kif_unref(kif, PFI_KIF_REF_NONE);
		pool_put(&pf_state_key_pl, skw);
		return (ENOMEM);
@


1.95
log
@save somespace in the state by collapsing two 8 bit ints used as booleans
into one 8 bit flags field.
shrinks the state structure by 4 bytes on 32bit archs
ryan ok
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.94 2008/06/10 04:24:17 henning Exp $	*/
d227 1
a227 1
		d->scrub = pool_get(&pf_state_scrub_pl, PR_NOWAIT);
a229 1
		bzero(d->scrub, sizeof(*d->scrub));
d271 1
a271 1
		st = pool_get(&pf_state_pl, PR_NOWAIT);
a275 1
	bzero(st, sizeof(*st));
@


1.94
log
@implement a sloppy tcpstate tracker which does not look at sequence
numbers at all. scary consequences; only tobe used in very specific
situations where you don't see all packets of a connection, e. g.
asymmetric routing. ok ryan reyk theo
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.93 2008/05/29 01:00:53 mcbride Exp $	*/
d346 1
a346 2
	st->allow_opts = sp->allow_opts;
	st->sloppy = sp->sloppy;
d1264 1
a1264 2
		sp->allow_opts = st->allow_opts;
		sp->sloppy = st->sloppy;
@


1.93
log
@Second half of PF state table rearrangement.
- Mechanical change: Use arrays for state key pointers in pf_state, and
  addr/port in pf_state_key, to allow the use of indexes.
- Fix NAT, pfsync, pfctl, and tcpdump to handle the new state structures.
  In struct pfsync_state, both state keys are included even when identical.
- Also fix some bugs discovered in the existing code during testing.
  (in particular, "block return" for TCP packets was not returning an RST)

ok henning beck deraadt
tested by otto dlg beck laurent

Special thanks to users Manuel Pata and Emilio Perea who did enough testing
to actually find some bugs.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.91 2008/05/18 11:54:04 mcbride Exp $	*/
d347 1
d1266 1
@


1.92
log
@rewrite the state table logic.
complete the split off of the layer 3/4 adressing information from the extra
information in the actual state. a state key holds a list of states, and a
state points to two state keys - they're only different in the NAT case.
More specificially, it deprecates the (often difficult to understand)
concept of lan, ext, and gwy addresses, replacing them with WIRE and
STACK side address tuples.  (af, proto, saddr, daddr, sport, dport).
Concept first brought up some years ago on a ferry ride in bc by ryan and
me, I spent some time over the last year getting closer, and finally
got it completed in japan with ryan. dlg also took part, helped a lot,
and saved us 8 bytes.
This commit removes support for any kind of NAT as well as pfsync.
It also paves the road for some code simplification and some very cool
future stuff.
ok ryan beck, tested by many
@
text
@d240 1
a240 1
	struct pf_state_key *sk = NULL;
d279 1
a279 1
	if ((sk = pf_alloc_state_key()) == NULL) {
d284 13
d305 6
a310 1
		pool_put(&pf_state_key_pl, sk);
a313 1
	pf_attach_state(sk, st, 0, PF_SK_BOTH); /* XXX RYAN NAT */
a320 1
#ifdef XXX_HENNING_RYAN_FIXED_PFSYNC
d322 15
a336 4
	pf_state_host_ntoh(&sp->lan, &sk->lan);
	pf_state_host_ntoh(&sp->gwy, &sk->gwy);
	pf_state_host_ntoh(&sp->ext, &sk->ext);
#endif
a342 3

	sk->af = sp->af;
	sk->proto = sp->proto;
d352 1
a352 1
	if (pf_state_insert(kif, sk, st)) {
d560 1
a560 1
			sk = st->key_wire;	/* XXX right one? */
d697 1
a697 1
			sk = st->key_wire; /* XXX right one? */
d1149 1
a1149 1
	struct pf_state_key *sk = st->key_wire;
d1235 10
a1244 5
#ifdef XXX_HENNING_RYAN_FIXED_PFSYNC
		pf_state_host_hton(&sk->lan, &sp->lan);
		pf_state_host_hton(&sk->gwy, &sp->gwy);
		pf_state_host_hton(&sk->ext, &sp->ext);
#endif
@


1.91
log
@KNF
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.90 2008/05/06 03:45:21 mpf Exp $	*/
d279 1
a279 1
	if ((sk = pf_alloc_state_key(st)) == NULL) {
d296 1
d304 1
d309 1
a309 1

d319 1
a319 1
	sk->direction = sp->direction;
d328 1
a328 1
	if (pf_insert_state(kif, st)) {
d351 1
d451 8
a458 7
			for (sk = RB_MIN(pf_state_tree_lan_ext,
			    &pf_statetbl_lan_ext); sk; sk = nextsk) {
				nextsk = RB_NEXT(pf_state_tree_lan_ext,
				    &pf_statetbl_lan_ext, sk);
				TAILQ_FOREACH(st, &sk->states, next) {
					if (st->creatorid == creatorid) {
						st->sync_flags |=
d460 1
a460 1
						pf_unlink_state(st);
d536 1
a536 1
			sk = st->state_key;
d673 1
a673 1
			sk = st->state_key;
d1125 1
a1125 1
	struct pf_state_key *sk = st->state_key;
d1211 1
d1215 1
a1215 1

d1233 1
a1233 1
		sp->direction = sk->direction;
@


1.90
log
@Add a counter to record how many states have been created by a rule.
It shows up in pfctl verbose mode and in the 7th field of the labels
output.  Also remove the label printing for scrub rules, as they
do not support labels.
OK dhartmei@@ (on an earlier version), henning@@, mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.89 2008/01/12 17:08:33 mpf Exp $	*/
d593 1
a593 1
	    		pfsync_alloc_scrub_memory(&sp->dst, &st->dst);
d720 1
a720 1
	    		pfsync_alloc_scrub_memory(&up->dst, &st->dst);
d1719 1
a1719 1
			            !bcmp(&tdb->tdb_dst, &u->dst,
@


1.89
log
@Kill all timeouts and undo carp demotion on pfsync_clone_destroy.
Panic reported by deraadt.
OK henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.88 2007/12/14 18:33:37 deraadt Exp $	*/
d271 1
a271 1
	if (!r->max_states || r->states < r->max_states)
d300 2
a301 1
	r->states++;
d329 1
a329 1
		r->states--;
@


1.88
log
@add sysctl entry points into various network layers, in particular to
provide netstat(1) with data it needs;  ok claudio reyk
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.87 2007/09/18 18:56:02 markus Exp $	*/
d180 10
@


1.87
log
@allow 4095 instead of 20 multicast group memberships per socket (you need
one entry for each multicast group and interface combination). this allows
you to run OSPF with more than 10 interfaces.
adapted from freebsd; ok claudio, henning, mpf
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.86 2007/09/15 16:43:51 henning Exp $	*/
d39 1
d1760 19
@


1.86
log
@malloc sweep:
-remove useless casts
-MALLOC/FREE -> malloc/free
-use M_ZERO where appropriate instead of seperate bzero
feedback & ok krw, hshoexer
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.85 2007/09/03 06:15:06 joel Exp $	*/
d144 4
d183 1
@


1.85
log
@Make use of the pfsync 'badval' and 'stale' counters instead of using
'badstate' everywhere.


ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.84 2007/09/01 18:49:27 henning Exp $	*/
d128 2
a129 1
	if ((pfsyncif = malloc(sizeof(*pfsyncif), M_DEVBUF, M_NOWAIT)) == NULL)
a130 1
	bzero(pfsyncif, sizeof(*pfsyncif));
@


1.84
log
@since the
MGET* macros were changed to function calls, there wasn't any
need for the pool declarations and the inclusion of pool.h
From: tbert <bret.lambert@@gmail.com>
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.83 2007/06/26 14:44:12 mcbride Exp $	*/
d465 1
a465 1
					printf("pfsync_insert: PFSYNC_ACT_INS: "
d467 1
a467 1
				pfsyncstats.pfsyncs_badstate++;
d499 1
a499 1
					printf("pfsync_insert: PFSYNC_ACT_UPD: "
d501 1
a501 1
				pfsyncstats.pfsyncs_badstate++;
d563 1
a563 1
				pfsyncstats.pfsyncs_badstate++;
d630 1
a630 1
					printf("pfsync_insert: "
d633 1
a633 1
				pfsyncstats.pfsyncs_badstate++;
d689 1
a689 1
				pfsyncstats.pfsyncs_badstate++;
@


1.83
log
@Fix a race condition during ruleset reload; make sure we don't walk off
the end of the array of rule pointers when attaching a pfsync'd state
to a rule. Reported in PR5508 by mayer@@netlab.nec.de.

ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.82 2007/06/25 13:57:18 henning Exp $	*/
d48 1
@


1.82
log
@pretty mechanical change: now that the state tables use seperate state
keys that can map to multiple states (last not least for ifbound) we don't
need state tables hanging off each struct kif representing an interface
any more. use two globals for the two tables. ok markus ryan
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.81 2007/06/24 11:17:13 mcbride Exp $	*/
d246 3
a248 1
	if (sp->rule != htonl(-1) && sp->anchor == htonl(-1) && chksum_flag)
@


1.81
log
@Save some bytes and make code more readable by removing junk union and
unused ifname (this information is in struct pf_state_sync now).

Also a bit of KNF on the pf_state struct.

ok mpf@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.80 2007/06/21 11:55:54 henning Exp $	*/
d429 1
a429 1
			    &pfi_all->pfik_lan_ext); sk; sk = nextsk) {
d431 1
a431 1
				    &pfi_all->pfik_lan_ext, sk);
@


1.80
log
@reimplement interface bound states in a non-retarded way.
previously, we had a set of state tables attached to each interface. so for
every packet we had to do a lookup in the tables for the interface, and
afterwards in the global tables.
since we split state keys and states now, use only the global tables, and
put the actual states in a tail queue attached to the state key. sort the
list so that ifbound states come before global ones. on lookup, we only
have to compare the interface pointer on the actual states and use the
first one where either the interface matches or the state is not interface
bound. thus, if you don't actually use ifbound states, and there is only
one state per state key, the overhead is close to zero, where we had extra
lookups before. in addition to a much cleaner design (that'll allow for more
goodies later) this gives us ~12.5% more forwarding performance.
mostly hacked at c2k7, lots of help, testing and ok mcbride & markus
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.79 2007/06/14 13:38:27 henning Exp $	*/
d1186 1
a1186 1
		strlcpy(sp->ifname, st->u.s.kif->pfik_name, sizeof(sp->ifname));
d1440 1
a1440 1
			state = TAILQ_NEXT(state, u.s.entry_list);
@


1.79
log
@sprinkle some #ifdef IPSEC so that pfsync compiles w/o ipsec
from mickey, ok me markus mickey
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.78 2007/06/01 18:44:22 henning Exp $	*/
d429 1
a429 1
			    &kif->pfik_lan_ext); sk; sk = nextsk) {
d431 7
a437 5
				    &kif->pfik_lan_ext, sk);
				if (sk->state->creatorid == creatorid) {
					sk->state->sync_flags |=
					    PFSTATE_FROMSYNC;
					pf_unlink_state(sk->state);
@


1.78
log
@factor out duplicated code to allocate state key and cross-reference it
with a state entry into a new pf_alloc_state_key() function and use it
everywhere. makes upcoming changes way easier and is cleaner anyway.
conceptually agreed by ryan, but he's on the road now ;(
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.77 2007/05/31 20:38:12 henning Exp $	*/
d336 1
d338 1
d821 1
d834 1
d1597 1
d1748 1
@


1.77
log
@unlink the right state, ryan ok
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.76 2007/05/31 18:48:05 mcbride Exp $	*/
d258 3
a260 2
	sk = pool_get(&pf_state_key_pl, PR_NOWAIT);
	if (sk == NULL) {
a264 4
	bzero(st, sizeof(*st));
	bzero(sk, sizeof(*sk));
	sk->state = st;
	st->state_key = sk;
@


1.76
log
@Move the state id and creatorid (used mainly by pfsync) into struct pf_state.

ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.75 2007/05/31 04:11:42 mcbride Exp $	*/
d436 1
a436 1
					pf_unlink_state(st);
@


1.75
log
@First step of rearranging pf's state table internals...

- Split pf_state into pf_state (used for tracking connection information),
  and pf_state_key (used for searching the state table)

- Use pfsync_state in the ioctl for userland access to the state
  table. This will sheild userland somewhat from future changes.

ok henning@@ toby@@ pyr@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.74 2007/05/26 17:13:31 jason Exp $	*/
d305 2
a306 2
	bcopy(sp->id, &sk->id, sizeof(sk->id));
	sk->creatorid = sp->creatorid;
d332 1
a332 1
	struct pf_state_key_cmp key;
d402 3
a404 2
		struct pf_state_key *nexts;
		struct pfi_kif	*kif;
d416 4
a419 4
			for (sk = RB_MIN(pf_state_tree_id, &tree_id);
			    sk; sk = nexts) {
				nexts = RB_NEXT(pf_state_tree_id, &tree_id, sk);
				if (sk->creatorid == creatorid) {
d421 1
a421 1
					pf_unlink_state(sk->state);
d430 2
a431 2
			    &kif->pfik_lan_ext); sk; sk = nexts) {
				nexts = RB_NEXT(pf_state_tree_lan_ext,
d433 4
a436 3
				if (sk->creatorid == creatorid) {
					st->sync_flags |= PFSTATE_FROMSYNC;
					pf_unlink_state(sk->state);
d501 2
a502 2
			bcopy(sp->id, &key.id, sizeof(key.id));
			key.creatorid = sp->creatorid;
d504 1
a504 1
			st = pf_find_state_byid(&key);
d557 2
a558 2
					    betoh64(sk->id),
					    ntohl(sk->creatorid));
d596 2
a597 2
			bcopy(sp->id, &key.id, sizeof(key.id));
			key.creatorid = sp->creatorid;
d599 1
a599 1
			st = pf_find_state_byid(&key);
d633 2
a634 2
			bcopy(up->id, &key.id, sizeof(key.id));
			key.creatorid = up->creatorid;
d636 1
a636 1
			st = pf_find_state_byid(&key);
d683 2
a684 2
					    betoh64(sk->id),
					    ntohl(sk->creatorid));
d720 2
a721 2
			bcopy(dp->id, &key.id, sizeof(key.id));
			key.creatorid = dp->creatorid;
d723 1
a723 1
			st = pf_find_state_byid(&key);
d750 2
a751 2
			bcopy(rup->id, &key.id, sizeof(key.id));
			key.creatorid = rup->creatorid;
d753 1
a753 1
			if (key.id == 0 && key.creatorid == 0) {
d765 1
a765 1
				st = pf_find_state_byid(&key);
d1154 1
a1154 1
					if (!memcmp(usp->id, &sk->id,
d1156 1
a1156 1
					    usp->creatorid == sk->creatorid) {
d1180 2
a1181 2
		bcopy(&sk->id, sp->id, sizeof(sp->id));
		sp->creatorid = sk->creatorid;
d1260 2
a1261 2
				bcopy(&sk->id, up->id, sizeof(up->id));
				up->creatorid = sk->creatorid;
d1275 2
a1276 2
			bcopy(&sk->id, dp->id, sizeof(dp->id));
			dp->creatorid = sk->creatorid;
@


1.74
log
@one extern seems to be better than 20 for ifqmaxlen; ok krw
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.73 2006/11/16 13:13:38 henning Exp $	*/
d223 1
d258 6
d265 3
d276 1
d287 3
a289 3
	pf_state_host_ntoh(&sp->lan, &st->lan);
	pf_state_host_ntoh(&sp->gwy, &st->gwy);
	pf_state_host_ntoh(&sp->ext, &st->ext);
d298 3
a300 3
	st->af = sp->af;
	st->proto = sp->proto;
	st->direction = sp->direction;
d305 2
a306 2
	bcopy(sp->id, &st->id, sizeof(st->id));
	st->creatorid = sp->creatorid;
d331 2
a332 1
	struct pf_state_cmp key;
d402 1
a402 1
		struct pf_state *nexts;
d415 4
a418 4
			for (st = RB_MIN(pf_state_tree_id, &tree_id);
			    st; st = nexts) {
				nexts = RB_NEXT(pf_state_tree_id, &tree_id, st);
				if (st->creatorid == creatorid) {
d420 1
a420 1
					pf_unlink_state(st);
d428 2
a429 2
			for (st = RB_MIN(pf_state_tree_lan_ext,
			    &kif->pfik_lan_ext); st; st = nexts) {
d431 2
a432 2
				    &kif->pfik_lan_ext, st);
				if (st->creatorid == creatorid) {
d434 1
a434 1
					pf_unlink_state(st);
d509 1
d511 1
a511 1
			if (st->proto == IPPROTO_TCP) {
d555 2
a556 2
					    betoh64(st->id),
					    ntohl(st->creatorid));
d646 1
d648 1
a648 1
			if (st->proto == IPPROTO_TCP) {
d681 2
a682 2
					    betoh64(st->id),
					    ntohl(st->creatorid));
d1096 1
d1152 1
a1152 1
					if (!memcmp(usp->id, &st->id,
d1154 1
a1154 1
					    usp->creatorid == st->creatorid) {
d1178 2
a1179 2
		bcopy(&st->id, sp->id, sizeof(sp->id));
		sp->creatorid = st->creatorid;
d1182 3
a1184 3
		pf_state_host_hton(&st->lan, &sp->lan);
		pf_state_host_hton(&st->gwy, &sp->gwy);
		pf_state_host_hton(&st->ext, &sp->ext);
d1201 3
a1203 3
		sp->af = st->af;
		sp->proto = st->proto;
		sp->direction = st->direction;
d1258 2
a1259 2
				bcopy(&st->id, up->id, sizeof(up->id));
				up->creatorid = st->creatorid;
d1273 2
a1274 2
			bcopy(&st->id, dp->id, sizeof(dp->id));
			dp->creatorid = st->creatorid;
@


1.73
log
@no need to always attach pfsync0 any more. ok mpf mcbride
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.72 2006/11/01 23:39:34 mcbride Exp $	*/
a108 1
extern int ifqmaxlen;
@


1.72
log
@Attach pfsync0 and pflog0 by default like they used to, /etc/rc depends on
them being there.

diff & ok deraadt
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.71 2006/11/01 00:02:14 henning Exp $	*/
a116 1
	(void) pfsync_clone_create(&pfsync_cloner, 0);
@


1.71
log
@remove redundant null check, ok ryan
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.70 2006/10/31 22:01:56 henning Exp $	*/
d117 1
@


1.70
log
@slightly improve consustency and readability, no functional change
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.68 2006/10/31 17:37:11 deraadt Exp $	*/
d1634 2
a1635 2
	if (sc == NULL || (ifp->if_bpf == NULL && sc->sc_sync_ifp == NULL &&
	    sc->sc_sync_peer.s_addr == INADDR_PFSYNC_GROUP)) {
@


1.69
log
@in pfsync_update_tdb, when there is no pfsync interface, we must return
without trying to free the (in that case nonexistant) tdb mbuf
found out the hard way by pedro
@
text
@a1284 2
	else
		ifp = &sc->sc_if;
d1286 1
a1329 2
	else
		ifp = &sc->sc_if;
d1331 1
@


1.68
log
@hard to believe people still manage to commit non-compiling code once in a while
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.67 2006/10/31 14:49:01 henning Exp $	*/
d1632 2
a1633 2
	if (sc != NULL)
		ifp = &sc->sc_if;
d1635 1
@


1.67
log
@make pfsync a clonable too, but prevent more than one instance from
beeing created for now - much more work would be required to change that
input & ok ryan
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.66 2006/06/02 19:53:12 mpf Exp $	*/
d1089 2
a1090 3
		return (0)
	else
		ifp = &sc->sc_if;
@


1.66
log
@Introduce attributes to interface groups.
As a first user, move the global carp(4) demotion counter
into the interface group. Thus we have the possibility
to define which carp interfaces are demoted together.

Put the demotion counter into the reserved field of the carp header.
With this, we can have carp act smarter if multiple errors occur.
It now always takes over other carp peers, that are advertising
with a higher demote count.  As a side effect, we can also have
group failovers without the need of running in preempt mode.
The protocol change does not break compability with older
implementations.

Collaborative work with mcbride@@

OK mcbride@@, henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.65 2006/05/28 02:04:15 mcbride Exp $	*/
d81 2
a82 2
struct pfsync_softc	pfsyncif;
struct pfsyncstats	pfsyncstats;
d85 2
d111 3
d117 5
d124 3
d128 19
a146 17
	bzero(&pfsyncif, sizeof(pfsyncif));
	pfsyncif.sc_mbuf = NULL;
	pfsyncif.sc_mbuf_net = NULL;
	pfsyncif.sc_mbuf_tdb = NULL;
	pfsyncif.sc_statep.s = NULL;
	pfsyncif.sc_statep_net.s = NULL;
	pfsyncif.sc_statep_tdb.t = NULL;
	pfsyncif.sc_maxupdates = 128;
	pfsyncif.sc_sync_peer.s_addr = INADDR_PFSYNC_GROUP;
	pfsyncif.sc_sendaddr.s_addr = INADDR_PFSYNC_GROUP;
	pfsyncif.sc_ureq_received = 0;
	pfsyncif.sc_ureq_sent = 0;
	pfsyncif.sc_bulk_send_next = NULL;
	pfsyncif.sc_bulk_terminator = NULL;
	ifp = &pfsyncif.sc_if;
	strlcpy(ifp->if_xname, "pfsync0", sizeof ifp->if_xname);
	ifp->if_softc = &pfsyncif;
d153 5
a157 5
	pfsync_setmtu(&pfsyncif, ETHERMTU);
	timeout_set(&pfsyncif.sc_tmo, pfsync_timeout, &pfsyncif);
	timeout_set(&pfsyncif.sc_tdb_tmo, pfsync_tdb_timeout, &pfsyncif);
	timeout_set(&pfsyncif.sc_bulk_tmo, pfsync_bulk_update, &pfsyncif);
	timeout_set(&pfsyncif.sc_bulkfail_tmo, pfsync_bulkfail, &pfsyncif);
d166 11
a176 1
	bpfattach(&pfsyncif.sc_if.if_bpf, ifp, DLT_PFSYNC, PFSYNC_HDRLEN);
d178 4
d319 1
a319 1
	struct pfsync_softc *sc = &pfsyncif;
d337 1
a337 1
	if (!sc->sc_sync_ifp || !pf_status.running)
d1077 2
a1078 2
	struct ifnet *ifp = &pfsyncif.sc_if;
	struct pfsync_softc *sc = ifp->if_softc;
d1088 5
d1278 1
a1278 1
	struct ifnet *ifp = &pfsyncif.sc_if;
d1280 1
a1280 1
	struct pfsync_softc *sc = ifp->if_softc;
d1284 5
d1325 2
a1326 2
	struct ifnet *ifp = &pfsyncif.sc_if;
	struct pfsync_softc *sc = ifp->if_softc;
d1330 5
d1627 2
a1628 2
	struct ifnet *ifp = &pfsyncif.sc_if;
	struct pfsync_softc *sc = ifp->if_softc;
d1633 5
a1637 2
	if (ifp->if_bpf == NULL && sc->sc_sync_ifp == NULL &&
	    sc->sc_sync_peer.s_addr == INADDR_PFSYNC_GROUP) {
@


1.65
log
@Only preemptively increase the replay counter for outbound TDBs.

Another ipsec failover fix from nathanael at polymorpheus dot com.

ok hshoexer@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.64 2006/05/13 05:23:45 mcbride Exp $	*/
d62 1
a62 1
extern int carp_suppress_preempt;
d146 4
d764 1
a764 1
					carp_suppress_preempt--;
d929 1
a929 1
				carp_suppress_preempt++;
d1431 1
a1431 1
			carp_suppress_preempt--;
@


1.64
log
@Avoid potential hash collisions and increase efficiency by doing an exact
comparison of the TDB before collapsing multiple updates.

Another ipsec failover fix from Nathanael <list-openbsd-tech@@polymorpheus.com>
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.63 2006/05/06 18:31:00 mcbride Exp $	*/
d1551 1
a1551 18
		/*
		 * When a failover happens, the master's rpl is probably above
		 * what we see here (we may be up to a second late), so
		 * increase it a bit to manage most such situations.
		 *
		 * For now, just add an offset that is likely to be larger
		 * than the number of packets we can see in one second. The RFC
		 * just says the next packet must have a higher seq value.
		 *
		 * XXX What is a good algorithm for this? We could use
		 * a rate-determined increase, but to know it, we would have
		 * to extend struct tdb.
		 * XXX pt->rpl can wrap over MAXINT, but if so the real tdb
		 * will soon be replaced anyway. For now, just don't handle
		 * this edge case.
		 */
#define RPL_INCR 16384
		pt->rpl = ntohl(pt->rpl) + RPL_INCR;
d1577 1
a1577 1
pfsync_update_tdb(struct tdb *tdb)
d1653 19
a1671 1
	pt->rpl = htonl(tdb->tdb_rpl);
@


1.63
log
@The SPI in a TDB is actually stored in network order. Make sa synchronisation
work between little-endian and big-endian machines, and compare the spi
against SPI_RESERVED_MAX correctly.

Fix from Nathanael <list-openbsd-tech at polymorpheus dot com>
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.62 2006/03/25 22:41:47 djm Exp $	*/
a1642 2
			int hash = tdb_hash(tdb->tdb_spi, &tdb->tdb_dst,
			    tdb->tdb_sproto);
d1645 4
a1648 2
				if (tdb_hash(u->spi, &u->dst,
				    u->sproto) == hash) {
@


1.62
log
@allow bpf(4) to ignore packets based on their direction (inbound or
outbound), using a new BIOCSDIRFILT ioctl;
guidance, feedback and ok canacar@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.61 2006/03/04 22:40:15 brad Exp $	*/
d1543 1
a1543 2
	pt->spi = htonl(pt->spi);
	if (pt->spi <= SPI_RESERVED_MAX ||
a1547 4
	if (pt->dst.sa.sa_family == AF_INET)
		pt->dst.sin.sin_addr.s_addr =
		    htonl(pt->dst.sin.sin_addr.s_addr);

d1647 1
a1647 5
				/* XXX Ugly, u is network ordered. */
				if (u->dst.sa.sa_family == AF_INET)
					u->dst.sin.sin_addr.s_addr =
					    ntohl(u->dst.sin.sin_addr.s_addr);
				if (tdb_hash(ntohl(u->spi), &u->dst,
a1651 3
				if (u->dst.sa.sa_family == AF_INET)
					u->dst.sin.sin_addr.s_addr =
					    htonl(u->dst.sin.sin_addr.s_addr);
d1665 1
a1665 1
		pt->spi = htonl(tdb->tdb_spi);
a1666 3
		if (pt->dst.sa.sa_family == AF_INET)
			pt->dst.sin.sin_addr.s_addr =
			    htonl(pt->dst.sin.sin_addr.s_addr);
@


1.61
log
@With the exception of two other small uncommited diffs this moves
the remainder of the network stack from splimp to splnet.

ok miod@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.60 2006/02/20 20:12:14 damien Exp $	*/
d1456 1
a1456 1
		bpf_mtap(ifp->if_bpf, m);
d1487 1
a1487 1
		bpf_mtap(ifp->if_bpf, m);
@


1.60
log
@Fix kernel builds without bpfilter. Linking is still broken.

"Please commit this diff ASAP" brad@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.59 2005/11/04 08:24:14 mcbride Exp $	*/
d161 1
a161 1
		s = splimp();
@


1.59
log
@crank pf_state and pf_src_node byte and packet counters to u_in64_t, since
we're breaking pfsync compatibility this cycle anyways.

Requested by djm@@, ok henning@@, 'wheee!' deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.58 2005/11/01 06:26:52 pascoe Exp $	*/
d1441 1
d1443 1
d1472 1
d1474 1
@


1.58
log
@Always sure that we have memory for the 'dst' scrub information, which may
not have been allocated at the initial state synchronisation time.

ok henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.57 2005/10/28 03:20:41 mcbride Exp $	*/
d1138 4
a1141 4
		sp->packets[0] = htonl(st->packets[0]);
		sp->packets[1] = htonl(st->packets[1]);
		sp->bytes[0] = htonl(st->bytes[0]);
		sp->bytes[1] = htonl(st->bytes[1]);
@


1.57
log
@s/rmatch/chksum_flag/ to clarify what's going on. Pointed out by dhartmei@@

Oh. and a KNF nit.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.56 2005/10/27 12:34:40 mcbride Exp $	*/
d525 1
d651 1
@


1.56
log
@Basic support for attaching states from pfsync to the correct rules.
Applies only to rules in the main ruleset (not anchors) if the ruleset
checksum matches. Necessary to fix the following for pfsync'd states:
	- per-rule limits on number of states
	- altq
	- rule-based settings such as timeouts

More work to do re: nat rules, src-nodes, etc.

NOTE: This is modifies the pfsync header and version number.
Tools which process pfsync packets must be recompiled, and firewalls with
different versions will not sync.

ok mpf@@ henning@@ dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.55 2005/09/28 01:46:32 pascoe Exp $	*/
d188 1
a188 1
pfsync_insert_net_state(struct pfsync_state *sp, u_int8_t rmatch)
d213 1
a213 1
	if (sp->rule != htonl(-1) && sp->anchor == htonl(-1) && rmatch)
d299 1
a299 1
	u_int8_t rmatch = 0;
d354 1
a354 1
		rmatch++;
d421 2
a422 1
			if ((error = pfsync_insert_net_state(sp, rmatch))) {
d461 1
a461 1
				if (pfsync_insert_net_state(sp, rmatch))
d706 1
a706 1
					sc->sc_bulk_send_next = 
@


1.55
log
@Improve the safety of pf IOCTLs, taking into account that some paths can sleep.

- Introduces a rw_lock in pfioctl so that we can have concurrent readers
  but only one process performing updates at a time;

- Separates state expiry into "unlink" and "free" parts; anyone can unlink
  a state/src node from the RB trees at any time, but a state can only be
  freed whilst the write lock is held;

- Converts state_updates into list state_list containing all states,
  regardless of whether they are "linked" or "unlinked";

- Introduces a new PFTM_UNLINKED state that is used on the "unlinked" states
  to signal that they can be freed;

- Converts pf_purge_expired_state to an "unlink" state routine, which only
  unlinks the state from the RB trees.  Freeing the state/src nodes is left
  to the purge thread, which runs whilst holding a write lock, such that all
  "next" references remain valid;

- Converts pfsync_bulk_update and DIOCGETSTATES to walk state_list rather
  than the RB trees;

- Converts the purge thread to use the new state_list and perform a partial
  purge every second, with the target rate a full state table walk every
  PFTM_INTERVAL seconds.

seen by mcbride, henning, dhartmei pre-3.8, but too intrusive for then
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.54 2005/08/18 10:28:13 pascoe Exp $	*/
a28 2
#include "bpfilter.h"
#include "pfsync.h"
d68 3
d88 1
a88 1
int	pfsync_insert_net_state(struct pfsync_state *);
d188 1
a188 1
pfsync_insert_net_state(struct pfsync_state *sp)
d210 2
a211 2
	 * Just use the default rule until we have infrastructure to find the
	 * best matching rule.
d213 5
a217 1
	r = &pf_default_rule;
d299 1
d353 3
d421 1
a421 1
			if ((error = pfsync_insert_net_state(sp))) {
d460 1
a460 1
				if (pfsync_insert_net_state(sp))
d1026 3
d1491 1
a1491 1
	
d1582 1
a1582 1
  bad:
d1587 1
a1587 1
	return;	
@


1.54
log
@Rearrange pf_state and pfi_kif so that the parts of the structure needed
to search for a particular entry in the RB trees are at the start of the
structure.

This permits us to place a much smaller structure on the stack in the
interrupt paths that match packets against state entries.

ok mcbride
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.53 2005/08/16 11:22:43 pascoe Exp $	*/
d126 2
a365 1
					st->timeout = PFTM_PURGE;
d367 1
a379 1
					st->timeout = PFTM_PURGE;
d381 1
a545 1
			st->timeout = PFTM_PURGE;
d547 1
a667 1
			st->timeout = PFTM_PURGE;
d669 1
d695 4
a1101 2
	TAILQ_REMOVE(&state_updates, st, u.s.entry_updates);
	TAILQ_INSERT_TAIL(&state_updates, st, u.s.entry_updates);
d1349 7
a1355 13
	while ((state = TAILQ_FIRST(&state_updates)) != NULL &&
	    ++i < (sc->sc_maxcount * PFSYNC_BULKPACKETS)) {
		if (state->pfsync_time > sc->sc_ureq_received) {
			/* we're done */
			pfsync_send_bus(sc, PFSYNC_BUS_END);
			sc->sc_ureq_received = 0;
			timeout_del(&sc->sc_bulk_tmo);
			if (pf_status.debug >= PF_DEBUG_MISC)
				printf("pfsync: bulk update complete\n");
			break;
		} else {
			/* send an update and move to end of list */
			if (!state->sync_flags)
d1357 2
a1358 4
			state->pfsync_time = time_uptime;
			TAILQ_REMOVE(&state_updates, state, u.s.entry_updates);
			TAILQ_INSERT_TAIL(&state_updates, state,
			    u.s.entry_updates);
d1360 22
a1381 3
			/* look again for more in a bit */
			timeout_add(&sc->sc_bulk_tmo, 1);
		}
@


1.53
log
@Synchronise timestamp modulation and scrubbing min ttl information.

ok henning mcbride, looks good frantzen
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.52 2005/08/11 17:58:58 mcbride Exp $	*/
d280 2
a281 1
	struct pf_state *st, key;
@


1.52
log
@Remove bogus debug printf().

ok ho@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.51 2005/08/03 00:55:07 pascoe Exp $	*/
d85 2
d171 14
d220 10
a258 1

d263 4
@


1.51
log
@Eliminate another case where pool routines are called without process context.
Instead of purging immediately, let the state be purged at the purge interval.

ok henning
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.50 2005/08/01 11:14:47 pascoe Exp $	*/
a1525 1
	printf("pfsync_update_net_tdb: badness\n");
@


1.50
log
@Minor whitespace cleanup.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.49 2005/07/12 17:40:51 mickey Exp $	*/
d335 1
a335 1
					pf_purge_expired_state(st);
d349 1
a349 1
					pf_purge_expired_state(st);
a515 1
			pf_purge_expired_state(st);
a637 1
			pf_purge_expired_state(st);
@


1.49
log
@default mtu to no more than ETHERMTU to avoid fragmentation; henning@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.48 2005/05/28 15:10:07 ho Exp $	*/
d332 1
a332 1
                		nexts = RB_NEXT(pf_state_tree_id, &tree_id, st);
d458 1
a458 1
				else if ( st->dst.state > sp->dst.state)
d985 1
a985 1
	if (action == PFSYNC_ACT_TDB_UPD) 
d1437 1
a1437 1
	if (sc->sc_sync_ifp || 
d1488 1
a1488 1
		pt->dst.sin.sin_addr.s_addr = 
d1494 1
a1494 1
		/* 
d1515 1
a1515 1
		if (pt->rpl < tdb->tdb_rpl || 
d1569 1
a1569 1
			 * XXX will never happen as long as there's 
@


1.48
log
@Add SA replay counter synchronization to pfsync(4). Required for IPsec
failover gateways. ok mcbride@@, "looks good" hshoexer@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.47 2005/05/21 21:03:57 henning Exp $	*/
d46 2
a51 1
#include <netinet/in.h>
a58 3
#ifndef INET
#include <netinet/in.h>
#endif
d133 1
a133 1
	pfsync_setmtu(&pfsyncif, MCLBYTES);
@


1.47
log
@clean up and rework the interface absraction code big time, rip out multiple
useless layers of indirection and make the code way cleaner overall.
this is just the start, more to come...
worked very hard on by Ryan and me in Montreal last week, on the airplane to
vancouver and yesterday here in calgary. it hurt.
ok ryan theo
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.46 2005/02/20 15:58:38 mcbride Exp $	*/
d88 1
d97 2
d100 1
d117 1
d120 1
d137 1
d260 1
d730 12
d957 4
d987 4
a990 1
	timeout_add(&sc->sc_tmo, hz);
d1272 11
d1383 1
a1383 2
pfsync_sendout(sc)
	struct pfsync_softc *sc;
d1408 24
a1431 3
	if (sc->sc_sync_ifp || sc->sc_sync_peer.s_addr != INADDR_PFSYNC_GROUP) {
		struct ip *ip;
		struct sockaddr sa;
d1433 8
d1473 162
@


1.46
log
@Avoid use after free when purging states.

ok henning@@ dhartmei@@ claudio@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.45 2005/02/15 21:31:22 aaron Exp $	*/
d176 1
a176 1
	kif = pfi_lookup_create(sp->ifname);
d194 1
a194 1
		pfi_maybe_destroy(kif);
d230 1
a230 1
		pfi_maybe_destroy(kif);
d333 1
a333 5
			kif = pfi_lookup_if(cp->ifname);
			if (kif == NULL) {
				if (pf_status.debug >= PF_DEBUG_MISC)
					printf("pfsync_input: PFSYNC_ACT_CLR "
					    "bad interface: %s\n", cp->ifname);
d335 1
a335 1
				goto done;
@


1.46.2.1
log
@MFC:
Fix by pascoe@@

Eliminate another case where pool routines are called without process context.
Instead of purging immediately, let the state be purged at the purge interval.

ok deraadt@@ pascoe@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.46 2005/02/20 15:58:38 mcbride Exp $	*/
d329 1
a329 1
					st->sync_flags |= PFSTATE_FROMSYNC;
d347 1
a347 1
					st->sync_flags |= PFSTATE_FROMSYNC;
d514 1
d637 1
@


1.45
log
@Fix scoping error which could cause some states with an empty ifname to be
purged errneously.  mpf@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.44 2005/01/20 17:54:26 mcbride Exp $	*/
d311 1
d324 3
a326 1
			RB_FOREACH(st, pf_state_tree_id, &tree_id) {
d341 4
a344 2
			RB_FOREACH(st, pf_state_tree_lan_ext,
			    &kif->pfik_lan_ext) {
@


1.44
log
@sc->sc_sync_ifp = NULL if we fail to attach the multicast group.

ok mpf@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.43 2005/01/20 17:47:38 mcbride Exp $	*/
d324 1
a324 1
				if (st->creatorid == creatorid)
d327 1
@


1.43
log
@Use syncdev instead of syncif in ifconfig, and modify ioctl struct pfsyncreq
in kernel code to match.  Brings pfsync in line with carp, vlan and pppoe
devices. Old syncif and -syncif options still work, will be removed later.

ok markus@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.42 2004/12/16 00:45:34 mcbride Exp $	*/
d834 1
d843 1
@


1.42
log
@Clean up handling of sync_flags.

ok pascoe@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.41 2004/12/13 01:47:26 pascoe Exp $	*/
d771 1
a771 1
			strlcpy(pfsyncr.pfsyncr_syncif,
d794 1
a794 1
		if (pfsyncr.pfsyncr_syncif[0] == 0) {
d811 1
a811 1
		if ((sifp = ifunit(pfsyncr.pfsyncr_syncif)) == NULL)
@


1.41
log
@Set creation timestamps correctly on states learnt by pfsync that are
more than a second old.

ok mcbride@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.40 2004/12/06 10:27:53 mpf Exp $	*/
d226 1
a226 1
	st->sync_flags = sp->sync_flags | PFSTATE_FROMSYNC;
d469 3
a471 2
					pfsync_pack_state(PFSYNC_ACT_UPD, st,
					    flags);
d596 3
a598 2
				pfsync_pack_state(PFSYNC_ACT_UPD, st,
				    PFSYNC_FLAG_STALE);
d668 3
a670 1
				pfsync_pack_state(PFSYNC_ACT_UPD, st, 0);
a1080 1
		sp->sync_flags = st->sync_flags & PFSTATE_NOSYNC;
d1082 1
a1082 1
			sp->sync_flags = st->sync_flags & PFSTATE_STALE;
@


1.40
log
@At PFSYNC_ACT_CLR:
Also purge states with an empty ifname.
ok mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.39 2004/11/16 20:07:56 mcbride Exp $	*/
d214 1
a214 1
	st->creation = ntohl(sp->creation) + time_second;
@


1.39
log
@Fix for PR3983
- Add a new PFSTATE_STALE flag to uncompressed state updates sent as a result
  of a stale state being detected, and prevent updates with this flag from
  generating similar messages.
- For the specific case where the state->src in the recieved update is ok but
  the state.dst is not, take the partial update, then "fail" to let the other
  peers pick up the better data that we have. From Chris Pascoe.

ok dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.38 2004/09/17 21:49:15 mcbride Exp $	*/
d326 1
@


1.38
log
@Clean up reference counting wrt state creation and destruction. Fixes
problems with adaptive timeouts, max-states limits, and rules not being
freed from memory.

Diff from Chris Pascoe.

ok henning@@ dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.37 2004/08/30 07:44:28 mcbride Exp $	*/
d391 2
a424 2
				else if (st->dst.state > sp->dst.state)
					sfail = 2;
d428 12
a439 1
				else if (st->dst.state >= TCPS_SYN_SENT &&
d454 1
a454 1
					printf("pfsync: ignoring stale update "
d456 3
a458 1
					    "creatorid: %08x\n", sfail,
d463 8
a470 5
				/* we have a better state, send it out */
				if (sc->sc_mbuf != NULL && !stale)
					pfsync_sendout(sc);
				stale++;
				pfsync_pack_state(PFSYNC_ACT_UPD, st, 0);
d594 2
a595 1
				pfsync_pack_state(PFSYNC_ACT_UPD, st, 0);
d959 1
a959 1
pfsync_pack_state(u_int8_t action, struct pf_state *st, int compress)
d1077 2
d1090 1
a1090 1
	if (sc->sc_sync_ifp && compress) {
@


1.37
log
@Increment the states reference counter in the rule attached to the state
being inserted, so that the counter does not wrap back when the state
is removed. This fixes pfsync setups with adaptive timeouts.

From Chris Pascoe

ok canacar@@ dhartmei@@ henning@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.36 2004/08/03 05:32:28 mcbride Exp $	*/
d202 1
d231 2
@


1.36
log
@Allow a unicast ip address to be specified for pfsync to send it's state
updates to; this allows pairs of pfsync firewalls to protect the traffic
with IPSec.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.35 2004/06/21 23:50:36 tholo Exp $	*/
d201 2
@


1.35
log
@First step towards more sane time handling in the kernel -- this changes
things such that code that only need a second-resolution uptime or wall
time, and used to get that from time.tv_secs or mono_time.tv_secs now get
this from separate time_t globals time_second and time_uptime.

ok art@@ niklas@@ nordin@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.34 2004/06/04 22:25:09 mcbride Exp $	*/
d116 1
d746 1
d757 6
d783 1
a785 2
		else if (sifp == sc->sc_sync_ifp)
			break;
d802 2
a803 1
		if (sc->sc_sync_ifp) {
d806 5
d812 1
d822 1
d824 2
d839 1
a839 1
				return(ENOMEM);
d954 2
a955 1
	if (ifp->if_bpf == NULL && sc->sc_sync_ifp == NULL) {
d1339 1
a1339 1
	if (sc->sc_sync_ifp) {
a1340 1
		struct ifaddr *ifa;
d1360 1
a1360 5
		sa.sa_family = AF_INET;
		ifa = ifaof_ifpforaddr(&sa, sc->sc_sync_ifp);
		if (ifa == NULL)
			return (0);
		ip->ip_src.s_addr = ifatoia(ifa)->ia_addr.sin_addr.s_addr;
d1365 1
a1365 1
		sc->sc_sendaddr.s_addr = INADDR_PFSYNC_GROUP;
@


1.34
log
@Remove the multicast address when we unconfigure the syncif.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.33 2004/05/17 17:15:07 mickey Exp $	*/
d40 1
a102 3
extern struct timeval time;
extern struct timeval mono_time;
extern int hz;
d210 2
a211 2
	st->creation = ntohl(sp->creation) + time.tv_sec;
	st->expire = ntohl(sp->expire) + time.tv_sec;
d453 1
a453 1
			st->expire = ntohl(sp->expire) + time.tv_sec;
d577 1
a577 1
			st->expire = ntohl(up->expire) + time.tv_sec;
d630 1
a630 1
				sc->sc_ureq_received = mono_time.tv_sec;
d670 1
a670 1
			if (mono_time.tv_sec - ntohl(bus->endtime) >=
d810 1
a810 1
			sc->sc_ureq_sent = mono_time.tv_sec;
d991 1
a991 1
	secs = time.tv_sec;
d993 1
a993 1
	st->pfsync_time = mono_time.tv_sec;
d1211 1
a1211 1
		bus->endtime = htonl(mono_time.tv_sec - sc->sc_ureq_received);
d1245 1
a1245 1
			state->pfsync_time = mono_time.tv_sec;
@


1.33
log
@fix uninitialized var; found by millert@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.32 2004/04/30 22:08:18 mcbride Exp $	*/
d770 4
@


1.32
log
@Unbreak building pfsync without carp. Found by marc@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.32 2004/04/30 21:51:10 mcbride Exp $	*/
d1120 1
a1120 1
	int ret;
d1272 1
a1272 1
		} else 
@


1.31
log
@Make carp(4) aware of its physical interface:
- If the physical interface goes down or the link goes down,
  the carp interface goes down as well.
- We treat this like the preemption holdoff with pfsync.
  So if one of the carp interfaces is known to be bad (because the
  physical interface it's associated with is bad), all the other carp
  interfaces back off: they won't preempt, and their advskew goes to 240.

ok cedric@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.30 2004/04/28 00:20:47 pb Exp $	*/
d678 1
d681 1
d809 1
d812 1
d1279 1
d1282 1
@


1.30
log
@point out that pfsync_send_bus and pfsync_sendout must be called in splnet()

ok mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.29 2004/04/25 18:09:30 pb Exp $	*/
d63 5
a81 1
int			pfsync_sync_ok;
d100 1
d678 2
d807 2
d1275 2
@


1.29
log
@get rid of a complete state tree walk at state expire while in splnet()

ok mcbride@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.28 2004/04/25 17:52:37 pb Exp $	*/
d1180 1
d1274 1
@


1.28
log
@dont splx across functions

pointed at by Joris Vink who was baffeled how this should work anyway

ok mcbride@@ henning@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.27 2004/04/05 00:21:39 mcbride Exp $	*/
d329 1
a329 1
				if (st->creatorid == creatorid)
d331 2
a334 1
		pf_purge_expired_states();
a478 5
			/*
			 * XXX
			 * pf_purge_expired_states() is expensive,
			 * we really want to purge the state directly.
			 */
d481 1
a482 1
		pf_purge_expired_states();
a599 5
			/*
			 * XXX
			 * pf_purge_expired_states() is expensive,
			 * we really want to purge the state directly.
			 */
d602 1
a603 1
		pf_purge_expired_states();
@


1.27
log
@Prevent stale states (states older than the local version) from overwriting
the local state.

Tricky state comparisons from frantzen@@ ok cedric@@ dhartmei@@

Post-ok addition of code to broadcast an update with the better local version
when this happens. Torture tested by beck@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.26 2004/03/28 18:14:20 mcbride Exp $	*/
d519 5
a523 1
				pfsync_request_update(up, &src);
d813 5
a817 1
			pfsync_request_update(NULL, NULL);
d1116 1
a1116 1
	int s, ret;
d1120 1
a1120 2
		    (void *)&sc->sc_statep.s)) == NULL) {
			splx(s);
a1121 1
		}
d1128 1
a1128 2
			    (void *)&sc->sc_statep.s)) == NULL) {
				splx(s);
a1129 1
			}
d1256 1
d1261 9
a1269 2
		pfsync_request_update(NULL, NULL);
		pfsync_sendout(sc);
@


1.26
log
@Check variables in incoming packets which can cause problems if they're set
to arbitrary values. Invalid state->timeout can hit a KASSERT in pf, the other
ones should be ok but we check them just to make sure.

ok dhartmei@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.25 2004/03/23 09:57:44 mcbride Exp $	*/
d45 2
d246 1
a246 1
	int iplen, action, error, i, s, count, offp;
d402 45
a450 1

d452 2
d524 48
d577 1
a577 1
		if (update_requested)
a622 1
		/* XXX send existing. pfsync_pack_state should handle this. */
@


1.25
log
@Hold off for 1 second before beginning bulk transfer. Avoids looping
until mono_time.tv_sec advances past the time the bulk transfer request
was recieved.

ok cedric@@ deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.24 2004/03/22 04:54:17 mcbride Exp $	*/
d346 13
d379 11
d453 12
@


1.24
log
@Support for best effort bulk transfers of states when pfsync syncif is
configured.  This this allows pfsync+carp clusters to come up gracefully
without killing active connections. pfsync now prevents carp from
preempting to become master until the state table has sync'd.

ABI change, any application which use struct pf_state must be recompiled.

Reminded about this by Christian Gut. Thanks to beck@@ cedric@@ and dhartmei@@
for testing and comments.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.23 2004/02/20 19:22:03 mcbride Exp $	*/
d506 1
a506 1
				pfsync_bulk_update(sc);
@


1.23
log
@Make pfsync deal with clearing states bound to a group or interface (eg
pfctl -i fxp0 -Fs). Also don't send out individual state deletions if we're
sending a clear message, move pfsync_clear_states() inside splnet, and fix
if_pfsync.h includes in  pf.c and pf_ioctl.c.

ok cedric@@ dhartmei@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.22 2004/02/10 09:21:54 mcbride Exp $	*/
d74 3
a76 2
struct pfsync_softc pfsyncif;
struct pfsyncstats pfsyncstats;
d88 1
a88 1
int	pfsync_sendout(struct pfsync_softc *sc);
d90 3
d96 2
d104 1
d112 2
d125 2
d241 1
d500 14
a513 4
			st = pf_find_state_byid(&key);
			if (st == NULL) {
				pfsyncstats.pfsyncs_badstate++;
				continue;
a514 1
			pfsync_pack_state(PFSYNC_ACT_UPD, st, 0);
d520 39
d671 9
a712 1
	extern int hz;
d740 4
d848 4
d999 2
a1000 1
	sc->sc_sendaddr = *src;
d1005 4
a1008 2
	bcopy(up->id, rup->id, sizeof(rup->id));
	rup->creatorid = up->creatorid;
d1025 1
a1025 1
	if (sc->sc_mbuf != NULL) {
a1026 1
	}
d1052 85
@


1.22
log
@Make pfsync work correctly with IP options on 64-bit alignment
sensitive CPUs. Pointed out by deraadt@@.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.21 2004/02/08 09:18:45 mcbride Exp $	*/
d81 1
a81 1
	       struct rtentry *);
d288 1
a294 2

		s = splsoftnet();
d298 20
a317 3
		RB_FOREACH(st, pf_state_tree_id, &tree_id) {
			if (st->creatorid == creatorid)
				st->timeout = PFTM_PURGE;
d321 1
d938 1
a938 1
pfsync_clear_states(u_int32_t creatorid)
d957 2
@


1.21
log
@Fix kernel panic which occurs under very high load:
- Make sure we calculate the correct maximum size for PFSYNC_ACT_UREQ.
- Make pfsync_sendout() return immediately if there is nothing to send.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.20 2004/02/07 05:26:21 mcbride Exp $	*/
d155 1
a155 2
		    "id: %016llx creatorid: %08x\n",
		    betoh64(sp->id), ntohl(sp->creatorid));
d204 1
a204 1
	st->id = sp->id;
d337 1
a337 1
			key.id = sp->id;
d369 1
a369 1
			key.id = sp->id;
d400 1
a400 1
			key.id = up->id;
d431 1
a431 1
			key.id = dp->id;
a461 1

d468 1
a468 1
			key.id = rup->id;
d744 2
a745 1
					if (usp->id == st->id &&
d768 1
a768 1
		sp->id = st->id;
d847 1
a847 1
				up->id = st->id;
d862 1
a862 1
			dp->id = st->id;
d911 1
a911 1
	rup->id = up->id;
@


1.20
log
@Use the offset provided to us by m_pulldown(), rather than using size of
ip and pfsync headers. This makes us behave correctly if the packet is
spread across multiple mbufs (which does not appear to happen in practice).
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.19 2004/01/22 09:25:25 mcbride Exp $	*/
d641 4
a652 4
	case PFSYNC_ACT_CLR:
		len = sizeof(struct pfsync_header) +
		    sizeof(struct pfsync_state_clr);
		break;
d654 2
a655 2
		len = sizeof(struct pfsync_header) +
		    sizeof(struct pfsync_state_upd_req);
d898 1
a898 1
			if ((sc->sc_mbuf = pfsync_get_mbuf(sc, PFSYNC_ACT_UPD,
d963 1
a963 1
	struct mbuf *m = sc->sc_mbuf;
d966 4
a976 1

@


1.19
log
@- Include the value of pf_state.timeout in pfsync messages
- Fix the expiry time calculations, for real
- Unbreak the collapsing of multiple updates into one
And a little KNF for good measure.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.18 2004/01/20 17:40:31 henning Exp $	*/
d297 1
a297 1
		cp = (void *)((char *)mp->m_data + iplen + PFSYNC_HDRLEN);
d316 2
a317 2
		for (i = 0, sp = (void *)((char *)mp->m_data +
		    iplen + PFSYNC_HDRLEN); i < count; i++, sp++) {
d336 2
a337 2
		for (i = 0, sp = (void *)((char *)mp->m_data +
		    iplen + PFSYNC_HDRLEN); i < count; i++, sp++) {
d368 2
a369 2
		for (i = 0, sp = (void *)((char *)mp->m_data +
		    iplen + PFSYNC_HDRLEN); i < count; i++, sp++) {
d399 2
a400 2
		for (i = 0, up = (void *)((char *)mp->m_data +
		    iplen + PFSYNC_HDRLEN); i < count; i++, up++) {
d430 2
a431 2
		for (i = 0, dp = (void *)((char *)mp->m_data +
		    iplen + PFSYNC_HDRLEN); i < count; i++, dp++) {
d467 3
a469 2
		for (i = 0, rup = (void *)((char *)mp->m_data +
		    iplen + PFSYNC_HDRLEN); i < count; i++, rup++) {
@


1.18
log
@the pfsync interface does not have a baudrate, so don't claim 100 MBit/s

ok mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.17 2004/01/20 03:36:19 mcbride Exp $	*/
a151 1
	u_long secs;
d195 2
a196 2
	secs = time.tv_sec;
	st->creation = ntohl(sp->creation) + secs;
d202 1
a208 4
	if (sp->expire)
		st->expire = ntohl(sp->expire) + secs;
	else
		st->expire = 0;
a233 1
	u_long secs;
d344 1
a344 1
				if (pfsync_insert_net_state(sp)) 
d350 2
a351 5
			secs = time.tv_sec;
			if (sp->expire)
				st->expire = 0;
			else
				st->expire = ntohl(sp->expire) + secs;
d414 2
a415 6
			secs = time.tv_sec;
			if (up->expire)
				st->expire = 0;
			else
				st->expire = ntohl(up->expire) + secs;

d464 1
a464 1
		/* XXX send existing. pfsync_pack_state should handle this. */ 
d641 2
a642 2
		len = (sc->sc_maxcount * sizeof(struct pfsync_state_upd))
		    + sizeof(struct pfsync_header);
d645 2
a646 2
		len = (sc->sc_maxcount * sizeof(struct pfsync_state_del))
		    + sizeof(struct pfsync_header);
d650 1
a650 1
		     sizeof(struct pfsync_state_clr);
d654 1
a654 1
		     sizeof(struct pfsync_state_upd_req);
d657 2
a658 2
		len = (sc->sc_maxcount * sizeof(struct pfsync_state))
		    + sizeof(struct pfsync_header);
d712 1
a712 1
	} 
d761 1
d796 1
d836 1
a836 1
			if (i < h->count) {
d850 1
@


1.17
log
@Ignore pfsync packets if pf is not running.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.16 2004/01/19 19:46:33 mcbride Exp $	*/
a113 1
	ifp->if_baudrate = IF_Mbps(100);
@


1.16
log
@Update comment; handling PFSYNC_ACT_UPD in pfsync_input() is no longer
optional.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.15 2004/01/19 07:24:07 mcbride Exp $	*/
d244 1
a244 1
	if (!sc->sc_sync_ifp)
@


1.15
log
@Clean up creation and expiry timestamp calculations.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.14 2003/12/31 11:18:25 cedric Exp $	*/
a333 5

	/*
	 * It's not strictly necessary for us to support the "uncompressed"
	 * update and delete actions, but it's relatively simple for us to do.
	 */
d365 4
@


1.14
log
@Many improvements to the handling of interfaces in PF.

1) PF should do the right thing when unplugging/replugging or cloning/
destroying NICs.

2) Rules can be loaded in the kernel for not-yet-existing devices
(USB, PCMCIA, Cardbus). For example, it is valid to write:
"pass in on kue0" before kue USB is plugged in.

3) It is possible to write rules that apply to group of interfaces
(drivers), like "pass in on ppp all"

4) There is a new ":peer" modifier that completes the ":broadcast"
and ":network" modifiers.

5) There is a new ":0" modifier that will filter out interface aliases.
Can also be applied to DNS names to restore original PF behaviour.

6) The dynamic interface syntax (foo) has been vastly improved, and
now support multiple addresses, v4 and v6 addresses, and all userland
modifiers, like "pass in from (fxp0:network)"

7) Scrub rules now support the !if syntax.

8) States can be bound to the specific interface that created them or
to  a group of interfaces for example:

- pass all keep state (if-bound)
- pass all keep state (group-bound)
- pass all keep state (floating)

9) The default value when only keep state is given can be selected by
using the "set state-policy" statement.

10) "pfctl -ss" will now print the interface scope of the state.

This diff change the pf_state structure slighltly, so you should
recompile your userland tools (pfctl, authpf, pflogd, tcpdump...)

Tested on i386, sparc, sparc64 by Ryan
Tested on macppc, sparc64 by Daniel

ok deraadt@@ mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.12 2003/12/18 16:07:38 dhartmei Exp $	*/
d198 1
a198 1
	st->creation = secs + ntohl(sp->creation);
a209 1
	secs = time.tv_sec;
d211 2
a213 2
	else
		st->expire = ntohl(sp->expire) + secs;
@


1.13
log
@Add a new PFSYNC_ACT_UREQ message type.

A pfsync system which recieves a partial update for a state it cannot
find can now request a full version of the update, and insert it.
pfsync'd firewalls now converge more gracefully if one is missing some
states (due to reset, lost insert packets, etc).
@
text
@d152 1
d162 9
d179 2
a180 1
	if (st == NULL)
d182 1
d216 2
a217 1
	if (pf_insert_state(st)) {
d307 1
a307 1
		RB_FOREACH(st, pf_state_tree_ext_gwy, &tree_ext_gwy) {
d353 1
a353 1
			st = pf_find_state(&key, PF_ID);
d384 1
a384 1
			st = pf_find_state(&key, PF_ID);
d415 1
a415 1
			st = pf_find_state(&key, PF_ID);
d450 1
a450 1
			st = pf_find_state(&key, PF_ID);
d487 1
a487 1
			st = pf_find_state(&key, PF_ID);
a700 1

d785 1
@


1.12
log
@resolve compiler warnings, from Pyun YongHyeon, ok cedric@@, mcbride@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.11 2003/12/16 08:17:56 mcbride Exp $	*/
d86 1
d104 1
d223 2
d278 3
d342 3
a344 2
				/* try to do an insert? */
				pfsyncstats.pfsyncs_badstate++;
d387 3
a389 1
	case PFSYNC_ACT_UPD_C:
d404 3
a406 1
				/* send out a request for a full state? */
d419 2
d423 1
d457 28
d654 4
d688 1
d690 1
a690 1
pfsync_pack_state(u_int8_t action, struct pf_state *st)
d751 1
d799 1
a799 2
	} else
		sp->updates++;
d810 1
a810 1
	if (sc->sc_sync_ifp) {
d875 44
a989 1
		m->m_flags |= M_MCAST;
d1007 5
a1011 1
		ip->ip_dst.s_addr = INADDR_PFSYNC_GROUP;
d1017 1
a1017 1
	} else {
a1018 1
	}
@


1.11
log
@Don't do all the heavy pfsync processing if there are no bpf listeners
and no network synchronization is happening.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.10 2003/12/15 21:49:38 deraadt Exp $	*/
d257 1
a257 1
	ph = (void *)ip + iplen;
@


1.10
log
@sc_sp is a #define on some architectures, use a different name
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.9 2003/12/15 07:28:25 mcbride Exp $	*/
d511 8
d654 14
@


1.9
log
@Fix whitespace screwups before henning wakes up.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.8 2003/12/15 07:11:30 mcbride Exp $	*/
d100 2
a101 2
	pfsyncif.sc_sp.s = NULL;
	pfsyncif.sc_sp_net.s = NULL;
d653 1
a653 1
		    (void *)&sc->sc_sp.s)) == NULL) {
d663 1
a663 1
			    (void *)&sc->sc_sp.s)) == NULL) {
d693 1
a693 1
		sp = sc->sc_sp.s++;
d757 1
a757 1
			    (void *)&sc->sc_sp_net.s)) == NULL) {
d774 1
a774 1
				up = sc->sc_sp_net.u++;
d787 1
a787 1
			dp = sc->sc_sp_net.d++;
d818 1
a818 1
	    (void *)&sc->sc_sp.c)) == NULL) {
d823 1
a823 1
	cp = sc->sc_sp.c;
d851 1
a851 1
	sc->sc_sp.s = NULL;
d863 1
a863 1
		sc->sc_sp_net.s = NULL;
@


1.8
log
@Add initial support for pf state synchronization over the network.
Implemented as an in-kernel multicast IP protocol.

Turn it on like this:

# ifconfig pfsync0 up syncif fxp0

There is not yet any authentication on this protocol, so the syncif
must be on a trusted network. ie, a crossover cable between the two
firewalls.

NOTABLE CHANGES:
- A new index based on a unique (creatorid, stateid) tuple has been
  added to the state tree.
- Updates now appear on the pfsync(4) interface; multiple updates may
  be compressed into a single update.
- Applications which use bpf on pfsync(4) will need modification;
  packets on pfsync no longer contains regular pf_state structs,
  but pfsync_state structs which contain no pointers.

Much more to come.

ok deraadt@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.7 2003/11/08 19:51:38 dhartmei Exp $	*/
d283 2
a284 2
		s = splsoftnet();	
		cp = (void *)((char *)mp->m_data + iplen + PFSYNC_HDRLEN); 
d287 1
a287 1
                RB_FOREACH(st, pf_state_tree_ext_gwy, &tree_ext_gwy) {
d289 1
a289 1
                        	st->timeout = PFTM_PURGE;
d291 2
a292 2
                pf_purge_expired_states();
                splx(s);
d302 1
a302 1
		s = splsoftnet();	
d308 1
a308 1
                       			goto done;
d326 2
a327 2
		
		s = splsoftnet();	
d356 2
a357 2
		
		s = splsoftnet();	
d369 1
a369 1
			 * XXX 
d385 2
a386 2
		
		s = splsoftnet();	
d415 2
a416 2
		
		s = splsoftnet();	
d428 1
a428 1
			 * XXX 
d443 1
a443 1
	
d485 1
a485 1
		if (ifr->ifr_mtu < ifp->if_mtu) 
d492 1
a492 1
		if (sc->sc_sync_ifp) 
d496 1
a496 1
                if ((error = copyout(&pfsyncr, ifr->ifr_data, sizeof(pfsyncr))))
d508 1
a508 1
                
d520 1
a520 1
		    (sc->sc_sync_ifp != NULL && 
d525 1
a525 1
		
d527 1
a527 1
		
d548 1
a548 1
		
d566 1
a566 1
		mtu = mtu_req; 
d617 1
a617 1
	} else 
d694 1
a694 1
		sc->sc_mbuf->m_pkthdr.len = 
d753 1
a753 1
		
d763 1
a763 1
		
@


1.7
log
@Return proper anchor rule number in correct byte order.
From Pyun YongHyeon. ok henning@@, canacar@@
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.6 2003/06/21 09:07:01 djm Exp $	*/
d33 1
d48 1
d50 2
d75 1
d78 2
a79 1
void	pfsync_setmtu(struct pfsync_softc *sc, int);
d85 1
a85 1
struct mbuf *pfsync_get_mbuf(struct pfsync_softc *sc, u_int8_t action);
d87 1
a87 1
void	pfsync_timeout(void *v);
d90 1
d97 1
d99 4
a102 2
	pfsyncif.sc_ptr = NULL;
	pfsyncif.sc_count = 8;
d146 304
d461 1
d464 4
a467 1
	int s;
d485 1
a485 1
		if (ifr->ifr_mtu < ifp->if_mtu)
d490 61
d559 2
a560 2
pfsync_setmtu(sc, mtu)
	struct pfsync_softc *sc;
d562 10
a571 3
{
	sc->sc_count = (mtu - sizeof(struct pfsync_header)) /
	    sizeof(struct pf_state);
d573 1
a573 1
	    sc->sc_count * sizeof(struct pf_state);
d577 1
a577 3
pfsync_get_mbuf(sc, action)
	struct pfsync_softc *sc;
	u_int8_t action;
d590 19
a608 1
	len = sc->sc_if.if_mtu;
d616 4
a619 1
	}
d621 1
a621 2
	m->m_pkthdr.len = m->m_len = len;

d628 1
a628 2
	sc->sc_mbuf = m;
	sc->sc_ptr = (struct pf_state *)((char *)h + PFSYNC_HDRLEN);
a629 1

d634 1
a634 3
pfsync_pack_state(action, st)
	u_int8_t action;
	struct pf_state *st;
a635 1
	extern struct timeval time;
d638 4
a641 2
	struct pfsync_header *h;
	struct pf_state *sp;
a642 1
	struct mbuf *m;
d644 2
a645 1
	int s, ret;
d651 3
a653 3
	m = sc->sc_mbuf;
	if (m == NULL) {
		if ((m = pfsync_get_mbuf(sc, action)) == NULL) {
d657 1
a657 1
		h = mtod(m, struct pfsync_header *);
d659 1
a659 1
		h = mtod(m, struct pfsync_header *);
d662 2
a663 1
			if ((m = pfsync_get_mbuf(sc, action)) == NULL) {
d667 19
a685 1
			h = mtod(m, struct pfsync_header *);
d689 1
a689 3
	sp = sc->sc_ptr++;
	h->count++;
	bzero(sp, sizeof(*sp));
d691 39
a729 3
	bcopy(&st->lan, &sp->lan, sizeof(sp->lan));
	bcopy(&st->gwy, &sp->gwy, sizeof(sp->gwy));
	bcopy(&st->ext, &sp->ext, sizeof(sp->ext));
a733 3
	bcopy(&st->rt_addr, &sp->rt_addr, sizeof(sp->rt_addr));
	secs = time.tv_sec;
	sp->creation = htonl(secs - st->creation);
a737 17
	sp->packets[0] = htonl(st->packets[0]);
	sp->packets[1] = htonl(st->packets[1]);
	sp->bytes[0] = htonl(st->bytes[0]);
	sp->bytes[1] = htonl(st->bytes[1]);
	if ((r = st->rule.ptr) == NULL)
		sp->rule.nr = htonl(-1);
	else
		sp->rule.nr = htonl(r->nr);
	if ((r = st->anchor.ptr) == NULL)
		sp->anchor.nr = htonl(-1);
	else
		sp->anchor.nr = htonl(r->nr);
	sp->af = st->af;
	sp->proto = st->proto;
	sp->direction = st->direction;
	sp->log = st->log;
	sp->allow_opts = st->allow_opts;
d739 60
a798 2
	ret = 0;
	if (h->count == sc->sc_count)
d802 1
a802 1
	return (0);
d806 1
a806 2
pfsync_clear_state(st)
	struct pf_state *st;
d810 1
a810 1
	struct mbuf *m = sc->sc_mbuf;
d814 5
a818 1
	if (m == NULL && (m = pfsync_get_mbuf(sc, PFSYNC_ACT_CLR)) == NULL) {
d822 3
d851 1
a851 1
	sc->sc_ptr = NULL;
d858 45
a902 1
	m_freem(m);
@


1.6
log
@count packets and bidirectionally on state entries, allowing for fine-grained
traffic reporting w/ pfsync; ok dhartmei@@

Note: ABI change (new fields in struct pf_state), requires a rebuild of
pfctl and tcpdump.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.5 2003/05/03 21:15:11 deraadt Exp $	*/
d241 1
a241 1
	struct pf_rule *r = st->rule.ptr;
d291 1
a291 1
	if (r == NULL)
d295 4
@


1.5
log
@string fixes; tedu ok
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.4 2002/12/23 18:53:59 mickey Exp $	*/
d287 4
a290 2
	sp->packets = htonl(st->packets);
	sp->bytes = htonl(st->bytes);
@


1.4
log
@no need to htons the port, it's already in net order, since we swapped it back in tcpdump, worked fine (; from bdd@@ieee.org
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.3 2002/12/20 22:13:27 mickey Exp $	*/
d94 1
a94 1
	strcpy(ifp->if_xname, "pfsync0");
@


1.4.4.1
log
@Sync the SMP branch to -current. This includes moving to ELF.
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.4 2002/12/23 18:53:59 mickey Exp $	*/
d94 1
a94 1
	strlcpy(ifp->if_xname, "pfsync0", sizeof ifp->if_xname);
@


1.4.4.2
log
@Merge of current from two weeks agointo the SMP branch
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
a32 1
#include <sys/proc.h>
a46 1
#include <netinet/in_systm.h>
a47 2
#include <netinet/ip.h>
#include <netinet/ip_var.h>
a70 1
struct pfsyncstats pfsyncstats;
d73 1
a73 2
void	pfsync_setmtu(struct pfsync_softc *, int);
int	pfsync_insert_net_state(struct pfsync_state *);
d79 1
a79 2
struct mbuf *pfsync_get_mbuf(struct pfsync_softc *, u_int8_t, void **);
int	pfsync_request_update(struct pfsync_state_upd *, struct in_addr *);
d81 1
a81 1
void	pfsync_timeout(void *);
a83 1
extern struct timeval time;
a89 1
	bzero(&pfsyncif, sizeof(pfsyncif));
d91 2
a92 5
	pfsyncif.sc_mbuf_net = NULL;
	pfsyncif.sc_statep.s = NULL;
	pfsyncif.sc_statep_net.s = NULL;
	pfsyncif.sc_maxupdates = 128;
	pfsyncif.sc_sendaddr.s_addr = INADDR_PFSYNC_GROUP;
d102 1
a135 344
pfsync_insert_net_state(struct pfsync_state *sp)
{
	struct pf_state	*st = NULL;
	struct pf_rule *r = NULL;
	struct pfi_kif	*kif;

	if (sp->creatorid == 0 && pf_status.debug >= PF_DEBUG_MISC) {
		printf("pfsync_insert_net_state: invalid creator id:"
		    "id: %016llx creatorid: %08x\n",
		    betoh64(sp->id), ntohl(sp->creatorid));
		return (EINVAL);
	}

	kif = pfi_lookup_create(sp->ifname);
	if (kif == NULL) {
		if (pf_status.debug >= PF_DEBUG_MISC)
			printf("pfsync_insert_net_state: "
			    "unknown interface: %s\n", sp->ifname);
		/* skip this state */
		return (0);
	}

	/*
	 * Just use the default rule until we have infrastructure to find the
	 * best matching rule.
	 */
	r = &pf_default_rule;

	if (!r->max_states || r->states < r->max_states)
		st = pool_get(&pf_state_pl, PR_NOWAIT);
	if (st == NULL) {
		pfi_maybe_destroy(kif);
		return (ENOMEM);
	}
	bzero(st, sizeof(*st));

	st->rule.ptr = r;
	/* XXX get pointers to nat_rule and anchor */

	/* fill in the rest of the state entry */
	pf_state_host_ntoh(&sp->lan, &st->lan);
	pf_state_host_ntoh(&sp->gwy, &st->gwy);
	pf_state_host_ntoh(&sp->ext, &st->ext);

	pf_state_peer_ntoh(&sp->src, &st->src);
	pf_state_peer_ntoh(&sp->dst, &st->dst);

	bcopy(&sp->rt_addr, &st->rt_addr, sizeof(st->rt_addr));
	st->creation = ntohl(sp->creation) + time.tv_sec;
	st->expire = ntohl(sp->expire) + time.tv_sec;

	st->af = sp->af;
	st->proto = sp->proto;
	st->direction = sp->direction;
	st->log = sp->log;
	st->timeout = sp->timeout;
	st->allow_opts = sp->allow_opts;

	st->id = sp->id;
	st->creatorid = sp->creatorid;
	st->sync_flags = sp->sync_flags | PFSTATE_FROMSYNC;


	if (pf_insert_state(kif, st)) {
		pfi_maybe_destroy(kif);
		pool_put(&pf_state_pl, st);
		return (EINVAL);
	}

	return (0);
}

void
pfsync_input(struct mbuf *m, ...)
{
	struct ip *ip = mtod(m, struct ip *);
	struct pfsync_header *ph;
	struct pfsync_softc *sc = &pfsyncif;
	struct pf_state *st, key;
	struct pfsync_state *sp;
	struct pfsync_state_upd *up;
	struct pfsync_state_del *dp;
	struct pfsync_state_clr *cp;
	struct pfsync_state_upd_req *rup;
	struct in_addr src;
	struct mbuf *mp;
	int iplen, action, error, i, s, count, offp;

	pfsyncstats.pfsyncs_ipackets++;

	/* verify that we have a sync interface configured */
	if (!sc->sc_sync_ifp || !pf_status.running)
		goto done;

	/* verify that the packet came in on the right interface */
	if (sc->sc_sync_ifp != m->m_pkthdr.rcvif) {
		pfsyncstats.pfsyncs_badif++;
		goto done;
	}

	/* verify that the IP TTL is 255.  */
	if (ip->ip_ttl != PFSYNC_DFLTTL) {
		pfsyncstats.pfsyncs_badttl++;
		goto done;
	}

	iplen = ip->ip_hl << 2;

	if (m->m_pkthdr.len < iplen + sizeof(*ph)) {
		pfsyncstats.pfsyncs_hdrops++;
		goto done;
	}

	if (iplen + sizeof(*ph) > m->m_len) {
		if ((m = m_pullup(m, iplen + sizeof(*ph))) == NULL) {
			pfsyncstats.pfsyncs_hdrops++;
			goto done;
		}
		ip = mtod(m, struct ip *);
	}
	ph = (struct pfsync_header *)((char *)ip + iplen);

	/* verify the version */
	if (ph->version != PFSYNC_VERSION) {
		pfsyncstats.pfsyncs_badver++;
		goto done;
	}

	action = ph->action;
	count = ph->count;

	/* make sure it's a valid action code */
	if (action >= PFSYNC_ACT_MAX) {
		pfsyncstats.pfsyncs_badact++;
		goto done;
	}

	/* Cheaper to grab this now than having to mess with mbufs later */
	src = ip->ip_src;

	switch (action) {
	case PFSYNC_ACT_CLR: {
		u_int32_t creatorid;
		if ((mp = m_pulldown(m, iplen + sizeof(*ph),
		    sizeof(*cp), &offp)) == NULL) {
			pfsyncstats.pfsyncs_badlen++;
			return;
		}

		s = splsoftnet();
		cp = (void *)((char *)mp->m_data + iplen + PFSYNC_HDRLEN);
		creatorid = cp->creatorid;

		RB_FOREACH(st, pf_state_tree_id, &tree_id) {
			if (st->creatorid == creatorid)
				st->timeout = PFTM_PURGE;
		}
		pf_purge_expired_states();
		splx(s);
		break;
	}
	case PFSYNC_ACT_INS:
		if ((mp = m_pulldown(m, iplen + sizeof(*ph),
		    count * sizeof(*sp), &offp)) == NULL) {
			pfsyncstats.pfsyncs_badlen++;
			return;
		}

		s = splsoftnet();
		for (i = 0, sp = (void *)((char *)mp->m_data +
		    iplen + PFSYNC_HDRLEN); i < count; i++, sp++) {
			if ((error = pfsync_insert_net_state(sp))) {
				if (error == ENOMEM) {
					splx(s);
					goto done;
				}
				continue;
			}
		}
		splx(s);
		break;
	case PFSYNC_ACT_UPD:
		if ((mp = m_pulldown(m, iplen + sizeof(*ph),
		    count * sizeof(*sp), &offp)) == NULL) {
			pfsyncstats.pfsyncs_badlen++;
			return;
		}

		s = splsoftnet();
		for (i = 0, sp = (void *)((char *)mp->m_data +
		    iplen + PFSYNC_HDRLEN); i < count; i++, sp++) {
			key.id = sp->id;
			key.creatorid = sp->creatorid;

			st = pf_find_state_byid(&key);
			if (st == NULL) {
				/* insert the update */
				if (pfsync_insert_net_state(sp))
					pfsyncstats.pfsyncs_badstate++;
				continue;
			}
			pf_state_peer_ntoh(&sp->src, &st->src);
			pf_state_peer_ntoh(&sp->dst, &st->dst);
			st->expire = ntohl(sp->expire) + time.tv_sec;
			st->timeout = sp->timeout;

		}
		splx(s);
		break;
	/*
	 * It's not strictly necessary for us to support the "uncompressed"
	 * delete action, but it's relatively simple and maintains consistency.
	 */
	case PFSYNC_ACT_DEL:
		if ((mp = m_pulldown(m, iplen + sizeof(*ph),
		    count * sizeof(*sp), &offp)) == NULL) {
			pfsyncstats.pfsyncs_badlen++;
			return;
		}

		s = splsoftnet();
		for (i = 0, sp = (void *)((char *)mp->m_data +
		    iplen + PFSYNC_HDRLEN); i < count; i++, sp++) {
			key.id = sp->id;
			key.creatorid = sp->creatorid;

			st = pf_find_state_byid(&key);
			if (st == NULL) {
				pfsyncstats.pfsyncs_badstate++;
				continue;
			}
			/*
			 * XXX
			 * pf_purge_expired_states() is expensive,
			 * we really want to purge the state directly.
			 */
			st->timeout = PFTM_PURGE;
			st->sync_flags |= PFSTATE_FROMSYNC;
		}
		pf_purge_expired_states();
		splx(s);
		break;
	case PFSYNC_ACT_UPD_C: {
		int update_requested = 0;

		if ((mp = m_pulldown(m, iplen + sizeof(*ph),
		    count * sizeof(*up), &offp)) == NULL) {
			pfsyncstats.pfsyncs_badlen++;
			return;
		}

		s = splsoftnet();
		for (i = 0, up = (void *)((char *)mp->m_data +
		    iplen + PFSYNC_HDRLEN); i < count; i++, up++) {
			key.id = up->id;
			key.creatorid = up->creatorid;

			st = pf_find_state_byid(&key);
			if (st == NULL) {
				/* We don't have this state. Ask for it. */
				pfsync_request_update(up, &src);
				update_requested = 1;
				pfsyncstats.pfsyncs_badstate++;
				continue;
			}
			pf_state_peer_ntoh(&up->src, &st->src);
			pf_state_peer_ntoh(&up->dst, &st->dst);
			st->expire = ntohl(up->expire) + time.tv_sec;
			st->timeout = up->timeout;
		}
		if (update_requested)
			pfsync_sendout(sc);
		splx(s);
		break;
	}
	case PFSYNC_ACT_DEL_C:
		if ((mp = m_pulldown(m, iplen + sizeof(*ph),
		    count * sizeof(*dp), &offp)) == NULL) {
			pfsyncstats.pfsyncs_badlen++;
			return;
		}

		s = splsoftnet();
		for (i = 0, dp = (void *)((char *)mp->m_data +
		    iplen + PFSYNC_HDRLEN); i < count; i++, dp++) {
			key.id = dp->id;
			key.creatorid = dp->creatorid;

			st = pf_find_state_byid(&key);
			if (st == NULL) {
				pfsyncstats.pfsyncs_badstate++;
				continue;
			}
			/*
			 * XXX
			 * pf_purge_expired_states() is expensive,
			 * we really want to purge the state directly.
			 */
			st->timeout = PFTM_PURGE;
			st->sync_flags |= PFSTATE_FROMSYNC;
		}
		pf_purge_expired_states();
		splx(s);
		break;
	case PFSYNC_ACT_INS_F:
	case PFSYNC_ACT_DEL_F:
		/* not implemented */
		break;
	case PFSYNC_ACT_UREQ:
		if ((mp = m_pulldown(m, iplen + sizeof(*ph),
		    count * sizeof(*rup), &offp)) == NULL) {
			pfsyncstats.pfsyncs_badlen++;
			return;
		}

		s = splsoftnet();

		/* XXX send existing. pfsync_pack_state should handle this. */
		if (sc->sc_mbuf != NULL)
			pfsync_sendout(sc);
		for (i = 0, rup = (void *)((char *)mp->m_data +
		    iplen + PFSYNC_HDRLEN); i < count; i++, rup++) {
			key.id = rup->id;
			key.creatorid = rup->creatorid;

			st = pf_find_state_byid(&key);
			if (st == NULL) {
				pfsyncstats.pfsyncs_badstate++;
				continue;
			}
			pfsync_pack_state(PFSYNC_ACT_UPD, st, 0);
		}
		if (sc->sc_mbuf != NULL)
			pfsync_sendout(sc);
		splx(s);
		break;
	}

done:
	if (m)
		m_freem(m);
}

int
a146 1
	struct proc *p = curproc;
d149 1
a149 4
	struct ip_moptions *imo = &sc->sc_imo;
	struct pfsyncreq pfsyncr;
	struct ifnet    *sifp;
	int s, error;
a171 69
	case SIOCGETPFSYNC:
		bzero(&pfsyncr, sizeof(pfsyncr));
		if (sc->sc_sync_ifp)
			strlcpy(pfsyncr.pfsyncr_syncif,
			    sc->sc_sync_ifp->if_xname, IFNAMSIZ);
		pfsyncr.pfsyncr_maxupdates = sc->sc_maxupdates;
		if ((error = copyout(&pfsyncr, ifr->ifr_data, sizeof(pfsyncr))))
			return (error);
		break;
	case SIOCSETPFSYNC:
		if ((error = suser(p, p->p_acflag)) != 0)
			return (error);
		if ((error = copyin(ifr->ifr_data, &pfsyncr, sizeof(pfsyncr))))
			return (error);

		if (pfsyncr.pfsyncr_maxupdates > 255)
			return (EINVAL);
		sc->sc_maxupdates = pfsyncr.pfsyncr_maxupdates;

		if (pfsyncr.pfsyncr_syncif[0] == 0) {
			sc->sc_sync_ifp = NULL;
			if (sc->sc_mbuf_net != NULL) {
				/* Don't keep stale pfsync packets around. */
				s = splnet();
				m_freem(sc->sc_mbuf_net);
				sc->sc_mbuf_net = NULL;
				sc->sc_statep_net.s = NULL;
				splx(s);
			}
			break;
		}
		if ((sifp = ifunit(pfsyncr.pfsyncr_syncif)) == NULL)
			return (EINVAL);
		else if (sifp == sc->sc_sync_ifp)
			break;

		s = splnet();
		if (sifp->if_mtu < sc->sc_if.if_mtu ||
		    (sc->sc_sync_ifp != NULL &&
		    sifp->if_mtu < sc->sc_sync_ifp->if_mtu) ||
		    sifp->if_mtu < MCLBYTES - sizeof(struct ip))
			pfsync_sendout(sc);
		sc->sc_sync_ifp = sifp;

		pfsync_setmtu(sc, sc->sc_if.if_mtu);

		if (imo->imo_num_memberships > 0) {
			in_delmulti(imo->imo_membership[--imo->imo_num_memberships]);
			imo->imo_multicast_ifp = NULL;
		}

		if (sc->sc_sync_ifp) {
			struct in_addr addr;

			addr.s_addr = INADDR_PFSYNC_GROUP;
			if ((imo->imo_membership[0] =
			    in_addmulti(&addr, sc->sc_sync_ifp)) == NULL) {
				splx(s);
				return (ENOBUFS);
			}
			imo->imo_num_memberships++;
			imo->imo_multicast_ifp = sc->sc_sync_ifp;
			imo->imo_multicast_ttl = PFSYNC_DFLTTL;
			imo->imo_multicast_loop = 0;
		}
		splx(s);

		break;

d180 3
a182 1
pfsync_setmtu(struct pfsync_softc *sc, int mtu_req)
d184 2
a185 11
	int mtu;

	if (sc->sc_sync_ifp && sc->sc_sync_ifp->if_mtu < mtu_req)
		mtu = sc->sc_sync_ifp->if_mtu;
	else
		mtu = mtu_req;

	sc->sc_maxcount = (mtu - sizeof(struct pfsync_header)) /
	    sizeof(struct pfsync_state);
	if (sc->sc_maxcount > 254)
	    sc->sc_maxcount = 254;
d187 1
a187 1
	    sc->sc_maxcount * sizeof(struct pfsync_state);
d191 3
a193 1
pfsync_get_mbuf(struct pfsync_softc *sc, u_int8_t action, void **sp)
d206 1
a206 23
	switch (action) {
	case PFSYNC_ACT_UPD_C:
		len = (sc->sc_maxcount * sizeof(struct pfsync_state_upd)) +
		    sizeof(struct pfsync_header);
		break;
	case PFSYNC_ACT_DEL_C:
		len = (sc->sc_maxcount * sizeof(struct pfsync_state_del)) +
		    sizeof(struct pfsync_header);
		break;
	case PFSYNC_ACT_CLR:
		len = sizeof(struct pfsync_header) +
		    sizeof(struct pfsync_state_clr);
		break;
	case PFSYNC_ACT_UREQ:
		len = sizeof(struct pfsync_header) +
		    sizeof(struct pfsync_state_upd_req);
		break;
	default:
		len = (sc->sc_maxcount * sizeof(struct pfsync_state)) +
		    sizeof(struct pfsync_header);
		break;
	}

d214 3
a216 3
		m->m_data += (MCLBYTES - len) &~ (sizeof(long) - 1);
	} else
		MH_ALIGN(m, len);
a217 2
	m->m_pkthdr.rcvif = NULL;
	m->m_pkthdr.len = m->m_len = sizeof(struct pfsync_header);
d224 2
a225 1
	*sp = (void *)((char *)h + PFSYNC_HDRLEN);
d227 1
d232 3
a234 1
pfsync_pack_state(u_int8_t action, struct pf_state *st, int compress)
d236 1
d239 4
a242 5
	struct pfsync_header *h, *h_net;
	struct pfsync_state *sp = NULL;
	struct pfsync_state_upd *up = NULL;
	struct pfsync_state_del *dp = NULL;
	struct pf_rule *r;
d244 1
a244 16
	int s, ret = 0;
	u_int8_t i = 255, newaction = 0;

	/*
	 * If a packet falls in the forest and there's nobody around to
	 * hear, does it make a sound?
	 */
	if (ifp->if_bpf == NULL && sc->sc_sync_ifp == NULL) {
		/* Don't leave any stale pfsync packets hanging around. */
		if (sc->sc_mbuf != NULL) {
			m_freem(sc->sc_mbuf);
			sc->sc_mbuf = NULL;
			sc->sc_statep.s = NULL;
		}
		return (0);
	}
d250 3
a252 3
	if (sc->sc_mbuf == NULL) {
		if ((sc->sc_mbuf = pfsync_get_mbuf(sc, action,
		    (void *)&sc->sc_statep.s)) == NULL) {
d256 1
a256 1
		h = mtod(sc->sc_mbuf, struct pfsync_header *);
d258 1
a258 1
		h = mtod(sc->sc_mbuf, struct pfsync_header *);
d261 1
a261 2
			if ((sc->sc_mbuf = pfsync_get_mbuf(sc, action,
			    (void *)&sc->sc_statep.s)) == NULL) {
d265 1
a265 20
			h = mtod(sc->sc_mbuf, struct pfsync_header *);
		} else {
			/*
			 * If it's an update, look in the packet to see if
			 * we already have an update for the state.
			 */
			if (action == PFSYNC_ACT_UPD && sc->sc_maxupdates) {
				struct pfsync_state *usp =
				    (void *)((char *)h + PFSYNC_HDRLEN);

				for (i = 0; i < h->count; i++) {
					if (usp->id == st->id &&
					    usp->creatorid == st->creatorid) {
						sp = usp;
						sp->updates++;
						break;
					}
					usp++;
				}
			}
d269 3
a271 40
	secs = time.tv_sec;

	if (sp == NULL) {
		/* not a "duplicate" update */
		i = 255;
		sp = sc->sc_statep.s++;
		sc->sc_mbuf->m_pkthdr.len =
		    sc->sc_mbuf->m_len += sizeof(struct pfsync_state);
		h->count++;
		bzero(sp, sizeof(*sp));

		sp->id = st->id;
		sp->creatorid = st->creatorid;

		strlcpy(sp->ifname, st->u.s.kif->pfik_name, sizeof(sp->ifname));
		pf_state_host_hton(&st->lan, &sp->lan);
		pf_state_host_hton(&st->gwy, &sp->gwy);
		pf_state_host_hton(&st->ext, &sp->ext);

		bcopy(&st->rt_addr, &sp->rt_addr, sizeof(sp->rt_addr));

		sp->creation = htonl(secs - st->creation);
		sp->packets[0] = htonl(st->packets[0]);
		sp->packets[1] = htonl(st->packets[1]);
		sp->bytes[0] = htonl(st->bytes[0]);
		sp->bytes[1] = htonl(st->bytes[1]);
		if ((r = st->rule.ptr) == NULL)
			sp->rule = htonl(-1);
		else
			sp->rule = htonl(r->nr);
		if ((r = st->anchor.ptr) == NULL)
			sp->anchor = htonl(-1);
		else
			sp->anchor = htonl(r->nr);
		sp->af = st->af;
		sp->proto = st->proto;
		sp->direction = st->direction;
		sp->log = st->log;
		sp->allow_opts = st->allow_opts;
		sp->timeout = st->timeout;
d273 3
a275 2
		sp->sync_flags = st->sync_flags & PFSTATE_NOSYNC;
	}
d280 3
d287 11
d299 2
a300 61
	/* do we need to build "compressed" actions for network transfer? */
	if (sc->sc_sync_ifp && compress) {
		switch (action) {
		case PFSYNC_ACT_UPD:
			newaction = PFSYNC_ACT_UPD_C;
			break;
		case PFSYNC_ACT_DEL:
			newaction = PFSYNC_ACT_DEL_C;
			break;
		default:
			/* by default we just send the uncompressed states */
			break;
		}
	}

	if (newaction) {
		if (sc->sc_mbuf_net == NULL) {
			if ((sc->sc_mbuf_net = pfsync_get_mbuf(sc, newaction,
			    (void *)&sc->sc_statep_net.s)) == NULL) {
				splx(s);
				return (ENOMEM);
			}
		}
		h_net = mtod(sc->sc_mbuf_net, struct pfsync_header *);

		switch (newaction) {
		case PFSYNC_ACT_UPD_C:
			if (i != 255) {
				up = (void *)((char *)h_net +
				    PFSYNC_HDRLEN + (i * sizeof(*up)));
				up->updates++;
			} else {
				h_net->count++;
				sc->sc_mbuf_net->m_pkthdr.len =
				    sc->sc_mbuf_net->m_len += sizeof(*up);
				up = sc->sc_statep_net.u++;

				bzero(up, sizeof(*up));
				up->id = st->id;
				up->creatorid = st->creatorid;
			}
			up->timeout = st->timeout;
			up->expire = sp->expire;
			up->src = sp->src;
			up->dst = sp->dst;
			break;
		case PFSYNC_ACT_DEL_C:
			sc->sc_mbuf_net->m_pkthdr.len =
			    sc->sc_mbuf_net->m_len += sizeof(*dp);
			dp = sc->sc_statep_net.d++;
			h_net->count++;

			bzero(dp, sizeof(*dp));
			dp->id = st->id;
			dp->creatorid = st->creatorid;
			break;
		}
	}

	if (h->count == sc->sc_maxcount ||
	    (sc->sc_maxupdates && (sp->updates >= sc->sc_maxupdates)))
d304 1
a304 1
	return (ret);
a306 1
/* This must be called in splnet() */
d308 2
a309 1
pfsync_request_update(struct pfsync_state_upd *up, struct in_addr *src)
a311 1
	struct pfsync_header *h;
d313 1
a313 43
	struct pfsync_state_upd_req *rup;
	int s, ret;

	if (sc->sc_mbuf == NULL) {
		if ((sc->sc_mbuf = pfsync_get_mbuf(sc, PFSYNC_ACT_UREQ,
		    (void *)&sc->sc_statep.s)) == NULL) {
			splx(s);
			return (ENOMEM);
		}
		h = mtod(sc->sc_mbuf, struct pfsync_header *);
	} else {
		h = mtod(sc->sc_mbuf, struct pfsync_header *);
		if (h->action != PFSYNC_ACT_UREQ) {
			pfsync_sendout(sc);
			if ((sc->sc_mbuf = pfsync_get_mbuf(sc, PFSYNC_ACT_UPD,
			    (void *)&sc->sc_statep.s)) == NULL) {
				splx(s);
				return (ENOMEM);
			}
			h = mtod(sc->sc_mbuf, struct pfsync_header *);
		}
	}

	sc->sc_sendaddr = *src;
	sc->sc_mbuf->m_pkthdr.len = sc->sc_mbuf->m_len += sizeof(*rup);
	h->count++;
	rup = sc->sc_statep.r++;
	bzero(rup, sizeof(*rup));
	rup->id = up->id;
	rup->creatorid = up->creatorid;

	if (h->count == sc->sc_maxcount)
		ret = pfsync_sendout(sc);

	return (ret);
}

int
pfsync_clear_states(u_int32_t creatorid)
{
	struct ifnet *ifp = &pfsyncif.sc_if;
	struct pfsync_softc *sc = ifp->if_softc;
	struct pfsync_state_clr *cp;
d317 1
a317 5
	if (sc->sc_mbuf != NULL) {
		pfsync_sendout(sc);
	}
	if ((sc->sc_mbuf = pfsync_get_mbuf(sc, PFSYNC_ACT_CLR,
	    (void *)&sc->sc_statep.c)) == NULL) {
a320 3
	sc->sc_mbuf->m_pkthdr.len = sc->sc_mbuf->m_len += sizeof(*cp);
	cp = sc->sc_statep.c;
	cp->creatorid = creatorid;
d347 1
a347 1
	sc->sc_statep.s = NULL;
d354 1
a354 47

	if (sc->sc_mbuf_net) {
		m_freem(m);
		m = sc->sc_mbuf_net;
		sc->sc_mbuf_net = NULL;
		sc->sc_statep_net.s = NULL;
	}

	if (sc->sc_sync_ifp) {
		struct ip *ip;
		struct ifaddr *ifa;
		struct sockaddr sa;

		M_PREPEND(m, sizeof(struct ip), M_DONTWAIT);
		if (m == NULL) {
			pfsyncstats.pfsyncs_onomem++;
			return (0);
		}
		ip = mtod(m, struct ip *);
		ip->ip_v = IPVERSION;
		ip->ip_hl = sizeof(*ip) >> 2;
		ip->ip_tos = IPTOS_LOWDELAY;
		ip->ip_len = htons(m->m_pkthdr.len);
		ip->ip_id = htons(ip_randomid());
		ip->ip_off = htons(IP_DF);
		ip->ip_ttl = PFSYNC_DFLTTL;
		ip->ip_p = IPPROTO_PFSYNC;
		ip->ip_sum = 0;

		bzero(&sa, sizeof(sa));
		sa.sa_family = AF_INET;
		ifa = ifaof_ifpforaddr(&sa, sc->sc_sync_ifp);
		if (ifa == NULL)
			return (0);
		ip->ip_src.s_addr = ifatoia(ifa)->ia_addr.sin_addr.s_addr;

		if (sc->sc_sendaddr.s_addr == INADDR_PFSYNC_GROUP)
			m->m_flags |= M_MCAST;
		ip->ip_dst = sc->sc_sendaddr;
		sc->sc_sendaddr.s_addr = INADDR_PFSYNC_GROUP;

		pfsyncstats.pfsyncs_opackets++;

		if (ip_output(m, NULL, NULL, IP_RAWOUTPUT, &sc->sc_imo, NULL))
			pfsyncstats.pfsyncs_oerrors++;
	} else
		m_freem(m);
@


1.4.4.3
log
@Merge with the trunk
@
text
@a44 2
#include <netinet/tcp.h>
#include <netinet/tcp_seq.h>
a60 5
#include "carp.h"
#if NCARP > 0
extern int carp_suppress_preempt;
#endif

d74 2
a75 2
struct pfsync_softc	pfsyncif;
struct pfsyncstats	pfsyncstats;
d81 1
a81 1
	    struct rtentry *);
d87 1
a87 1
int	pfsync_sendout(struct pfsync_softc *);
a88 3
void	pfsync_send_bus(struct pfsync_softc *, u_int8_t);
void	pfsync_bulk_update(void *);
void	pfsync_bulkfail(void *);
a89 1
int	pfsync_sync_ok;
a91 2
extern struct timeval mono_time;
extern int hz;
a97 1
	pfsync_sync_ok = 1;
a104 2
	pfsyncif.sc_ureq_received = 0;
	pfsyncif.sc_ureq_sent = 0;
a115 2
	timeout_set(&pfsyncif.sc_bulk_tmo, pfsync_bulk_update, &pfsyncif);
	timeout_set(&pfsyncif.sc_bulkfail_tmo, pfsync_bulkfail, &pfsyncif);
d155 2
a156 1
		    " %08x\n", ntohl(sp->creatorid));
d205 1
a205 1
	bcopy(sp->id, &st->id, sizeof(st->id));
a230 1
	struct pfsync_state_bus *bus;
d233 1
a233 1
	int iplen, action, error, i, s, count, offp, sfail, stale = 0;
a288 1
		struct pfi_kif	*kif;
d295 3
a297 1
		cp = (struct pfsync_state_clr *)(mp->m_data + offp);
d300 3
a302 22
		s = splsoftnet();
		if (cp->ifname[0] == '\0') {
			RB_FOREACH(st, pf_state_tree_id, &tree_id) {
				if (st->creatorid == creatorid)
					st->timeout = PFTM_PURGE;
			}
		} else {
			kif = pfi_lookup_if(cp->ifname);
			if (kif == NULL) {
				if (pf_status.debug >= PF_DEBUG_MISC)
					printf("pfsync_input: PFSYNC_ACT_CLR "
					    "bad interface: %s\n", cp->ifname);
				splx(s);
				goto done;
			}
			RB_FOREACH(st, pf_state_tree_lan_ext,
			    &kif->pfik_lan_ext) {
				if (st->creatorid == creatorid) {
					st->timeout = PFTM_PURGE;
					pf_purge_expired_state(st);
				}
			}
d304 1
a305 1

d316 2
a317 15
		for (i = 0, sp = (struct pfsync_state *)(mp->m_data + offp);
		    i < count; i++, sp++) {
			/* check for invalid values */
			if (sp->timeout >= PFTM_MAX ||
			    sp->src.state > PF_TCPS_PROXY_DST ||
			    sp->dst.state > PF_TCPS_PROXY_DST ||
			    sp->direction > PF_OUT ||
			    (sp->af != AF_INET && sp->af != AF_INET6)) {
				if (pf_status.debug >= PF_DEBUG_MISC)
					printf("pfsync_insert: PFSYNC_ACT_INS: "
					    "invalid value\n");
				pfsyncstats.pfsyncs_badstate++;
				continue;
			}

d336 3
a338 14
		for (i = 0, sp = (struct pfsync_state *)(mp->m_data + offp);
		    i < count; i++, sp++) {
			/* check for invalid values */
			if (sp->timeout >= PFTM_MAX ||
			    sp->src.state > PF_TCPS_PROXY_DST ||
			    sp->dst.state > PF_TCPS_PROXY_DST) {
				if (pf_status.debug >= PF_DEBUG_MISC)
					printf("pfsync_insert: PFSYNC_ACT_UPD: "
					    "invalid value\n");
				pfsyncstats.pfsyncs_badstate++;
				continue;
			}

			bcopy(sp->id, &key.id, sizeof(key.id));
a347 45
			sfail = 0;
			if (st->proto == IPPROTO_TCP) {
				/*
				 * The state should never go backwards except
				 * for syn-proxy states.  Neither should the
				 * sequence window slide backwards.
				 */
				if (st->src.state > sp->src.state &&
				    (st->src.state < PF_TCPS_PROXY_SRC ||
				    sp->src.state >= PF_TCPS_PROXY_SRC))
					sfail = 1;
				else if (st->dst.state > sp->dst.state)
					sfail = 2;
				else if (SEQ_GT(st->src.seqlo,
				    ntohl(sp->src.seqlo)))
					sfail = 3;
				else if (st->dst.state >= TCPS_SYN_SENT &&
				    SEQ_GT(st->dst.seqlo, ntohl(sp->dst.seqlo)))
					sfail = 4;
			} else {
				/*
				 * Non-TCP protocol state machine always go
				 * forwards
				 */
				if (st->src.state > sp->src.state)
					sfail = 5;
				else if ( st->dst.state > sp->dst.state)
					sfail = 6;
			}
			if (sfail) {
				if (pf_status.debug >= PF_DEBUG_MISC)
					printf("pfsync: ignoring stale update "
					    "(%d) id: %016llx "
					    "creatorid: %08x\n", sfail,
					    betoh64(st->id),
					    ntohl(st->creatorid));
				pfsyncstats.pfsyncs_badstate++;

				/* we have a better state, send it out */
				if (sc->sc_mbuf != NULL && !stale)
					pfsync_sendout(sc);
				stale++;
				pfsync_pack_state(PFSYNC_ACT_UPD, st, 0);
				continue;
			}
d352 1
a353 2
		if (stale && sc->sc_mbuf != NULL)
			pfsync_sendout(sc);
d368 3
a370 3
		for (i = 0, sp = (struct pfsync_state *)(mp->m_data + offp);
		    i < count; i++, sp++) {
			bcopy(sp->id, &key.id, sizeof(key.id));
d378 5
a384 1
			pf_purge_expired_state(st);
d386 1
d399 3
a401 15
		for (i = 0, up = (struct pfsync_state_upd *)(mp->m_data + offp);
		    i < count; i++, up++) {
			/* check for invalid values */
			if (up->timeout >= PFTM_MAX ||
			    up->src.state > PF_TCPS_PROXY_DST ||
			    up->dst.state > PF_TCPS_PROXY_DST) {
				if (pf_status.debug >= PF_DEBUG_MISC)
					printf("pfsync_insert: "
					    "PFSYNC_ACT_UPD_C: "
					    "invalid value\n");
				pfsyncstats.pfsyncs_badstate++;
				continue;
			}

			bcopy(up->id, &key.id, sizeof(key.id));
d407 1
a407 5
				error = pfsync_request_update(up, &src);
				if (error == ENOMEM) {
					splx(s);
					goto done;
				}
a411 48
			sfail = 0;
			if (st->proto == IPPROTO_TCP) {
				/*
				 * The state should never go backwards except
				 * for syn-proxy states.  Neither should the
				 * sequence window slide backwards.
				 */
				if (st->src.state > up->src.state &&
				    (st->src.state < PF_TCPS_PROXY_SRC ||
				    up->src.state >= PF_TCPS_PROXY_SRC))
					sfail = 1;
				else if (st->dst.state > up->dst.state)
					sfail = 2;
				else if (SEQ_GT(st->src.seqlo,
				    ntohl(up->src.seqlo)))
					sfail = 3;
				else if (st->dst.state >= TCPS_SYN_SENT &&
				    SEQ_GT(st->dst.seqlo, ntohl(up->dst.seqlo)))
					sfail = 4;
			} else {
				/*
				 * Non-TCP protocol state machine always go
				 * forwards
				 */
				if (st->src.state > up->src.state)
					sfail = 5;
				else if (st->dst.state > up->dst.state)
					sfail = 6;
			}
			if (sfail) {
				if (pf_status.debug >= PF_DEBUG_MISC)
					printf("pfsync: ignoring stale update "
					    "(%d) id: %016llx "
					    "creatorid: %08x\n", sfail,
					    betoh64(st->id),
					    ntohl(st->creatorid));
				pfsyncstats.pfsyncs_badstate++;

				/* we have a better state, send it out */
				if ((!stale || update_requested) &&
				    sc->sc_mbuf != NULL) {
					pfsync_sendout(sc);
					update_requested = 0;
				}
				stale++;
				pfsync_pack_state(PFSYNC_ACT_UPD, st, 0);
				continue;
			}
d417 1
a417 1
		if ((update_requested || stale) && sc->sc_mbuf)
d430 3
a432 3
		for (i = 0, dp = (struct pfsync_state_del *)(mp->m_data + offp);
		    i < count; i++, dp++) {
			bcopy(dp->id, &key.id, sizeof(key.id));
d440 5
a446 1
			pf_purge_expired_state(st);
d448 1
d463 2
d467 3
a469 4
		for (i = 0,
		    rup = (struct pfsync_state_upd_req *)(mp->m_data + offp);
		    i < count; i++, rup++) {
			bcopy(rup->id, &key.id, sizeof(key.id));
d472 4
a475 14
			if (key.id == 0 && key.creatorid == 0) {
				sc->sc_ureq_received = mono_time.tv_sec;
				if (pf_status.debug >= PF_DEBUG_MISC)
					printf("pfsync: received "
					    "bulk update request\n");
				pfsync_send_bus(sc, PFSYNC_BUS_START);
				timeout_add(&sc->sc_bulk_tmo, 1 * hz);
			} else {
				st = pf_find_state_byid(&key);
				if (st == NULL) {
					pfsyncstats.pfsyncs_badstate++;
					continue;
				}
				pfsync_pack_state(PFSYNC_ACT_UPD, st, 0);
d477 1
a482 43
	case PFSYNC_ACT_BUS:
		/* If we're not waiting for a bulk update, who cares. */
		if (sc->sc_ureq_sent == 0)
			break;

		if ((mp = m_pulldown(m, iplen + sizeof(*ph),
		    sizeof(*bus), &offp)) == NULL) {
			pfsyncstats.pfsyncs_badlen++;
			return;
		}
		bus = (struct pfsync_state_bus *)(mp->m_data + offp);
		switch (bus->status) {
		case PFSYNC_BUS_START:
			timeout_add(&sc->sc_bulkfail_tmo,
			    pf_pool_limits[PF_LIMIT_STATES].limit /
			    (PFSYNC_BULKPACKETS * sc->sc_maxcount));
			if (pf_status.debug >= PF_DEBUG_MISC)
				printf("pfsync: received bulk "
				    "update start\n");
			break;
		case PFSYNC_BUS_END:
			if (mono_time.tv_sec - ntohl(bus->endtime) >=
			    sc->sc_ureq_sent) {
				/* that's it, we're happy */
				sc->sc_ureq_sent = 0;
				sc->sc_bulk_tries = 0;
				timeout_del(&sc->sc_bulkfail_tmo);
#if NCARP > 0
				if (!pfsync_sync_ok)
					carp_suppress_preempt--;
#endif
				pfsync_sync_ok = 1;
				if (pf_status.debug >= PF_DEBUG_MISC)
					printf("pfsync: received valid "
					    "bulk update end\n");
			} else {
				if (pf_status.debug >= PF_DEBUG_MISC)
					printf("pfsync: received invalid "
					    "bulk update end: bad timestamp\n");
			}
			break;
		}
		break;
a559 4
			if (imo->imo_num_memberships > 0) {
				in_delmulti(imo->imo_membership[--imo->imo_num_memberships]);
				imo->imo_multicast_ifp = NULL;
			}
a594 17

			/* Request a full state table update. */
			sc->sc_ureq_sent = mono_time.tv_sec;
#if NCARP > 0
			if (pfsync_sync_ok)
				carp_suppress_preempt++;
#endif
			pfsync_sync_ok = 0;
			if (pf_status.debug >= PF_DEBUG_MISC)
				printf("pfsync: requesting bulk update\n");
			timeout_add(&sc->sc_bulkfail_tmo, 5 * hz);
			error = pfsync_request_update(NULL, NULL);
			if (error == ENOMEM) {
				splx(s);
				return(ENOMEM);
			}
			pfsync_sendout(sc);
d628 1
a639 4
	case PFSYNC_ACT_CLR:
		len = sizeof(struct pfsync_header) +
		    sizeof(struct pfsync_state_clr);
		break;
d648 4
a652 4
		len = (sc->sc_maxcount * sizeof(struct pfsync_state_upd_req)) +
		    sizeof(struct pfsync_header);
		break;
	case PFSYNC_ACT_BUS:
d654 1
a654 1
		    sizeof(struct pfsync_state_bus);
d745 1
a745 2
					if (!memcmp(usp->id, &st->id,
					    PFSYNC_ID_LEN) &&
a758 4
	st->pfsync_time = mono_time.tv_sec;
	TAILQ_REMOVE(&state_updates, st, u.s.entry_updates);
	TAILQ_INSERT_TAIL(&state_updates, st, u.s.entry_updates);

d768 1
a768 1
		bcopy(&st->id, sp->id, sizeof(sp->id));
d847 1
a847 1
				bcopy(&st->id, up->id, sizeof(up->id));
d862 1
a862 1
			bcopy(&st->id, dp->id, sizeof(dp->id));
d884 1
a884 1
	int ret = 0;
d888 2
a889 1
		    (void *)&sc->sc_statep.s)) == NULL)
d891 1
d897 3
a899 2
			if ((sc->sc_mbuf = pfsync_get_mbuf(sc, PFSYNC_ACT_UREQ,
			    (void *)&sc->sc_statep.s)) == NULL)
d901 1
d906 1
a906 2
	if (src != NULL)
		sc->sc_sendaddr = *src;
d911 2
a912 4
	if (up != NULL) {
		bcopy(up->id, rup->id, sizeof(rup->id));
		rup->creatorid = up->creatorid;
	}
d921 1
a921 1
pfsync_clear_states(u_int32_t creatorid, char *ifname)
d929 1
a929 1
	if (sc->sc_mbuf != NULL)
d931 1
a939 2
	if (ifname != NULL)
		strlcpy(cp->ifname, ifname, IFNAMSIZ);
a956 99
/* This must be called in splnet() */
void
pfsync_send_bus(struct pfsync_softc *sc, u_int8_t status)
{
	struct pfsync_state_bus *bus;

	if (sc->sc_mbuf != NULL)
		pfsync_sendout(sc);

	if (pfsync_sync_ok &&
	    (sc->sc_mbuf = pfsync_get_mbuf(sc, PFSYNC_ACT_BUS,
	    (void *)&sc->sc_statep.b)) != NULL) {
		sc->sc_mbuf->m_pkthdr.len = sc->sc_mbuf->m_len += sizeof(*bus);
		bus = sc->sc_statep.b;
		bus->creatorid = pf_status.hostid;
		bus->status = status;
		bus->endtime = htonl(mono_time.tv_sec - sc->sc_ureq_received);
		pfsync_sendout(sc);
	}
}

void
pfsync_bulk_update(void *v)
{
	struct pfsync_softc *sc = v;
	int s, i = 0;
	struct pf_state *state;

	s = splnet();
	if (sc->sc_mbuf != NULL)
		pfsync_sendout(sc);

	/*
	 * Grab at most PFSYNC_BULKPACKETS worth of states which have not
	 * been sent since the latest request was made.
	 */
	while ((state = TAILQ_FIRST(&state_updates)) != NULL &&
	    ++i < (sc->sc_maxcount * PFSYNC_BULKPACKETS)) {
		if (state->pfsync_time > sc->sc_ureq_received) {
			/* we're done */
			pfsync_send_bus(sc, PFSYNC_BUS_END);
			sc->sc_ureq_received = 0;
			timeout_del(&sc->sc_bulk_tmo);
			if (pf_status.debug >= PF_DEBUG_MISC)
				printf("pfsync: bulk update complete\n");
			break;
		} else {
			/* send an update and move to end of list */
			if (!state->sync_flags)
				pfsync_pack_state(PFSYNC_ACT_UPD, state, 0);
			state->pfsync_time = mono_time.tv_sec;
			TAILQ_REMOVE(&state_updates, state, u.s.entry_updates);
			TAILQ_INSERT_TAIL(&state_updates, state,
			    u.s.entry_updates);

			/* look again for more in a bit */
			timeout_add(&sc->sc_bulk_tmo, 1);
		}
	}
	if (sc->sc_mbuf != NULL)
		pfsync_sendout(sc);
	splx(s);
}

void
pfsync_bulkfail(void *v)
{
	struct pfsync_softc *sc = v;
	int s, error;

	if (sc->sc_bulk_tries++ < PFSYNC_MAX_BULKTRIES) {
		/* Try again in a bit */
		timeout_add(&sc->sc_bulkfail_tmo, 5 * hz);
		s = splnet();
		error = pfsync_request_update(NULL, NULL);
		if (error == ENOMEM) {
			if (pf_status.debug >= PF_DEBUG_MISC)
				printf("pfsync: cannot allocate mbufs for "
				    "bulk update\n");
		} else
			pfsync_sendout(sc);
		splx(s);
	} else {
		/* Pretend like the transfer was ok */
		sc->sc_ureq_sent = 0;
		sc->sc_bulk_tries = 0;
#if NCARP > 0
		if (!pfsync_sync_ok)
			carp_suppress_preempt--;
#endif
		pfsync_sync_ok = 1;
		if (pf_status.debug >= PF_DEBUG_MISC)
			printf("pfsync: failed to receive "
			    "bulk update status\n");
		timeout_del(&sc->sc_bulkfail_tmo);
	}
}

/* This must be called in splnet() */
d962 1
a962 1
	struct mbuf *m;
a964 4

	if (sc->sc_mbuf == NULL)
		return (0);
	m = sc->sc_mbuf;
d972 1
@


1.3
log
@replace struct assignment w/ bcopy w/ help and testing of millert@@; henning@@ ok; fixes unaligned trap on alpha from pr3037
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.2 2002/12/03 15:52:34 mickey Exp $	*/
d273 3
a275 3
	bcopy(&st->lan, &sp->lan, sizeof(sp->lan)); HTONS(sp->lan.port);
	bcopy(&st->gwy, &sp->gwy, sizeof(sp->gwy)); HTONS(sp->gwy.port);
	bcopy(&st->ext, &sp->ext, sizeof(sp->ext)); HTONS(sp->ext.port);
@


1.2
log
@no need to mh_align (while it's wrong), cleaner mtu setting; dhartmei@@ ok
@
text
@d1 1
a1 1
/*	$OpenBSD: if_pfsync.c,v 1.1 2002/11/29 18:25:22 mickey Exp $	*/
d273 3
a275 3
	sp->lan = st->lan; HTONS(sp->lan.port);
	sp->gwy = st->gwy; HTONS(sp->gwy.port);
	sp->ext = st->ext; HTONS(sp->ext.port);
d280 1
a280 1
	sp->rt_addr = st->rt_addr;
@


1.1
log
@expose state table changes
@
text
@d1 1
a1 1
/*	$OpenBSD$	*/
a59 2
#define PFSYNCMTU	\
    (sizeof(struct pfsync_header) + sizeof(struct pf_state) * 4)
d73 1
a76 1
void	pfsyncrtrequest(int, struct rtentry *, struct sockaddr *);
a95 1
	ifp->if_mtu = PFSYNCMTU;
d102 2
a143 8
void
pfsyncrtrequest(int cmd, struct rtentry *rt, struct sockaddr *sa)
{
	if (rt)
		rt->rt_rmx.rmx_mtu = PFSYNCMTU;
}

/* ARGSUSED */
d169 1
a169 4
		sc->sc_count = (ifr->ifr_mtu - sizeof(struct pfsync_header)) /
		    sizeof(struct pf_state);
		ifp->if_mtu = sizeof(struct pfsync_header) +
		    sc->sc_count * sizeof(struct pf_state);
d179 11
a216 1
	MH_ALIGN(m, m->m_len);
@

